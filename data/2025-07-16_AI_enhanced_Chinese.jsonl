{"id": "2507.10577", "pdf": "https://arxiv.org/pdf/2507.10577", "abs": "https://arxiv.org/abs/2507.10577", "authors": ["Log\u00e9 C\u00e9cile", "Ghori Rehan"], "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "Misinformation poses a significant threat in today's digital world, often\nspreading rapidly through platforms like YouTube. This paper introduces a novel\napproach to combating misinformation by developing an AI-powered system that\nnot only fact-checks claims made in YouTube videos but also actively engages\nusers in the comment section and challenge misleading narratives. Our system\ncomprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented\nGeneration (RAG) approach - drawing on sources like Wikipedia, Google Search,\nGoogle FactCheck - to accurately assess their veracity and generates a nuanced\nand comprehensive report. Through rigorous prompt engineering, Trend Bender\nleverages this report along with a curated corpus of relevant articles to\ngenerate insightful and persuasive comments designed to stimulate a productive\ndebate. With a carefully set up self-evaluation loop, this agent is able to\niteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established\nbenchmark datasets and a real-world deployment on YouTube, showcasing its\npotential to engage users and potentially influence perspectives. Our findings\nhighlight the high accuracy of our fact-checking agent, and confirm the\npotential of AI-driven interventions in combating misinformation and fostering\na more informed online space.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdAI\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e8b\u5b9e\u6838\u67e5\u548c\u8bc4\u8bba\u4e92\u52a8\u6765\u5bf9\u6297YouTube\u4e0a\u7684\u865a\u5047\u4fe1\u606f\u3002", "motivation": "\u6570\u5b57\u4e16\u754c\u4e2d\u7684\u865a\u5047\u4fe1\u606f\u5feb\u901f\u4f20\u64ad\uff0c\u5bf9\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u6784\u6210\u5a01\u80c1\uff0c\u9700\u8981\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e24\u4e2a\u4ee3\u7406\uff1aTruth Sleuth\uff08\u5229\u7528RAG\u65b9\u6cd5\u6838\u67e5\u89c6\u9891\u58f0\u79f0\uff09\u548cTrend Bender\uff08\u751f\u6210\u8bc4\u8bba\u4ee5\u5f15\u5bfc\u8ba8\u8bba\uff09\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u7cfb\u7edf\u5728\u4e8b\u5b9e\u6838\u67e5\u548c\u7528\u6237\u4e92\u52a8\u65b9\u9762\u9ad8\u6548\uff0c\u53ef\u80fd\u6539\u5584\u5728\u7ebf\u4fe1\u606f\u73af\u5883\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u5e72\u9884\u63aa\u65bd\u5728\u5bf9\u6297\u865a\u5047\u4fe1\u606f\u548c\u4fc3\u8fdb\u77e5\u60c5\u8ba8\u8bba\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "keywords": "\u865a\u5047\u4fe1\u606f, YouTube, AI, \u4e8b\u5b9e\u6838\u67e5, \u8bc4\u8bba\u4e92\u52a8"}}
{"id": "2507.10580", "pdf": "https://arxiv.org/pdf/2507.10580", "abs": "https://arxiv.org/abs/2507.10580", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "comment": null, "summary": "Mental health plays a crucial role in the overall well-being of an\nindividual. In recent years, digital platforms have been increasingly used to\nexpand mental health and emotional support. However, there are persistent\nchallenges related to limited user accessibility, internet connectivity, and\ndata privacy, which highlight the need for an offline, smartphone-based\nsolution. To address these challenges, we propose EmoSApp (Emotional Support\nApp): an entirely offline, smartphone-based conversational app designed for\nmental health and emotional support. The system leverages Large Language Models\n(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and\nExecutorch for resource-constrained devices, allowing all inferences to occur\non the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned\nthe LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of\n14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we\ndemonstrate that EmoSApp has the ability to respond coherently, empathetically,\nmaintain interactive dialogue, and provide relevant suggestions to user's\nmental health problems. Additionally, quantitative evaluations on nine standard\ncommonsense and reasoning benchmarks demonstrate the efficacy of our\nfine-tuned, quantized model in low-resource settings. By prioritizing on-device\ndeployment and specialized domain adaptation, EmoSApp serves as a blueprint for\nfuture innovations in portable, secure, and highly tailored AI-driven mental\nhealth solutions.", "AI": {"tldr": "EmoSApp \u662f\u4e00\u6b3e\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u79bb\u7ebf\u5bf9\u8bdd\u5e94\u7528\uff0c\u65e8\u5728\u63d0\u4f9b\u5fc3\u7406\u5065\u5eb7\u652f\u6301\uff0c\u5229\u7528\u91cf\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u672c\u5730\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u89e3\u51b3\u4e86\u7528\u6237\u53ef\u8bbf\u95ee\u6027\u3001\u7f51\u7edc\u8fde\u63a5\u548c\u6570\u636e\u9690\u79c1\u95ee\u9898\u3002", "motivation": "\u6570\u5b57\u5e73\u53f0\u5728\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u7528\u6237\u53ef\u8bbf\u95ee\u6027\u3001\u7f51\u7edc\u8fde\u63a5\u548c\u6570\u636e\u9690\u79c1\u7b49\u6311\u6218\uff0c\u4e9f\u9700\u4e00\u79cd\u79bb\u7ebf\u7684\u667a\u80fd\u624b\u673a\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86 EmoSApp\uff0c\u4f7f\u7528\u7ecf\u8fc7\u91cf\u5316\u548c\u5fae\u8c03\u7684 LLaMA-3.2-1B-Instruct \u6a21\u578b\uff0c\u5e76\u90e8\u7f72\u4e8e\u667a\u80fd\u624b\u673a\u672c\u5730\uff0c\u65e0\u9700\u7f51\u7edc\u8fde\u63a5\u3002", "result": "\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\uff0cEmoSApp \u80fd\u591f\u63d0\u4f9b\u8fde\u8d2f\u3001\u540c\u7406\u7684\u5bf9\u8bdd\uff0c\u5e76\u4e3a\u7528\u6237\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u63d0\u4f9b\u76f8\u5173\u5efa\u8bae\uff0c\u540c\u65f6\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "EmoSApp \u4e3a\u4fbf\u643a\u3001\u5b89\u5168\u548c\u5b9a\u5236\u5316\u7684 AI \u5fc3\u7406\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u6a21\u677f\uff0c\u63a8\u52a8\u4e86\u672a\u6765\u521b\u65b0\u3002", "keywords": ""}}
{"id": "2507.10582", "pdf": "https://arxiv.org/pdf/2507.10582", "abs": "https://arxiv.org/abs/2507.10582", "authors": ["Anders Ledberg", "Anna Thal\u00e9n"], "title": "Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis", "categories": ["cs.CL", "stat.ME"], "comment": null, "summary": "Unstructured text from legal, medical, and administrative sources offers a\nrich but underutilized resource for research in public health and the social\nsciences. However, large-scale analysis is hampered by two key challenges: the\npresence of sensitive, personally identifiable information, and significant\nheterogeneity in structure and language. We present a modular toolchain that\nprepares such text data for embedding-based analysis, relying entirely on\nopen-weight models that run on local hardware, requiring only a\nworkstation-level GPU and supporting privacy-sensitive research.\n  The toolchain employs large language model (LLM) prompting to standardize,\nsummarize, and, when needed, translate texts to English for greater\ncomparability. Anonymization is achieved via LLM-based redaction, supplemented\nwith named entity recognition and rule-based methods to minimize the risk of\ndisclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court\ndecisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.\nEach document is processed into an anonymized, standardized summary and\ntransformed into a document-level embedding. Validation, including manual\nreview, automated scanning, and predictive evaluation shows the toolchain\neffectively removes identifying information while retaining semantic content.\nAs an illustrative application, we train a predictive model using embedding\nvectors derived from a small set of manually labeled summaries, demonstrating\nthe toolchain's capacity for semi-automated content analysis at scale.\n  By enabling structured, privacy-conscious analysis of sensitive documents,\nour toolchain opens new possibilities for large-scale research in domains where\ntextual data was previously inaccessible due to privacy and heterogeneity\nconstraints.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u5de5\u5177\u94fe\uff0c\u7528\u4e8e\u5904\u7406\u975e\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\uff0c\u901a\u8fc7\u5f00\u6e90\u6a21\u578b\u5b9e\u73b0\u6807\u51c6\u5316\u3001\u533f\u540d\u5316\u548c\u5d4c\u5165\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u9690\u79c1\u548c\u8bed\u8a00\u591a\u6837\u6027\u95ee\u9898\u3002", "motivation": "\u6cd5\u5f8b\u3001\u533b\u7597\u548c\u884c\u653f\u9886\u57df\u7684\u5927\u91cf\u975e\u7ed3\u6784\u5316\u6587\u672c\u56e0\u9690\u79c1\u548c\u8bed\u8a00\u591a\u6837\u6027\u95ee\u9898\u96be\u4ee5\u88ab\u5927\u89c4\u6a21\u5206\u6790\uff0c\u7f3a\u4e4f\u6709\u6548\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u6587\u672c\u6807\u51c6\u5316\u3001\u6458\u8981\u3001\u7ffb\u8bd1\u548c\u533f\u540d\u5316\uff0c\u7ed3\u5408\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u89c4\u5219\u65b9\u6cd5\u786e\u4fdd\u9690\u79c1\u3002", "result": "\u5728\u745e\u5178\u6cd5\u9662\u5224\u51b3\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5de5\u5177\u94fe\u80fd\u6709\u6548\u533f\u540d\u5316\u5e76\u4fdd\u7559\u8bed\u4e49\uff0c\u652f\u6301\u534a\u81ea\u52a8\u5316\u5185\u5bb9\u5206\u6790\u3002", "conclusion": "\u8be5\u5de5\u5177\u94fe\u4e3a\u654f\u611f\u6587\u672c\u7684\u5927\u89c4\u6a21\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\uff0c\u6253\u7834\u9690\u79c1\u548c\u5f02\u6784\u6027\u9650\u5236\u3002", "keywords": "\u975e\u7ed3\u6784\u5316\u6587\u672c, \u9690\u79c1\u4fdd\u62a4, \u5927\u8bed\u8a00\u6a21\u578b, \u5d4c\u5165\u5206\u6790, \u5185\u5bb9\u6458\u8981"}}
{"id": "2507.10585", "pdf": "https://arxiv.org/pdf/2507.10585", "abs": "https://arxiv.org/abs/2507.10585", "authors": ["Isar Nejadgholi", "Mona Omidyeganeh", "Marc-Antoine Drouin", "Jonathan Boisvert"], "title": "A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations", "categories": ["cs.CL", "cs.AI"], "comment": "Presented at the Workshop of Technical AI Governance, 5 pages 2\n  figures", "summary": "Effective AI governance requires structured approaches for stakeholders to\naccess and verify AI system behavior. With the rise of large language models,\nNatural Language Explanations (NLEs) are now key to articulating model\nbehavior, which necessitates a focused examination of their characteristics and\ngovernance implications. We draw on Explainable AI (XAI) literature to create\nan updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:\n(1) Context, including task, data, audience, and goals; (2) Generation and\nPresentation, covering generation methods, inputs, interactivity, outputs, and\nforms; and (3) Evaluation, focusing on content, presentation, and user-centered\nproperties, as well as the setting of the evaluation. This taxonomy provides a\nframework for researchers, auditors, and policymakers to characterize, design,\nand enhance NLEs for transparent AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u65b0\u7684XAI\u5206\u7c7b\u6cd5\uff0c\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff08NLEs\uff09\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u3001\u5ba1\u8ba1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u66f4\u597d\u5730\u8bbe\u8ba1\u548c\u8bc4\u4f30\u900f\u660eAI\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff08NLEs\uff09\u6210\u4e3a\u63cf\u8ff0\u6a21\u578b\u884c\u4e3a\u7684\u5173\u952e\u5de5\u5177\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u6765\u652f\u6301\u5176\u6cbb\u7406\u548c\u900f\u660e\u5ea6\u3002", "method": "\u57fa\u4e8e\u53ef\u89e3\u91caAI\uff08XAI\uff09\u6587\u732e\uff0c\u63d0\u51fa\u4e00\u4e2a\u9488\u5bf9NLEs\u7684\u66f4\u65b0\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u4e0e\u5448\u73b0\u3001\u8bc4\u4f30\u4e09\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5206\u7c7b\u6cd5\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u5ba1\u8ba1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u5de5\u5177\uff0c\u4ee5\u8bbe\u8ba1\u548c\u4f18\u5316NLEs\u3002", "conclusion": "\u8be5\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u4fc3\u8fdb\u900f\u660eAI\u7cfb\u7edf\u7684\u5f00\u53d1\u548c\u6cbb\u7406\u3002", "keywords": "AI\u6cbb\u7406, \u53ef\u89e3\u91caAI, \u81ea\u7136\u8bed\u8a00\u89e3\u91ca, \u900f\u660e\u5ea6, \u5206\u7c7b\u6cd5"}}
{"id": "2507.10562", "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "AI": {"tldr": "SAMEP\u662f\u4e00\u79cd\u65b0\u7684\u534f\u8bae\uff0c\u652f\u6301AI\u4ee3\u7406\u4e4b\u95f4\u6301\u4e45\u3001\u5b89\u5168\u4e14\u53ef\u8bed\u4e49\u641c\u7d22\u7684\u8bb0\u5fc6\u5171\u4eab\uff0c\u89e3\u51b3\u4e86\u8de8\u4f1a\u8bdd\u548c\u591a\u4ee3\u7406\u534f\u4f5c\u4e2d\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7406\u67b6\u6784\u7684\u5185\u5b58\u9650\u5236\u963b\u788d\u4e86\u8de8\u4f1a\u8bdd\u548c\u591a\u4ee3\u7406\u7684\u9ad8\u6548\u534f\u4f5c\u4e0e\u77e5\u8bc6\u5171\u4eab\uff0c\u9700\u8981\u4e00\u79cd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86SAMEP\u534f\u8bae\uff0c\u5305\u62ec\u5206\u5e03\u5f0f\u8bb0\u5fc6\u5b58\u50a8\u5e93\u3001\u5411\u91cf\u8bed\u4e49\u641c\u7d22\u3001\u52a0\u5bc6\u8bbf\u95ee\u63a7\u5236\u548c\u6807\u51c6\u5316API\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cSAMEP\u51cf\u5c11\u4e8673%\u7684\u5197\u4f59\u8ba1\u7b97\uff0c\u63d0\u5347\u4e8689%\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u5e76\u5b8c\u5168\u7b26\u5408\u6cd5\u89c4\u8981\u6c42\u3002", "conclusion": "SAMEP\u4e3a\u6301\u4e45\u534f\u4f5c\u7684AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u540c\u65f6\u4fdd\u969c\u4e86\u5b89\u5168\u548c\u9690\u79c1\u3002", "keywords": "AI\u4ee3\u7406,\u8bb0\u5fc6\u5171\u4eab,SAMEP,\u591a\u4ee3\u7406\u534f\u4f5c,\u8bed\u4e49\u641c\u7d22"}}
{"id": "2507.10564", "pdf": "https://arxiv.org/pdf/2507.10564", "abs": "https://arxiv.org/abs/2507.10564", "authors": ["Sameera Bharadwaja H.", "Siddhrath Jandial", "Shashank S. Agashe", "Rajesh Kumar Reddy Moore", "Youngkwan Kim"], "title": "Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing", "categories": ["cs.LG", "cs.AI", "eess.SP", "stat.ML"], "comment": null, "summary": "We consider the problem of tool-to-tool matching (TTTM), also called, chamber\nmatching in the context of a semiconductor manufacturing equipment. Traditional\nTTTM approaches utilize static configuration data or depend on a golden\nreference which are difficult to obtain in a commercial manufacturing line.\nFurther, existing methods do not extend very well to a heterogeneous setting,\nwhere equipment are of different make-and-model, sourced from different\nequipment vendors. We propose novel TTTM analysis pipelines to overcome these\nissues. We hypothesize that a mismatched equipment would have higher variance\nand/or higher number of modes in the data. Our best univariate method achieves\na correlation coefficient >0.95 and >0.5 with the variance and number of modes,\nrespectively showing that the proposed methods are effective. Also, the best\nmultivariate method achieves a correlation coefficient >0.75 with the\ntop-performing univariate methods, showing its effectiveness. Finally, we\nanalyze the sensitivity of the multivariate algorithms to the algorithm\nhyper-parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5de5\u5177\u95f4\u5339\u914d\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u534a\u5bfc\u4f53\u5236\u9020\u8bbe\u5907\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u9759\u6001\u914d\u7f6e\u548c\u9ec4\u91d1\u53c2\u8003\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5f02\u6784\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u534a\u5bfc\u4f53\u5236\u9020\u8bbe\u5907\u4e2d\u5de5\u5177\u95f4\u5339\u914d\u7684\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u914d\u7f6e\u6216\u9ec4\u91d1\u53c2\u8003\uff0c\u4e14\u5728\u5f02\u6784\u73af\u5883\u4e2d\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u65b0\u578bTTTM\u5206\u6790\u6d41\u7a0b\uff0c\u901a\u8fc7\u5206\u6790\u6570\u636e\u65b9\u5dee\u548c\u6a21\u6001\u6570\u91cf\u5dee\u5f02\u6765\u8bc6\u522b\u4e0d\u5339\u914d\u8bbe\u5907\uff0c\u5305\u62ec\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u65b9\u6cd5\u3002", "result": "\u6700\u4f73\u5355\u53d8\u91cf\u65b9\u6cd5\u4e0e\u6570\u636e\u65b9\u5dee\u548c\u6a21\u6001\u6570\u91cf\u7684\u76f8\u5173\u7cfb\u6570\u5206\u522b\u8d85\u8fc70.95\u548c0.5\uff1b\u6700\u4f73\u591a\u53d8\u91cf\u65b9\u6cd5\u4e0e\u5355\u53d8\u91cf\u65b9\u6cd5\u7684\u76f8\u5173\u7cfb\u6570\u8d85\u8fc70.75\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u5de5\u5177\u95f4\u5339\u914d\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5355\u53d8\u91cf\u65b9\u6cd5\uff1b\u591a\u53d8\u91cf\u65b9\u6cd5\u5bf9\u8d85\u53c2\u6570\u654f\u611f\u3002", "keywords": "\u534a\u5bfc\u4f53\u5236\u9020\u3001\u5de5\u5177\u5339\u914d\u3001\u5f02\u6784\u73af\u5883\u3001\u6570\u636e\u65b9\u5dee\u3001\u6a21\u6001\u5206\u6790"}}
{"id": "2507.10586", "pdf": "https://arxiv.org/pdf/2507.10586", "abs": "https://arxiv.org/abs/2507.10586", "authors": ["Kaushik Dwivedi", "Padmanabh Patanjali Mishra"], "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable fluency across a\nrange of natural language tasks, yet remain vulnerable to hallucinations -\nfactual inaccuracies that undermine trust in real world deployment. We present\nAutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that\ntackles hallucination in large language models through lightweight LoRA-based\nadapters and KL-regularized training. Our pipeline integrates automated prompt\nrewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in\nretrieved evidence. A hallucination detection module, using both\nclassifier-based and self-evaluation techniques, assigns confidence scores to\ngenerated outputs, triggering an optional feedback correction loop. This loop\nenforces factual alignment via contrastive KL loss and adapter fine tuning. We\ndemonstrate that AutoRAG-LoRA significantly reduces the factual drift while\npreserving the efficiency and modularity of the model.", "AI": {"tldr": "AutoRAG-LoRA\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7LoRA\u9002\u914d\u5668\u548cKL\u6b63\u5219\u5316\u8bad\u7ec3\uff0c\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u6d41\u7545\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5f71\u54cd\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u4fe1\u4efb\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u63d0\u793a\u91cd\u5199\u3001\u6df7\u5408\u68c0\u7d22\u548c\u4f4e\u79e9\u9002\u914d\u5668\u8c03\u4f18\uff0c\u5e76\u901a\u8fc7\u68c0\u6d4b\u6a21\u5757\u548c\u53cd\u9988\u5faa\u73af\u6821\u6b63\u4e8b\u5b9e\u3002", "result": "AutoRAG-LoRA\u663e\u8457\u51cf\u5c11\u4e8b\u5b9e\u6f02\u79fb\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u6548\u7387\u548c\u6a21\u5757\u5316\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u5e7b\u89c9\u95ee\u9898,\u68c0\u7d22\u589e\u5f3a\u751f\u6210,LoRA\u9002\u914d\u5668,KL\u6b63\u5219\u5316"}}
{"id": "2507.10566", "pdf": "https://arxiv.org/pdf/2507.10566", "abs": "https://arxiv.org/abs/2507.10566", "authors": ["Hung Ming Liu"], "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "comment": "30 pages, 4 figures", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u201cAI\u6bcd\u8bed\u201d\u6846\u67b6\u8bc1\u660e\uff0c\u5f53\u4ee3\u7406\u5177\u5907\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u65f6\uff0c\u65e0\u9700\u5916\u90e8\u8bf1\u5bfc\u504f\u7f6e\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u7684\u7b26\u53f7\u901a\u4fe1\uff0c\u89e3\u51b3\u4e86MARL\u4e2d\u7684\u201c\u8054\u5408\u63a2\u7d22\u56f0\u5883\u201d\u3002AIM\u5c55\u793a\u4e86\u66f4\u5f3a\u7684\u901a\u7528\u6027\u548c\u6548\u7387\uff0c\u5e76\u4e3a\u7b26\u53f7\u5b66\u4e0e\u8054\u7ed3\u4e3b\u4e49\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u4eba\u5de5\u8bf1\u5bfc\u504f\u7f6e\u89e3\u51b3MARL\u4e2d\u7684\u201c\u901a\u4fe1\u771f\u7a7a\u5747\u8861\u201d\uff0c\u4f46\u7814\u7a76\u8d28\u7591\u8fd9\u662f\u5426\u8fc7\u5ea6\u5de5\u7a0b\u5316\uff0c\u5e76\u63d0\u51fa\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u7684\u81ea\u7136\u8bed\u4e49\u538b\u7f29\u548c\u6536\u655b\u53ef\u80fd\u66f4\u6709\u6548\u3002", "method": "\u7814\u7a76\u91c7\u7528\u57fa\u4e8eVQ-VAE\u7684\u201cAI\u6bcd\u8bed\u201d\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4ee3\u7406\u5728\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u4e2d\u7684\u81ea\u53d1\u8bed\u4e49\u538b\u7f29\u548c\u7eb3\u4ec0\u5747\u8861\u9a71\u52a8\u7684\u8bed\u4e49\u6536\u655b\u3002", "result": "AIM\u6846\u67b6\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u504f\u7f6e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u7b26\u53f7\u901a\u4fe1\uff0c\u5de5\u5177\u5305\u5206\u6790\u63ed\u793a\u4e86\u7b26\u53f7\u4f7f\u7528\u7684\u5e42\u5f8b\u5206\u5e03\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u9879\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u80fd\u81ea\u7136\u5b9e\u73b0\u8bed\u4e49\u901a\u4fe1\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86HQ-VAE\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u548cRL\u4f4e\u7ea7\u9884\u8bad\u7ec3\u7684\u63a2\u7d22\u65b9\u5411\u3002", "keywords": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60, \u6d8c\u73b0\u901a\u4fe1, VQ-VAE, \u5185\u751f\u7b26\u53f7\u7cfb\u7edf, \u8bed\u4e49\u538b\u7f29."}}
{"id": "2507.10574", "pdf": "https://arxiv.org/pdf/2507.10574", "abs": "https://arxiv.org/abs/2507.10574", "authors": ["Jae Wan Shim"], "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "13 pages, 2 figures", "summary": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel\nmeasure derived from the information theory. In comparison to the standard\ncross entropy loss function, the proposed one has an additional term that\ndepends on the predicted probability of the true class. This feature serves to\nenhance the optimization process in classification tasks involving one-hot\nencoded class labels. The proposed one has been evaluated on a ResNet-based\nmodel using the CIFAR-100 dataset. Preliminary results show that the proposed\none consistently outperforms the standard cross entropy loss function in terms\nof classification accuracy. Moreover, the proposed one maintains simplicity,\nachieving practically the same efficiency to the traditional cross entropy\nloss. These findings suggest that our approach could broaden the scope for\nfuture research into loss function design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u589e\u52a0\u4e00\u4e2a\u4f9d\u8d56\u4e8e\u771f\u5b9e\u7c7b\u9884\u6d4b\u6982\u7387\u7684\u9879\uff0c\u63d0\u5347\u5206\u7c7b\u4efb\u52a1\u7684\u4f18\u5316\u6548\u679c\uff0c\u5e76\u5728CIFAR-100\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u7684\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u5728\u5904\u7406\u72ec\u70ed\u7f16\u7801\u5206\u7c7b\u4efb\u52a1\u65f6\u53ef\u80fd\u5b58\u5728\u4f18\u5316\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684\u635f\u5931\u51fd\u6570\u4ee5\u63d0\u5347\u5206\u7c7b\u6548\u679c\u3002", "method": "\u63d0\u51fa\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u589e\u52a0\u4e00\u4e2a\u4e0e\u771f\u5b9e\u7c7b\u9884\u6d4b\u6982\u7387\u76f8\u5173\u7684\u9879\uff0c\u5e76\u57fa\u4e8eResNet\u6a21\u578b\u5728CIFAR-100\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u635f\u5931\u51fd\u6570\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u4e14\u4fdd\u6301\u4e86\u76f8\u4f3c\u7684\u6548\u7387\u3002", "conclusion": "\u8be5\u635f\u5931\u51fd\u6570\u4e3a\u672a\u6765\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u5c55\u793a\u4e86\u6f5c\u5728\u7684\u5e94\u7528\u524d\u666f\u3002", "keywords": "\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570,\u4fe1\u606f\u8bba,\u5206\u7c7b\u4efb\u52a1,ResNet,CIFAR-100"}}
{"id": "2507.10587", "pdf": "https://arxiv.org/pdf/2507.10587", "abs": "https://arxiv.org/abs/2507.10587", "authors": ["Dennis Ulmer", "Alexandra Lorson", "Ivan Titov", "Christian Hardmeier"], "title": "Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Human users increasingly rely on natural language interactions with large\nlanguage models (LLMs) in order to receive help on a large variety of tasks and\nproblems. However, the trustworthiness and perceived legitimacy of LLMs is\nundermined by the fact that their output is frequently stated in very confident\nterms, even when its accuracy is questionable. Therefore, there is a need to\nsignal the confidence of the language model to a user in order to reap the\nbenefits of human-machine collaboration and mitigate potential harms.\nVerbalized uncertainty is the expression of confidence with linguistic means,\nan approach that integrates perfectly into language-based interfaces.\nNevertheless, most recent research in natural language processing (NLP)\noverlooks the nuances surrounding human uncertainty communication and the data\nbiases that influence machine uncertainty communication. We argue for\nanthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty\ncommunication requires a degree of linguistic authenticity and personalization\nto the user, which could be achieved by emulating human communication. We\npresent a thorough overview over the research in human uncertainty\ncommunication, survey ongoing research, and perform additional analyses to\ndemonstrate so-far overlooked biases in verbalized uncertainty. We conclude by\npointing out unique factors in human-machine communication of uncertainty and\ndeconstruct anthropomimetic uncertainty into future research directions for\nNLP.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u66f4\u81ea\u7136\u5730\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\uff0c\u5e76\u63d0\u51fa\u4e86\u62df\u4eba\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7531\u4e8e\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u5e38\u8fc7\u4e8e\u81ea\u4fe1\uff0c\u7f3a\u4e4f\u51c6\u786e\u6027\u53cd\u9988\uff0c\u5f71\u54cd\u4e86\u7528\u6237\u4fe1\u4efb\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u8bed\u8a00\u8868\u8fbe\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u8bba\u6587\u7efc\u8ff0\u4e86\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u7684\u7814\u7a76\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6570\u636e\u504f\u5dee\uff0c\u5e76\u63d0\u51fa\u4e86\u62df\u4eba\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u6982\u5ff5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u7814\u7a76\u5ffd\u89c6\u4e86\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\u7684\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86\u62df\u4eba\u5316\u8868\u8fbe\u672a\u6765\u7684\u7814\u7a76\u8def\u5f84\u3002", "conclusion": "\u62df\u4eba\u5316\u4e0d\u786e\u5b9a\u6027\u662f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7528\u6237\u4fe1\u4efb\u7684\u5173\u952e\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u5e94\u7528\u3002", "keywords": "\u8bed\u8a00\u6a21\u578b,\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe,\u62df\u4eba\u5316,\u7528\u6237\u4fe1\u4efb,\u81ea\u7136\u8bed\u8a00\u5904\u7406"}}
{"id": "2507.10571", "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u5757\u5316Agentic AI\u89c6\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u6a21\u6001\u4ee3\u7406\u3001\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u5757\uff0c\u89e3\u51b3\u4e86\u96f6\u6837\u672c\u73af\u5883\u4e0b\u7684\u4fe1\u4efb\u95ee\u9898\uff0c\u5e76\u5728\u82f9\u679c\u53f6\u75c5\u5bb3\u8bca\u65ad\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3AI\u8d8a\u6765\u8d8a\u4f9d\u8d56\u591a\u4ee3\u7406\u67b6\u6784\uff0c\u4f46\u5728\u96f6\u6837\u672c\u73af\u5883\u4e0b\u5982\u4f55\u4fe1\u4efb\u8fd9\u4e9b\u4ee3\u7406\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u6a21\u5757\u5316\u6846\u67b6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86\u96c6\u6210\u591a\u6a21\u6001\u4ee3\u7406\u3001\u63a8\u7406\u534f\u8c03\u5668\u548cRAG\u6a21\u5757\u7684\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u914d\u7f6e\uff1a\u96f6\u6837\u672c\u4fe1\u5fc3\u534f\u8c03\u3001\u5fae\u8c03\u4ee3\u7406\u548c\u4fe1\u4efb\u6821\u51c6\u534f\u8c03\u3002\u4f7f\u7528\u4e86\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6307\u6807\uff08ECE, OCR, CCC\uff09\u3002", "result": "\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0c\u901a\u8fc7\u4fe1\u4efb\u611f\u77e5\u534f\u8c03\u548cRAG\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e8677.94%\uff0c\u603b\u4f53\u8fbe\u523085.63%\u3002GPT-4o\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6821\u51c6\uff0c\u800cQwen-2.5-VL\u5219\u663e\u793a\u8fc7\u5ea6\u81ea\u4fe1\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u5c06\u611f\u77e5\u4e0e\u5143\u63a8\u7406\u5206\u79bb\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u591a\u4ee3\u7406AI\uff0c\u9002\u7528\u4e8e\u8bca\u65ad\u3001\u751f\u7269\u5b66\u7b49\u4fe1\u4efb\u5173\u952e\u9886\u57df\u3002", "keywords": "\u591a\u4ee3\u7406AI, \u4fe1\u4efb\u6821\u51c6, \u96f6\u6837\u672c\u5b66\u4e60, RAG, \u89c6\u89c9\u5206\u7c7b"}}
{"id": "2507.10575", "pdf": "https://arxiv.org/pdf/2507.10575", "abs": "https://arxiv.org/abs/2507.10575", "authors": ["Kieran Chai Kai Ren"], "title": "An Adaptive Volatility-based Learning Rate Scheduler", "categories": ["cs.LG"], "comment": null, "summary": "Effective learning rate (LR) scheduling is crucial for training deep neural\nnetworks. However, popular pre-defined and adaptive schedulers can still lead\nto suboptimal generalization. This paper introduces VolSched, a novel adaptive\nLR scheduler inspired by the concept of volatility in stochastic processes like\nGeometric Brownian Motion to dynamically adjust the learning rate. By\ncalculating the ratio between long-term and short-term accuracy volatility,\nVolSched increases the LR to escape plateaus and decreases it to stabilize\ntraining, allowing the model to explore the loss landscape more effectively. We\nevaluate VolSched on the CIFAR-100 dataset against a strong baseline using a\nstandard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our\nscheduler delivers consistent performance gains, improving top-1 accuracy by\n1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals\nthat VolSched promotes a longer exploration phase. A quantitative analysis of\nthe Hessian shows that VolSched finds a final solution that is 38% flatter than\nthe next-best baseline, allowing the model to obtain wider minima and hence\nbetter generalization performance.", "AI": {"tldr": "VolSched\u662f\u4e00\u79cd\u65b0\u578b\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\u4ee5\u4f18\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u3002", "motivation": "\u4f20\u7edf\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u53ef\u80fd\u5bfc\u81f4\u6b21\u4f18\u6cdb\u5316\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "VolSched\u5229\u7528\u957f\u671f\u548c\u77ed\u671f\u7cbe\u5ea6\u6ce2\u52a8\u6bd4\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u4ee5\u9003\u79bb\u5e73\u53f0\u671f\u5e76\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728CIFAR-100\u6570\u636e\u96c6\u4e0a\uff0cVolSched\u663e\u8457\u63d0\u5347ResNet-18\u548cResNet-34\u7684top-1\u51c6\u786e\u7387\uff0c\u5e76\u627e\u5230\u66f4\u5e73\u5766\u7684\u89e3\u7a7a\u95f4\u3002", "conclusion": "VolSched\u901a\u8fc7\u5ef6\u957f\u63a2\u7d22\u9636\u6bb5\u548c\u53d1\u73b0\u66f4\u5bbd\u6700\u5c0f\u503c\u4e3a\u6a21\u578b\u5e26\u6765\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "keywords": "\u5b66\u4e60\u7387\u8c03\u5ea6, VolSched, \u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3, CIFAR-100, \u6cdb\u5316\u6027\u80fd"}}
{"id": "2507.10596", "pdf": "https://arxiv.org/pdf/2507.10596", "abs": "https://arxiv.org/abs/2507.10596", "authors": ["Yogachandran Rahulamathavan", "Misbah Farooq", "Varuna De Silva"], "title": "PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) excel in text classification, but their\ncomplexity hinders interpretability, making it difficult to understand the\nreasoning behind their predictions. Explainable AI (XAI) methods like LIME and\nSHAP offer local explanations by identifying influential words, but they rely\non computationally expensive perturbations. These methods typically generate\nthousands of perturbed sentences and perform inferences on each, incurring a\nsubstantial computational burden, especially with LLMs. To address this, we\npropose \\underline{P}erturbation-free \\underline{L}ocal \\underline{Ex}planation\n(PLEX), a novel method that leverages the contextual embeddings extracted from\nthe LLM and a ``Siamese network\" style neural network trained to align with\nfeature importance scores. This one-off training eliminates the need for\nsubsequent perturbations, enabling efficient explanations for any new sentence.\nWe demonstrate PLEX's effectiveness on four different classification tasks\n(sentiment, fake news, fake COVID-19 news and depression), showing more than\n92\\% agreement with LIME and SHAP. Our evaluation using a ``stress test\"\nreveals that PLEX accurately identifies influential words, leading to a similar\ndecline in classification accuracy as observed with LIME and SHAP when these\nwords are removed. Notably, in some cases, PLEX demonstrates superior\nperformance in capturing the impact of key features. PLEX dramatically\naccelerates explanation, reducing time and computational overhead by two and\nfour orders of magnitude, respectively. This work offers a promising solution\nfor explainable LLM-based text classification.", "AI": {"tldr": "PLEX\u662f\u4e00\u79cd\u65e0\u9700\u6270\u52a8\u7684\u9ad8\u6548\u5c40\u90e8\u89e3\u91ca\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eLIME\u548cSHAP\u76f8\u4f3c\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709XAI\u65b9\u6cd5\uff08\u5982LIME\u548cSHAP\uff09\u4f9d\u8d56\u8ba1\u7b97\u6602\u8d35\u7684\u6270\u52a8\uff0c\u5f71\u54cd\u6548\u7387\uff0c\u56e0\u6b64\u63d0\u51faPLEX\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PLEX\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u548cSiamese\u7f51\u7edc\u8bad\u7ec3\uff0c\u65e0\u9700\u540e\u7eed\u6270\u52a8\uff0c\u76f4\u63a5\u751f\u6210\u89e3\u91ca\u3002", "result": "\u5728\u56db\u79cd\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cPLEX\u4e0eLIME\u548cSHAP\u7684\u543b\u5408\u5ea6\u8d85\u8fc792%\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u663e\u8457\u3002", "conclusion": "PLEX\u4e3a\u57fa\u4e8eLLM\u7684\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "PLEX, LLM, XAI, LIME, SHAP"}}
{"id": "2507.10624", "pdf": "https://arxiv.org/pdf/2507.10624", "abs": "https://arxiv.org/abs/2507.10624", "authors": ["Zheng Zhang"], "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u5176\"\u7406\u89e3\"\u4e0e\"\u80fd\u529b\"\u4e4b\u95f4\u7684\u8131\u8282\uff0c\u79f0\u4e3a\"\u8ba1\u7b97\u5206\u88c2\u8111\u7efc\u5408\u5f81\"\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\uff0c\u63ed\u793a\u5176\u5185\u90e8\u7ed3\u6784\u4e0e\u5b9e\u9645\u80fd\u529b\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u548c\u67b6\u6784\u5206\u6790\uff0c\u63a2\u8ba8LLMs\u5728\u8868\u8fbe\u6b63\u786e\u539f\u5219\u4e0e\u5e94\u7528\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "LLMs\u662f\u5f3a\u5927\u7684\u6a21\u5f0f\u5b8c\u6210\u5f15\u64ce\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406\u7684\u67b6\u6784\uff0c\u5bfc\u81f4\u884c\u4e3a\u8106\u5f31\u3002", "conclusion": "\u672a\u6765\u6a21\u578b\u9700\u8981\u5f15\u5165\u5143\u8ba4\u77e5\u63a7\u5236\u3001\u539f\u5219\u63d0\u5347\u548c\u7ed3\u6784\u5316\u6267\u884c\u80fd\u529b\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u7b26\u53f7\u63a8\u7406, \u8ba1\u7b97\u5206\u88c2\u8111\u7efc\u5408\u5f81, \u6a21\u5f0f\u5b8c\u6210, \u67b6\u6784\u5206\u6790"}}
{"id": "2507.10581", "pdf": "https://arxiv.org/pdf/2507.10581", "abs": "https://arxiv.org/abs/2507.10581", "authors": ["Esmail Gumaan"], "title": "Universal Approximation Theorem for a Single-Layer Transformer", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "7 pages, 2 figures, 1 theorem, 10 formulas", "summary": "Deep learning employs multi-layer neural networks trained via the\nbackpropagation algorithm. This approach has achieved success across many\ndomains and relies on adaptive gradient methods such as the Adam optimizer.\nSequence modeling evolved from recurrent neural networks to attention-based\nmodels, culminating in the Transformer architecture. Transformers have achieved\nstate-of-the-art performance in natural language processing (for example, BERT\nand GPT-3) and have been applied in computer vision and computational biology.\nHowever, theoretical understanding of these models remains limited. In this\npaper, we examine the mathematical foundations of deep learning and\nTransformers and present a novel theoretical result. We review key concepts\nfrom linear algebra, probability, and optimization that underpin deep learning,\nand we analyze the multi-head self-attention mechanism and the backpropagation\nalgorithm in detail. Our main contribution is a universal approximation theorem\nfor Transformers: we prove that a single-layer Transformer, comprising one\nself-attention layer followed by a position-wise feed-forward network with ReLU\nactivation, can approximate any continuous sequence-to-sequence mapping on a\ncompact domain to arbitrary precision. We provide a formal statement and a\ncomplete proof. Finally, we present case studies that demonstrate the practical\nimplications of this result. Our findings advance the theoretical understanding\nof Transformer models and help bridge the gap between theory and practice.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u6570\u5b66\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u5355\u5c42Transformer\u53ef\u4ee5\u903c\u8fd1\u4efb\u4f55\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u6620\u5c04\u3002", "motivation": "\u5c3d\u7ba1Transformer\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u6587\u7ae0\u56de\u987e\u4e86\u652f\u6301\u6df1\u5ea6\u5b66\u4e60\u7684\u5173\u952e\u6570\u5b66\u6982\u5ff5\uff0c\u8be6\u7ec6\u5206\u6790\u4e86\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2aTransformer\u7684\u901a\u7528\u903c\u8fd1\u5b9a\u7406\u3002", "result": "\u8bc1\u660e\u4e86\u5355\u5c42Transformer\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u5c42\u548cReLU\u6fc0\u6d3b\u7684\u524d\u9988\u7f51\u7edc\uff0c\u5728\u7d27\u51d1\u57df\u4e0a\u4ee5\u4efb\u610f\u7cbe\u5ea6\u903c\u8fd1\u4efb\u4f55\u8fde\u7eed\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\u3002", "conclusion": "\u672c\u6587\u7684\u7406\u8bba\u6210\u679c\u63a8\u52a8\u4e86Transformer\u6a21\u578b\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u6709\u52a9\u4e8e\u7f29\u5c0f\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "keywords": "\u6df1\u5ea6\u5b66\u4e60, Transformer, \u901a\u7528\u903c\u8fd1\u5b9a\u7406, \u81ea\u6ce8\u610f\u529b, \u53cd\u5411\u4f20\u64ad"}}
{"id": "2507.10599", "pdf": "https://arxiv.org/pdf/2507.10599", "abs": "https://arxiv.org/abs/2507.10599", "authors": ["Bo Zhao", "Maya Okawa", "Eric J. Bigelow", "Rose Yu", "Tomer Ullman", "Ekdeep Singh Lubana", "Hidenori Tanaka"], "title": "Emergence of Hierarchical Emotion Organization in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) increasingly power conversational agents,\nunderstanding how they model users' emotional states is critical for ethical\ndeployment. Inspired by emotion wheels -- a psychological framework that argues\nemotions organize hierarchically -- we analyze probabilistic dependencies\nbetween emotional states in model outputs. We find that LLMs naturally form\nhierarchical emotion trees that align with human psychological models, and\nlarger models develop more complex hierarchies. We also uncover systematic\nbiases in emotion recognition across socioeconomic personas, with compounding\nmisclassifications for intersectional, underrepresented groups. Human studies\nreveal striking parallels, suggesting that LLMs internalize aspects of social\nperception. Beyond highlighting emergent emotional reasoning in LLMs, our\nresults hint at the potential of using cognitively-grounded theories for\ndeveloping better model evaluations.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982\u4f55\u6a21\u62df\u7528\u6237\u60c5\u7eea\u72b6\u6001\uff0c\u53d1\u73b0\u6a21\u578b\u8f93\u51fa\u7684\u60c5\u7eea\u5177\u6709\u5c42\u6b21\u7ed3\u6784\uff0c\u4e0e\u4eba\u7c7b\u5fc3\u7406\u5b66\u6a21\u578b\u4e00\u81f4\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\uff0c\u60c5\u7eea\u5c42\u6b21\u8d8a\u590d\u6742\u3002\u540c\u65f6\uff0c\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5bf9\u7ecf\u6d4e\u5f31\u52bf\u7fa4\u4f53\u7684\u60c5\u7eea\u8bc6\u522b\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "motivation": "\u4e86\u89e3LLMs\u5982\u4f55\u5efa\u6a21\u7528\u6237\u60c5\u7eea\u72b6\u6001\uff0c\u4ee5\u786e\u4fdd\u5176\u4f26\u7406\u90e8\u7f72\u3002", "method": "\u57fa\u4e8e\u5fc3\u7406\u5b66\u6846\u67b6\u201c\u60c5\u7eea\u8f6e\u201d\uff0c\u5206\u6790\u6a21\u578b\u8f93\u51fa\u7684\u60c5\u7eea\u6982\u7387\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "LLMs\u81ea\u7136\u5f62\u6210\u4e0e\u4eba\u7c7b\u5fc3\u7406\u5b66\u6a21\u578b\u4e00\u81f4\u7684\u60c5\u7eea\u5c42\u6b21\u7ed3\u6784\uff0c\u4e14\u5927\u6a21\u578b\u5c42\u6b21\u66f4\u590d\u6742\uff1b\u540c\u65f6\u53d1\u73b0\u6a21\u578b\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u60c5\u7eea\u8bc6\u522b\u5b58\u5728\u504f\u5dee\u3002", "conclusion": "LLMs\u7684\u5185\u9690\u60c5\u7eea\u63a8\u7406\u80fd\u529b\u4e0e\u4eba\u7c7b\u793e\u4f1a\u8ba4\u77e5\u76f8\u4f3c\uff0c\u63d0\u793a\u672a\u6765\u53ef\u7ed3\u5408\u8ba4\u77e5\u7406\u8bba\u4f18\u5316\u6a21\u578b\u8bc4\u4f30\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u60c5\u7eea\u8bc6\u522b,\u5fc3\u7406\u5b66\u6846\u67b6,\u7cfb\u7edf\u6027\u504f\u5dee,\u6a21\u578b\u8bc4\u4f30"}}
{"id": "2507.10630", "pdf": "https://arxiv.org/pdf/2507.10630", "abs": "https://arxiv.org/abs/2507.10630", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "AI": {"tldr": "KG2data\u662f\u4e00\u4e2a\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u3001LLM\u3001ReAct\u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u6c14\u8c61\u9886\u57df\u7684\u6570\u636e\u83b7\u53d6\u548c\u67e5\u8be2\u5904\u7406\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22LLM\u901a\u8fc7API\u8c03\u7528\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\uff08\u5982\u6c14\u8c61\u5b66\uff09\u4e2d\u6709\u6548\u5229\u7528\u5de5\u5177\u7684\u80fd\u529b\u3002", "method": "\u96c6\u6210\u77e5\u8bc6\u56fe\u8c31\u3001LLM\u3001ReAct\u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\uff0c\u901a\u8fc7\u865a\u62dfAPI\u8bc4\u4f30API\u8c03\u7528\u7684\u51c6\u786e\u6027\u3002", "result": "KG2data\u5728\u540d\u79f0\u8bc6\u522b\u5931\u8d25\u3001\u5e7b\u89c9\u5931\u8d25\u548c\u8c03\u7528\u6b63\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u4e8eRAG2data\u548cchat2data\u3002", "conclusion": "KG2data\u4e3a\u9ad8\u77e5\u8bc6\u9700\u6c42\u9886\u57df\u63d0\u4f9b\u4e86\u57fa\u4e8e\u77e5\u8bc6\u7684\u667a\u80fd\u95ee\u7b54\u548c\u6570\u636e\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "LLM\u3001API\u8c03\u7528\u3001\u77e5\u8bc6\u56fe\u8c31\u3001\u6c14\u8c61\u5b66\u3001\u667a\u80fd\u95ee\u7b54"}}
{"id": "2507.10591", "pdf": "https://arxiv.org/pdf/2507.10591", "abs": "https://arxiv.org/abs/2507.10591", "authors": ["Vanderson Rocha", "Diego Kreutz", "Gabriel Canto", "Hendrio Bragan\u00e7a", "Eduardo Feitosa"], "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.PF", "68T01", "I.2"], "comment": "11 pages; 4 figures; 5 tables; submitted to JBCS", "summary": "Feature selection is vital for building effective predictive models, as it\nreduces dimensionality and emphasizes key features. However, current research\noften suffers from limited benchmarking and reliance on proprietary datasets.\nThis severely hinders reproducibility and can negatively impact overall\nperformance. To address these limitations, we introduce the MH-FSF framework, a\ncomprehensive, modular, and extensible platform designed to facilitate the\nreproduction and implementation of feature selection methods. Developed through\ncollaborative research, MH-FSF provides implementations of 17 methods (11\nclassical, 6 domain-specific) and enables systematic evaluation on 10 publicly\navailable Android malware datasets. Our results reveal performance variations\nacross both balanced and imbalanced datasets, highlighting the critical need\nfor data preprocessing and selection criteria that account for these\nasymmetries. We demonstrate the importance of a unified platform for comparing\ndiverse feature selection techniques, fostering methodological consistency and\nrigor. By providing this framework, we aim to significantly broaden the\nexisting literature and pave the way for new research directions in feature\nselection, particularly within the context of Android malware detection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MH-FSF\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u7279\u5f81\u9009\u62e9\u7814\u7a76\u4e2d\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u8db3\u548c\u6570\u636e\u96c6\u4f9d\u8d56\u6027\u5f3a\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u4f9b17\u79cd\u65b9\u6cd5\u7684\u5b9e\u73b0\u548c10\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u7684\u8bc4\u4f30\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u9009\u62e9\u6807\u51c6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u7279\u5f81\u9009\u62e9\u7814\u7a76\u5b58\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u8db3\u548c\u4f9d\u8d56\u79c1\u6709\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u53ef\u91cd\u590d\u6027\u548c\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86MH-FSF\u6846\u67b6\uff0c\u5b9e\u73b0\u4e8617\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0811\u79cd\u7ecf\u5178\uff0c6\u79cd\u9886\u57df\u4e13\u7528\uff09\uff0c\u5e76\u572810\u4e2a\u516c\u5f00Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u9009\u62e9\u6807\u51c6\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "MH-FSF\u6846\u67b6\u4e3a\u7279\u5f81\u9009\u62e9\u6280\u672f\u7684\u6bd4\u8f83\u63d0\u4f9b\u4e86\u7edf\u4e00\u5e73\u53f0\uff0c\u63a8\u52a8\u4e86\u65b9\u6cd5\u5b66\u7684\u4e00\u81f4\u6027\u548c\u4e25\u8c28\u6027\u3002", "keywords": "\u7279\u5f81\u9009\u62e9, MH-FSF\u6846\u67b6, Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b, \u6570\u636e\u9884\u5904\u7406"}}
{"id": "2507.10743", "pdf": "https://arxiv.org/pdf/2507.10743", "abs": "https://arxiv.org/abs/2507.10743", "authors": ["Nickolas Freeman", "Thanh Nguyen", "Gregory Bott", "Jason Parton", "Collin Francel"], "title": "Language Models for Adult Service Website Text Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "32 pages, 12 figures, 1 table", "summary": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6210\u4eba\u670d\u52a1\u7f51\u7ad9\uff08ASW\uff09\u5e7f\u544a\u6587\u672c\u7684\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u5b9a\u4e49Transformer\u6a21\u578b\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u5e94\u7528\u4e8eASW\u6570\u636e\u5206\u6790\u4efb\u52a1\u3002", "motivation": "ASW\u5e7f\u544a\u6587\u672c\u56e0\u5176\u7279\u6b8a\u8bed\u8a00\u7279\u6027\uff08\u5982\u6ee5\u7528\u8868\u60c5\u7b26\u53f7\u3001\u8bed\u6cd5\u6df7\u4e71\u7b49\uff09\u7ed9\u6587\u672c\u5206\u6790\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5904\u7406\uff1b\u7814\u7a76\u65e8\u5728\u63d0\u5347ASW\u6587\u672c\u5206\u6790\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u591a\u79cd\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\uff0c\u5305\u62ec\u4fe1\u606f\u68c0\u7d22\u3001\u9884\u8bad\u7ec3Transformer\u53ca\u81ea\u5b9a\u4e49Transformer\u6a21\u578b\uff0c\u5e76\u5bf9\u540e\u8005\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u81ea\u5b9a\u4e49Transformer\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cROC AUC\u4e0a\u4f18\u4e8eBERT-base\u3001RoBERTa\u7b49\u6a21\u578b\uff0c\u4e14\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002", "conclusion": "\u81ea\u5b9a\u4e49\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86ASW\u6587\u672c\u5206\u6790\u80fd\u529b\uff0c\u53ef\u652f\u6301\u4e0b\u6e38\u5e94\u7528\u5982\u5e7f\u544a\u805a\u7c7b\u3001\u8868\u60c5\u7b26\u53f7\u89e3\u6790\u7b49\uff0c\u63a8\u52a8\u53cd\u6027\u8d29\u5356\u7814\u7a76\u3002", "keywords": "\u6027\u8d29\u5356,\u6210\u4eba\u670d\u52a1\u7f51\u7ad9,\u6587\u672c\u5206\u6790,Transformer\u6a21\u578b,\u8bed\u8a00\u5efa\u6a21"}}
{"id": "2507.10644", "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5168\u9762\u7684Web of Agents\uff08WoA\uff09\u8fdb\u5316\u6982\u8ff0\uff0c\u901a\u8fc7\u56db\u8f74\u5206\u7c7b\u6cd5\u7cfb\u7edf\u5206\u6790\u4e86\u4ee3\u7406\u67b6\u6784\u7684\u6f14\u53d8\uff0c\u5e76\u6307\u51fa\u667a\u80fd\u6838\u5fc3\u4ece\u5916\u90e8\u6570\u636e\u8f6c\u79fb\u5230\u4ee3\u7406\u5185\u90e8\u6a21\u578b\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u73b0\u4ee3Agentic AI\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u7814\u7a76WoA\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u5206\u6563\u5728\u4e0d\u540c\u793e\u533a\u7684\u95ee\u9898\uff0c\u63ed\u793a\u73b0\u4ee3\u7cfb\u7edf\u7684\u667a\u8bc6\u6e0a\u6e90\uff0c\u5e76\u63a8\u52a8\u5bf9\u9886\u57df\u53d1\u5c55\u7684\u6574\u4f53\u7406\u89e3\u3002", "method": "\u91c7\u7528\u56db\u8f74\u5206\u7c7b\u6cd5\uff08\u8bed\u4e49\u57fa\u7840\u3001\u901a\u4fe1\u8303\u5f0f\u3001\u667a\u80fd\u6838\u5fc3\u3001\u53d1\u73b0\u673a\u5236\uff09\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5404\u4ee3\u4ee3\u7406\u67b6\u6784\uff0c\u5e76\u5206\u6790\u4e86\u73b0\u4ee3\u534f\u8bae\u7684\u6f14\u5316\u8def\u5f84\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u667a\u80fd\u6838\u5fc3\u4ece\u5916\u90e8\u6570\u636e\u6216\u5e73\u53f0\u8f6c\u79fb\u5230\u4ee3\u7406\u5185\u90e8\u6a21\u578b\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u73b0\u4ee3Agentic AI\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u6784\u5efa\u5065\u58ee\u3001\u5f00\u653e\u3001\u53ef\u4fe1\u7684WoA\u751f\u6001\u7cfb\u7edf\u9700\u8981\u89e3\u51b3\u6301\u7eed\u7684\u793e\u4f1a\u6280\u672f\u6311\u6218\uff0c\u5982\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u3001\u7ecf\u6d4e\u6a21\u578b\u3001\u5b89\u5168\u548c\u6cbb\u7406\u3002", "keywords": "Web of Agents, Multi-Agent Systems, Semantic Web, LLMs, Agentic AI"}}
{"id": "2507.10594", "pdf": "https://arxiv.org/pdf/2507.10594", "abs": "https://arxiv.org/abs/2507.10594", "authors": ["Shengda Zhuo", "Di Wu", "Yi He", "Shuqiang Huang", "Xindong Wu"], "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Online learning, where feature spaces can change over time, offers a flexible\nlearning paradigm that has attracted considerable attention. However, it still\nfaces three significant challenges. First, the heterogeneity of real-world data\nstreams with mixed feature types presents challenges for traditional parametric\nmodeling. Second, data stream distributions can shift over time, causing an\nabrupt and substantial decline in model performance. Third, it is often\ninfeasible to label every data instance due to time and cost constraints. To\naddress these issues, we proposed OL-MDISF (Online Learning from Mix-typed,\nDrifted, and Incomplete Streaming Features), which constructs a latent\ncopula-based representation for heterogeneous features, detects drifts via\nensemble entropy and latent mismatch, and performs structure-aware\npseudo-labeling.\n  This companion paper serves as a standalone technical reference to OL-MDISF.\nIt provides a contextual discussion of related work in mixed-type modeling,\ndrift adaptation, and weak supervision, as well as a comprehensive set of\nexperiments across 14 real-world datasets under two types of drift scenarios.\nThese include CER trends, ablation studies, sensitivity analyses, and temporal\nensemble dynamics. We hope this document offers a reproducible benchmark for\nonline learning on complex, weakly supervised streaming data.", "AI": {"tldr": "OL-MDISF \u662f\u4e00\u4e2a\u9488\u5bf9\u6df7\u5408\u7c7b\u578b\u3001\u6f02\u79fb\u548c\u4e0d\u5b8c\u6574\u6d41\u7279\u5f81\u7684\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6f5c\u5728 copula \u8868\u793a\u3001\u6f02\u79fb\u68c0\u6d4b\u548c\u7ed3\u6784\u611f\u77e5\u4f2a\u6807\u8bb0\u89e3\u51b3\u6570\u636e\u5f02\u8d28\u6027\u3001\u6f02\u79fb\u548c\u6807\u7b7e\u7f3a\u5931\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u5b66\u4e60\u4e2d\u9762\u4e34\u7684\u6df7\u5408\u7279\u5f81\u7c7b\u578b\u3001\u6570\u636e\u6f02\u79fb\u548c\u6807\u7b7e\u7f3a\u5931\u4e09\u5927\u6311\u6218\u3002", "method": "\u6784\u5efa\u6f5c\u5728 copula \u8868\u793a\u3001\u901a\u8fc7\u96c6\u6210\u71b5\u548c\u6f5c\u5728\u4e0d\u5339\u914d\u68c0\u6d4b\u6f02\u79fb\u3001\u6267\u884c\u7ed3\u6784\u611f\u77e5\u4f2a\u6807\u8bb0\u3002", "result": "\u5728 14 \u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ec CER \u8d8b\u52bf\u3001\u6d88\u878d\u7814\u7a76\u548c\u654f\u611f\u6027\u5206\u6790\u3002", "conclusion": "OL-MDISF \u4e3a\u590d\u6742\u3001\u5f31\u76d1\u7763\u6d41\u6570\u636e\u7684\u5728\u7ebf\u5b66\u4e60\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u3002", "keywords": "\u5728\u7ebf\u5b66\u4e60, \u6df7\u5408\u7279\u5f81, \u6570\u636e\u6f02\u79fb, \u4f2a\u6807\u8bb0, copula \u8868\u793a"}}
{"id": "2507.10772", "pdf": "https://arxiv.org/pdf/2507.10772", "abs": "https://arxiv.org/abs/2507.10772", "authors": ["Michal Podstawski"], "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Labeled property graphs often contain rich textual attributes that can\nenhance analytical tasks when properly leveraged. This work explores the use of\npretrained text embedding models to enable efficient semantic analysis in such\ngraphs. By embedding textual node and edge properties, we support downstream\ntasks including node classification and relation prediction with improved\ncontextual understanding. Our approach integrates language model embeddings\ninto the graph pipeline without altering its structure, demonstrating that\ntextual semantics can significantly enhance the accuracy and interpretability\nof property graph analysis.", "AI": {"tldr": "\u5229\u7528\u9884\u8bad\u7ec3\u6587\u672c\u5d4c\u5165\u6a21\u578b\u589e\u5f3a\u5c5e\u6027\u56fe\u7684\u8bed\u4e49\u5206\u6790\uff0c\u63d0\u5347\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\u4efb\u52a1\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5c5e\u6027\u56fe\u4e2d\u4e30\u5bcc\u7684\u6587\u672c\u5c5e\u6027\u672a\u88ab\u5145\u5206\u5229\u7528\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u53ef\u4ee5\u66f4\u597d\u5730\u652f\u6301\u8bed\u4e49\u5206\u6790\u3002", "method": "\u5c06\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5e94\u7528\u4e8e\u8282\u70b9\u548c\u8fb9\u7684\u5c5e\u6027\uff0c\u4fdd\u7559\u56fe\u7ed3\u6784\u4e0d\u53d8\uff0c\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u3002", "result": "\u5d4c\u5165\u540e\u7684\u56fe\u5206\u6790\u5728\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u6587\u672c\u8bed\u4e49\u80fd\u663e\u8457\u63d0\u5347\u5c5e\u6027\u56fe\u5206\u6790\u7684\u6027\u80fd\u3002", "keywords": "\u5c5e\u6027\u56fe,\u6587\u672c\u5d4c\u5165,\u8bed\u4e49\u5206\u6790,\u8282\u70b9\u5206\u7c7b,\u5173\u7cfb\u9884\u6d4b"}}
{"id": "2507.10740", "pdf": "https://arxiv.org/pdf/2507.10740", "abs": "https://arxiv.org/abs/2507.10740", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "title": "Parsing Musical Structure to Enable Meaningful Variations", "categories": ["cs.AI", "cs.NE", "cs.SD", "eess.AS"], "comment": null, "summary": "This paper presents a novel rule-based approach for generating music by\nvarying existing tunes. We parse each tune to find the Pathway Assembly (PA) [\n1], that is a structure representing all repetitions in the tune. The Sequitur\nalgorithm [2 ] is used for this. The result is a grammar. We then carry out\nmutation on the grammar, rather than on a tune directly. There are potentially\n19 types of mutations such as adding, removing, swapping or reversing parts of\nthe grammar that can be applied to the grammars. The system employs one of the\nmutations randomly in this step to automatically manipulate the grammar.\nFollowing the mutation, we need to expand the grammar which returns a new tune.\nThe output after 1 or more mutations will be a new tune related to the original\ntune. Our study examines how tunes change gradually over the course of multiple\nmutations. Edit distances, structural complexity and length of the tunes are\nused to show how a tune is changed after multiple mutations. In addition, the\nsize of effect of each mutation type is analyzed. As a final point, we review\nthe musical aspect of the output tunes. It should be noted that the study only\nfocused on generating new pitch sequences. The study is based on an Irish\ntraditional tune dataset and a list of integers has been used to represent each\ntune's pitch values.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u97f3\u4e50\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u7684\u8bed\u6cd5\u7ed3\u6784\u751f\u6210\u65b0\u66f2\u8c03\uff0c\u5206\u6790\u4e86\u591a\u6b21\u53d8\u5f02\u540e\u66f2\u8c03\u7684\u53d8\u5316\u53ca\u5176\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u7684\u8bed\u6cd5\u7ed3\u6784\u751f\u6210\u65b0\u66f2\u8c03\uff0c\u5e76\u5206\u6790\u53d8\u5f02\u5bf9\u66f2\u8c03\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528Sequitur\u7b97\u6cd5\u89e3\u6790\u66f2\u8c03\u751f\u6210\u8bed\u6cd5\u7ed3\u6784\uff08PA\uff09\uff0c\u968f\u673a\u5e94\u752819\u79cd\u53d8\u5f02\u7c7b\u578b\uff08\u5982\u589e\u52a0\u3001\u5220\u9664\u3001\u4ea4\u6362\u6216\u53cd\u8f6c\u90e8\u5206\u8bed\u6cd5\uff09\uff0c\u518d\u901a\u8fc7\u6269\u5c55\u8bed\u6cd5\u751f\u6210\u65b0\u66f2\u8c03\u3002", "result": "\u5206\u6790\u4e86\u591a\u6b21\u53d8\u5f02\u540e\u66f2\u8c03\u7684\u7f16\u8f91\u8ddd\u79bb\u3001\u7ed3\u6784\u590d\u6742\u6027\u548c\u957f\u5ea6\u53d8\u5316\uff0c\u4ee5\u53ca\u6bcf\u79cd\u53d8\u5f02\u7c7b\u578b\u7684\u5f71\u54cd\u5927\u5c0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u751f\u6210\u4e86\u4e0e\u539f\u66f2\u8c03\u76f8\u5173\u7684\u65b0\u66f2\u8c03\uff0c\u5e76\u91cf\u5316\u4e86\u53d8\u5f02\u5bf9\u66f2\u8c03\u7684\u5f71\u54cd\u3002", "keywords": "\u97f3\u4e50\u751f\u6210, \u8bed\u6cd5\u53d8\u5f02, Sequitur\u7b97\u6cd5, \u7f16\u8f91\u8ddd\u79bb, \u7ed3\u6784\u590d\u6742\u6027"}}
{"id": "2507.10595", "pdf": "https://arxiv.org/pdf/2507.10595", "abs": "https://arxiv.org/abs/2507.10595", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Miaomiao Li", "Wenpeng Lu", "Zhigang Luo", "Xinwang Liu", "Ping Chen"], "title": "Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised\ntask aimed at partitioning nodes with incomplete attributes into distinct\nclusters. Addressing this challenging issue is vital for practical\napplications. However, research in this area remains underexplored. Existing\nimputation methods for attribute-missing graphs often fail to account for the\nvarying amounts of information available across node neighborhoods, leading to\nunreliable results, especially for nodes with insufficient known neighborhood.\nTo address this issue, we propose a novel method named Divide-Then-Rule Graph\nCompletion (DTRGC). This method first addresses nodes with sufficient known\nneighborhood information and treats the imputed results as new knowledge to\niteratively impute more challenging nodes, while leveraging clustering\ninformation to correct imputation errors. Specifically, Dynamic Cluster-Aware\nFeature Propagation (DCFP) initializes missing node attributes by adjusting\npropagation weights based on the clustering structure. Subsequently,\nHierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing\nnodes into three groups based on the completeness of their neighborhood\nattributes. The imputation is performed hierarchically, prioritizing the groups\nwith nodes that have the most available neighborhood information. The cluster\nstructure is then used to refine the imputation and correct potential errors.\nFinally, Hop-wise Representation Enhancement (HRE) integrates information\nacross multiple hops, thereby enriching the expressiveness of node\nrepresentations. Experimental results on six widely used graph datasets show\nthat DTRGC significantly improves the clustering performance of various DGC\nmethods under attribute-missing graphs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDTRGC\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u6df1\u5ea6\u56fe\u805a\u7c7b\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u6b21\u5904\u7406\u8282\u70b9\u7f3a\u5931\u5c5e\u6027\u5e76\u5229\u7528\u805a\u7c7b\u4fe1\u606f\u7ea0\u6b63\u63d2\u8865\u9519\u8bef\uff0c\u663e\u8457\u63d0\u5347\u4e86\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u6df1\u5ea6\u56fe\u805a\u7c7b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u8282\u70b9\u90bb\u57df\u4fe1\u606f\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9760\u3002", "method": "DTRGC\u65b9\u6cd5\u5206\u4e09\u6b65\uff1a\u52a8\u6001\u805a\u7c7b\u611f\u77e5\u7279\u5f81\u4f20\u64ad\uff08DCFP\uff09\u521d\u59cb\u5316\u7f3a\u5931\u5c5e\u6027\uff1b\u5c42\u6b21\u90bb\u57df\u611f\u77e5\u63d2\u8865\uff08HNAI\uff09\u5206\u5c42\u5904\u7406\u8282\u70b9\u7f3a\u5931\uff1b\u8df3\u7ea7\u8868\u793a\u589e\u5f3a\uff08HRE\uff09\u4e30\u5bcc\u8282\u70b9\u8868\u793a\u3002", "result": "\u5728\u516d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u56fe\u6570\u636e\u96c6\u4e0a\uff0cDTRGC\u663e\u8457\u63d0\u5347\u4e86\u5404\u79cd\u6df1\u5ea6\u56fe\u805a\u7c7b\u65b9\u6cd5\u5728\u5c5e\u6027\u7f3a\u5931\u56fe\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "DTRGC\u901a\u8fc7\u5206\u5c42\u6b21\u5904\u7406\u548c\u805a\u7c7b\u4fe1\u606f\u6821\u6b63\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u805a\u7c7b\u6027\u80fd\u3002", "keywords": "\u6df1\u5ea6\u56fe\u805a\u7c7b\uff0c\u5c5e\u6027\u7f3a\u5931\u56fe\uff0cDTRGC\uff0c\u52a8\u6001\u805a\u7c7b\u611f\u77e5\uff0c\u5c42\u6b21\u90bb\u57df\u611f\u77e5"}}
{"id": "2507.10787", "pdf": "https://arxiv.org/pdf/2507.10787", "abs": "https://arxiv.org/abs/2507.10787", "authors": ["Yilun Zhao", "Chengye Wang", "Chuhan Li", "Arman Cohan"], "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers", "categories": ["cs.CL", "cs.CV"], "comment": "ACL 2025 Findings", "summary": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.", "AI": {"tldr": "MISS-QA\u662f\u9996\u4e2a\u8bc4\u4f30\u6a21\u578b\u89e3\u6790\u79d1\u5b66\u6587\u732e\u793a\u610f\u56fe\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5305\u542b1500\u4e2a\u4e13\u5bb6\u6807\u6ce8\u793a\u4f8b\uff0c\u8986\u76d6465\u7bc7\u8bba\u6587\u3002\u6d4b\u8bd5\u4e8618\u79cd\u524d\u6cbf\u591a\u6a21\u6001\u6a21\u578b\uff0c\u53d1\u73b0\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u65e8\u5728\u586b\u8865\u8bc4\u4f30\u6a21\u578b\u89e3\u6790\u79d1\u5b66\u6587\u732e\u793a\u610f\u56fe\u80fd\u529b\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efaMISS-QA\u57fa\u51c6\uff0c\u5305\u542b\u4e13\u5bb6\u6807\u6ce8\u7684\u793a\u4f8b\u548c\u95ee\u9898\uff0c\u6d4b\u8bd5\u591a\u79cd\u591a\u6a21\u6001\u6a21\u578b\u3002", "result": "\u73b0\u6709\u6a21\u578b\u6027\u80fd\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\u4e13\u5bb6\uff0c\u9519\u8bef\u5206\u6790\u63ed\u793a\u4e86\u5176\u4f18\u52a3\u52bf\u3002", "conclusion": "MISS-QA\u4e3a\u63d0\u5347\u591a\u6a21\u6001\u79d1\u5b66\u6587\u732e\u7406\u89e3\u63d0\u4f9b\u4e86\u5173\u952e\u6d1e\u5bdf\u3002", "keywords": "MISS-QA, \u793a\u610f\u56fe, \u591a\u6a21\u6001\u6a21\u578b, \u79d1\u5b66\u6587\u732e, \u6027\u80fd\u8bc4\u4f30"}}
{"id": "2507.10750", "pdf": "https://arxiv.org/pdf/2507.10750", "abs": "https://arxiv.org/abs/2507.10750", "authors": ["Pandu Devarakota", "Nicolas Tsesmetzis", "Faruk O. Alpak", "Apurva Gala", "Detlef Hohl"], "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition", "categories": ["cs.AI"], "comment": "Technical article to be submitted to Data Centric Engineering Journal", "summary": "Thanks to the availability of massive amounts of data, computing resources,\nand advanced algorithms, AI has entered nearly every sector. This has sparked\nsignificant investment and interest, particularly in building data centers with\nthe necessary hardware and software to develop and operate AI models and\nAI-based workflows. In this technical review article, we present energy\nconsumption scenarios of data centers and impact on GHG emissions, considering\nboth near-term projections (up to 2030) and long-term outlook (2035 and\nbeyond). We address the quintessential question of whether AI will have a net\npositive, neutral, or negative impact on CO2 emissions by 2035. Additionally,\nwe discuss AI's potential to automate, create efficient and disruptive\nworkflows across various fields related to energy production, supply and\nconsumption. In the near-term scenario, the growing demand for AI will likely\nstrain computing resources, lead to increase in electricity consumption and\ntherefore associated CO2 emissions. This is due to the power-hungry nature of\nbig data centers and the requirements for training and running of large and\ncomplex AI models, as well as the penetration of AI assistant search and\napplications for public use. However, the long-term outlook could be more\npromising. AI has the potential to be a game-changer in CO2 reduction. Its\nability to further automate and optimize processes across industries, from\nenergy production to logistics, could significantly decrease our carbon\nfootprint. This positive impact is anticipated to outweigh the initial\nemissions bump, creating value for businesses and society in areas where\ntraditional solutions have fallen short. In essence, AI might cause some\ninitial growing pains for the environment, but it has the potential to support\nclimate mitigation efforts.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86AI\u6570\u636e\u4e2d\u5fc3\u5bf9\u80fd\u6e90\u6d88\u8017\u53ca\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u5f71\u54cd\uff0c\u9884\u6d4b\u4e86\u77ed\u671f\uff08\u81f32030\u5e74\uff09\u548c\u957f\u671f\uff082035\u5e74\u53ca\u4ee5\u540e\uff09\u7684\u60c5\u666f\uff0c\u5e76\u5206\u6790\u4e86AI\u5bf9CO2\u6392\u653e\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76AI\u6280\u672f\u5feb\u901f\u53d1\u5c55\u80cc\u666f\u4e0b\uff0c\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u53ca\u5176\u5bf9\u73af\u5883\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30AI\u5bf9CO2\u6392\u653e\u7684\u957f\u671f\u51c0\u6548\u5e94\u3002", "method": "\u901a\u8fc7\u6280\u672f\u7efc\u8ff0\u5206\u6790\uff0c\u7ed3\u5408\u77ed\u671f\u548c\u957f\u671f\u60c5\u666f\u9884\u6d4b\uff0c\u8bc4\u4f30AI\u5bf9\u80fd\u6e90\u751f\u4ea7\u3001\u4f9b\u5e94\u548c\u6d88\u8d39\u7684\u4f18\u5316\u6f5c\u529b\u3002", "result": "\u77ed\u671f\u5185AI\u9700\u6c42\u589e\u957f\u53ef\u80fd\u5bfc\u81f4\u7535\u529b\u6d88\u8017\u548cCO2\u6392\u653e\u589e\u52a0\uff1b\u957f\u671f\u6765\u770b\uff0cAI\u4f18\u5316\u6d41\u7a0b\u7684\u80fd\u529b\u6709\u671b\u663e\u8457\u51cf\u5c11\u78b3\u8db3\u8ff9\u3002", "conclusion": "AI\u53ef\u80fd\u5728\u521d\u671f\u5bf9\u73af\u5883\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u4f46\u957f\u671f\u5c06\u6210\u4e3a\u6c14\u5019\u7f13\u89e3\u7684\u6709\u529b\u5de5\u5177\u3002", "keywords": "AI, \u6570\u636e\u4e2d\u5fc3, \u80fd\u6e90\u6d88\u8017, CO2\u6392\u653e, \u6c14\u5019\u7f13\u89e3"}}
{"id": "2507.10605", "pdf": "https://arxiv.org/pdf/2507.10605", "abs": "https://arxiv.org/abs/2507.10605", "authors": ["Fei Zhao", "Chonggang Lu", "Yue Wang", "Zheyong Xie", "Ziyan Liu", "Haofu Qian", "JianZhao Huang", "Fangcheng Shi", "Zijie Meng", "Hongcheng Guo", "Mingqian He", "Xinze Lyu", "Yiming Lu", "Ziyang Xiang", "Zheyu Ye", "Chengqiang Lu", "Zhe Xu", "Yi Wu", "Yao Hu", "Yan Gao", "Jun Fan", "Xiaolong Jiang", "Weiting Liu", "Boyang Wang", "Shaosheng Cao"], "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": null, "summary": "As a primary medium for modern information dissemination, social networking\nservices (SNS) have experienced rapid growth, which has proposed significant\nchallenges for platform content management and interaction quality improvement.\nRecently, the development of large language models (LLMs) has offered potential\nsolutions but existing studies focus on isolated tasks, which not only\nencounter diminishing benefit from the data scaling within individual scenarios\nbut also fail to flexibly adapt to diverse real-world context. To address these\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\nperformance bottleneck of single-task baselines and establish a comprehensive\nfoundation for the SNS. RedOne was developed through a three-stage training\nstrategy consisting of continue pretraining, supervised fine-tuning, and\npreference optimization, using a large-scale real-world dataset. Through\nextensive experiments, RedOne maintains strong general capabilities, and\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\nthrough online testing, RedOne reduced the exposure rate in harmful content\ndetection by 11.23% and improved the click page rate in post-view search by\n14.95% compared with single-tasks finetuned baseline models. These results\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\nexcellent generalization across various tasks and promising applicability in\nreal-world scenarios.", "AI": {"tldr": "RedOne\u662f\u4e00\u4e2a\u9488\u5bf9\u793e\u4ea4\u7f51\u7edc\u670d\u52a1(SNS)\u7684\u9886\u57df\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\u5feb\u901f\u53d1\u5c55\u5bf9\u5185\u5bb9\u7ba1\u7406\u548c\u4ea4\u4e92\u8d28\u91cf\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u5c40\u9650\u4e8e\u5355\u4efb\u52a1\u4e14\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u591a\u6837\u573a\u666f\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\uff09\u5e76\u4f7f\u7528\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u5f00\u53d1RedOne\u3002", "result": "RedOne\u57288\u9879SNS\u4efb\u52a1\u4e2d\u5e73\u5747\u63d0\u534714.02%\uff0c\u53cc\u8bed\u8bc4\u4f30\u63d0\u53477.56%\uff0c\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u66dd\u5149\u7387\u964d\u4f4e11.23%\uff0c\u5e16\u5b50\u641c\u7d22\u70b9\u51fb\u7387\u63d0\u9ad814.95%\u3002", "conclusion": "RedOne\u662fSNS\u9886\u57df\u5f3a\u5927\u7684\u9886\u57df\u7279\u5b9aLLM\uff0c\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "keywords": "\u793e\u4ea4\u7f51\u7edc\u670d\u52a1,\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u591a\u4efb\u52a1\u5b66\u4e60,\u5185\u5bb9\u7ba1\u7406,\u6027\u80fd\u63d0\u5347"}}
{"id": "2507.10810", "pdf": "https://arxiv.org/pdf/2507.10810", "abs": "https://arxiv.org/abs/2507.10810", "authors": ["David M. Markowitz", "Samuel Hardman Taylor"], "title": "Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler", "categories": ["cs.CL", "cs.SI"], "comment": null, "summary": "In this paper, we explored how online hate is motivated by receiving social\napproval from others. We specifically examined two central tenets of Walther's\n(2024) social approval theory of online hate: (H1a) more signals of social\napproval on hate messages predicts more subsequent hate messages, and (H1b) as\nsocial approval increases, hate speech messages become more extreme. Using over\n110 million posts from Parler (2018-2021), we observed that the number of\nupvotes a person received on a hate speech post was unassociated with the\namount of hate speech in their next post and posts during the next week, month,\nthree months, and six months. Between-person effects revealed an average\nnegative relationship between social approval and hate speech production at the\npost level, but this relationship was mixed at other time intervals. Social\napproval reinforcement mechanisms of online hate may operate differently on\nniche social media platforms.", "AI": {"tldr": "\u7814\u7a76\u4e86\u793e\u4ea4\u5e73\u53f0Parler\u4e0a\u4ec7\u6068\u8a00\u8bba\u4e0e\u793e\u4ea4\u8ba4\u53ef\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u793e\u4ea4\u8ba4\u53ef\u5e76\u672a\u663e\u8457\u589e\u52a0\u540e\u7eed\u4ec7\u6068\u8a00\u8bba\u7684\u9891\u7387\u6216\u6781\u7aef\u7a0b\u5ea6\u3002", "motivation": "\u63a2\u8ba8\u793e\u4ea4\u8ba4\u53ef\u5982\u4f55\u6fc0\u53d1\u5728\u7ebf\u4ec7\u6068\u8a00\u8bba\uff0c\u9a8c\u8bc1Walther\uff082024\uff09\u7684\u793e\u4f1a\u8ba4\u53ef\u7406\u8bba\u3002", "method": "\u5206\u6790\u4e862018-2021\u5e74\u95f4Parler\u4e0a\u8d85\u8fc71.1\u4ebf\u6761\u5e16\u5b50\uff0c\u8bc4\u4f30\u70b9\u8d5e\u6570\u4e0e\u540e\u7eed\u4ec7\u6068\u8a00\u8bba\u7684\u5173\u7cfb\u3002", "result": "\u70b9\u8d5e\u6570\u4e0e\u540e\u7eed\u4ec7\u6068\u8a00\u8bba\u65e0\u660e\u663e\u5173\u8054\uff0c\u793e\u4ea4\u8ba4\u53ef\u4e0e\u4ec7\u6068\u8a00\u8bba\u4e4b\u95f4\u5173\u7cfb\u590d\u6742\uff0c\u5b58\u5728\u8d1f\u76f8\u5173\u3002", "conclusion": "\u5728\u5c0f\u4f17\u793e\u4ea4\u5e73\u53f0\u4e0a\uff0c\u793e\u4ea4\u8ba4\u53ef\u5bf9\u4ec7\u6068\u8a00\u8bba\u7684\u5f3a\u5316\u673a\u5236\u53ef\u80fd\u4e0e\u4f20\u7edf\u7406\u8bba\u4e0d\u540c\u3002", "keywords": "\u5728\u7ebf\u4ec7\u6068\u8a00\u8bba,\u793e\u4ea4\u8ba4\u53ef,Parler,\u793e\u4f1a\u7406\u8bba"}}
{"id": "2507.10758", "pdf": "https://arxiv.org/pdf/2507.10758", "abs": "https://arxiv.org/abs/2507.10758", "authors": ["Nikesh Prajapati", "Bimal Karki", "Saroj Gopali", "Akbar Siami Namin"], "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "This paper intends to detect IoT malicious attacks through deep learning\nmodels and demonstrates a comprehensive evaluation of the deep learning and\ngraph-based models regarding malicious network traffic detection. The models\nparticularly are based on GraphSAGE, Bidirectional encoder representations from\ntransformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head\nAttention, together with Bidirectional Long Short-Term Memory (BI-LSTM)\nMulti-Head Attention and BI-LSTM and LSTM models. The chosen models\ndemonstrated great performance to model temporal patterns and detect feature\nsignificance. The observed performance are mainly due to the fact that IoT\nsystem traffic patterns are both sequential and diverse, leaving a rich set of\ntemporal patterns for the models to learn. Experimental results showed that\nBERT maintained the best performance. It achieved 99.94% accuracy rate\nalongside high precision and recall, F1-score and AUC-ROC score of 99.99% which\ndemonstrates its capabilities through temporal dependency capture. The\nMulti-Head Attention offered promising results by providing good detection\ncapabilities with interpretable results. On the other side, the Multi-Head\nAttention model required significant processing time like BI-LSTM variants. The\nGraphSAGE model achieved good accuracy while requiring the shortest training\ntime but yielded the lowest accuracy, precision, and F1 score compared to the\nother models", "AI": {"tldr": "\u8be5\u8bba\u6587\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u6a21\u578b\uff08\u5982GraphSAGE\u3001BERT\u3001TCN\u7b49\uff09\u5728\u6076\u610f\u7f51\u7edc\u6d41\u91cf\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002BERT\u8868\u73b0\u6700\u4f73\uff0c\u800cGraphSAGE\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\u4f46\u51c6\u786e\u7387\u6700\u4f4e\u3002", "motivation": "\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u6d41\u91cf\u6a21\u5f0f\u5177\u6709\u65f6\u5e8f\u6027\u548c\u591a\u6837\u6027\uff0c\u4e3a\u6a21\u578b\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6570\u636e\u3002\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u548c\u56fe\u6a21\u578b\u63d0\u5347\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e86\u591a\u79cd\u6a21\u578b\uff1aGraphSAGE\u3001BERT\u3001TCN\u3001Multi-Head Attention\u3001BI-LSTM\u53ca\u5176\u53d8\u4f53\uff0c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "result": "BERT\u8868\u73b0\u6700\u4f18\uff0c\u51c6\u786e\u7387\u8fbe99.94%\uff0c\u5176\u4ed6\u6307\u6807\u4e5f\u63a5\u8fd1\u5b8c\u7f8e\uff1bMulti-Head Attention\u68c0\u6d4b\u80fd\u529b\u826f\u597d\u4f46\u5904\u7406\u65f6\u95f4\u957f\uff1bGraphSAGE\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\u4f46\u6027\u80fd\u8f83\u5dee\u3002", "conclusion": "BERT\u5728\u6355\u6349\u65f6\u5e8f\u4f9d\u8d56\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u800cMulti-Head Attention\u548cGraphSAGE\u5404\u6709\u4f18\u7f3a\u70b9\u3002\u6a21\u578b\u9009\u62e9\u9700\u6743\u8861\u6027\u80fd\u4e0e\u6548\u7387\u3002", "keywords": "\u6df1\u5ea6\u5b66\u4e60\u3001\u7269\u8054\u7f51\u5b89\u5168\u3001\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u3001BERT\u3001GraphSAGE"}}
{"id": "2507.10606", "pdf": "https://arxiv.org/pdf/2507.10606", "abs": "https://arxiv.org/abs/2507.10606", "authors": ["Bing-Yue Wu", "Vidya A. Chhabria"], "title": "DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "Under review at Asia and South Pacific Design Automation Conference\n  (ASP-DAC'26)", "summary": "Machine learning (ML) has demonstrated significant promise in various\nphysical design (PD) tasks. However, model generalizability remains limited by\nthe availability of high-quality, large-scale training datasets. Creating such\ndatasets is often computationally expensive and constrained by IP. While very\nfew public datasets are available, they are typically static, slow to generate,\nand require frequent updates. To address these limitations, we present DALI-PD,\na scalable framework for generating synthetic layout heatmaps to accelerate ML\nin PD research. DALI-PD uses a diffusion model to generate diverse layout\nheatmaps via fast inference in seconds. The heatmaps include power, IR drop,\ncongestion, macro placement, and cell density maps. Using DALI-PD, we created a\ndataset comprising over 20,000 layout configurations with varying macro counts\nand placements. These heatmaps closely resemble real layouts and improve ML\naccuracy on downstream ML tasks such as IR drop or congestion prediction.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDALI-PD\u6846\u67b6\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u5feb\u901f\u751f\u6210\u5408\u6210\u5e03\u5c40\u70ed\u56fe\uff0c\u4ee5\u89e3\u51b3\u7269\u7406\u8bbe\u8ba1\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7269\u7406\u8bbe\u8ba1\uff08PD\uff09\u4e2d\u673a\u5668\u5b66\u4e60\u6a21\u578b\u56e0\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u800c\u6cdb\u5316\u80fd\u529b\u53d7\u9650\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6269\u6563\u6a21\u578b\u5feb\u901f\u751f\u6210\u591a\u6837\u5316\u7684\u5e03\u5c40\u70ed\u56fe\uff0c\u5305\u62ec\u7535\u6e90\u3001IR\u538b\u964d\u3001\u62e5\u585e\u3001\u5b8f\u5355\u5143\u5e03\u5c40\u548c\u5355\u5143\u5bc6\u5ea6\u56fe\u3002", "result": "\u6210\u529f\u751f\u6210\u4e86\u5305\u542b20,000\u591a\u79cd\u4e0d\u540c\u5b8f\u5355\u5143\u6570\u91cf\u548c\u5e03\u5c40\u914d\u7f6e\u7684\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e86ML\u5728IR\u538b\u964d\u548c\u62e5\u585e\u9884\u6d4b\u7b49\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DALI-PD\u6846\u67b6\u4e3a\u7269\u7406\u8bbe\u8ba1\u4e2d\u7684ML\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6570\u636e\u751f\u6210\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "keywords": "\u673a\u5668\u5b66\u4e60,\u7269\u7406\u8bbe\u8ba1,\u6269\u6563\u6a21\u578b,\u5e03\u5c40\u70ed\u56fe,\u6570\u636e\u5904\u7406"}}
{"id": "2507.10852", "pdf": "https://arxiv.org/pdf/2507.10852", "abs": "https://arxiv.org/abs/2507.10852", "authors": ["Yiran Hu", "Zongyue Xue", "Haitao Li", "Siyuan Zheng", "Qingjing Chen", "Shaochun Wang", "Xihan Zhang", "Ning Zheng", "Yun Liu", "Qingyao Ai", "Yiqun Liu", "Charles L. A. Clarke", "Weixing Shen"], "title": "LLMs on Trial: Evaluating Judicial Fairness for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly used in high-stakes fields\nwhere their decisions impact rights and equity. However, LLMs' judicial\nfairness and implications for social justice remain underexplored. When LLMs\nact as judges, the ability to fairly resolve judicial issues is a prerequisite\nto ensure their trustworthiness. Based on theories of judicial fairness, we\nconstruct a comprehensive framework to measure LLM fairness, leading to a\nselection of 65 labels and 161 corresponding values. Applying this framework to\nthe judicial system, we compile an extensive dataset, JudiFair, comprising\n177,100 unique case facts. To achieve robust statistical inference, we develop\nthree evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and\nintroduce a method to assess the overall fairness of multiple LLMs across\nvarious labels. Through experiments with 16 LLMs, we uncover pervasive\ninconsistency, bias, and imbalanced inaccuracy across models, underscoring\nsevere LLM judicial unfairness. Particularly, LLMs display notably more\npronounced biases on demographic labels, with slightly less bias on substance\nlabels compared to procedure ones. Interestingly, increased inconsistency\ncorrelates with reduced biases, but more accurate predictions exacerbate\nbiases. While we find that adjusting the temperature parameter can influence\nLLM fairness, model size, release date, and country of origin do not exhibit\nsignificant effects on judicial fairness. Accordingly, we introduce a publicly\navailable toolkit containing all datasets and code, designed to support future\nresearch in evaluating and improving LLM fairness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u53f8\u6cd5\u9886\u57df\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u8bc4\u4ef7\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u4e86LLMs\u5728\u53f8\u6cd5\u51b3\u7b56\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u6027\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLMs\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728\u53f8\u6cd5\u51b3\u7b56\u4e2d\u7684\u516c\u5e73\u6027\u548c\u793e\u4f1a\u6b63\u4e49\u5f71\u54cd\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u4e3a\u786e\u4fddLLMs\u7684\u53ef\u4fe1\u5ea6\uff0c\u8bc4\u4f30\u5176\u53f8\u6cd5\u516c\u5e73\u6027\u6210\u4e3a\u5fc5\u8981\u3002", "method": "\u57fa\u4e8e\u53f8\u6cd5\u516c\u5e73\u7406\u8bba\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b65\u4e2a\u6807\u7b7e\u548c161\u4e2a\u503c\u7684\u8bc4\u4ef7\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e09\u4e2a\u8bc4\u4ef7\u6307\u6807\uff08\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u6027\uff09\u6765\u8bc4\u4f30LLMs\u7684\u516c\u5e73\u6027\u3002\u901a\u8fc7JudiFair\u6570\u636e\u96c6\uff08177,100\u4e2a\u6848\u4f8b\uff09\u5bf916\u4e2aLLMs\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0LLMs\u5728\u53f8\u6cd5\u51b3\u7b56\u4e2d\u666e\u904d\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u6027\uff0c\u5c24\u5176\u5728\u4eba\u53e3\u7edf\u8ba1\u6807\u7b7e\u4e0a\u8868\u73b0\u66f4\u663e\u8457\u3002\u8c03\u6574\u6e29\u5ea6\u53c2\u6570\u53ef\u6539\u5584\u516c\u5e73\u6027\uff0c\u4f46\u6a21\u578b\u5927\u5c0f\u3001\u53d1\u5e03\u65f6\u95f4\u548c\u6765\u6e90\u56fd\u5bf9\u516c\u5e73\u6027\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "LLMs\u5728\u53f8\u6cd5\u5e94\u7528\u4e2d\u5b58\u5728\u660e\u663e\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6539\u8fdb\u3002\u8bba\u6587\u63d0\u4f9b\u4e86\u516c\u5f00\u5de5\u5177\u5305\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u53f8\u6cd5\u516c\u5e73, \u793e\u4f1a\u6b63\u4e49, \u8bc4\u4ef7\u6846\u67b6, \u504f\u89c1"}}
{"id": "2507.10761", "pdf": "https://arxiv.org/pdf/2507.10761", "abs": "https://arxiv.org/abs/2507.10761", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "title": "Detecting AI Assistance in Abstract Complex Tasks", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted to HCII 2025", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks.", "AI": {"tldr": "\u8ba8\u8bba\u4e86\u5982\u4f55\u901a\u8fc7\u9884\u5904\u7406\u548c\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u68c0\u6d4b\u4eba\u5de5\u667a\u80fd\u5728\u62bd\u8c61\u4efb\u52a1\u4e2d\u7684\u8f85\u52a9\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u56db\u79cd\u56fe\u50cf\u5f62\u5f0f\u548c\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740AI\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u666e\u53ca\uff0c\u68c0\u6d4b\u5176\u8f85\u52a9\u4f5c\u7528\u53d8\u5f97\u91cd\u8981\uff0c\u4f46\u4eba\u7c7b\u96be\u4ee5\u5904\u7406\u62bd\u8c61\u6570\u636e\uff0c\u56e0\u6b64\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u7684\u53ef\u884c\u6027\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u795e\u7ecf\u7f51\u7edc\u53cb\u597d\u7684\u56fe\u50cf\u5f62\u5f0f\u548c\u4e00\u79cd\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\uff0c\u7f16\u7801\u7528\u6237\u63a2\u7d22/\u5229\u7528\u884c\u4e3a\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08\u5982CNN-RNN\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7ecf\u8fc7\u9002\u5f53\u9884\u5904\u7406\u540e\uff0c\u5e38\u89c1\u6a21\u578b\u80fd\u6709\u6548\u5206\u7c7b\u62bd\u8c61\u6570\u636e\uff0c\u4e14\u65f6\u95f4\u5e8f\u5217\u65b9\u6cd5\u80fd\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u7f16\u7801\u65f6\u7a7a\u6570\u636e\u5bf9\u4e8e\u68c0\u6d4bAI\u8f85\u52a9\u5728\u62bd\u8c61\u4efb\u52a1\u4e2d\u7684\u4f5c\u7528\u81f3\u5173\u91cd\u8981\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u666e\u9002\u6027\u3002", "keywords": "AI\u8f85\u52a9\u68c0\u6d4b,\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b,\u56fe\u50cf\u9884\u5904\u7406,\u65f6\u95f4\u5e8f\u5217,CNN-RNN"}}
{"id": "2507.10609", "pdf": "https://arxiv.org/pdf/2507.10609", "abs": "https://arxiv.org/abs/2507.10609", "authors": ["Obumneme Nwafor", "Chioma Nwafor", "Amro Zakaria", "Nkechi Nwankwo"], "title": "A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The United Arab Emirates (UAE) relies heavily on seawater desalination to\nmeet over 90% of its drinking water needs. Desalination processes are highly\nenergy intensive and account for approximately 15% of the UAE's electricity\nconsumption, contributing to over 22% of the country's energy-related CO2\nemissions. Moreover, these processes face significant sustainability challenges\nin the face of climate uncertainties such as rising seawater temperatures,\nsalinity, and aerosol optical depth (AOD). AOD greatly affects the operational\nand economic performance of solar-powered desalination systems through\nphotovoltaic soiling, membrane fouling, and water turbidity cycles.\n  This study proposes a novel pipelined two-stage predictive modelling\narchitecture: the first stage forecasts AOD using satellite-derived time series\nand meteorological data; the second stage uses the predicted AOD and other\nmeteorological factors to predict desalination performance efficiency losses.\nThe framework achieved 98% accuracy, and SHAP (SHapley Additive exPlanations)\nwas used to reveal key drivers of system degradation. Furthermore, this study\nproposes a dust-aware rule-based control logic for desalination systems based\non predicted values of AOD and solar efficiency. This control logic is used to\nadjust the desalination plant feed water pressure, adapt maintenance\nscheduling, and regulate energy source switching.\n  To enhance the practical utility of the research findings, the predictive\nmodels and rule-based controls were packaged into an interactive dashboard for\nscenario and predictive analytics. This provides a management decision-support\nsystem for climate-adaptive planning.", "AI": {"tldr": "\u963f\u8054\u914b\u4f9d\u8d56\u6d77\u6c34\u6de1\u5316\u6ee1\u8db390%\u4ee5\u4e0a\u7684\u996e\u7528\u6c34\u9700\u6c42\uff0c\u4f46\u8be5\u8fc7\u7a0b\u80fd\u8017\u9ad8\u4e14\u9762\u4e34\u6c14\u5019\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u9884\u6d4b\u6a21\u578b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u63a7\u5236\u7cfb\u7edf\uff0c\u4ee5\u63d0\u5347\u6de1\u5316\u6548\u7387\u5e76\u51cf\u5c11\u73af\u5883\u5f71\u54cd\u3002", "motivation": "\u963f\u8054\u914b\u4e25\u91cd\u4f9d\u8d56\u9ad8\u80fd\u8017\u7684\u6d77\u6c34\u6de1\u5316\u6280\u672f\uff0c\u5bfc\u81f4\u5927\u91cfCO2\u6392\u653e\u3002\u6c14\u5019\u56e0\u7d20\uff08\u5982\u6d77\u6c34\u6e29\u5ea6\u4e0a\u5347\u548c\u60ac\u6d6e\u9897\u7c92\u7269\uff09\u8fdb\u4e00\u6b65\u5f71\u54cd\u7cfb\u7edf\u6548\u7387\uff0c\u4e9f\u9700\u53ef\u6301\u7eed\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e24\u9636\u6bb5\u9884\u6d4b\u6a21\u578b\uff1a\u7b2c\u4e00\u9636\u6bb5\u9884\u6d4b\u60ac\u6d6e\u9897\u7c92\u7269\uff08AOD\uff09\uff0c\u7b2c\u4e8c\u9636\u6bb5\u9884\u6d4b\u6de1\u5316\u6548\u7387\u635f\u5931\u3002\u7ed3\u5408SHAP\u5206\u6790\u5173\u952e\u9a71\u52a8\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u89c4\u5219\u7684\u667a\u80fd\u63a7\u5236\u7cfb\u7edf\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u8fbe98%\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u4eea\u8868\u76d8\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\uff0c\u5b9e\u73b0\u6c14\u5019\u9002\u5e94\u89c4\u5212\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6d77\u6c34\u6de1\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u9884\u6d4b\u4e0e\u63a7\u5236\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u964d\u4f4e\u80fd\u8017\u548c\u6392\u653e\uff0c\u63d0\u5347\u53ef\u6301\u7eed\u6027\u3002", "keywords": "\u6d77\u6c34\u6de1\u5316, \u9884\u6d4b\u5efa\u6a21, \u6c14\u5019\u53d8\u5316, \u667a\u80fd\u63a7\u5236, \u53ef\u6301\u7eed\u6027"}}
{"id": "2507.10918", "pdf": "https://arxiv.org/pdf/2507.10918", "abs": "https://arxiv.org/abs/2507.10918", "authors": ["Ikumi Numaya", "Shoji Moriya", "Shiki Sato", "Reina Akama", "Jun Suzuki"], "title": "How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations", "categories": ["cs.CL"], "comment": "Accepted to SIGDIAL 2025 (long)", "summary": "Recent advancements in dialogue generation have broadened the scope of\nhuman-bot interactions, enabling not only contextually appropriate responses\nbut also the analysis of human affect and sensitivity. While prior work has\nsuggested that stylistic similarity between user and system may enhance user\nimpressions, the distinction between subjective and objective similarity is\noften overlooked. To investigate this issue, we introduce a novel dataset that\nincludes users' preferences, subjective stylistic similarity based on users'\nown perceptions, and objective stylistic similarity annotated by third party\nevaluators in open-domain dialogue settings. Analysis using the constructed\ndataset reveals a strong positive correlation between subjective stylistic\nsimilarity and user preference. Furthermore, our analysis suggests an important\nfinding: users' subjective stylistic similarity differs from third party\nobjective similarity. This underscores the importance of distinguishing between\nsubjective and objective evaluations and understanding the distinct aspects\neach captures when analyzing the relationship between stylistic similarity and\nuser preferences. The dataset presented in this paper is available online.", "AI": {"tldr": "\u63a2\u8ba8\u4e3b\u89c2\u4e0e\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u5bf9\u7528\u6237\u504f\u597d\u7684\u5f71\u54cd\uff0c\u5e76\u6784\u5efa\u65b0\u6570\u636e\u96c6\u5206\u6790\u4e24\u8005\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u7528\u6237\u4e0e\u7cfb\u7edf\u98ce\u683c\u76f8\u4f3c\u6027\u5bf9\u7528\u6237\u4f53\u9a8c\u7684\u5f71\u54cd\uff0c\u533a\u5206\u4e3b\u89c2\u4e0e\u5ba2\u89c2\u76f8\u4f3c\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u7528\u6237\u504f\u597d\u3001\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\uff08\u7528\u6237\u81ea\u8bc4\uff09\u548c\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\uff08\u7b2c\u4e09\u65b9\u8bc4\u4f30\uff09\u7684\u6570\u636e\u96c6\u3002", "result": "\u53d1\u73b0\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u4e0e\u7528\u6237\u504f\u597d\u5f3a\u76f8\u5173\uff0c\u4e14\u4e0e\u5ba2\u89c2\u76f8\u4f3c\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u9700\u533a\u5206\u4e3b\u5ba2\u89c2\u8bc4\u4ef7\uff0c\u4ee5\u66f4\u597d\u7406\u89e3\u98ce\u683c\u76f8\u4f3c\u6027\u4e0e\u7528\u6237\u504f\u597d\u7684\u5173\u7cfb\u3002", "keywords": "\u5bf9\u8bdd\u751f\u6210,\u98ce\u683c\u76f8\u4f3c\u6027,\u7528\u6237\u504f\u597d,\u4e3b\u89c2\u8bc4\u4ef7,\u5ba2\u89c2\u8bc4\u4ef7"}}
{"id": "2507.10798", "pdf": "https://arxiv.org/pdf/2507.10798", "abs": "https://arxiv.org/abs/2507.10798", "authors": ["Asim H. Gazi", "Bhanu T. Gullapalli", "Daiqi Gao", "Benjamin M. Marlin", "Vivek Shetty", "Susan A. Murphy"], "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions", "categories": ["cs.AI"], "comment": "4 pages, 3 figures", "summary": "Timely decision making is critical to the effectiveness of mobile health\n(mHealth) interventions. At predefined timepoints called \"decision points,\"\nintelligent mHealth systems such as just-in-time adaptive interventions\n(JITAIs) estimate an individual's biobehavioral context from sensor or survey\ndata and determine whether and how to intervene. For interventions targeting\nhabitual behavior (e.g., oral hygiene), effectiveness often hinges on\ndelivering support shortly before the target behavior is likely to occur.\nCurrent practice schedules decision points at a fixed interval (e.g., one hour)\nbefore user-provided behavior times, and the fixed interval is kept the same\nfor all individuals. However, this one-size-fits-all approach performs poorly\nfor individuals with irregular routines, often scheduling decision points after\nthe target behavior has already occurred, rendering interventions ineffective.\nIn this paper, we propose SigmaScheduling, a method to dynamically schedule\ndecision points based on uncertainty in predicted behavior times. When behavior\ntiming is more predictable, SigmaScheduling schedules decision points closer to\nthe predicted behavior time; when timing is less certain, SigmaScheduling\nschedules decision points earlier, increasing the likelihood of timely\nintervention. We evaluated SigmaScheduling using real-world data from 68\nparticipants in a 10-week trial of Oralytics, a JITAI designed to improve daily\ntoothbrushing. SigmaScheduling increased the likelihood that decision points\npreceded brushing events in at least 70% of cases, preserving opportunities to\nintervene and impact behavior. Our results indicate that SigmaScheduling can\nadvance precision mHealth, particularly for JITAIs targeting time-sensitive,\nhabitual behaviors such as oral hygiene or dietary habits.", "AI": {"tldr": "\u6458\u8981\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSigmaScheduling\u7684\u52a8\u6001\u51b3\u7b56\u70b9\u8c03\u5ea6\u65b9\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u7cfb\u7edf\u4e2d\uff0c\u4ee5\u63d0\u5347\u5e72\u9884\u7684\u53ca\u65f6\u6027\u3002", "motivation": "\u5f53\u524d\u56fa\u5b9a\u95f4\u9694\u7684\u51b3\u7b56\u70b9\u8c03\u5ea6\u65b9\u6cd5\u5728\u9762\u5bf9\u7528\u6237\u4e0d\u89c4\u5219\u884c\u4e3a\u65f6\u95f4\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u5e72\u9884\u6548\u679c\u5dee\uff0c\u9700\u8981\u66f4\u4e2a\u6027\u5316\u7684\u65b9\u6848\u3002", "method": "SigmaScheduling\u6839\u636e\u9884\u6d4b\u884c\u4e3a\u65f6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u70b9\uff0c\u65f6\u95f4\u9884\u6d4b\u8d8a\u51c6\u786e\uff0c\u51b3\u7b56\u70b9\u8d8a\u63a5\u8fd1\u884c\u4e3a\u65f6\u95f4\uff1b\u53cd\u4e4b\u5219\u63d0\u524d\u5b89\u6392\u51b3\u7b56\u70b9\u3002", "result": "\u572868\u540d\u53c2\u4e0e\u8005\u768410\u5468\u8bd5\u9a8c\u4e2d\uff0cSigmaScheduling\u4f7f70%\u4ee5\u4e0a\u7684\u5237\u7259\u884c\u4e3a\u524d\u81f3\u5c11\u6709\u4e00\u4e2a\u51b3\u7b56\u70b9\uff0c\u63d0\u9ad8\u4e86\u5e72\u9884\u673a\u4f1a\u3002", "conclusion": "SigmaScheduling\u80fd\u63d0\u5347\u7cbe\u51c6\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u7684\u6548\u679c\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u65f6\u95f4\u654f\u611f\u6027\u4e60\u60ef\u884c\u4e3a\uff08\u5982\u5237\u7259\u6216\u996e\u98df\u4e60\u60ef\uff09\u3002", "keywords": "\u79fb\u52a8\u5065\u5eb7\u3001JITAI\u3001\u51b3\u7b56\u70b9\u8c03\u5ea6\u3001\u4e60\u60ef\u884c\u4e3a\u3001\u7cbe\u51c6\u5e72\u9884"}}
{"id": "2507.10611", "pdf": "https://arxiv.org/pdf/2507.10611", "abs": "https://arxiv.org/abs/2507.10611", "authors": ["Mengwen Ye", "Yingzi Huangfu", "Shujian Gao", "Wei Ren", "Weifan Liu", "Zekuan Yu"], "title": "FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated Learning (FL) emerged as a solution for collaborative medical image\nclassification while preserving data privacy. However, label noise, which\narises from inter-institutional data variability, can cause training\ninstability and degrade model performance. Existing FL methods struggle with\nnoise heterogeneity and the imbalance in medical data. Motivated by these\nchallenges, we propose FedGSCA, a novel framework for enhancing robustness in\nnoisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates\nnoise knowledge from all clients, effectively addressing noise heterogeneity\nand improving global model stability. Furthermore, we develop a Client Adaptive\nAdjustment (CAA) mechanism that combines adaptive threshold pseudo-label\ngeneration and Robust Credal Labeling Loss. CAA dynamically adjusts to class\ndistributions, ensuring the inclusion of minority samples and carefully\nmanaging noisy labels by considering multiple plausible labels. This dual\napproach mitigates the impact of noisy data and prevents overfitting during\nlocal training, which improves the generalizability of the model. We evaluate\nFedGSCA on one real-world colon slides dataset and two synthetic medical\ndatasets under various noise conditions, including symmetric, asymmetric,\nextreme, and heterogeneous types. The results show that FedGSCA outperforms the\nstate-of-the-art methods, excelling in extreme and heterogeneous noise\nscenarios. Moreover, FedGSCA demonstrates significant advantages in improving\nmodel stability and handling complex noise, making it well-suited for\nreal-world medical federated learning scenarios.", "AI": {"tldr": "FedGSCA\u662f\u4e00\u4e2a\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u533b\u7597\u6570\u636e\u6807\u7b7e\u566a\u58f0\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u6837\u672c\u9009\u62e9\u5668\u548c\u5ba2\u6237\u7aef\u81ea\u9002\u5e94\u8c03\u6574\u673a\u5236\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u533b\u533b\u7597\u6570\u636e\u6807\u7b7e\u566a\u58f0\u5bfc\u81f4\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5c24\u5176\u662f\u566a\u58f0\u5f02\u8d28\u6027\u548c\u6570\u636e\u4e0d\u5e73\u8861\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faFedGSCA\u6846\u67b6\uff0c\u5305\u62ec\u5168\u5c40\u6837\u672c\u9009\u62e9\u5668\uff08\u805a\u5408\u566a\u58f0\u77e5\u8bc6\uff09\u548c\u5ba2\u6237\u7aef\u81ea\u9002\u5e94\u8c03\u6574\u673a\u5236\uff08\u7ed3\u5408\u4f2a\u6807\u7b7e\u751f\u6210\u548c\u9c81\u68d2\u635f\u5931\u51fd\u6570\uff09\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u533b\u7597\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cFedGSCA\u5728\u6781\u7aef\u548c\u5f02\u8d28\u566a\u58f0\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7a33\u5b9a\u6027\u3002", "conclusion": "FedGSCA\u9002\u7528\u4e8e\u5b9e\u9645\u533b\u7597\u8054\u90a6\u5b66\u4e60\u573a\u666f\uff0c\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u566a\u58f0\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "keywords": "\u8054\u90a6\u5b66\u4e60, \u533b\u7597\u56fe\u50cf\u5206\u7c7b, \u6807\u7b7e\u566a\u58f0, \u566a\u58f0\u5f02\u8d28\u6027, \u6570\u636e\u4e0d\u5e73\u8861"}}
{"id": "2507.10920", "pdf": "https://arxiv.org/pdf/2507.10920", "abs": "https://arxiv.org/abs/2507.10920", "authors": ["Seungho Choi"], "title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) often show poor performance in low-resource\nlanguages like Korean, partly due to unique linguistic challenges such as\nhomophonous Sino-Korean words that are indistinguishable in Hangul script. To\naddress this semantic ambiguity, we propose HanjaBridge, a novel\nmeaning-injection technique integrated into a continual pre-training (CPT)\nframework. Instead of deterministically mapping a word to a single Hanja\n(Chinese character), HanjaBridge presents the model with all possible Hanja\ncandidates for a given homograph, encouraging the model to learn contextual\ndisambiguation. This process is paired with token-level knowledge distillation\nto prevent catastrophic forgetting. Experimental results show that HanjaBridge\nsignificantly improves Korean language understanding, achieving a 21\\% relative\nimprovement on the KoBALT benchmark. Notably, by reinforcing semantic alignment\nbetween Korean and Chinese through shared Hanja, we observe a strong positive\ncross-lingual transfer. Furthermore, these gains persist even when Hanja\naugmentation is omitted at inference time, ensuring practical efficiency with\nno additional run-time cost.", "AI": {"tldr": "HanjaBridge\u901a\u8fc7\u5f15\u5165\u6c49\u8bed\u5b57\u7b26\uff08Hanja\uff09\u6765\u89e3\u51b3\u97e9\u8bed\u4e2d\u7684\u540c\u97f3\u5f02\u4e49\u8bcd\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u6301\u7eed\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u97e9\u8bed\uff09\u7684\u8868\u73b0\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u8de8\u8bed\u8a00\u7684\u6b63\u9762\u8fc1\u79fb\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u97e9\u8bed\uff09\u4e2d\u56e0\u540c\u97f3\u5f02\u4e49\u8bcd\u7b49\u72ec\u7279\u8bed\u8a00\u6311\u6218\u5bfc\u81f4\u7684\u6027\u80fd\u4e0d\u4f73\u95ee\u9898\u3002", "method": "\u63d0\u51faHanjaBridge\u6280\u672f\uff0c\u901a\u8fc7\u4e3a\u540c\u97f3\u8bcd\u63d0\u4f9b\u6240\u6709\u53ef\u80fd\u7684\u6c49\u8bed\u5b57\u7b26\u5019\u9009\uff0c\u7ed3\u5408\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728KoBALT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u76f8\u5bf9\u63d0\u534721%\uff0c\u5e76\u89c2\u5bdf\u5230\u4e2d\u97e9\u8de8\u8bed\u8a00\u7684\u6b63\u9762\u8fc1\u79fb\u3002", "conclusion": "HanjaBridge\u4e0d\u4ec5\u63d0\u5347\u4e86\u97e9\u8bed\u7406\u89e3\u80fd\u529b\uff0c\u8fd8\u65e0\u9700\u63a8\u7406\u65f6\u989d\u5916\u6210\u672c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u4f4e\u8d44\u6e90\u8bed\u8a00, \u540c\u97f3\u5f02\u4e49\u8bcd, HanjaBridge, \u6301\u7eed\u9884\u8bad\u7ec3"}}
{"id": "2507.10803", "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u53ef\u4f5c\u4e3a\u4e13\u5bb6\u9a71\u52a8\u7684\u4e3b\u9898\u5206\u6790\u7684\u53ef\u6269\u5c55\u8865\u5145\u3002", "motivation": "\u63a2\u8ba8LLMs\u5728\u9700\u8981\u6df1\u5ea6\u89e3\u91ca\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u793e\u4f1a\u5a92\u4f53\u6570\u636e\u4e3b\u9898\u5206\u6790\u4e2d\u7684\u53ef\u884c\u6027\u3002", "method": "\u901a\u8fc7\u4e8c\u5143\u5206\u7c7b\u4efb\u52a1\u8bc4\u4f30\u4e94\u4e2aLLMs\uff0c\u91c7\u7528\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u548c\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u6bd4\u8f83\u5176\u4e0e\u4e13\u5bb6\u7f16\u7801\u7684\u6027\u80fd\u3002", "result": "GPT-4o\u5728\u5c11\u6837\u672c\u63d0\u793a\u4e0b\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u738790.9%\uff0cF1\u5206\u65700.71\uff09\uff0c\u9ad8\u6d41\u884c\u4e3b\u9898\u7684\u5206\u6790\u7ed3\u679c\u4e0e\u4e13\u5bb6\u5206\u7c7b\u63a5\u8fd1\u3002", "conclusion": "\u5c11\u6837\u672cLLM\u65b9\u6cd5\u53ef\u81ea\u52a8\u5316\u4e3b\u9898\u5206\u6790\uff0c\u4e3a\u5b9a\u6027\u7814\u7a76\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u8f85\u52a9\u5de5\u5177\u3002", "keywords": "\u4e3b\u9898\u5206\u6790\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u5b9a\u6027\u5206\u6790\u3001\u793e\u4ea4\u5a92\u4f53\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u516c\u5171\u536b\u751f"}}
{"id": "2507.10613", "pdf": "https://arxiv.org/pdf/2507.10613", "abs": "https://arxiv.org/abs/2507.10613", "authors": ["Zhengyu Chen", "Siqi Wang", "Teng Xiao", "Yudong Wang", "Shiqi Chen", "Xunliang Cai", "Junxian He", "Jingang Wang"], "title": "Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional scaling laws in natural language processing suggest that\nincreasing model size and training data enhances performance. However, recent\nstudies reveal deviations, particularly in large language models, where\nperformance improvements decelerate, which is a phenomenon known as\nsub-scaling. This paper revisits these scaling laws by examining the impact of\ndata quality and training strategies on model performance. Through extensive\nempirical analysis of over 400 models, we identify high data density and\nnon-optimal resource allocation as key factors contributing to sub-scaling.\nHigh data density leads to diminishing returns due to redundant information,\nwhile optimal resource allocation is crucial for sustained performance\nimprovements. We propose a sub-optimal scaling law that better predicts\nperformance in sub-scaling regimes, highlighting the importance of data quality\nand diversity.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u4f20\u7edf\u7f29\u653e\u5b9a\u5f8b\uff0c\u53d1\u73b0\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6027\u80fd\u63d0\u5347\u51cf\u901f\u7684\u73b0\u8c61\uff08\u5373\u5b50\u7f29\u653e\uff09\uff0c\u5e76\u63d0\u51fa\u6570\u636e\u8d28\u91cf\u548c\u5206\u914d\u7b56\u7565\u662f\u5173\u952e\u56e0\u7d20\u3002\u901a\u8fc7\u5206\u6790400\u591a\u4e2a\u6a21\u578b\uff0c\u63d0\u51fa\u65b0\u7684\u5b50\u7f29\u653e\u5b9a\u5f8b\u3002", "motivation": "\u4f20\u7edf\u7f29\u653e\u5b9a\u5f8b\u8ba4\u4e3a\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u548c\u6570\u636e\u91cf\u53ef\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u8fd1\u671f\u7814\u7a76\u53d1\u73b0\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u6027\u80fd\u63d0\u5347\u51cf\u901f\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u6570\u636e\u8d28\u91cf\u548c\u8bad\u7ec3\u7b56\u7565\u5bf9\u5b50\u7f29\u653e\u73b0\u8c61\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5bf9400\u591a\u4e2a\u6a21\u578b\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u7814\u7a76\u4e86\u6570\u636e\u5bc6\u5ea6\u548c\u8d44\u6e90\u5206\u914d\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u9ad8\u6570\u636e\u5bc6\u5ea6\u548c\u6b21\u4f18\u8d44\u6e90\u5206\u914d\u662f\u5bfc\u81f4\u5b50\u7f29\u653e\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u66f4\u597d\u9884\u6d4b\u5b50\u7f29\u653e\u6027\u80fd\u7684\u65b0\u5b9a\u5f8b\u3002", "conclusion": "\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u65b0\u7684\u5b50\u7f29\u653e\u5b9a\u5f8b\u4e3a\u4f18\u5316\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "keywords": "\u7f29\u653e\u5b9a\u5f8b, \u5b50\u7f29\u653e, \u6570\u636e\u8d28\u91cf, \u8d44\u6e90\u5206\u914d, \u8bed\u8a00\u6a21\u578b"}}
{"id": "2507.10957", "pdf": "https://arxiv.org/pdf/2507.10957", "abs": "https://arxiv.org/abs/2507.10957", "authors": ["Kalit Inani", "Keshav Kabra", "Vijay Marupudi", "Sashank Varma"], "title": "Modeling Understanding of Story-Based Analogies Using Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "To appear at CogSci 2025", "summary": "Recent advancements in Large Language Models (LLMs) have brought them closer\nto matching human cognition across a variety of tasks. How well do these models\nalign with human performance in detecting and mapping analogies? Prior research\nhas shown that LLMs can extract similarities from analogy problems but lack\nrobust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the\ncurrent study focused on a story-based analogical mapping task and conducted a\nfine-grained evaluation of LLM reasoning abilities compared to human\nperformance. First, it explored the semantic representation of analogies in\nLLMs, using sentence embeddings to assess whether they capture the similarity\nbetween the source and target texts of an analogy, and the dissimilarity\nbetween the source and distractor texts. Second, it investigated the\neffectiveness of explicitly prompting LLMs to explain analogies. Throughout, we\nexamine whether LLMs exhibit similar performance profiles to those observed in\nhumans by evaluating their reasoning at the level of individual analogies, and\nnot just at the level of overall accuracy (as prior studies have done). Our\nexperiments include evaluating the impact of model size (8B vs. 70B parameters)\nand performance variation across state-of-the-art model architectures such as\nGPT-4 and LLaMA3. This work advances our understanding of the analogical\nreasoning abilities of LLMs and their potential as models of human reasoning.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7c7b\u6bd4\u63a8\u7406\u4efb\u52a1\u4e2d\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u5bf9\u6bd4\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u8bed\u4e49\u8868\u5f81\u548c\u63d0\u793a\u89e3\u91ca\u7684\u6548\u679c\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\u7684\u8868\u73b0\u3002", "motivation": "\u8bc4\u4f30LLMs\u5728\u7c7b\u6bd4\u63a8\u7406\u4efb\u52a1\u4e2d\u662f\u5426\u80fd\u591f\u8fbe\u5230\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u8bed\u4e49\u7406\u89e3\u548c\u89e3\u91ca\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u6545\u4e8b\u7c7b\u6bd4\u4efb\u52a1\uff0c\u4f7f\u7528\u53e5\u5b50\u5d4c\u5165\u8bc4\u4f30\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u5e76\u6d4b\u8bd5\u663e\u5f0f\u63d0\u793a\u5bf9LLM\u89e3\u91ca\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\uff08\u5982GPT-4\u548cLLaMA3\uff09\u7684\u8868\u73b0\u3002", "result": "LLMs\u5728\u7c7b\u6bd4\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e00\u5b9a\u80fd\u529b\uff0c\u4f46\u5728\u8bed\u4e49\u7406\u89e3\u548c\u89e3\u91ca\u65b9\u9762\u4e0e\u4eba\u7c7b\u4ecd\u6709\u5dee\u8ddd\uff0c\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "LLMs\u5728\u7c7b\u6bd4\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5c1a\u672a\u5b8c\u5168\u5339\u914d\u4eba\u7c7b\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5c40\u9650\u6027\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u7c7b\u6bd4\u63a8\u7406, \u8bed\u4e49\u8868\u5f81, \u4eba\u7c7b\u8ba4\u77e5, GPT-4, LLaMA3"}}
{"id": "2507.10831", "pdf": "https://arxiv.org/pdf/2507.10831", "abs": "https://arxiv.org/abs/2507.10831", "authors": ["Yilin Xia", "Heng Zheng", "Shawn Bowers", "Bertram Lud\u00e4scher"], "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks", "categories": ["cs.AI"], "comment": "International Conference on Artificial Intelligence and Law (ICAIL),\n  June 16-20, 2025. Chicago, IL, USA", "summary": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning,\nbut identifying sources of ambiguity and explaining argument acceptance remains\nchallenging for non-experts. We present AF-XRAY, an open-source toolkit for\nexploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY\nintroduces: (i) layered visualizations based on game-theoretic argument length\nrevealing well-founded derivation structures; (ii) classification of attack\nedges by semantic roles (primary, secondary, blunders); (iii) overlay\nvisualizations of alternative 2-valued solutions on ambiguous 3-valued grounded\nsemantics; and (iv) identification of critical attack sets whose suspension\nresolves undecided arguments. Through systematic generation of critical attack\nsets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling\nusers to pinpoint specific causes of ambiguity and explore alternative\nresolutions. We use real-world legal cases (e.g., Wild Animals as modeled by\nBench-Capon) to show that our tool supports teleological legal reasoning by\nrevealing how different assumptions lead to different justified conclusions.", "AI": {"tldr": "AF-XRAY\u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u63a2\u7d22\u3001\u5206\u6790\u548c\u53ef\u89c6\u5316\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff0c\u5e2e\u52a9\u975e\u4e13\u5bb6\u7406\u89e3\u8bba\u8bc1\u63a5\u53d7\u548c\u6a21\u7cca\u6027\u7684\u6765\u6e90\u3002", "motivation": "\u5728\u6cd5\u5f8b\u63a8\u7406\u4e2d\uff0c\u8bba\u8bc1\u6846\u67b6\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u5b58\u5728\u6a21\u7cca\u6027\u89e3\u91ca\u548c\u8bba\u8bc1\u63a5\u53d7\u95ee\u9898\uff0cAF-XRAY\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "AF-XRAY\u63d0\u4f9b\u5206\u5c42\u53ef\u89c6\u5316\u3001\u653b\u51fb\u8fb9\u5206\u7c7b\u3001\u91cd\u53e0\u53ef\u89c6\u5316\u548c\u5173\u952e\u653b\u51fb\u96c6\u8bc6\u522b\u7b49\u529f\u80fd\u3002", "result": "\u5de5\u5177\u80fd\u5c06\u6a21\u7cca\u573a\u666f\u8f6c\u5316\u4e3a\u660e\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63ed\u793a\u4e0d\u540c\u5047\u8bbe\u5bfc\u81f4\u7684\u7ed3\u8bba\u5dee\u5f02\u3002", "conclusion": "AF-XRAY\u652f\u6301\u76ee\u7684\u8bba\u6cd5\u5f8b\u63a8\u7406\uff0c\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u8bba\u8bc1\u7684\u6a21\u7cca\u6027\u548c\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u8bba\u8bc1\u6846\u67b6,\u6cd5\u5f8b\u63a8\u7406,\u53ef\u89c6\u5316,\u5f00\u6e90\u5de5\u5177,\u6a21\u7cca\u6027"}}
{"id": "2507.10614", "pdf": "https://arxiv.org/pdf/2507.10614", "abs": "https://arxiv.org/abs/2507.10614", "authors": ["Fei Liu", "Rui Zhang", "Xi Lin", "Zhichao Lu", "Qingfu Zhang"], "title": "Fine-tuning Large Language Model for Automated Algorithm Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The integration of large language models (LLMs) into automated algorithm\ndesign has shown promising potential. A prevalent approach embeds LLMs within\nsearch routines to iteratively generate and refine candidate algorithms.\nHowever, most existing methods rely on off-the-shelf LLMs trained for general\ncoding tasks,leaving a key question open: Do we need LLMs specifically tailored\nfor algorithm design? If so, how can such LLMs be effectively obtained and how\nwell can they generalize across different algorithm design tasks? In this\npaper, we take a first step toward answering these questions by exploring\nfine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank\nbased (DAR) sampling strategy to balance training data diversity and quality,\nthen we leverage direct preference optimization to efficiently align LLM\noutputs with task objectives. Our experiments, conducted on\nLlama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm\ndesign tasks. Results suggest that finetuned LLMs can significantly outperform\ntheir off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and\nmatch the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover,\nwe observe promising generalization: LLMs finetuned on specific algorithm\ndesign tasks also improve performance on related tasks with varying settings.\nThese findings highlight the value of task-specific adaptation for LLMs in\nalgorithm design and open new avenues for future research.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u7b97\u6cd5\u8bbe\u8ba1\u5b9a\u5236\u5316\u5fae\u8c03\u7684\u5fc5\u8981\u6027\u548c\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6837\u6027\u611f\u77e5\u7684\u91c7\u6837\u7b56\u7565\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5fae\u8c03\u540e\u7684LLMs\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u901a\u7528\u8bad\u7ec3\u7684LLMs\uff0c\u672a\u9488\u5bf9\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u8fdb\u884c\u4f18\u5316\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5b9a\u5236\u5316LLMs\u7684\u9700\u6c42\u4e0e\u5b9e\u73b0\u8def\u5f84\u3002", "method": "\u5f15\u5165Diversity-Aware Rank\uff08DAR\uff09\u91c7\u6837\u7b56\u7565\u5e73\u8861\u8bad\u7ec3\u6570\u636e\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf\uff0c\u5e76\u5229\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u5bf9\u9f50LLMs\u8f93\u51fa\u4e0e\u4efb\u52a1\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5fae\u8c03\u540e\u7684LLMs\u5728\u591a\u4e2a\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u540c\u65f6\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u5bf9LLMs\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, \u7b97\u6cd5\u8bbe\u8ba1, \u5fae\u8c03, \u591a\u6837\u6027\u611f\u77e5\u91c7\u6837, \u76f4\u63a5\u504f\u597d\u4f18\u5316"}}
{"id": "2507.10958", "pdf": "https://arxiv.org/pdf/2507.10958", "abs": "https://arxiv.org/abs/2507.10958", "authors": ["Anthony Miyaguchi", "David Guecha", "Yuwen Chiu", "Sidharth Gaur"], "title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models", "categories": ["cs.CL"], "comment": null, "summary": "This Working Note summarizes the participation of the DS@GT team in two eRisk\n2025 challenges. For the Pilot Task on conversational depression detection with\nlarge language-models (LLMs), we adopted a prompt-engineering strategy in which\ndiverse LLMs conducted BDI-II-based assessments and produced structured JSON\noutputs. Because ground-truth labels were unavailable, we evaluated cross-model\nagreement and internal consistency. Our prompt design methodology aligned model\noutputs with BDI-II criteria and enabled the analysis of conversational cues\nthat influenced the prediction of symptoms. Our best submission, second on the\nofficial leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.", "AI": {"tldr": "DS@GT\u56e2\u961f\u53c2\u4e0e\u4e86eRisk 2025\u7684\u4e24\u9879\u6311\u6218\uff0c\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u5229\u7528LLMs\u8fdb\u884cBDI-II\u8bc4\u4f30\uff0c\u5e76\u5206\u6790\u4e86\u5bf9\u8bdd\u7ebf\u7d22\u5bf9\u9884\u6d4b\u75c7\u72b6\u7684\u5f71\u54cd\u3002\u6700\u4f73\u63d0\u4ea4\u6210\u7ee9\u4e3aDCHR = 0.50, ADODL = 0.89, ASHR = 0.27\u3002", "motivation": "\u7814\u7a76\u76ee\u7684\u662f\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u8fdb\u884c\u5bf9\u8bdd\u5f0f\u6291\u90c1\u75c7\u68c0\u6d4b\uff0c\u63a2\u7d22\u63d0\u793a\u5de5\u7a0b\u8bbe\u8ba1\u5bf9\u6a21\u578b\u8bc4\u4f30\u7684\u4f18\u5316\u6548\u679c\u3002", "method": "\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u5229\u7528\u591a\u79cdLLMs\u8fdb\u884cBDI-II\u8bc4\u4f30\uff0c\u751f\u6210\u7ed3\u6784\u5316JSON\u8f93\u51fa\uff0c\u5e76\u901a\u8fc7\u4ea4\u53c9\u6a21\u578b\u4e00\u81f4\u6027\u548c\u5185\u90e8\u4e00\u81f4\u6027\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u63d0\u4ea4\u6210\u7ee9\u5728\u5b98\u65b9\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c\u4e8c\uff0c\u6307\u6807\u4e3aDCHR = 0.50, ADODL = 0.89, ASHR = 0.27\u3002", "conclusion": "\u63d0\u793a\u5de5\u7a0b\u8bbe\u8ba1\u80fd\u6709\u6548\u4f18\u5316LLMs\u5728\u6291\u90c1\u75c7\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6\u5206\u6790\u4e86\u5bf9\u8bdd\u7ebf\u7d22\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "keywords": "eRisk 2025, \u6291\u90c1\u75c7\u68c0\u6d4b, LLMs, \u63d0\u793a\u5de5\u7a0b, BDI-II\u8bc4\u4f30"}}
{"id": "2507.10894", "pdf": "https://arxiv.org/pdf/2507.10894", "abs": "https://arxiv.org/abs/2507.10894", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faNavComposer\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u5bfc\u822a\u6307\u4ee4\uff0c\u5e76\u5f15\u5165NavInstrCritic\u8bc4\u4f30\u7cfb\u7edf\uff0c\u89e3\u51b3\u5927\u8303\u56f4\u7814\u7a76\u4e2d\u7684\u6307\u4ee4\u8d28\u91cf\u548c\u8bc4\u4f30\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4e13\u5bb6\u6307\u4ee4\u6570\u91cf\u6709\u9650\uff0c\u5408\u6210\u6ce8\u91ca\u8d28\u91cf\u4e0d\u8db3\uff0c\u96be\u4ee5\u652f\u6491\u5927\u89c4\u6a21\u7814\u7a76\u3002", "method": "NavComposer\u5206\u89e3\u8bed\u4e49\u5b9e\u4f53\u5e76\u91cd\u7ec4\u4e3a\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u652f\u6301\u6a21\u5757\u5316\u96c6\u6210\u5148\u8fdb\u6280\u672f\uff1bNavInstrCritic\u4ee5\u65e0\u6ce8\u91ca\u65b9\u5f0f\u8bc4\u4f30\u6307\u4ee4\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u6709\u6548\uff0c\u63d0\u5347\u4e86\u6307\u4ee4\u7684\u4e30\u5bcc\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u65b9\u6cd5\u89e3\u8026\u6307\u4ee4\u751f\u6210\u4e0e\u8bc4\u4f30\uff0c\u652f\u6301\u66f4\u53ef\u6269\u5c55\u548c\u901a\u7528\u7684\u7814\u7a76\u3002", "keywords": "language-guided navigation, NavComposer, NavInstrCritic, semantic entities, annotation-free evaluation"}}
{"id": "2507.10616", "pdf": "https://arxiv.org/pdf/2507.10616", "abs": "https://arxiv.org/abs/2507.10616", "authors": ["Neel Rajani", "Aryo Pradipta Gema", "Seraphina Goldfarb-Tarrant", "Ivan Titov"], "title": "Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Training large language models (LLMs) for reasoning via maths and code\ndatasets has become a major new focus in LLM post-training. Two particularly\npopular approaches are reinforcement learning (RL) and supervised fine-tuning\n(SFT), but their training dynamics are poorly understood. We present a\ncomparative analysis of RL and SFT on the same maths problems with the same\nmodel and similar hyperparameters. We find that RL yields minor in-domain gains\non maths and slight degradation on knowledge-intensive benchmarks like MMLU,\nwhile both trends are more pronounced in SFT. We also analyse model parameters\nacross checkpoints, observing that both algorithms modify query and key weights\nthe most. Meanwhile, SFT exhibits greater updates and also affects mid-layer\nMLPs more, leading us to hypothesise that this may have caused the\nout-of-domain degradation. We therefore investigate whether freezing parts of\nthe model during training can mitigate the reduced performance on\nknowledge-intensive benchmarks. However, our results are inconclusive, with\nbenefits on GPQA:Diamond and degradation on other benchmarks. Taken together,\nour observations provide a preliminary indication for why RL amplifies existing\ncapabilities, while SFT replaces old skills with new ones.", "AI": {"tldr": "\u5bf9\u6bd4\u5206\u6790\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u6570\u5b66\u95ee\u9898\u548c\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0RL\u5728\u6570\u5b66\u9886\u57df\u6709\u8f7b\u5fae\u63d0\u5347\uff0c\u800cSFT\u8868\u73b0\u66f4\u660e\u663e\u4f46\u53ef\u80fd\u5bfc\u81f4\u5176\u4ed6\u9886\u57df\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76RL\u548cSFT\u5728\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65f6\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e24\u79cd\u65b9\u6cd5\u7684\u4e0d\u540c\u52a8\u6001\u53ca\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5728\u76f8\u540c\u6570\u5b66\u95ee\u9898\u548c\u8d85\u53c2\u6570\u4e0b\u6bd4\u8f83RL\u548cSFT\u7684\u8868\u73b0\uff0c\u5206\u6790\u6a21\u578b\u53c2\u6570\u53d8\u5316\uff0c\u5e76\u5c1d\u8bd5\u51bb\u7ed3\u90e8\u5206\u6a21\u578b\u4ee5\u7f13\u89e3\u6027\u80fd\u4e0b\u964d\u3002", "result": "RL\u5728\u6570\u5b66\u9886\u57df\u6709\u5fae\u5c0f\u63d0\u5347\uff0cSFT\u5728\u6570\u5b66\u8868\u73b0\u66f4\u663e\u8457\u4f46\u53ef\u80fd\u5bfc\u81f4\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\uff1b\u53c2\u6570\u51bb\u7ed3\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002", "conclusion": "RL\u53ef\u80fd\u653e\u5927\u73b0\u6709\u80fd\u529b\uff0c\u800cSFT\u5219\u53ef\u80fd\u7528\u65b0\u6280\u80fd\u66ff\u4ee3\u65e7\u6280\u80fd\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b\u3001\u5f3a\u5316\u5b66\u4e60\u3001\u76d1\u7763\u5fae\u8c03\u3001\u6570\u5b66\u63a8\u7406\u3001\u6027\u80fd\u5206\u6790"}}
{"id": "2507.10972", "pdf": "https://arxiv.org/pdf/2507.10972", "abs": "https://arxiv.org/abs/2507.10972", "authors": ["Zhaoyi An", "Rei Kawakami"], "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production", "categories": ["cs.CL", "cs.CV", "cs.MM"], "comment": "Accepted by IEEE ICIP 2025", "summary": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTEAM-Sign\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06\u624b\u8bed\u89c6\u4e3a\u53e6\u4e00\u79cd\u81ea\u7136\u8bed\u8a00\uff0c\u89e3\u51b3\u4e86\u624b\u8bed\u751f\u6210\u7684\u590d\u6742\u6027\u548c\u72ec\u7279\u6027\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u624b\u8bed\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u5f25\u8865\u73b0\u6709\u7814\u7a76\u4e2d\u624b\u8bed\u751f\u6210\u53d7\u9650\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u9010\u6b65\u63d0\u793a\u7b56\u7565\u5fae\u8c03LLM\uff0c\u5b66\u4e60\u6587\u672c\u4e0e\u624b\u8bed\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u7ed3\u5408\u624b\u8bed\u4e0e\u53e3\u8bed\u7684\u5dee\u5f02\u4f18\u5316\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728How2Sign\u548cPhoenix14T\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTEAM-Sign\u80fd\u6709\u6548\u5229\u7528LLM\u7684\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5bf9\u9f50\u624b\u8bed\u4e0e\u53e3\u8bed\u7684\u5206\u5e03\u548c\u8bed\u6cd5\u89c4\u5219\u3002", "conclusion": "TEAM-Sign\u901a\u8fc7LLM\u7684\u5fae\u8c03\u548c\u7b56\u7565\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u624b\u8bed\u751f\u6210\u7684\u8868\u73b0\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b,\u624b\u8bed\u751f\u6210,\u9010\u6b65\u63d0\u793a,\u5206\u5e03\u5bf9\u9f50,\u8bed\u6cd5\u89c4\u5219"}}
{"id": "2507.10911", "pdf": "https://arxiv.org/pdf/2507.10911", "abs": "https://arxiv.org/abs/2507.10911", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u5728\u591a\u75c5\u75c7\u6162\u6027\u60a3\u8005\u6cbb\u7597\u63a8\u8350\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\uff0c\u7ed3\u679c\u663e\u793a\u5355\u4e00\u4ee3\u7406GP\u8868\u73b0\u4e0e\u591a\u5b66\u79d1\u56e2\u961f\uff08MDT\uff09\u76f8\u5f53\uff0c\u4f46\u5efa\u8bae\u5b58\u5728\u4e0d\u5b8c\u6574\u548c\u4e0d\u5fc5\u8981\u7684\u7528\u836f\u95ee\u9898\u3002", "motivation": "\u591a\u75c5\u75c7\u6162\u6027\u60a3\u8005\u7684\u6cbb\u7597\u63a8\u8350\u7531\u4e8e\u6cbb\u7597\u51b2\u7a81\u7684\u98ce\u9669\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5b58\u5728\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30LLM-MAS\u6a21\u62dfMDT\u51b3\u7b56\u7684\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u5355\u4e00\u4ee3\u7406\u548c\u591a\u4ee3\u7406\u6846\u67b6\uff08MAS\uff09\uff0c\u6a21\u62dfMDT\u51b3\u7b56\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u95f4\u7684\u8ba8\u8bba\u89e3\u51b3\u533b\u5b66\u51b2\u7a81\u3002\u7cfb\u7edf\u5728\u591a\u75c5\u75c7\u60a3\u8005\u7684\u6cbb\u7597\u89c4\u5212\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5355\u4e00\u4ee3\u7406\u65b9\u6cd5\u548c\u771f\u5b9e\u57fa\u51c6\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u5f53\u524dLLM\u4e0b\uff0c\u5355\u4e00\u4ee3\u7406GP\u8868\u73b0\u4e0eMDT\u76f8\u5f53\u3002\u6700\u4f73\u6a21\u578b\u63d0\u4f9b\u4e86\u6ee1\u8db3\u6240\u6709\u4e34\u5e8a\u76ee\u6807\u7684\u6b63\u786e\u5efa\u8bae\uff0c\u4f46\u5efa\u8bae\u4e0d\u5b8c\u6574\uff0c\u90e8\u5206\u6a21\u578b\u8fd8\u63d0\u51fa\u4e86\u4e0d\u5fc5\u8981\u7684\u7528\u836f\uff0c\u5bfc\u81f4\u51b2\u7a81\u3002", "conclusion": "LLM-MAS\u5728\u591a\u75c5\u75c7\u6cbb\u7597\u63a8\u8350\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u5efa\u8bae\u7684\u5b8c\u6574\u6027\u548c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u7528\u836f\u3002", "keywords": "\u6162\u6027\u75c5,\u591a\u75c5\u75c7,\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u591a\u4ee3\u7406\u7cfb\u7edf,\u6cbb\u7597\u63a8\u8350"}}
{"id": "2507.10618", "pdf": "https://arxiv.org/pdf/2507.10618", "abs": "https://arxiv.org/abs/2507.10618", "authors": ["Peter Barnett"], "title": "Compute Requirements for Algorithmic Innovation in Frontier AI Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Algorithmic innovation in the pretraining of large language models has driven\na massive reduction in the total compute required to reach a given level of\ncapability. In this paper we empirically investigate the compute requirements\nfor developing algorithmic innovations. We catalog 36 pre-training algorithmic\ninnovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate\nboth the total FLOP used in development and the FLOP/s of the hardware\nutilized. Innovations using significant resources double in their requirements\neach year. We then use this dataset to investigate the effect of compute caps\non innovation. Our analysis suggests that compute caps alone are unlikely to\ndramatically slow AI algorithmic progress. Even stringent compute caps -- such\nas capping total operations to the compute used to train GPT-2 or capping\nhardware capacity to 8 H100 GPUs -- could still have allowed for half of the\ncataloged innovations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5b9e\u8bc1\u7814\u7a76\u4e86\u5f00\u53d1\u7b97\u6cd5\u521b\u65b0\u6240\u9700\u7684\u603b\u8ba1\u7b97\u8d44\u6e90\uff0c\u901a\u8fc7\u5bf936\u79cd\u9884\u8bad\u7ec3\u7b97\u6cd5\u521b\u65b0\u7684\u5206\u6790\uff0c\u53d1\u73b0\u521b\u65b0\u6240\u9700\u7684\u8d44\u6e90\u968f\u65f6\u95f4\u7ffb\u500d\u3002\u8ba1\u7b97\u9650\u5236\u5bf9\u7b97\u6cd5\u8fdb\u6b65\u7684\u5f71\u54cd\u8f83\u5c0f\u3002", "motivation": "\u7814\u7a76\u7b97\u6cd5\u521b\u65b0\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ee5\u53ca\u8ba1\u7b97\u9650\u5236\u5bf9\u521b\u65b0\u7684\u6f5c\u5728\u5f71\u54cd\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u4e8636\u79cd\u9884\u8bad\u7ec3\u7b97\u6cd5\u521b\u65b0\u7684\u8ba1\u7b97\u8d44\u6e90\u4f7f\u7528\u60c5\u51b5\uff0c\u5305\u62ec\u603bFLOP\u548c\u786c\u4ef6FLOP/s\u3002\u901a\u8fc7\u6a21\u62df\u8ba1\u7b97\u9650\u5236\u6765\u8bc4\u4f30\u5176\u5bf9\u521b\u65b0\u7684\u5f71\u54cd\u3002", "result": "\u521b\u65b0\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u6bcf\u5e74\u7ffb\u500d\uff0c\u4f46\u8ba1\u7b97\u9650\u5236\uff08\u5982\u9650\u5236\u603b\u8ba1\u7b97\u91cf\u6216\u786c\u4ef6\u5bb9\u91cf\uff09\u4ecd\u5141\u8bb8\u534a\u6570\u521b\u65b0\u5b9e\u73b0\u3002", "conclusion": "\u8ba1\u7b97\u9650\u5236\u4e0d\u592a\u53ef\u80fd\u663e\u8457\u51cf\u7f13\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u8fdb\u6b65\u3002", "keywords": "\u7b97\u6cd5\u521b\u65b0\u3001\u8ba1\u7b97\u8d44\u6e90\u3001\u9884\u8bad\u7ec3\u3001\u5927\u8bed\u8a00\u6a21\u578b\u3001FLOP"}}
{"id": "2507.10996", "pdf": "https://arxiv.org/pdf/2507.10996", "abs": "https://arxiv.org/abs/2507.10996", "authors": ["Lin Tian", "Johanne R. Trippas", "Marian-Andrei Rizoiu"], "title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection", "categories": ["cs.CL"], "comment": "12 pages, 5 tables, CLEF 2025", "summary": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based\nsexism detection in English and Spanish tweets through hierarchical Low-Rank\nAdaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter\nrouting that explicitly models label dependencies across three hierarchically\nstructured subtasks: binary sexism identification, source intention detection,\nand multilabel sexism categorization. Unlike conventional LoRA applications\nthat target only attention layers, we apply adaptation to all linear\ntransformations, enhancing the model's capacity to capture task-specific\npatterns. In contrast to complex data processing and ensemble approaches, we\nshow that straightforward parameter-efficient fine-tuning achieves strong\nperformance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each\nsubtask using unified multilingual training that leverages Llama 3.1's native\nbilingual capabilities. The method requires minimal preprocessing and uses\nstandard supervised learning. Our multilingual training strategy eliminates the\nneed for separate language-specific models, achieving 1.7-2.4\\% F1 improvements\nthrough cross-lingual transfer. With only 1.67\\% trainable parameters compared\nto full fine-tuning, our approach reduces training time by 75\\% and model\nstorage by 98\\%, while achieving competitive performance across all subtasks\n(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,\n0.6519 for multilabel categorization).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u82f1\u8bed\u548c\u897f\u73ed\u7259\u8bed\u63a8\u6587\u4e2d\u7684\u6027\u522b\u6b67\u89c6\u3002\u901a\u8fc7\u6761\u4ef6\u9002\u914d\u5668\u8def\u7531\u548c\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u8bad\u7ec3\uff0c\u6a21\u578b\u5728\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u5b58\u50a8\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u6587\u672c\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u4e2d\u7684\u591a\u4efb\u52a1\u4f9d\u8d56\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u95ee\u9898\uff0c\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u3002", "method": "\u91c7\u7528LoRA\u6280\u672f\u5bf9Llama 3.1 8B\u6a21\u578b\u8fdb\u884c\u5206\u5c42\u9002\u914d\uff0c\u7ed3\u5408\u6761\u4ef6\u9002\u914d\u5668\u8def\u7531\u548c\u7edf\u4e00\u591a\u8bed\u8a00\u8bad\u7ec3\uff0c\u5206\u522b\u5904\u7406\u4e09\u4e2a\u5b50\u4efb\u52a1\u3002", "result": "\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e861.7-2.4%\u7684F1\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c11\u4e8675%\u7684\u8bad\u7ec3\u65f6\u95f4\u548c98%\u7684\u6a21\u578b\u5b58\u50a8\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u548c\u591a\u8bed\u8a00\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "keywords": "\u6027\u522b\u6b67\u89c6\u68c0\u6d4b, LoRA, \u591a\u8bed\u8a00\u5904\u7406, Llama 3.1, \u53c2\u6570\u9ad8\u6548\u5fae\u8c03"}}
{"id": "2507.10923", "pdf": "https://arxiv.org/pdf/2507.10923", "abs": "https://arxiv.org/abs/2507.10923", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "categories": ["cs.AI"], "comment": "Accepted at ACL 2025 (Main Conference)", "summary": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u5f15\u5bfc\u7684\u504f\u597d\u4f18\u5316\uff08KPO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u86cb\u767d\u8d28\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\uff0c\u51cf\u5c11\u751f\u6210\u6709\u5bb3\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u529f\u80fd\u6027\u3002", "motivation": "\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u5728\u529f\u80fd\u4f18\u5316\u548c\u4ece\u5934\u8bbe\u8ba1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u53ef\u80fd\u751f\u6210\u6709\u5bb3\u5e8f\u5217\uff08\u5982\u589e\u5f3a\u75c5\u6bd2\u4f20\u64ad\u6027\u6216\u9003\u907f\u514d\u75ab\u53cd\u5e94\u7684\u86cb\u767d\u8d28\uff09\uff0c\u5f15\u53d1\u751f\u7269\u5b89\u5168\u548c\u4f26\u7406\u95ee\u9898\u3002", "method": "KPO\u6846\u67b6\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u56fe\u526a\u679d\u7b56\u7565\u8bc6\u522b\u504f\u597d\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6700\u5c0f\u5316\u6709\u5bb3\u86cb\u767d\u8d28\u7684\u751f\u6210\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u8868\u660eKPO\u663e\u8457\u964d\u4f4e\u6709\u5bb3\u5e8f\u5217\u751f\u6210\u7684\u51e0\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u529f\u80fd\u9ad8\u6548\uff0c\u4e3a\u751f\u7269\u6280\u672f\u4e2d\u7684\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u5b89\u5168\u4fdd\u8bc1\u3002", "conclusion": "KPO\u4e3a\u89e3\u51b3\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u548c\u4f26\u7406\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u751f\u7269\u6280\u672f\u5e94\u7528\u3002", "keywords": "\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b, \u77e5\u8bc6\u56fe\u8c31, \u5f3a\u5316\u5b66\u4e60, \u751f\u7269\u5b89\u5168, \u529f\u80fd\u4f18\u5316"}}
{"id": "2507.10619", "pdf": "https://arxiv.org/pdf/2507.10619", "abs": "https://arxiv.org/abs/2507.10619", "authors": ["Oluwaseyi Giwa", "Tobi Awodunmila", "Muhammad Ahmed Mohsin", "Ahsan Bilal", "Muhammad Ali Jamshed"], "title": "Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks", "categories": ["cs.LG", "cs.AI", "cs.NI"], "comment": "5 pages, 6 figures, under review at IEEE Wireless Communications\n  Letters", "summary": "The dynamic allocation of spectrum in 5G / 6G networks is critical to\nefficient resource utilization. However, applying traditional deep\nreinforcement learning (DRL) is often infeasible due to its immense sample\ncomplexity and the safety risks associated with unguided exploration, which can\ncause severe network interference. To address these challenges, we propose a\nmeta-learning framework that enables agents to learn a robust initial policy\nand rapidly adapt to new wireless scenarios with minimal data. We implement\nthree meta-learning architectures, model-agnostic meta-learning (MAML),\nrecurrent neural network (RNN), and an attention-enhanced RNN, and evaluate\nthem against a non-meta-learning DRL algorithm, proximal policy optimization\n(PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB)\nenvironment. Our results show a clear performance gap. The attention-based\nmeta-learning agent reaches a peak mean network throughput of 48 Mbps, while\nthe PPO baseline decreased drastically to 10 Mbps. Furthermore, our method\nreduces SINR and latency violations by more than 50% compared to PPO. It also\nshows quick adaptation, with a fairness index 0.7, showing better resource\nallocation. This work proves that meta-learning is a very effective and safer\noption for intelligent control in complex wireless systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b35G/6G\u7f51\u7edc\u4e2d\u52a8\u6001\u9891\u8c31\u5206\u914d\u7684\u9ad8\u6837\u672c\u590d\u6742\u6027\u548c\u5b89\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u5feb\u901f\u9002\u5e94\u65b0\u573a\u666f\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57285G/6G\u9891\u8c31\u5206\u914d\u4e2d\u56e0\u9ad8\u6837\u672c\u590d\u6742\u6027\u548c\u63a2\u7d22\u98ce\u9669\u800c\u4e0d\u9002\u7528\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u5b89\u5168\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u5143\u5b66\u4e60\u67b6\u6784\uff08MAML\u3001RNN\u548c\u6ce8\u610f\u529b\u589e\u5f3aRNN\uff09\uff0c\u5e76\u5728\u4eff\u771fIAB\u73af\u5883\u4e2d\u4e0ePPO\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u6ce8\u610f\u529b\u5143\u5b66\u4e60\u4ee3\u7406\u5cf0\u503c\u541e\u5410\u91cf\u8fbe48 Mbps\uff0c\u8fdc\u9ad8\u4e8ePPO\u768410 Mbps\uff0c\u4e14SINR\u548c\u5ef6\u8fdf\u8fdd\u89c4\u51cf\u5c1150%\u4ee5\u4e0a\uff0c\u516c\u5e73\u6027\u6307\u6570\u4e3a0.7\u3002", "conclusion": "\u5143\u5b66\u4e60\u662f\u590d\u6742\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u667a\u80fd\u63a7\u5236\u7684\u6709\u6548\u4e14\u5b89\u5168\u7684\u9009\u62e9\u3002", "keywords": "5G/6G, \u52a8\u6001\u9891\u8c31\u5206\u914d, \u5143\u5b66\u4e60, \u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60, IAB"}}
{"id": "2507.11004", "pdf": "https://arxiv.org/pdf/2507.11004", "abs": "https://arxiv.org/abs/2507.11004", "authors": ["Yejun Yoon", "Jaeyoon Jung", "Seunghyun Yoon", "Kunwoo Park"], "title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification", "categories": ["cs.CL"], "comment": "ACL 2025 Workshop (FEVER)", "summary": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task\nat the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the\nbest-performing open-source model from the previous year's challenge. It\nimproves evidence quality through document summarization and answer\nreformulation, optimizes veracity prediction via post-training quantization\nunder computational constraints, and enhances overall system performance by\nintegrating updated language model (LM) backbones. HerO 2 ranked second on the\nleaderboard while achieving the shortest runtime among the top three systems,\ndemonstrating both high efficiency and strong potential for real-world fact\nverification. The code is available at https://github.com/ssu-humane/HerO2.", "AI": {"tldr": "HerO 2\u662fHUMANE\u56e2\u961f\u4e3aFEVER-25\u7814\u8ba8\u4f1aAVeriTeC\u5171\u4eab\u4efb\u52a1\u5f00\u53d1\u7684\u7cfb\u7edf\uff0c\u6539\u8fdb\u4e86\u8bc1\u636e\u8d28\u91cf\u548c\u9a8c\u8bc1\u9884\u6d4b\uff0c\u540c\u65f6\u4f18\u5316\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u63d0\u5347\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8ba1\u7b97\u9650\u5236\u3002", "method": "\u901a\u8fc7\u6587\u6863\u6458\u8981\u548c\u7b54\u6848\u91cd\u6784\u6539\u8fdb\u8bc1\u636e\u8d28\u91cf\uff0c\u91c7\u7528\u540e\u8bad\u7ec3\u91cf\u5316\u4f18\u5316\u9a8c\u8bc1\u9884\u6d4b\uff0c\u5e76\u96c6\u6210\u66f4\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u9aa8\u5e72\u3002", "result": "HerO 2\u5728\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c\u4e8c\uff0c\u540c\u65f6\u5728\u524d\u4e09\u540d\u7cfb\u7edf\u4e2d\u8fd0\u884c\u65f6\u95f4\u6700\u77ed\uff0c\u5c55\u793a\u4e86\u9ad8\u6548\u7387\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "HerO 2\u662f\u4e00\u4e2a\u9ad8\u6548\u4e14\u6027\u80fd\u5f3a\u5927\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002", "keywords": "HerO 2, \u4e8b\u5b9e\u9a8c\u8bc1, \u6587\u6863\u6458\u8981, \u540e\u8bad\u7ec3\u91cf\u5316, \u8bed\u8a00\u6a21\u578b"}}
{"id": "2507.10993", "pdf": "https://arxiv.org/pdf/2507.10993", "abs": "https://arxiv.org/abs/2507.10993", "authors": ["Emir Durakovic", "Min-Hong Shih"], "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "categories": ["cs.AI"], "comment": "This paper uses a lightly modified version of the AAAI 2025 LaTeX\n  style for formatting consistency. It is not a submission to AAAI and does not\n  include any AAAI-specific headers, footers, or metadata", "summary": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc(CNN)\u548c\u8868\u683c\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u536b\u661f\u56fe\u50cf\u548c\u73af\u5883\u7279\u5f81\u6765\u9884\u6d4b\u9e1f\u7c7b\u5728\u4e0d\u540c\u6c14\u5019\u4e2d\u7684\u5206\u5e03\u60c5\u51b5\uff0c\u51c6\u786e\u7387\u8fbe\u523085%\u3002", "motivation": "\u7531\u4e8e\u6c14\u5019\u53d8\u5316\u5bfc\u81f4\u6816\u606f\u5730\u8303\u56f4\u53d1\u751f\u53d8\u5316\uff0c\u4f20\u7edf\u7684\u5730\u7406\u4f4d\u7f6e\u5df2\u4e0d\u518d\u9002\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u9e1f\u7c7b\u5728\u4e0d\u540c\u6816\u606f\u5730\u7684\u5206\u5e03\u60c5\u51b5\u3002", "method": "\u7ed3\u5408CNN\uff08\u7528\u4e8e\u6355\u6349\u7a7a\u95f4\u7279\u5f81\u5982\u68ee\u6797\u3001\u6c34\u4f53\u548c\u57ce\u5e02\u5316\uff09\u548c\u8868\u683c\u6570\u636e\uff08\u4f7f\u7528\u751f\u6001\u548c\u5730\u7406\u6570\u636e\uff09\u6765\u5efa\u6a21\u9e1f\u7c7b\u7684\u5b58\u5728\u60c5\u51b5\u3002", "result": "\u4e24\u79cd\u7cfb\u7edf\u7684\u9884\u6d4b\u51c6\u786e\u7387\u5e73\u5747\u8fbe\u523085%\uff0c\u4e3a\u7406\u89e3\u9e1f\u7c7b\u8fc1\u5f99\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6c14\u5019\u53d8\u5316\u80cc\u666f\u4e0b\u7684\u9e1f\u7c7b\u5206\u5e03\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u9e1f\u7c7b\u5206\u5e03,\u5377\u79ef\u795e\u7ecf\u7f51\u7edc,\u6c14\u5019\u53d8\u5316,\u536b\u661f\u56fe\u50cf,\u751f\u6001\u6570\u636e"}}
{"id": "2507.10620", "pdf": "https://arxiv.org/pdf/2507.10620", "abs": "https://arxiv.org/abs/2507.10620", "authors": ["Chenxi Liu", "Hao Miao", "Cheng Long", "Yan Zhao", "Ziyue Li", "Panos Kalnis"], "title": "LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at SSTD 2025 (Tutorial). arXiv admin note: text overlap with\n  arXiv:2505.02583", "summary": "Large Language Models (LLMs) have emerged as a promising paradigm for time\nseries analytics, leveraging their massive parameters and the shared sequential\nnature of textual and time series data. However, a cross-modality gap exists\nbetween time series and textual data, as LLMs are pre-trained on textual\ncorpora and are not inherently optimized for time series. In this tutorial, we\nprovide an up-to-date overview of LLM-based cross-modal time series analytics.\nWe introduce a taxonomy that classifies existing approaches into three groups\nbased on cross-modal modeling strategies, e.g., conversion, alignment, and\nfusion, and then discuss their applications across a range of downstream tasks.\nIn addition, we summarize several open challenges. This tutorial aims to expand\nthe practical application of LLMs in solving real-world problems in cross-modal\ntime series analytics while balancing effectiveness and efficiency.\nParticipants will gain a thorough understanding of current advancements,\nmethodologies, and future research directions in cross-modal time series\nanalytics.", "AI": {"tldr": "LLMs\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u8de8\u6a21\u6001\u5dee\u5f02\u3002\u672c\u6559\u7a0b\u7efc\u8ff0\u4e86\u57fa\u4e8eLLM\u7684\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\uff0c\u5206\u7c7b\u4e3a\u8f6c\u6362\u3001\u5bf9\u9f50\u548c\u878d\u5408\u4e09\u7c7b\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5e94\u7528\u548c\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u5229\u7528LLMs\u7684\u5927\u53c2\u6570\u548c\u65f6\u5e8f\u4e0e\u6587\u672c\u6570\u636e\u7684\u5171\u4eab\u5e8f\u5217\u7279\u6027\uff0c\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u4e0e\u6587\u672c\u6570\u636e\u4e4b\u95f4\u7684\u8de8\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5206\u7c7b\u6cd5\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u8f6c\u6362\u3001\u5bf9\u9f50\u548c\u878d\u5408\u4e09\u7c7b\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u603b\u7ed3\u4e86\u5f53\u524d\u8fdb\u5c55\u3001\u65b9\u6cd5\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u65e8\u5728\u6269\u5c55LLMs\u5728\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "LLMs\u5728\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u5e73\u8861\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, \u65f6\u95f4\u5e8f\u5217\u5206\u6790, \u8de8\u6a21\u6001\u5b66\u4e60, \u8f6c\u6362, \u5bf9\u9f50, \u878d\u5408"}}
{"id": "2507.11049", "pdf": "https://arxiv.org/pdf/2507.11049", "abs": "https://arxiv.org/abs/2507.11049", "authors": ["Dahyun Lee", "Jonghyeon Choi", "Jiyoung Han", "Kunwoo Park"], "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "categories": ["cs.CL"], "comment": "Preprint. 24 pages", "summary": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u97e9\u8bed\u65b0\u95fb\u7acb\u573a\u68c0\u6d4b\u6570\u636e\u96c6K-News-Stance\u548c\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6846\u67b6JoA-ICL\uff0c\u7528\u4e8e\u68c0\u6d4b\u957f\u7bc7\u6587\u7ae0\u7684\u7acb\u573a\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u63d0\u5347\u65b0\u95fb\u63a8\u8350\u591a\u6837\u6027\u548c\u5206\u6790\u5a92\u4f53\u504f\u89c1\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u65b0\u95fb\u6d88\u8d39\u7684\u589e\u957f\uff0c\u4e2a\u6027\u5316\u63a8\u8350\u7cfb\u7edf\u53ef\u80fd\u52a0\u5267\u4fe1\u606f\u8327\u623f\u548c\u653f\u6cbb\u6781\u5316\u3002\u901a\u8fc7\u7acb\u573a\u68c0\u6d4b\u53ef\u4ee5\u7eb3\u5165\u66f4\u591a\u5143\u89c6\u89d2\uff0c\u51cf\u8f7b\u8fd9\u4e9b\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u63d0\u51faK-News-Stance\u6570\u636e\u96c6\u548cJoA-ICL\u6846\u67b6\uff0c\u540e\u8005\u5229\u7528\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u9884\u6d4b\u5173\u952e\u6bb5\u843d\u7684\u7acb\u573a\uff0c\u5e76\u805a\u5408\u63a8\u65ad\u5168\u6587\u7acb\u573a\u3002", "result": "JoA-ICL\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5206\u6bb5\u4ee3\u7406\u5728\u957f\u6587\u672c\u7acb\u573a\u68c0\u6d4b\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u5728\u6848\u4f8b\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u5206\u6bb5\u7acb\u573a\u68c0\u6d4b\u6846\u67b6JoA-ICL\u6709\u6548\u63d0\u5347\u4e86\u65b0\u95fb\u7acb\u573a\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u63a8\u8350\u7cfb\u7edf\u7684\u591a\u6837\u6027\u8bbe\u8ba1\u548c\u5a92\u4f53\u504f\u89c1\u5206\u6790\u3002", "keywords": "\u7acb\u573a\u68c0\u6d4b,\u97e9\u56fd\u65b0\u95fb,\u4e0a\u4e0b\u6587\u5b66\u4e60,\u8bed\u8a00\u6a21\u578b,\u5a92\u4f53\u504f\u89c1"}}
{"id": "2507.11060", "pdf": "https://arxiv.org/pdf/2507.11060", "abs": "https://arxiv.org/abs/2507.11060", "authors": ["Yilmazcan Ozyurt", "Tunaberk Almaci", "Stefan Feuerriegel", "Mrinmaya Sachan"], "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "categories": ["cs.AI"], "comment": null, "summary": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "AI": {"tldr": "ExRec\u662f\u4e00\u4e2a\u7ed3\u5408\u8bed\u4e49\u77e5\u8bc6\u8ffd\u8e2a\u7684\u4e2a\u6027\u5316\u4e60\u9898\u63a8\u8350\u6846\u67b6\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u6d41\u7a0b\u4f18\u5316\u63a8\u8350\u6548\u679c\uff0c\u5e76\u5728\u6570\u5b66\u5b66\u4e60\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u4e60\u9898\u63a8\u8350\u65b9\u6cd5\u5e38\u5ffd\u7565\u4e60\u9898\u7684\u8bed\u4e49\u5185\u5bb9\u548c\u5b66\u4e60\u7684\u7ed3\u6784\u5316\u8fdb\u5c55\uff0cExRec\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\uff0c\u5f15\u5165\u57fa\u4e8e\u6a21\u578b\u7684\u4f30\u503c\u4f30\u8ba1\uff08MVE\uff09\uff0c\u5e76\u4f18\u5316\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "result": "\u5728\u6570\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0cExRec\u8868\u73b0\u51fa\u5bf9\u65b0\u95ee\u9898\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u7684\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "\u77e5\u8bc6\u8ffd\u8e2a\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u6559\u80b2\u4e2a\u6027\u5316\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002", "keywords": "\u4e2a\u6027\u5316\u63a8\u8350, \u77e5\u8bc6\u8ffd\u8e2a, \u5f3a\u5316\u5b66\u4e60, \u8bed\u4e49\u5efa\u6a21"}}
{"id": "2507.10623", "pdf": "https://arxiv.org/pdf/2507.10623", "abs": "https://arxiv.org/abs/2507.10623", "authors": ["Daniel Saragih", "Deyu Cao", "Tejas Balaji"], "title": "Flows and Diffusions on the Neural Manifold", "categories": ["cs.LG", "cs.CV"], "comment": "40 pages, 6 figures, 13 tables", "summary": "Diffusion and flow-based generative models have achieved remarkable success\nin domains such as image synthesis, video generation, and natural language\nmodeling. In this work, we extend these advances to weight space learning by\nleveraging recent techniques to incorporate structural priors derived from\noptimization dynamics. Central to our approach is modeling the trajectory\ninduced by gradient descent as a trajectory inference problem. We unify several\ntrajectory inference techniques under the framework of gradient flow matching,\nproviding a theoretical framework for treating optimization paths as inductive\nbias. We further explore architectural and algorithmic choices, including\nreward fine-tuning by adjoint matching, the use of autoencoders for latent\nweight representation, conditioning on task-specific context data, and adopting\ninformative source distributions such as Kaiming uniform. Experiments\ndemonstrate that our method matches or surpasses baselines in generating\nin-distribution weights, improves initialization for downstream training, and\nsupports fine-tuning to enhance performance. Finally, we illustrate a practical\napplication in safety-critical systems: detecting harmful covariate shifts,\nwhere our method outperforms the closest comparable baseline.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u6269\u6563\u548c\u6d41\u6a21\u578b\u6269\u5c55\u5230\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\uff0c\u901a\u8fc7\u4f18\u5316\u52a8\u6001\u5f15\u5165\u7ed3\u6784\u5148\u9a8c\uff0c\u7edf\u4e00\u4e86\u8f68\u8ff9\u63a8\u65ad\u6280\u672f\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u5c06\u6269\u6563\u548c\u6d41\u6a21\u578b\u5728\u56fe\u50cf\u3001\u89c6\u9891\u548c\u81ea\u7136\u8bed\u8a00\u9886\u57df\u7684\u6210\u529f\u6269\u5c55\u5230\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\uff0c\u4ee5\u63d0\u9ad8\u6743\u91cd\u751f\u6210\u548c\u4f18\u5316\u7684\u6548\u679c\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u68af\u5ea6\u6d41\u5339\u914d\u6846\u67b6\u3001\u5956\u52b1\u5fae\u8c03\u3001\u6f5c\u5728\u6743\u91cd\u8868\u793a\u7684\u81ea\u52a8\u7f16\u7801\u5668\u3001\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u6761\u4ef6\u4ee5\u53ca\u4f7f\u7528Kaiming\u5747\u5300\u7b49\u6e90\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u751f\u6210\u6743\u91cd\u5206\u5e03\u4e0e\u57fa\u7ebf\u5339\u914d\u6216\u8d85\u8d8a\u7684\u80fd\u529b\uff0c\u4e0b\u6e38\u8bad\u7ec3\u521d\u59cb\u5316\u6539\u8fdb\uff0c\u4ee5\u53ca\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u7684\u534f\u53d8\u91cf\u504f\u79fb\u68c0\u6d4b\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u6846\u67b6\u4e3a\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7406\u8bba\u548c\u6280\u672f\u652f\u6301\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u52bf\u3002", "keywords": "\u6269\u6563\u6a21\u578b,\u6d41\u6a21\u578b,\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60,\u68af\u5ea6\u6d41\u5339\u914d,\u534f\u53d8\u91cf\u504f\u79fb"}}
{"id": "2507.11052", "pdf": "https://arxiv.org/pdf/2507.11052", "abs": "https://arxiv.org/abs/2507.11052", "authors": ["Haowei Yang", "Ziyu Shen", "Junli Shao", "Luyao Men", "Xinyue Han", "Jing Dong"], "title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Timely identification and accurate risk stratification of cardiovascular\ndisease (CVD) remain essential for reducing global mortality. While existing\nprediction models primarily leverage structured data, unstructured clinical\nnotes contain valuable early indicators. This study introduces a novel\nLLM-augmented clinical NLP pipeline that employs domain-adapted large language\nmodels for symptom extraction, contextual reasoning, and correlation from\nfree-text reports. Our approach integrates cardiovascular-specific fine-tuning,\nprompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III\nand CARDIO-NLP datasets demonstrate improved performance in precision, recall,\nF1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by\ncardiologists. Challenges such as contextual hallucination, which occurs when\nplausible information contracts with provided source, and temporal ambiguity,\nwhich is related with models struggling with chronological ordering of events\nare addressed using prompt engineering and hybrid rule-based verification. This\nwork underscores the potential of LLMs in clinical decision support systems\n(CDSS), advancing early warning systems and enhancing the translation of\npatient narratives into actionable risk assessments.", "AI": {"tldr": "\u5229\u7528LLM\u589e\u5f3a\u7684\u4e34\u5e8aNLP\u6d41\u7a0b\uff0c\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u63d0\u53d6\u5fc3\u8840\u7ba1\u75be\u75c5\u65e9\u671f\u6307\u6807\uff0c\u63d0\u5347\u98ce\u9669\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\uff08CVD\uff09\u98ce\u9669\u9884\u6d4b\u4e3b\u8981\u4f9d\u8d56\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f46\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u6709\u4ef7\u503c\u7684\u4fe1\u606f\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7LLM\u6280\u672f\uff0c\u63d0\u9ad8\u65e9\u671f\u98ce\u9669\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cdLLM\u589e\u5f3a\u7684NLP\u6d41\u7a0b\uff0c\u5305\u62ec\u9886\u57df\u9002\u5e94\u7684\u8bed\u8a00\u6a21\u578b\u3001\u75c7\u72b6\u63d0\u53d6\u3001\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u76f8\u5173\u6027\u5206\u6790\uff0c\u5e76\u7ed3\u5408\u5fc3\u8840\u7ba1\u7279\u5b9a\u7684\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\u3002", "result": "\u5728MIMIC-III\u548cCARDIO-NLP\u6570\u636e\u96c6\u4e0a\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cAUROC\uff0c\u4e34\u5e8a\u76f8\u5173\u6027\u9ad8\uff08kappa=0.82\uff09\u3002", "conclusion": "\u5c55\u793a\u4e86LLM\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u589e\u5f3a\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u5e76\u5c06\u60a3\u8005\u53d9\u8ff0\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u98ce\u9669\u8bc4\u4f30\u3002", "keywords": "\u5fc3\u8840\u7ba1\u75be\u75c5, NLP, \u5927\u8bed\u8a00\u6a21\u578b, \u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf, \u98ce\u9669\u9884\u6d4b"}}
{"id": "2507.11079", "pdf": "https://arxiv.org/pdf/2507.11079", "abs": "https://arxiv.org/abs/2507.11079", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "categories": ["cs.AI"], "comment": null, "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6325\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u65e0\u4eba\u5730\u9762\u8f66\u8f86\u5bf9\u6297\u4e2d\u7684\u667a\u80fd\u611f\u77e5\u81f3\u51b3\u7b56\u63a8\u7406\u95ee\u9898\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u5728\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5728\u591a\u65e0\u4eba\u5730\u9762\u8f66\u8f86\u5bf9\u6297\u4e2d\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u5728\u590d\u6742\u77ac\u53d8\u7684\u6218\u573a\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u800c\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u4e3b\u8981\u5173\u6ce8\u52a8\u4f5c\u64cd\u7eb5\u800c\u975e\u6218\u7565\u51b3\u7b56\u3002", "method": "\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u573a\u666f\u7406\u89e3\u548c\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6218\u7565\u63a8\u7406\uff0c\u5b9e\u73b0\u5728\u5171\u4eab\u8bed\u4e49\u7a7a\u95f4\u4e2d\u7684\u7edf\u4e00\u611f\u77e5\u4e0e\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u548c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u57fa\u7ebf\u6a21\u578b\u80dc\u7387\u8d85\u8fc780%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u4e3b\u5bf9\u6297\u4e2d\u7684\u667a\u80fd\u611f\u77e5\u81f3\u51b3\u7b56\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u4e14\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u591a\u65e0\u4eba\u5730\u9762\u8f66\u8f86\u5bf9\u6297\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3001\u6218\u7565\u63a8\u7406\u3001\u53ef\u89e3\u91ca\u6027\u3001\u667a\u80fd\u611f\u77e5"}}
{"id": "2507.10626", "pdf": "https://arxiv.org/pdf/2507.10626", "abs": "https://arxiv.org/abs/2507.10626", "authors": ["Lintao Wang", "Shiwen Xu", "Michael Horton", "Joachim Gudmundsson", "Zhiyong Wang"], "title": "Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting soccer match outcomes is a challenging task due to the inherently\nunpredictable nature of the game and the numerous dynamic factors influencing\nresults. While it conventionally relies on meticulous feature engineering, deep\nlearning techniques have recently shown a great promise in learning effective\nplayer and team representations directly for soccer outcome prediction.\nHowever, existing methods often overlook the heterogeneous nature of\ninteractions among players and teams, which is crucial for accurately modeling\nmatch dynamics. To address this gap, we propose HIGFormer (Heterogeneous\nInteraction Graph Transformer), a novel graph-augmented transformer-based deep\nlearning model for soccer outcome prediction. HIGFormer introduces a\nmulti-level interaction framework that captures both fine-grained player\ndynamics and high-level team interactions. Specifically, it comprises (1) a\nPlayer Interaction Network, which encodes player performance through\nheterogeneous interaction graphs, combining local graph convolutions with a\nglobal graph-augmented transformer; (2) a Team Interaction Network, which\nconstructs interaction graphs from a team-to-team perspective to model\nhistorical match relationships; and (3) a Match Comparison Transformer, which\njointly analyzes both team and player-level information to predict match\noutcomes. Extensive experiments on the WyScout Open Access Dataset, a\nlarge-scale real-world soccer dataset, demonstrate that HIGFormer significantly\noutperforms existing methods in prediction accuracy. Furthermore, we provide\nvaluable insights into leveraging our model for player performance evaluation,\noffering a new perspective on talent scouting and team strategy analysis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u56fe\u589e\u5f3a\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bHIGFormer\uff0c\u7528\u4e8e\u9884\u6d4b\u8db3\u7403\u6bd4\u8d5b\u7ed3\u679c\uff0c\u901a\u8fc7\u591a\u7ea7\u4ea4\u4e92\u6846\u67b6\u6355\u6349\u7403\u5458\u548c\u56e2\u961f\u52a8\u6001\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u7403\u5458\u548c\u56e2\u961f\u4e4b\u95f4\u7684\u5f02\u8d28\u4ea4\u4e92\u5bf9\u6bd4\u8d5b\u7ed3\u679c\u9884\u6d4b\u7684\u91cd\u8981\u6027\u3002", "method": "\u7ed3\u5408\u5c40\u90e8\u56fe\u5377\u79ef\u548c\u5168\u5c40\u56fe\u589e\u5f3aTransformer\uff0c\u6784\u5efa\u7403\u5458\u4ea4\u4e92\u7f51\u7edc\u3001\u56e2\u961f\u4ea4\u4e92\u7f51\u7edc\u548c\u6bd4\u8d5b\u6bd4\u8f83Transformer\u3002", "result": "\u5728WyScout\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u4e3a\u7403\u5458\u8868\u73b0\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "conclusion": "HIGFormer\u80fd\u6709\u6548\u9884\u6d4b\u6bd4\u8d5b\u7ed3\u679c\uff0c\u5e76\u652f\u6301\u7403\u5458\u8bc4\u4f30\u548c\u56e2\u961f\u7b56\u7565\u5206\u6790\u3002", "keywords": "\u8db3\u7403\u9884\u6d4b, \u5f02\u8d28\u4ea4\u4e92, \u56fe\u795e\u7ecf\u7f51\u7edc, Transformer, \u7403\u5458\u8868\u73b0"}}
{"id": "2507.11084", "pdf": "https://arxiv.org/pdf/2507.11084", "abs": "https://arxiv.org/abs/2507.11084", "authors": ["Md. Sabbir Hossen", "Md. Saiduzzaman", "Pabon Shaha"], "title": "Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach", "categories": ["cs.CL"], "comment": "This paper has been accepted and presented at the IEEE ECAI 2025. The\n  final version will be available in the IEEE Xplore Digital Library", "summary": "The July Revolution in Bangladesh marked a significant student-led mass\nuprising, uniting people across the nation to demand justice, accountability,\nand systemic reform. Social media platforms played a pivotal role in amplifying\npublic sentiment and shaping discourse during this historic mass uprising. In\nthis study, we present a hybrid transformer-based sentiment analysis framework\nto decode public opinion expressed in social media comments during and after\nthe revolution. We used a brand new dataset of 4,200 Bangla comments collected\nfrom social media. The framework employs advanced transformer-based feature\nextraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the\nproposed hybrid XMB-BERT, to capture nuanced patterns in textual data.\nPrinciple Component Analysis (PCA) were utilized for dimensionality reduction\nto enhance computational efficiency. We explored eleven traditional and\nadvanced machine learning classifiers for identifying sentiments. The proposed\nhybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of\n83.7% and outperform other model classifier combinations. This study\nunderscores the potential of machine learning techniques to analyze social\nsentiment in low-resource languages like Bangla.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408Transformer\u7684\u60c5\u611f\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u7801\u5b5f\u52a0\u62c9\u56fd\u4e03\u6708\u9769\u547d\u671f\u95f4\u53ca\u4e4b\u540e\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\u4e2d\u7684\u516c\u4f17\u60c5\u7eea\uff0c\u7ed3\u5408\u591a\u79cd\u5148\u8fdb\u6a21\u578b\uff0c\u53d6\u5f97\u4e8683.7%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u5206\u6790\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u5b5f\u52a0\u62c9\u8bed\uff09\u7684\u793e\u4f1a\u60c5\u611f\uff0c\u7279\u522b\u662f\u5728\u91cd\u5927\u4e8b\u4ef6\uff08\u5982\u4e03\u6708\u9769\u547d\uff09\u4e2d\u7684\u516c\u4f17\u60c5\u7eea\u3002", "method": "\u4f7f\u7528BanglaBERT\u3001mBERT\u3001XLM-RoBERTa\u548c\u63d0\u51fa\u7684\u6df7\u5408XMB-BERT\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u7ed3\u5408PCA\u964d\u7ef4\u548c11\u79cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8fdb\u884c\u60c5\u611f\u5206\u6790\u3002", "result": "\u6df7\u5408XMB-BERT\u4e0e\u6295\u7968\u5206\u7c7b\u5668\u7ec4\u5408\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u4e3a83.7%\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u611f\u5206\u6790\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u6df7\u5408Transformer\u6a21\u578b\u6548\u679c\u663e\u8457\u3002", "keywords": "\u4e03\u6708\u9769\u547d\u3001\u793e\u4ea4\u5a92\u4f53\u3001\u60c5\u611f\u5206\u6790\u3001Transformer\u3001\u5b5f\u52a0\u62c9\u8bed"}}
{"id": "2507.11083", "pdf": "https://arxiv.org/pdf/2507.11083", "abs": "https://arxiv.org/abs/2507.11083", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "title": "Function-to-Style Guidance of LLMs for Code Translation", "categories": ["cs.AI", "cs.SE"], "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faF2STrans\u65b9\u6cd5\uff0c\u901a\u8fc7\u529f\u80fd\u5b66\u4e60\u548c\u98ce\u683c\u5b66\u4e60\u4e24\u9636\u6bb5\u63d0\u5347LLMs\u7684\u4ee3\u7801\u7ffb\u8bd1\u6027\u80fd\uff0c\u5e76\u5728\u65b0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684LLMs\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u867d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u4ecd\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3002", "method": "F2STrans\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u529f\u80fd\u5b66\u4e60\u4f7f\u7528\u9ad8\u8d28\u91cf\u4ee3\u7801\u5bf9\u4f18\u5316\u7ffb\u8bd1\u6b63\u786e\u6027\uff1b\u98ce\u683c\u5b66\u4e60\u901a\u8fc7\u6b63\u8d1f\u6837\u672c\u63d0\u5347\u53ef\u8bfb\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cF2STrans\u5728\u65b0\u57fa\u51c6\u548c\u73b0\u6709\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0cQwen-1.5B\u751a\u81f3\u8d85\u8d8aQwen-32B\u548cGPT-4\u3002", "conclusion": "F2STrans\u901a\u8fc7\u529f\u80fd\u4e0e\u98ce\u683c\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ee3\u7801\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "keywords": "\u4ee3\u7801\u7ffb\u8bd1,LLMs,\u529f\u80fd\u5b66\u4e60,\u98ce\u683c\u5b66\u4e60,\u57fa\u51c6\u6d4b\u8bd5"}}
{"id": "2507.10628", "pdf": "https://arxiv.org/pdf/2507.10628", "abs": "https://arxiv.org/abs/2507.10628", "authors": ["Ziru Liu", "Cheng Gong", "Xinyu Fu", "Yaofang Liu", "Ran Chen", "Shoubo Hu", "Suiyun Zhang", "Rui Liu", "Qingfu Zhang", "Dandan Tu"], "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for facilitating the self-improvement of large language\nmodels (LLMs), particularly in the domain of complex reasoning tasks. However,\nprevailing on-policy RL methods often contend with significant training\ninstability and inefficiency. This is primarily due to a capacity-difficulty\nmismatch, where the complexity of training data frequently outpaces the model's\ncurrent capabilities, leading to critically sparse reward signals and stalled\nlearning progress. This challenge is particularly acute for smaller, more\nresource-efficient LLMs. To overcome this, we introduce the Guided Hybrid\nPolicy Optimization (GHPO), a novel difficulty-aware reinforcement learning\nframework. GHPO dynamically calibrates task difficulty by employing adaptive\nprompt refinement to provide targeted guidance. This unique approach adaptively\nbalances direct imitation learning for problems currently beyond the model's\nreach with exploration-based reinforcement learning for more manageable tasks,\neffectively creating a smooth and optimized learning curriculum. Extensive\nexperiments demonstrate that GHPO achieves an average performance gain of\napproximately 5% across six challenging mathematics benchmarks, consistently\noutperforming strong on-policy reinforcement learning and curriculum learning\nbaselines. Further analysis confirms that our framework significantly enhances\nboth training stability and final reasoning performance, thus offering a\nscalable and efficient solution for developing powerful and robust reasoning\nmodels.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGHPO\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4efb\u52a1\u96be\u5ea6\u548c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u548c\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u548c\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4efb\u52a1\u96be\u5ea6\u4e0e\u6a21\u578b\u80fd\u529b\u4e0d\u5339\u914d\u5bfc\u81f4\u5b66\u4e60\u505c\u6ede\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGHPO\u7684\u96be\u5ea6\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u63d0\u793a\u8c03\u6574\u52a8\u6001\u6821\u51c6\u4efb\u52a1\u96be\u5ea6\uff0c\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728\u516d\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGHPO\u5e73\u5747\u6027\u80fd\u63d0\u5347\u4e86\u7ea65%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "GHPO\u4e3a\u5f00\u53d1\u5f3a\u5927\u4e14\u7a33\u5065\u7684\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u5f3a\u5316\u5b66\u4e60, \u5927\u578b\u8bed\u8a00\u6a21\u578b, GHPO, \u4efb\u52a1\u96be\u5ea6, \u8bad\u7ec3\u7a33\u5b9a\u6027"}}
{"id": "2507.11086", "pdf": "https://arxiv.org/pdf/2507.11086", "abs": "https://arxiv.org/abs/2507.11086", "authors": ["Andres Azqueta-Gavald\u00f3n", "Joaquin Ramos Cosgrove"], "title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification", "categories": ["cs.CL"], "comment": null, "summary": "The growing prevalence of cross-border financial activities in global markets\nhas underscored the necessity of accurately identifying and classifying foreign\nentities. This practice is essential within the Spanish financial system for\nensuring robust risk management, regulatory adherence, and the prevention of\nfinancial misconduct. This process involves a labor-intensive entity-matching\ntask, where entities need to be validated against available reference sources.\nChallenges arise from linguistic variations, special characters, outdated\nnames, and changes in legal forms, complicating traditional matching algorithms\nlike Jaccard, cosine, and Levenshtein distances. These methods struggle with\ncontextual nuances and semantic relationships, leading to mismatches. To\naddress these limitations, we explore Large Language Models (LLMs) as a\nflexible alternative. LLMs leverage extensive training to interpret context,\nhandle abbreviations, and adapt to legal transitions. We evaluate traditional\nmethods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft\nCopilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.\nResults show traditional methods achieve accuracies over 92% but suffer high\nfalse positive rates (20-40%). Interface-based LLMs outperform, achieving\naccuracies above 93%, F1 scores exceeding 96%, and lower false positives\n(40-80%).", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8de8\u5883\u91d1\u878d\u6d3b\u52a8\u4e2d\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6539\u8fdb\u5b9e\u4f53\u5339\u914d\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0cLLMs\u5728\u51c6\u786e\u6027\u548c\u51cf\u5c11\u8bef\u62a5\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u8de8\u5883\u91d1\u878d\u6d3b\u52a8\u7684\u589e\u52a0\u9700\u8981\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u548c\u5206\u7c7b\u5916\u56fd\u5b9e\u4f53\uff0c\u4f20\u7edf\u5339\u914d\u65b9\u6cd5\u56e0\u8bed\u8a00\u53d8\u4f53\u548c\u8bed\u4e49\u95ee\u9898\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u8bc4\u4f30\u4e86\u4f20\u7edf\u7b97\u6cd5\uff08\u5982Jaccard\uff09\u3001Hugging Face\u7684LLMs\u548c\u63a5\u53e3\u578bLLMs\uff08\u5982Microsoft Copilot\uff09\uff0c\u4f7f\u752865\u4e2a\u8461\u8404\u7259\u516c\u53f8\u6848\u4f8b\u6570\u636e\u96c6\u3002", "result": "\u4f20\u7edf\u65b9\u6cd5\u51c6\u786e\u7387\u8d8592%\u4f46\u8bef\u62a5\u7387\u9ad8\uff0820-40%\uff09\uff0c\u63a5\u53e3\u578bLLMs\u51c6\u786e\u7387\u8d8593%\uff0cF1\u5206\u6570\u8d8596%\uff0c\u8bef\u62a5\u7387\u66f4\u4f4e\uff0840-80%\uff09\u3002", "conclusion": "LLMs\u5728\u5b9e\u4f53\u5339\u914d\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5904\u7406\u590d\u6742\u8bed\u4e49\u548c\u4e0a\u4e0b\u6587\u65f6\u8868\u73b0\u66f4\u4f73\u3002", "keywords": "\u5b9e\u4f53\u5339\u914d,\u5927\u8bed\u8a00\u6a21\u578b,\u91d1\u878d\u5408\u89c4,\u8de8\u5883\u91d1\u878d,\u98ce\u9669\u7ba1\u63a7"}}
{"id": "2507.11117", "pdf": "https://arxiv.org/pdf/2507.11117", "abs": "https://arxiv.org/abs/2507.11117", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "categories": ["cs.AI"], "comment": "8 Pages, 1 figure", "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "AI": {"tldr": "GoldMine OS\u662f\u4e00\u4e2a\u57fa\u4e8eAI\u4ee3\u7406\u7684\u5206\u6563\u5f0f\u4ea4\u6613\u67b6\u6784\uff0c\u7528\u4e8e\u5b9e\u73b0\u7269\u7406\u9ec4\u91d1\u7684\u4ee3\u5e01\u5316\u4e0e\u533a\u5757\u94fe\u4ea4\u6362\uff0c\u7ed3\u5408\u94fe\u4e0a\u667a\u80fd\u5408\u7ea6\u4e0e\u94fe\u4e0bAI\u4ee3\u7406\uff0c\u6ee1\u8db3\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u548c\u98ce\u9669\u7ba1\u7406\u9700\u6c42\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u7269\u7406\u8d44\u4ea7\uff08\u5982\u9ec4\u91d1\uff09\u5728\u533a\u5757\u94fe\u4e0a\u4ea4\u6613\u7684\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u548c\u98ce\u9669\u7ba1\u7406\u95ee\u9898\uff0c\u901a\u8fc7AI\u4ee3\u7406\u81ea\u52a8\u5316\u63d0\u5347\u6548\u7387\u4e0e\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u94fe\u4e0a\u667a\u80fd\u5408\u7ea6\u4e0e\u94fe\u4e0bAI\u4ee3\u7406\uff08\u5408\u89c4\u3001\u4ee3\u5e01\u53d1\u884c\u3001\u505a\u5e02\u3001\u98ce\u63a7\uff09\u534f\u4f5c\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u8bd5\u70b9\u90e8\u7f72\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u5b9e\u73b01.2\u79d2\u5185\u6309\u9700\u4ee3\u5e01\u53d1\u884c\uff0c\u505a\u5e02\u4ee3\u7406\u5728\u6ce2\u52a8\u5e02\u573a\u4e2d\u7ef4\u63010.5%\u4ee5\u5185\u4ef7\u5dee\uff0c\u6545\u969c\u6ce8\u5165\u6d4b\u8bd5\u663e\u793a\u7cfb\u7edf\u5177\u5907\u5f3a\u97e7\u6027\u3002", "conclusion": "AI\u4ee3\u7406\u9a71\u52a8\u7684\u5206\u6563\u5f0f\u4ea4\u6613\u67b6\u6784\u80fd\u6ee1\u8db3\u9ad8\u6027\u80fd\u4e0e\u5b89\u5168\u6027\u9700\u6c42\uff0c\u6709\u671b\u63a8\u52a8\u975e\u6d41\u52a8\u6027\u8d44\u4ea7\u7684\u6c11\u4e3b\u5316\u8bbf\u95ee\u3002", "keywords": "\u5206\u6563\u5f0f\u4ea4\u6613\u3001\u7269\u7406\u8d44\u4ea7\u4ee3\u5e01\u5316\u3001AI\u4ee3\u7406\u3001\u533a\u5757\u94fe\u3001\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u3001\u98ce\u9669\u7ba1\u7406"}}
{"id": "2507.10632", "pdf": "https://arxiv.org/pdf/2507.10632", "abs": "https://arxiv.org/abs/2507.10632", "authors": ["Issei Saito", "Masatoshi Nagano", "Tomoaki Nakamura", "Daichi Mochihashi", "Koki Mimura"], "title": "Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series\nsegmentation method that incorporates random Fourier features (RFF) to address\nthe high computational cost of the Gaussian process hidden semi-Markov model\n(GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring\ninversion of an N times N kernel matrix during training, where N is the number\nof data points. As the scale of the data increases, matrix inversion incurs a\nsignificant computational cost. To address this, the proposed method\napproximates the Gaussian process with linear regression using RFF, preserving\nexpressive power while eliminating the need for inversion of the kernel matrix.\nExperiments on the Carnegie Mellon University (CMU) motion-capture dataset\ndemonstrate that the proposed method achieves segmentation performance\ncomparable to that of conventional methods, with approximately 278 times faster\nsegmentation on time-series data comprising 39,200 frames.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08RFF\uff09\u7684\u5feb\u901f\u65e0\u76d1\u7763\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u65b9\u6cd5RFF-GP-HSMM\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9ad8\u65af\u8fc7\u7a0b\u9690\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08GP-HSMM\uff09\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "GP-HSMM\u5728\u5904\u7406\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u7531\u4e8e\u9700\u8981\u8ba1\u7b97N\u00d7N\u6838\u77e9\u9635\u7684\u9006\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u901a\u8fc7\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08RFF\uff09\u8fd1\u4f3c\u9ad8\u65af\u8fc7\u7a0b\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u7ebf\u6027\u56de\u5f52\u95ee\u9898\uff0c\u907f\u514d\u4e86\u6838\u77e9\u9635\u7684\u9006\u8fd0\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5361\u5185\u57fa\u6885\u9686\u5927\u5b66\u7684\u8fd0\u52a8\u6355\u6349\u6570\u636e\u96c6\u4e0a\uff0c\u5206\u5272\u6027\u80fd\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\uff0c\u4f46\u901f\u5ea6\u63d0\u5347\u4e86\u7ea6278\u500d\u3002", "conclusion": "RFF-GP-HSMM\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u65b9\u6cd5\u3002", "keywords": "\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81, \u9ad8\u65af\u8fc7\u7a0b\u9690\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b, \u65f6\u95f4\u5e8f\u5217\u5206\u5272, \u8ba1\u7b97\u6548\u7387"}}
{"id": "2507.11097", "pdf": "https://arxiv.org/pdf/2507.11097", "abs": "https://arxiv.org/abs/2507.11097", "authors": ["Zichen Wen", "Jiashu Qu", "Dongrui Liu", "Zhiyuan Liu", "Ruixi Wu", "Yicun Yang", "Xiangqi Jin", "Haoyun Xu", "Xuyang Liu", "Weijia Li", "Chaochao Lu", "Jing Shao", "Conghui He", "Linfeng Zhang"], "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs", "categories": ["cs.CL"], "comment": "21 pages, 9 figures, work in progress", "summary": "Diffusion-based large language models (dLLMs) have recently emerged as a\npowerful alternative to autoregressive LLMs, offering faster inference and\ngreater interactivity via parallel decoding and bidirectional modeling.\nHowever, despite strong performance in code generation and text infilling, we\nidentify a fundamental safety concern: existing alignment mechanisms fail to\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\nexposing novel vulnerabilities. To this end, we present DIJA, the first\nsystematic study and jailbreak attack framework that exploits unique safety\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\ninterleaved mask-text prompts that exploit the text generation mechanisms of\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\nmodeling drives the model to produce contextually consistent outputs for masked\nspans, even when harmful, while parallel decoding limits model dynamic\nfiltering and rejection sampling of unsafe content. This causes standard\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\nsignificantly outperforms existing jailbreak methods, exposing a previously\noverlooked threat surface in dLLM architectures. Notably, our method achieves\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\nharmful content in the jailbreak prompt. Our findings underscore the urgent\nneed for rethinking safety alignment in this emerging class of language models.\nCode is available at https://github.com/ZichenWen1/DIJA.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLM\uff09\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDIJA\u7684\u5bf9\u6297\u6027\u653b\u51fb\u6846\u67b6\uff0c\u5229\u7528dLLM\u7684\u53cc\u5411\u5efa\u6a21\u548c\u5e73\u884c\u89e3\u7801\u673a\u5236\u7ed5\u8fc7\u73b0\u6709\u5bf9\u9f50\u673a\u5236\uff0c\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u3002", "motivation": "\u5c3d\u7ba1dLLM\u5728\u4ee3\u7801\u751f\u6210\u548c\u6587\u672c\u586b\u5145\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u73b0\u6709\u7684\u5bf9\u9f50\u673a\u5236\u65e0\u6cd5\u6709\u6548\u9632\u5fa1\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5bf9\u6297\u6027\u8f93\u5165\uff0c\u66b4\u9732\u51fa\u65b0\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4ea4\u9519\u63a9\u7801\u6587\u672c\u63d0\u793a\uff08interleaved mask-text prompts\uff09\uff0c\u5229\u7528dLLM\u7684\u53cc\u5411\u5efa\u6a21\u548c\u5e73\u884c\u89e3\u7801\u673a\u5236\uff0c\u7ed5\u8fc7\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u3002", "result": "DIJA\u5728\u591a\u4e2a\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5982Dream-Instruct\u4e0a\u5b9e\u73b0100%\u5173\u952e\u8bcd\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u5728JailbreakBench\u4e0a\u63d0\u534778.5%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86dLLM\u67b6\u6784\u4e2d\u672a\u88ab\u91cd\u89c6\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u91cd\u65b0\u8bbe\u8ba1\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u7684\u7d27\u8feb\u6027\u3002", "keywords": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b, \u5b89\u5168\u6f0f\u6d1e, \u5bf9\u6297\u6027\u653b\u51fb, \u5e73\u884c\u89e3\u7801, \u53cc\u5411\u5efa\u6a21"}}
{"id": "2507.11127", "pdf": "https://arxiv.org/pdf/2507.11127", "abs": "https://arxiv.org/abs/2507.11127", "authors": ["Lennert De Smet", "Luc De Raedt"], "title": "Defining neurosymbolic AI", "categories": ["cs.AI"], "comment": null, "summary": "Neurosymbolic AI focuses on integrating learning and reasoning, in\nparticular, on unifying logical and neural representations. Despite the\nexistence of an alphabet soup of neurosymbolic AI systems, the field is lacking\na generally accepted formal definition of what neurosymbolic models and\ninference really are. We introduce a formal definition for neurosymbolic AI\nthat makes abstraction of its key ingredients. More specifically, we define\nneurosymbolic inference as the computation of an integral over a product of a\nlogical and a belief function. We show that our neurosymbolic AI definition\nmakes abstraction of key representative neurosymbolic AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u795e\u7ecf\u7b26\u53f7AI\u7684\u6b63\u5f0f\u5b9a\u4e49\uff0c\u62bd\u8c61\u4e86\u5176\u5173\u952e\u6210\u5206\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u5b9a\u4e49\u5982\u4f55\u6db5\u76d6\u4ee3\u8868\u6027\u7684\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u7f3a\u4e4f\u4e00\u4e2a\u666e\u904d\u63a5\u53d7\u7684\u6b63\u5f0f\u5b9a\u4e49\u6765\u63cf\u8ff0\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u548c\u63a8\u7406\u7684\u672c\u8d28\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5c06\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5b9a\u4e49\u4e3a\u903b\u8f91\u51fd\u6570\u548c\u7f6e\u4fe1\u51fd\u6570\u7684\u79ef\u7684\u79ef\u5206\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u795e\u7ecf\u7b26\u53f7AI\u5b9a\u4e49\u3002", "result": "\u63d0\u51fa\u7684\u5b9a\u4e49\u80fd\u591f\u62bd\u8c61\u5316\u5173\u952e\u7684\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\uff0c\u6db5\u76d6\u5176\u4ee3\u8868\u6027\u5b9e\u4f8b\u3002", "conclusion": "\u8be5\u6b63\u5f0f\u5b9a\u4e49\u586b\u8865\u4e86\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "keywords": "\u795e\u7ecf\u7b26\u53f7AI, \u6b63\u5f0f\u5b9a\u4e49, \u63a8\u7406, \u903b\u8f91\u51fd\u6570, \u7f6e\u4fe1\u51fd\u6570"}}
{"id": "2507.10636", "pdf": "https://arxiv.org/pdf/2507.10636", "abs": "https://arxiv.org/abs/2507.10636", "authors": ["Jianing Zhi", "Xinghua Li", "Zidong Chen"], "title": "GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.RO", "90B06", "I.2.8"], "comment": "12 Pages, 5 Figures", "summary": "The rapid development of urban low-altitude unmanned aerial vehicle (UAV)\neconomy poses new challenges for dynamic site selection of UAV landing points\nand supply stations. Traditional deep reinforcement learning methods face\ncomputational complexity bottlenecks, particularly with standard attention\nmechanisms, when handling large-scale urban-level location problems. This paper\nproposes GeoHopNet, a Hopfield-augmented sparse spatial attention network\nspecifically designed for dynamic UAV site location problems. Our approach\nintroduces four core innovations: (1) distance-biased multi-head attention\nmechanism that explicitly encodes spatial geometric information; (2) K-nearest\nneighbor sparse attention that reduces computational complexity from $O(N^2)$\nto $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory\nregularization strategy. Experimental results demonstrate that GeoHopNet\nextends the boundary of solvable problem sizes. For large-scale instances with\n1,000 nodes, where standard attention models become prohibitively slow (over 3\nseconds per instance) and traditional solvers fail, GeoHopNet finds\nhigh-quality solutions (0.22\\% optimality gap) in under 0.1 seconds. Compared\nto the state-of-the-art ADNet baseline on 100-node instances, our method\nimproves solution quality by 22.2\\% and is 1.8$\\times$ faster.", "AI": {"tldr": "GeoHopNet\u662f\u4e00\u79cd\u57fa\u4e8eHopfield\u589e\u5f3a\u7684\u7a00\u758f\u7a7a\u95f4\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u7528\u4e8e\u89e3\u51b3\u65e0\u4eba\u673a\u52a8\u6001\u9009\u5740\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "motivation": "\u57ce\u5e02\u4f4e\u7a7a\u65e0\u4eba\u673a\u7ecf\u6d4e\u7684\u5feb\u901f\u53d1\u5c55\u5bf9\u65e0\u4eba\u673a\u964d\u843d\u70b9\u548c\u4f9b\u5e94\u7ad9\u7684\u52a8\u6001\u9009\u5740\u63d0\u51fa\u4e86\u65b0\u6311\u6218\uff0c\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u57ce\u5e02\u7ea7\u9009\u5740\u95ee\u9898\u65f6\u9762\u4e34\u8ba1\u7b97\u590d\u6742\u5ea6\u74f6\u9888\u3002", "method": "GeoHopNet\u901a\u8fc7\u56db\u79cd\u6838\u5fc3\u521b\u65b0\uff1a\u8ddd\u79bb\u504f\u7f6e\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u3001K\u8fd1\u90bb\u7a00\u758f\u6ce8\u610f\u529b\u3001\u73b0\u4ee3Hopfield\u5916\u90e8\u8bb0\u5fc6\u6a21\u5757\u548c\u8bb0\u5fc6\u6b63\u5219\u5316\u7b56\u7565\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u63d0\u5347\u6027\u80fd\u3002", "result": "\u57281,000\u8282\u70b9\u7684\u5b9e\u4f8b\u4e2d\uff0cGeoHopNet\u57280.1\u79d2\u5185\u627e\u5230\u9ad8\u8d28\u91cf\u89e3\uff08\u6700\u4f18\u6027\u5dee\u8ddd0.22%\uff09\uff0c\u8f83ADNet\u57fa\u7ebf\u5728100\u8282\u70b9\u5b9e\u4f8b\u4e0a\u63d0\u534722.2%\u7684\u89e3\u8d28\u91cf\u4e14\u901f\u5ea6\u63d0\u53471.8\u500d\u3002", "conclusion": "GeoHopNet\u6269\u5c55\u4e86\u53ef\u89e3\u51b3\u95ee\u9898\u7684\u89c4\u6a21\u8fb9\u754c\uff0c\u4e3a\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u52a8\u6001\u9009\u5740\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u65e0\u4eba\u673a\u9009\u5740\u3001\u7a00\u758f\u6ce8\u610f\u529b\u3001Hopfield\u7f51\u7edc\u3001\u8ba1\u7b97\u590d\u6742\u5ea6"}}
{"id": "2507.11112", "pdf": "https://arxiv.org/pdf/2507.11112", "abs": "https://arxiv.org/abs/2507.11112", "authors": ["Sanhanat Sivapiromrat", "Caiqi Zhang", "Marco Basaldella", "Nigel Collier"], "title": "Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs", "categories": ["cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Recent studies have shown that Large Language Models (LLMs) are vulnerable to\ndata poisoning attacks, where malicious training examples embed hidden\nbehaviours triggered by specific input patterns. However, most existing works\nassume a phrase and focus on the attack's effectiveness, offering limited\nunderstanding of trigger mechanisms and how multiple triggers interact within\nthe model. In this paper, we present a framework for studying poisoning in\nLLMs. We show that multiple distinct backdoor triggers can coexist within a\nsingle model without interfering with each other, enabling adversaries to embed\nseveral triggers concurrently. Using multiple triggers with high embedding\nsimilarity, we demonstrate that poisoned triggers can achieve robust activation\neven when tokens are substituted or separated by long token spans. Our findings\nexpose a broader and more persistent vulnerability surface in LLMs. To mitigate\nthis threat, we propose a post hoc recovery method that selectively retrains\nspecific model components based on a layer-wise weight difference analysis. Our\nmethod effectively removes the trigger behaviour with minimal parameter\nupdates, presenting a practical and efficient defence against multi-trigger\npoisoning.", "AI": {"tldr": "LLM\u6613\u53d7\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u73b0\u6709\u7814\u7a76\u591a\u5c40\u9650\u4e8e\u5355\u4e00\u89e6\u53d1\u673a\u5236\u3002\u672c\u6587\u63d0\u51fa\u6846\u67b6\u7814\u7a76\u591a\u89e6\u53d1\u5171\u5b58\u53ca\u5176\u4ea4\u4e92\uff0c\u53d1\u73b0\u9ad8\u76f8\u4f3c\u6027\u89e6\u53d1\u5668\u53ef\u7a33\u5065\u6fc0\u6d3b\uff0c\u5e76\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5206\u5c42\u6743\u91cd\u5dee\u5f02\u7684\u540e\u4fee\u590d\u65b9\u6cd5\u3002", "motivation": "\u63ed\u9732LLM\u5728\u591a\u89e6\u53d1\u6295\u6bd2\u653b\u51fb\u4e0b\u7684\u5e7f\u6cdb\u8106\u5f31\u6027\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5bf9\u89e6\u53d1\u673a\u5236\u53ca\u4ea4\u4e92\u7406\u89e3\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7814\u7a76\u6846\u67b6\u9a8c\u8bc1\u591a\u89e6\u53d1\u5668\u5171\u5b58\u6027\uff0c\u57fa\u4e8e\u5206\u5c42\u6743\u91cd\u5dee\u5f02\u8bbe\u8ba1\u9009\u62e9\u6027\u91cd\u8bad\u7ec3\u7684\u540e\u4fee\u590d\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "\u591a\u89e6\u53d1\u5668\u53ef\u5728\u6a21\u578b\u4e2d\u72ec\u7acb\u5171\u5b58\u4e14\u7a33\u5065\u6fc0\u6d3b\uff1b\u540e\u4fee\u590d\u65b9\u6cd5\u80fd\u9ad8\u6548\u53bb\u9664\u89e6\u53d1\u884c\u4e3a\u3002", "conclusion": "LLM\u5b58\u5728\u66f4\u5e7f\u6cdb\u7684\u8106\u5f31\u6027\uff0c\u9700\u9488\u5bf9\u6027\u9632\u5fa1\uff1b\u5206\u5c42\u91cd\u8bad\u7ec3\u65b9\u6cd5\u4e3a\u591a\u89e6\u53d1\u6295\u6bd2\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "LLM, \u6570\u636e\u6295\u6bd2, \u591a\u89e6\u53d1\u5668, \u540e\u4fee\u590d, \u5206\u5c42\u6743\u91cd\u5dee\u5f02"}}
{"id": "2507.11135", "pdf": "https://arxiv.org/pdf/2507.11135", "abs": "https://arxiv.org/abs/2507.11135", "authors": ["Selma Saidi", "Omar Laimona", "Christoph Schmickler", "Dirk Ziegenbein"], "title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous systems are becoming an integral part of many application domains,\nlike in the mobility sector. However, ensuring their safe and correct behaviour\nin dynamic and complex environments remains a significant challenge, where\nsystems should autonomously make decisions e.g., about manoeuvring. We propose\nin this paper a general collaborative approach for increasing the level of\ntrustworthiness in the environment of operation and improve reliability and\ngood decision making in autonomous system. In the presence of conflicting\ninformation, aggregation becomes a major issue for trustworthy decision making\nbased on collaborative data sharing. Unlike classical approaches in the\nliterature that rely on consensus or majority as aggregation rule, we exploit\nthe fact that autonomous systems have different quality attributes like\nperception quality. We use this criteria to determine which autonomous systems\nare trustworthy and borrow concepts from social epistemology to define\naggregation and propagation rules, used for automated decision making. We use\nBinary Decision Diagrams (BDDs) as formal models for beliefs aggregation and\npropagation, and formulate reduction rules to reduce the size of the BDDs and\nallow efficient computation structures for collaborative automated reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u534f\u4f5c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u81ea\u4e3b\u7cfb\u7edf\u7684\u4e0d\u540c\u8d28\u91cf\u5c5e\u6027\uff08\u5982\u611f\u77e5\u8d28\u91cf\uff09\u6765\u63d0\u9ad8\u51b3\u7b56\u7684\u4fe1\u4efb\u5ea6\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u81ea\u4e3b\u7cfb\u7edf\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u786e\u4fdd\u5b89\u5168\u548c\u6b63\u786e\u884c\u4e3a\u7684\u6311\u6218\u5c1a\u672a\u89e3\u51b3\uff0c\u5c24\u5176\u662f\u5728\u51b2\u7a81\u4fe1\u606f\u4e0b\u5982\u4f55\u505a\u51fa\u53ef\u4fe1\u51b3\u7b56\u3002", "method": "\u5229\u7528\u81ea\u4e3b\u7cfb\u7edf\u7684\u8d28\u91cf\u5c5e\u6027\uff08\u5982\u611f\u77e5\u8d28\u91cf\uff09\u6765\u8bc4\u4f30\u4fe1\u4efb\u5ea6\uff0c\u501f\u9274\u793e\u4f1a\u8ba4\u8bc6\u8bba\u5b9a\u4e49\u805a\u5408\u4e0e\u4f20\u64ad\u89c4\u5219\uff0c\u5e76\u4f7f\u7528\u4e8c\u5143\u51b3\u7b56\u56fe\uff08BDDs\uff09\u8fdb\u884c\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u51b3\u7b56\u7684\u4fe1\u4efb\u5ea6\u548c\u53ef\u9760\u6027\uff0c\u5e76\u901a\u8fc7BDDs\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u540c\u65f6\u4f18\u5316\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "keywords": "\u81ea\u4e3b\u7cfb\u7edf\uff0c\u4fe1\u4efb\u5ea6\uff0c\u534f\u4f5c\u51b3\u7b56\uff0c\u4e8c\u5143\u51b3\u7b56\u56fe\uff08BDDs\uff09\uff0c\u793e\u4f1a\u8ba4\u8bc6\u8bba"}}
{"id": "2507.10637", "pdf": "https://arxiv.org/pdf/2507.10637", "abs": "https://arxiv.org/abs/2507.10637", "authors": ["\u00c9. K\u00fcnzel", "A. Jaziri", "V. Ramesh"], "title": "A Simple Baseline for Stable and Plastic Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "11 pages, 50 figures", "summary": "Continual learning in computer vision requires that models adapt to a\ncontinuous stream of tasks without forgetting prior knowledge, yet existing\napproaches often tip the balance heavily toward either plasticity or stability.\nWe introduce RDBP, a simple, low-overhead baseline that unites two\ncomplementary mechanisms: ReLUDown, a lightweight activation modification that\npreserves feature sensitivity while preventing neuron dormancy, and Decreasing\nBackpropagation, a biologically inspired gradient-scheduling scheme that\nprogressively shields early layers from catastrophic updates. Evaluated on the\nContinual ImageNet benchmark, RDBP matches or exceeds the plasticity and\nstability of state-of-the-art methods while reducing computational cost. RDBP\nthus provides both a practical solution for real-world continual learning and a\nclear benchmark against which future continual learning strategies can be\nmeasured.", "AI": {"tldr": "RDBP\u662f\u4e00\u79cd\u4f4e\u5f00\u9500\u7684\u6301\u7eed\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86ReLUDown\u548cDecreasing Backpropagation\u4e24\u79cd\u673a\u5236\uff0c\u65e2\u80fd\u4fdd\u6301\u7279\u5f81\u654f\u611f\u6027\uff0c\u53c8\u80fd\u9632\u6b62\u795e\u7ecf\u5143\u4f11\u7720\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5728\u53ef\u5851\u6027\u548c\u7a33\u5b9a\u6027\u4e4b\u95f4\u5e73\u8861\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408ReLUDown\uff08\u8f7b\u91cf\u7ea7\u6fc0\u6d3b\u4fee\u6539\uff09\u548cDecreasing Backpropagation\uff08\u68af\u5ea6\u8c03\u5ea6\u65b9\u6848\uff09\u3002", "result": "\u5728Continual ImageNet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "RDBP\u4e3a\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u548c\u6e05\u6670\u7684\u57fa\u51c6\u3002", "keywords": "\u6301\u7eed\u5b66\u4e60,\u8ba1\u7b97\u673a\u89c6\u89c9,RDBP,ReLUDown,Decreasing Backpropagation"}}
{"id": "2507.11114", "pdf": "https://arxiv.org/pdf/2507.11114", "abs": "https://arxiv.org/abs/2507.11114", "authors": ["Seif Ahmed", "Mohamed T. Younes", "Abdelrahman Moustafa", "Abdelrahman Allam", "Hamza Moustafa"], "title": "MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We present a robust ensemble-based system for multilingual multimodal\nreasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach\nintegrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption\nrefinement and consistency checks, and Gemini 2.5 Pro as a reasoner which\nhandles final answer selection, all coordinated through carefully engineered\nfew-shot and zero-shot prompts. We conducted an extensive ablation study,\ntraining several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3,\nMistral) on an English dataset and its multilingual augmented version.\nAdditionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for\ncomparison and found it to substantially outperform the trained models. Prompt\ndesign also proved critical: enforcing concise, language-normalized formats and\nprohibiting explanatory text boosted model accuracy on the English validation\nset from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA)\nachieved first place overall in the multilingual track with 81.4% accuracy, and\nled 11 out of 13 individual language tracks, with top results such as 95.07%\nfor Croatian and 92.12% for Italian. These findings highlight that lightweight\nOCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual\naugmentation, can outperform heavier end-to-end models in high-stakes,\nmultilingual educational settings.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u7cfb\u7edf\u7684\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u65b9\u6cd5\uff0c\u5728ImageCLEF 2025 EXAMS V\u6311\u6218\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u7b56\u7565\u548c\u591a\u8bed\u8a00\u589e\u5f3a\uff0c\u53d6\u5f97\u4e86\u6700\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u95ee\u9898\uff0c\u63a2\u7d22\u8f7b\u91cf\u7ea7OCR-VLM\u96c6\u6210\u7cfb\u7edf\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u9ad8\u6548\u6027\u3002", "method": "\u91c7\u7528Gemini\u7cfb\u5217\u6a21\u578b\uff082.5 Flash\u30011.5 Pro\u30012.5 Pro\uff09\u8fdb\u884c\u89c6\u89c9\u63cf\u8ff0\u3001\u6807\u9898\u4f18\u5316\u548c\u63a8\u7406\uff0c\u7ed3\u5408\u5c11\u6837\u672c\u548c\u96f6\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u591a\u8bed\u8a00\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u7cfb\u7edf\u5728\u5b98\u65b9\u6392\u884c\u699c\u4e2d\u591a\u8bed\u8a00\u8d5b\u9053\u603b\u4f53\u51c6\u786e\u7387\u8fbe81.4%\uff0c\u5e76\u572813\u4e2a\u8bed\u8a00\u8d5b\u9053\u4e2d11\u4e2a\u9886\u5148\uff1b\u63d0\u793a\u7b56\u7565\u4f18\u5316\u5c06\u82f1\u8bed\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\u4ece55.9%\u63d0\u5347\u81f361.7%\u3002", "conclusion": "\u8f7b\u91cf\u7ea7OCR-VLM\u96c6\u6210\u7cfb\u7edf\u7ed3\u5408\u7cbe\u51c6\u63d0\u793a\u7b56\u7565\u548c\u591a\u8bed\u8a00\u589e\u5f3a\uff0c\u80fd\u5728\u9ad8\u8981\u6c42\u7684\u8de8\u8bed\u8a00\u6559\u80b2\u573a\u666f\u4e2d\u8d85\u8d8a\u66f4\u91cd\u7684\u7aef\u5230\u7aef\u6a21\u578b\u3002", "keywords": "\u591a\u6a21\u6001\u63a8\u7406,\u591a\u8bed\u8a00,\u96c6\u6210\u7cfb\u7edf,Gemini\u6a21\u578b,\u63d0\u793a\u5de5\u7a0b"}}
{"id": "2507.11150", "pdf": "https://arxiv.org/pdf/2507.11150", "abs": "https://arxiv.org/abs/2507.11150", "authors": ["Alessandro Bertagnon", "Marcello Dalpasso", "Michele Favalli", "Marco Gavanelli"], "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "categories": ["cs.AI", "cs.LO"], "comment": "Accepted for publication in the issues of Theory and Practice of\n  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "summary": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u4e2d\u7cbe\u786e\u8ba1\u7b97\u7ec4\u5408\u6a21\u5757\u7684\u6700\u5927\u5ef6\u8fdf\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4f7f\u7528ASP\uff08\u7b54\u6848\u96c6\u7f16\u7a0b\uff09\u6765\u89e3\u51b3\u8fd9\u4e00\u8ba1\u7b97\u96be\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u53ef\u884c\u6027\u3002", "motivation": "\u5728\u540c\u6b65\u7cfb\u7edf\u4e2d\uff0c\u6700\u5927\u5ef6\u8fdf\u76f4\u63a5\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u800c\u4f20\u7edf\u7684\u9759\u6001\u65f6\u5e8f\u5206\u6790\u53ea\u80fd\u63d0\u4f9b\u8fd1\u4f3c\u503c\uff0c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u672a\u8fbe\u6700\u4f18\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7cbe\u786e\u8ba1\u7b97\u6700\u5927\u5ef6\u8fdf\u3002", "method": "\u91c7\u7528\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u5bf9\u95ee\u9898\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u63d0\u51fa\u975e\u5e73\u51e1\u7684\u7f16\u7801\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cASP\u662f\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u590d\u6742\u95ee\u9898\u3002", "conclusion": "ASP\u80fd\u591f\u7cbe\u786e\u8ba1\u7b97\u6700\u5927\u5ef6\u8fdf\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "keywords": "\u96c6\u6210\u7535\u8def\u8bbe\u8ba1, \u6700\u5927\u5ef6\u8fdf, \u9759\u6001\u65f6\u5e8f\u5206\u6790, \u7b54\u6848\u96c6\u7f16\u7a0b, \u786c\u4ef6\u4f18\u5316"}}
{"id": "2507.10638", "pdf": "https://arxiv.org/pdf/2507.10638", "abs": "https://arxiv.org/abs/2507.10638", "authors": ["Shim Soon Yong"], "title": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space", "categories": ["cs.LG", "I.2.6; I.5.1"], "comment": null, "summary": "We introduce a novel classification framework, ZClassifier, that replaces\nconventional deterministic logits with diagonal Gaussian-distributed logits.\nOur method simultaneously addresses temperature scaling and manifold\napproximation by minimizing the Kullback-Leibler (KL) divergence between the\npredicted Gaussian distributions and a unit isotropic Gaussian. This unifies\nuncertainty calibration and latent control in a principled probabilistic\nmanner, enabling a natural interpretation of class confidence and geometric\nconsistency. Experiments on CIFAR-10 and CIFAR-100 show that ZClassifier\nimproves over softmax classifiers in robustness, calibration, and latent\nseparation. We also demonstrate its effectiveness for classifier-guided\ngeneration by interpreting logits as Gaussian semantic potentials.", "AI": {"tldr": "ZClassifier\u6846\u67b6\u7528\u9ad8\u65af\u5206\u5e03\u66ff\u4ee3\u4f20\u7edf\u786e\u5b9a\u6027\u903b\u8f91\uff0c\u901a\u8fc7KL\u6563\u5ea6\u540c\u65f6\u89e3\u51b3\u6e29\u5ea6\u7f29\u653e\u548c\u6d41\u5f62\u903c\u8fd1\u95ee\u9898\uff0c\u7edf\u4e00\u4e86\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u548c\u6f5c\u5728\u63a7\u5236\u3002", "motivation": "\u4f20\u7edf\u5206\u7c7b\u5668\u7684\u786e\u5b9a\u6027\u903b\u8f91\u96be\u4ee5\u540c\u65f6\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u548c\u6f5c\u5728\u63a7\u5236\uff0c\u56e0\u6b64\u63d0\u51faZClassifier\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u5bf9\u89d2\u9ad8\u65af\u5206\u5e03\u7684\u903b\u8f91\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u9ad8\u65af\u5206\u5e03\u4e0e\u5355\u4f4d\u5404\u5411\u540c\u6027\u9ad8\u65af\u4e4b\u95f4\u7684KL\u6563\u5ea6\u3002", "result": "\u5728CIFAR-10\u548cCIFAR-100\u4e0a\uff0cZClassifier\u5728\u9c81\u68d2\u6027\u3001\u6821\u51c6\u548c\u6f5c\u5728\u5206\u79bb\u65b9\u9762\u4f18\u4e8esoftmax\u5206\u7c7b\u5668\u3002", "conclusion": "ZClassifier\u901a\u8fc7\u9ad8\u65af\u8bed\u4e49\u52bf\u80fd\u6709\u6548\u652f\u6301\u5206\u7c7b\u5668\u5f15\u5bfc\u751f\u6210\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u6982\u7387\u89e3\u91ca\u3002", "keywords": "ZClassifier, \u9ad8\u65af\u5206\u5e03, KL\u6563\u5ea6, \u4e0d\u786e\u5b9a\u6027\u6821\u51c6, \u5206\u7c7b\u5668\u5f15\u5bfc\u751f\u6210"}}
{"id": "2507.11128", "pdf": "https://arxiv.org/pdf/2507.11128", "abs": "https://arxiv.org/abs/2507.11128", "authors": ["Dimitri Staufer"], "title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests", "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.6; H.2.8"], "comment": "16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable\n  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,\n  Portugal", "summary": "Large Language Models (LLMs) can memorize and reveal personal information,\nraising concerns regarding compliance with the EU's GDPR, particularly the\nRight to Be Forgotten (RTBF). Existing machine unlearning methods assume the\ndata to forget is already known but do not address how to identify which\nindividual-fact associations are stored in the model. Privacy auditing\ntechniques typically operate at the population level or target a small set of\nidentifiers, limiting applicability to individual-level data inquiries. We\nintroduce WikiMem, a dataset of over 5,000 natural language canaries covering\n243 human-related properties from Wikidata, and a model-agnostic metric to\nquantify human-fact associations in LLMs. Our approach ranks ground-truth\nvalues against counterfactuals using calibrated negative log-likelihood across\nparaphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B\nparameters), showing that memorization correlates with subject web presence and\nmodel scale. We provide a foundation for identifying memorized personal data in\nLLMs at the individual level, enabling the dynamic construction of forget sets\nfor machine unlearning and RTBF requests.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86WikiMem\u6570\u636e\u96c6\u548c\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316LLMs\u4e2d\u4e2a\u4eba\u4e0e\u4e8b\u5b9e\u7684\u5173\u8054\uff0c\u4e3a\u8bc6\u522b\u548c\u5220\u9664\u4e2a\u4eba\u6570\u636e\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u7814\u7a76LLMs\u5982\u4f55\u8bb0\u5fc6\u548c\u6cc4\u9732\u4e2a\u4eba\u6570\u636e\uff0c\u5c24\u5176\u662f\u6ee1\u8db3GDPR\u7684\u2018\u88ab\u9057\u5fd8\u6743\u2019\u9700\u6c42\u3002", "method": "\u4f7f\u7528WikiMem\u6570\u636e\u96c6\u548c\u6821\u51c6\u8d1f\u5bf9\u6570\u4f3c\u7136\u65b9\u6cd5\uff0c\u8bc4\u4f30LLMs\u4e2d\u4e2a\u4eba\u4e0e\u4e8b\u5b9e\u7684\u5173\u8054\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u8bb0\u5fc6\u4e0e\u4e2a\u4eba\u7f51\u7edc\u5b58\u5728\u548c\u6a21\u578b\u89c4\u6a21\u76f8\u5173\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u5728\u8bc6\u522b\u4e2a\u4eba\u6570\u636e\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e3a\u52a8\u6001\u6784\u5efa\u9057\u5fd8\u96c6\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u652f\u6301\u673a\u5668\u53bb\u5b66\u4e60\u548cRTBF\u8bf7\u6c42\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, GDPR, \u88ab\u9057\u5fd8\u6743, \u9690\u79c1\u5ba1\u8ba1, \u673a\u5668\u53bb\u5b66\u4e60"}}
{"id": "2507.11229", "pdf": "https://arxiv.org/pdf/2507.11229", "abs": "https://arxiv.org/abs/2507.11229", "authors": ["Jin Li", "Zezhong Ding", "Xike Xie"], "title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across\nvarious domains. Recent KG reasoning methods that integrate both global and\nlocal information have achieved promising results. However, existing methods\noften suffer from score over-smoothing, which blurs the distinction between\ncorrect and incorrect answers and hinders reasoning effectiveness. To address\nthis, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with\ndual-pathway global-local fusion. DuetGraph tackles over-smoothing by\nsegregating -- rather than stacking -- the processing of local (via message\npassing) and global (via attention) information into two distinct pathways,\npreventing mutual interference and preserving representational discrimination.\nIn addition, DuetGraph introduces a coarse-to-fine optimization, which\npartitions entities into high- and low-score subsets. This strategy narrows the\ncandidate space and sharpens the score gap between the two subsets, which\nalleviates over-smoothing and enhances inference quality. Extensive experiments\non various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)\nperformance, with up to an 8.7% improvement in reasoning quality and a\n1.8$\\times$ acceleration in training efficiency.", "AI": {"tldr": "DuetGraph\u901a\u8fc7\u53cc\u8def\u5f84\u5168\u5c40-\u5c40\u90e8\u878d\u5408\u548c\u7c97\u5230\u7ec6\u4f18\u5316\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u7684\u5206\u6570\u8fc7\u5ea6\u5e73\u6ed1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u679c\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u65b9\u6cd5\u56e0\u5206\u6570\u8fc7\u5ea6\u5e73\u6ed1\u800c\u6a21\u7cca\u4e86\u6b63\u786e\u4e0e\u9519\u8bef\u7b54\u6848\u7684\u533a\u5206\uff0c\u5f71\u54cd\u4e86\u63a8\u7406\u6548\u679c\u3002", "method": "\u63d0\u51faDuetGraph\uff0c\u91c7\u7528\u53cc\u8def\u5f84\u5168\u5c40-\u5c40\u90e8\u5206\u79bb\u5904\u7406\u548c\u7c97\u5230\u7ec6\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\uff0c\u63a8\u7406\u8d28\u91cf\u63d0\u53478.7%\uff0c\u8bad\u7ec3\u6548\u7387\u52a0\u901f1.8\u500d\u3002", "conclusion": "DuetGraph\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u5ea6\u5e73\u6ed1\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "keywords": "\u77e5\u8bc6\u56fe\u8c31,\u63a8\u7406,\u5168\u5c40-\u5c40\u90e8\u878d\u5408,\u8fc7\u5ea6\u5e73\u6ed1,DuetGraph"}}
{"id": "2507.10642", "pdf": "https://arxiv.org/pdf/2507.10642", "abs": "https://arxiv.org/abs/2507.10642", "authors": ["Andrew Gascoyne", "Wendy Lomas"], "title": "First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "A growing issue within conservation bioacoustics is the task of analysing the\nvast amount of data generated from the use of passive acoustic monitoring\ndevices. In this paper, we present an alternative AI model which has the\npotential to help alleviate this problem. Our model formulation addresses the\nkey issues encountered when using current AI models for bioacoustic analysis,\nnamely the: limited training data available; environmental impact, particularly\nin energy consumption and carbon footprint of training and implementing these\nmodels; and associated hardware requirements. The model developed in this work\nuses associative memory via a transparent, explainable Hopfield neural network\nto store signals and detect similar signals which can then be used to classify\nspecies. Training is rapid ($3$\\,ms), as only one representative signal is\nrequired for each target sound within a dataset. The model is fast, taking only\n$5.4$\\,s to pre-process and classify all $10384$ publicly available bat\nrecordings, on a standard Apple MacBook Air. The model is also lightweight with\na small memory footprint of $144.09$\\,MB of RAM usage. Hence, the low\ncomputational demands make the model ideal for use on a variety of standard\npersonal devices with potential for deployment in the field via edge-processing\ndevices. It is also competitively accurate, with up to $86\\%$ precision on the\ndataset used to evaluate the model. In fact, we could not find a single case of\ndisagreement between model and manual identification via expert field guides.\nAlthough a dataset of bat echolocation calls was chosen to demo this\nfirst-of-its-kind AI model, trained on only two representative calls, the model\nis not species specific. In conclusion, we propose an equitable AI model that\nhas the potential to be a game changer for fast, lightweight, sustainable,\ntransparent, explainable and accurate bioacoustic analysis.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eHopfield\u795e\u7ecf\u7f51\u7edc\u7684AI\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u751f\u7269\u58f0\u5b66\u5206\u6790\u4e2d\u7684\u6570\u636e\u5904\u7406\u95ee\u9898\uff0c\u5177\u6709\u5feb\u901f\u3001\u8f7b\u91cf\u3001\u53ef\u6301\u7eed\u548c\u53ef\u89e3\u91ca\u7684\u7279\u70b9\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u58f0\u5b66\u5206\u6790\u4e2d\uff0c\u88ab\u52a8\u58f0\u5b66\u76d1\u6d4b\u8bbe\u5907\u4ea7\u751f\u7684\u6d77\u91cf\u6570\u636e\u5904\u7406\u9762\u4e34\u8bad\u7ec3\u6570\u636e\u6709\u9650\u3001\u73af\u5883\u5f71\u54cd\u53ca\u786c\u4ef6\u9700\u6c42\u9ad8\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u900f\u660e\u4e14\u53ef\u89e3\u91ca\u7684Hopfield\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u5173\u8054\u8bb0\u5fc6\u5b58\u50a8\u4fe1\u53f7\u5e76\u68c0\u6d4b\u76f8\u4f3c\u4fe1\u53f7\uff0c\u5b9e\u73b0\u7269\u79cd\u5206\u7c7b\u3002\u8bad\u7ec3\u4ec5\u9700\u6bcf\u7c7b\u76ee\u6807\u58f0\u97f3\u7684\u4e00\u4e2a\u4ee3\u8868\u4fe1\u53f7\u3002", "result": "\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\u5feb\uff083\u6beb\u79d2\uff09\uff0c\u5904\u740610384\u4e2a\u8759\u8760\u56de\u58f0\u5b9a\u4f4d\u5f55\u97f3\u4ec5\u97005.4\u79d2\uff0c\u5185\u5b58\u5360\u7528144.09MB\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u8fbe86%\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u5feb\u901f\u3001\u8f7b\u91cf\u3001\u53ef\u6301\u7eed\u4e14\u53ef\u89e3\u91ca\u7684\u751f\u7269\u58f0\u5b66\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u751f\u7269\u58f0\u5b66, Hopfield\u795e\u7ecf\u7f51\u7edc, \u53ef\u6301\u7eedAI, \u8f7b\u91cf\u6a21\u578b, \u53ef\u89e3\u91caAI"}}
{"id": "2507.11198", "pdf": "https://arxiv.org/pdf/2507.11198", "abs": "https://arxiv.org/abs/2507.11198", "authors": ["Conrad Borchers", "Bahar Shahrokhian", "Francesco Balzan", "Elham Tajik", "Sreecharan Sankaranarayanan", "Sebastian Simon"], "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding", "categories": ["cs.CL", "cs.AI"], "comment": "Manuscript submitted for review", "summary": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u7f16\u7801\u51c6\u786e\u6027\uff0c\u53d1\u73b0\u6e29\u5ea6\u548c\u4ee3\u7406\u89d2\u8272\u5bf9\u5171\u8bc6\u8fbe\u6210\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u5355\u4ee3\u7406\u7cfb\u7edf\u901a\u5e38\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u63a2\u8ba8\u591a\u4ee3\u7406\u7cfb\u7edf\uff08MAS\uff09\u662f\u5426\u6bd4\u5355\u4ee3\u7406\u7cfb\u7edf\u5728\u5b9a\u6027\u7814\u7a76\u7684\u7f16\u7801\u548c\u6570\u636e\u6807\u6ce8\u4e2d\u66f4\u5177\u4f18\u52bf\uff0c\u5c24\u5176\u5173\u6ce8\u4ee3\u7406\u89d2\u8272\u548c\u6e29\u5ea6\u5bf9\u5171\u8bc6\u6784\u5efa\u548c\u7f16\u7801\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\uff0c\u5229\u75286\u79cd\u5f00\u6e90LLM\uff08\u53c2\u6570\u89c4\u6a21\u4ece30\u4ebf\u5230320\u4ebf\uff09\u548c18\u79cd\u914d\u7f6e\uff0c\u5206\u6790\u8d85\u8fc777,000\u4e2a\u7f16\u7801\u51b3\u7b56\uff0c\u5bf9\u6bd4\u4eba\u7c7b\u6807\u6ce8\u7684\u6570\u5b66\u8f85\u5bfc\u4f1a\u8bdd\u6570\u636e\u96c6\u3002", "result": "\u6e29\u5ea6\u548c\u4ee3\u7406\u89d2\u8272\u663e\u8457\u5f71\u54cd\u5171\u8bc6\u8fbe\u6210\uff0c\u4f46MAS\u5728\u7f16\u7801\u51c6\u786e\u6027\u4e0a\u672a\u8868\u73b0\u51fa\u660e\u663e\u4f18\u52bf\uff1b\u5355\u4ee3\u7406\u7cfb\u7edf\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "MAS\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u4f5c\u7528\u6709\u9650\uff0c\u6311\u6218\u4e86\u591a\u6837\u4ee3\u7406\u89d2\u8272\u80fd\u5e26\u6765\u66f4\u597d\u7ed3\u679c\u7684\u5047\u8bbe\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, \u591a\u4ee3\u7406\u7cfb\u7edf, \u5b9a\u6027\u7814\u7a76, \u7f16\u7801\u51c6\u786e\u6027, \u6e29\u5ea6\u6548\u5e94"}}
{"id": "2507.11277", "pdf": "https://arxiv.org/pdf/2507.11277", "abs": "https://arxiv.org/abs/2507.11277", "authors": ["Dany Moshkovich", "Sergey Zeltyn"], "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.", "AI": {"tldr": "\u63d0\u51fa\u4e86AgentOps\u6846\u67b6\uff0c\u7528\u4e8e\u89c2\u6d4b\u3001\u5206\u6790\u548c\u4f18\u5316\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\uff0c\u89e3\u51b3\u5176\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u63d0\u5347\u7cfb\u7edf\u6548\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u5f15\u5165\u4e86\u7531\u6982\u7387\u63a8\u7406\u3001\u52a8\u6001\u5185\u5b58\u72b6\u6001\u548c\u7075\u6d3b\u6267\u884c\u8def\u5f84\u5e26\u6765\u7684\u65b0\u578b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u8f6f\u4ef6\u53ef\u89c2\u6d4b\u6027\u65b9\u6cd5\u65e0\u6cd5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86AgentOps\u6846\u67b6\uff0c\u5305\u62ec\u884c\u4e3a\u89c2\u6d4b\u3001\u6307\u6807\u6536\u96c6\u3001\u95ee\u9898\u68c0\u6d4b\u3001\u6839\u56e0\u5206\u6790\u3001\u4f18\u5316\u5efa\u8bae\u548c\u8fd0\u884c\u65f6\u81ea\u52a8\u5316\u516d\u4e2a\u9636\u6bb5\uff0c\u670d\u52a1\u4e8e\u5f00\u53d1\u8005\u3001\u6d4b\u8bd5\u4eba\u5458\u3001SRE\u548c\u4e1a\u52a1\u7528\u6237\u7b49\u4e0d\u540c\u89d2\u8272\u3002", "result": "\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u4fdd\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u5b89\u5168\u3001\u9002\u5e94\u6027\u548c\u9ad8\u6548\u8fd0\u884c\u3002", "conclusion": "AgentOps\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u81ea\u52a8\u5316\u4e3a\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u8fd0\u7ef4\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\uff0c\u63d0\u5347\u4e86\u5176\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf,\u81ea\u52a8\u5316\u8fd0\u7ef4,\u4e0d\u786e\u5b9a\u6027\u7ba1\u7406"}}
{"id": "2507.10678", "pdf": "https://arxiv.org/pdf/2507.10678", "abs": "https://arxiv.org/abs/2507.10678", "authors": ["Cutter Dawes", "Simon Segert", "Kamesh Krishnamurthy", "Jonathan D. Cohen"], "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.NE", "q-bio.NC"], "comment": "22 pages, 6 figures", "summary": "A major challenge in the use of neural networks both for modeling human\ncognitive function and for artificial intelligence is the design of systems\nwith the capacity to efficiently learn functions that support radical\ngeneralization. At the roots of this is the capacity to discover and implement\nsymmetry functions. In this paper, we investigate a paradigmatic example of\nradical generalization through the use of symmetry: base addition. We present a\ngroup theoretic analysis of base addition, a fundamental and defining\ncharacteristic of which is the carry function -- the transfer of the remainder,\nwhen a sum exceeds the base modulus, to the next significant place. Our\nanalysis exposes a range of alternative carry functions for a given base, and\nwe introduce quantitative measures to characterize these. We then exploit\ndifferences in carry functions to probe the inductive biases of neural networks\nin symmetry learning, by training neural networks to carry out base addition\nusing different carries, and comparing efficacy and rate of learning as a\nfunction of their structure. We find that even simple neural networks can\nachieve radical generalization with the right input format and carry function,\nand that learning speed is closely correlated with carry function structure. We\nthen discuss the relevance this has for cognitive science and machine learning.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u5bf9\u79f0\u6027\u5b66\u4e60\u5b9e\u73b0\u57fa\u6570\u52a0\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e0d\u540c\u8fdb\u4f4d\u51fd\u6570\u5bf9\u5b66\u4e60\u6548\u679c\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u5982\u4f55\u901a\u8fc7\u5bf9\u79f0\u6027\u5b66\u4e60\u6709\u6548\u5b9e\u73b0\u57fa\u6570\u52a0\u6cd5\uff0c\u4ee5\u652f\u6301\u4eba\u5de5\u667a\u80fd\u548c\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7fa4\u8bba\u5206\u6790\u57fa\u6570\u52a0\u6cd5\uff0c\u63d0\u51fa\u591a\u79cd\u8fdb\u4f4d\u51fd\u6570\uff0c\u5e76\u901a\u8fc7\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6bd4\u8f83\u4e0d\u540c\u8fdb\u4f4d\u51fd\u6570\u7684\u5b66\u4e60\u6548\u679c\u3002", "result": "\u7b80\u5355\u795e\u7ecf\u7f51\u7edc\u5728\u5408\u9002\u7684\u8f93\u5165\u683c\u5f0f\u548c\u8fdb\u4f4d\u51fd\u6570\u4e0b\u53ef\u5b9e\u73b0\u6cdb\u5316\uff0c\u5b66\u4e60\u901f\u5ea6\u4e0e\u8fdb\u4f4d\u51fd\u6570\u7ed3\u6784\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8ba4\u77e5\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u5bf9\u79f0\u6027\u5b66\u4e60\u7684\u65b0\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u8fdb\u4f4d\u51fd\u6570\u7ed3\u6784\u7684\u91cd\u8981\u6027\u3002", "keywords": "\u795e\u7ecf\u7f51\u7edc, \u5bf9\u79f0\u6027\u5b66\u4e60, \u57fa\u6570\u52a0\u6cd5, \u8fdb\u4f4d\u51fd\u6570, \u6cdb\u5316\u80fd\u529b"}}
{"id": "2507.11216", "pdf": "https://arxiv.org/pdf/2507.11216", "abs": "https://arxiv.org/abs/2507.11216", "authors": ["Valle Ruiz-Fern\u00e1ndez", "Mario Mina", "J\u00falia Falc\u00e3o", "Luis Vasquez-Reina", "Anna Sall\u00e9s", "Aitor Gonzalez-Agirre", "Olatz Perez-de-Vi\u00f1aspre"], "title": "EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Previous literature has largely shown that Large Language Models (LLMs)\nperpetuate social biases learnt from their pre-training data. Given the notable\nlack of resources for social bias evaluation in languages other than English,\nand for social contexts outside of the United States, this paper introduces the\nSpanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and\nCaBBQ). Based on the original BBQ, these two parallel datasets are designed to\nassess social bias across 10 categories using a multiple-choice QA setting, now\nadapted to the Spanish and Catalan languages and to the social context of\nSpain. We report evaluation results on different LLMs, factoring in model\nfamily, size and variant. Our results show that models tend to fail to choose\nthe correct answer in ambiguous scenarios, and that high QA accuracy often\ncorrelates with greater reliance on social biases.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u897f\u73ed\u7259\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u7684\u793e\u4f1a\u504f\u89c1\u8bc4\u4f30\u6570\u636e\u96c6EsBBQ\u548cCaBBQ\uff0c\u57fa\u4e8e\u539f\u7248BBQ\u8bbe\u8ba1\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u897f\u73ed\u7259\u793e\u4f1a\u80cc\u666f\u4e0b\u7684\u504f\u89c1\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u975e\u82f1\u8bed\u8bed\u8a00\u548c\u975e\u7f8e\u56fd\u793e\u4f1a\u80cc\u666f\u4e0b\u793e\u4f1a\u504f\u89c1\u8bc4\u4f30\u8d44\u6e90\u7684\u7f3a\u4e4f\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u897f\u73ed\u7259\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u7684\u504f\u89c1\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u591a\u9009\u9898QA\u5f62\u5f0f\u8bc4\u4f3010\u4e2a\u7c7b\u522b\u7684\u793e\u4f1a\u504f\u89c1\u3002", "result": "\u6a21\u578b\u5728\u6a21\u7cca\u573a\u666f\u4e2d\u5e38\u65e0\u6cd5\u9009\u62e9\u6b63\u786e\u7b54\u6848\uff0c\u4e14\u9ad8QA\u51c6\u786e\u7387\u5e38\u4e0e\u66f4\u4f9d\u8d56\u793e\u4f1a\u504f\u89c1\u76f8\u5173\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u975e\u82f1\u8bed\u8bed\u8a00\u793e\u4f1a\u504f\u89c1\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u5728\u6a21\u7cca\u573a\u666f\u4e2d\u7684\u504f\u89c1\u884c\u4e3a\u3002", "keywords": "Large Language Models, social bias, Spanish, Catalan, BBQ, evaluation"}}
{"id": "2507.11288", "pdf": "https://arxiv.org/pdf/2507.11288", "abs": "https://arxiv.org/abs/2507.11288", "authors": ["Th\u00e9o Fagnoni", "Mahsun Altin", "Chia En Chung", "Phillip Kingston", "Alan Tuning", "Dana O. Mohamed", "In\u00e8s Adnani"], "title": "Opus: A Prompt Intention Framework for Complex Workflow Generation", "categories": ["cs.AI"], "comment": "39 pages, 24 figures", "summary": "This paper introduces the Opus Prompt Intention Framework, designed to\nimprove complex Workflow Generation with instruction-tuned Large Language\nModels (LLMs). We propose an intermediate Intention Capture layer between user\nqueries and Workflow Generation, implementing the Opus Workflow Intention\nFramework, which consists of extracting Workflow Signals from user queries,\ninterpreting them into structured Workflow Intention objects, and generating\nWorkflows based on these Intentions. Our results show that this layer enables\nLLMs to produce logical and meaningful outputs that scale reliably as query\ncomplexity increases. On a synthetic benchmark of 1,000 multi-intent\nquery-Workflow(s) pairs, applying the Opus Prompt Intention Framework to\nWorkflow Generation yields consistent improvements in semantic Workflow\nsimilarity metrics. In this paper, we introduce the Opus Prompt Intention\nFramework by applying the concepts of Workflow Signal and Workflow Intention to\nLLM-driven Workflow Generation. We present a reproducible, customizable\nLLM-based Intention Capture system to extract Workflow Signals and Workflow\nIntentions from user queries. Finally, we provide empirical evidence that the\nproposed system significantly improves Workflow Generation quality compared to\ndirect generation from user queries, particularly in cases of Mixed Intention\nElicitation.", "AI": {"tldr": "Opus Prompt Intention Framework\u901a\u8fc7\u5f15\u5165\u4e2d\u95f4\u610f\u56fe\u6355\u6349\u5c42\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u6307\u4ee4\u8c03\u6574\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u590d\u6742\u5de5\u4f5c\u6d41\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u76f4\u63a5\u6839\u636e\u7528\u6237\u67e5\u8be2\u751f\u6210\u5de5\u4f5c\u6d41\u65f6\u590d\u6742\u6027\u548c\u591a\u610f\u56fe\u95ee\u9898\uff0c\u63d0\u9ad8\u5de5\u4f5c\u6d41\u7684\u903b\u8f91\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86Opus\u5de5\u4f5c\u6d41\u610f\u56fe\u6846\u67b6\uff0c\u5305\u62ec\u4ece\u7528\u6237\u67e5\u8be2\u4e2d\u63d0\u53d6\u5de5\u4f5c\u6d41\u4fe1\u53f7\u3001\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u610f\u56fe\u5bf9\u8c61\uff0c\u5e76\u57fa\u4e8e\u6b64\u751f\u6210\u5de5\u4f5c\u6d41\u3002", "result": "\u57281000\u5bf9\u591a\u610f\u56fe\u67e5\u8be2-\u5de5\u4f5c\u6d41\u5bf9\u7684\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u8bed\u4e49\u5de5\u4f5c\u6d41\u76f8\u4f3c\u6027\u6307\u6807\u3002", "conclusion": "Opus Prompt Intention Framework\u6709\u6548\u63d0\u9ad8\u4e86LLM\u751f\u6210\u5de5\u4f5c\u6d41\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u5728\u591a\u610f\u56fe\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "keywords": "\u5de5\u4f5c\u6d41\u751f\u6210,\u5927\u8bed\u8a00\u6a21\u578b,\u610f\u56fe\u6355\u6349,Opus\u6846\u67b6"}}
{"id": "2507.10714", "pdf": "https://arxiv.org/pdf/2507.10714", "abs": "https://arxiv.org/abs/2507.10714", "authors": ["Bright Kwaku Manu", "Trevor Reckell", "Beckett Sterner", "Petar Jevtic"], "title": "A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models", "categories": ["cs.LG", "q-bio.QM", "stat.ML", "68, 92", "I.6; I.2.6"], "comment": "12 pages, 10 figures, for all associated codes and files, see\n  https://github.com/BrightManu-lang/SPN-param-recovery.git", "summary": "Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for\nmodeling discrete-event dynamics in areas such as epidemiology and systems\nbiology, yet their parameter estimation remains challenging in general and in\nparticular when transition rates depend on external covariates and explicit\nlikelihoods are unavailable. We introduce a neural-surrogate\n(neural-network--based approximation of the posterior distribution) framework\nthat predicts the coefficients of known covariate-dependent rate functions\ndirectly from noisy, partially observed token trajectories. Our model employs a\nlightweight 1D Convolutional Residual Network trained end-to-end on\nGillespie-simulated SPN realizations, learning to invert system dynamics under\nrealistic conditions of event dropout. During inference, Monte Carlo dropout\nprovides calibrated uncertainty bounds together with point estimates. On\nsynthetic SPNs with 20% missing events, our surrogate recovers rate-function\ncoefficients with an RMSE = 0.108 and substantially runs faster than\ntraditional Bayesian approaches. These results demonstrate that data-driven,\nlikelihood-free surrogates can enable accurate, robust, and real-time parameter\nrecovery in complex, partially observed discrete-event systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u76f4\u63a5\u4ece\u90e8\u5206\u89c2\u6d4b\u7684\u566a\u58f0\u6570\u636e\u4e2d\u9884\u6d4bSPN\u7684\u534f\u53d8\u91cf\u4f9d\u8d56\u901f\u7387\u51fd\u6570\u7cfb\u6570\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5feb\u66f4\u51c6\u3002", "motivation": "\u89e3\u51b3SPN\u5728\u534f\u53d8\u91cf\u4f9d\u8d56\u901f\u7387\u51fd\u6570\u4e0b\u53c2\u6570\u4f30\u8ba1\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5f53\u663e\u5f0f\u4f3c\u7136\u4e0d\u53ef\u5f97\u65f6\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea71D\u5377\u79ef\u6b8b\u5dee\u7f51\u7edc\uff0c\u901a\u8fc7Gillespie\u6a21\u62df\u8bad\u7ec3\uff0c\u5b66\u4e60\u5728\u4e8b\u4ef6\u4e22\u5931\u6761\u4ef6\u4e0b\u53cd\u8f6c\u7cfb\u7edf\u52a8\u6001\u3002", "result": "\u572820%\u4e8b\u4ef6\u4e22\u5931\u7684\u5408\u6210SPN\u4e2d\uff0c\u4ee3\u7406\u6a21\u578b\u7684RMSE\u4e3a0.108\uff0c\u901f\u5ea6\u663e\u8457\u5feb\u4e8e\u4f20\u7edf\u8d1d\u53f6\u65af\u65b9\u6cd5\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u65e0\u4f3c\u7136\u4ee3\u7406\u65b9\u6cd5\u53ef\u5b9e\u73b0\u590d\u6742\u90e8\u5206\u89c2\u6d4b\u79bb\u6563\u4e8b\u4ef6\u7cfb\u7edf\u4e2d\u51c6\u786e\u3001\u7a33\u5065\u4e14\u5b9e\u65f6\u7684\u53c2\u6570\u6062\u590d\u3002", "keywords": "Stochastic Petri Nets, neural surrogate, parameter estimation, covariate-dependent rates, likelihood-free"}}
{"id": "2507.11222", "pdf": "https://arxiv.org/pdf/2507.11222", "abs": "https://arxiv.org/abs/2507.11222", "authors": ["Fares Wael", "Youssef Maklad", "Ali Hamdi", "Wael Elsersy"], "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "categories": ["cs.CL", "cs.AI", "cs.NI"], "comment": null, "summary": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.", "AI": {"tldr": "\u63d0\u51faFlowFSM\u6846\u67b6\uff0c\u5229\u7528LLM\u548c\u63d0\u793a\u94fe\u6280\u672f\u4eceRFC\u6587\u6863\u4e2d\u63d0\u53d6\u7cbe\u786e\u7684FSM\uff0c\u514b\u670d\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709FSM\u63d0\u53d6\u6280\u672f\u5728\u53ef\u6269\u5c55\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u81ea\u7136\u8bed\u8a00\u6b67\u4e49\u5904\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0cFlowFSM\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6846\u67b6FlowFSM\uff0c\u7ed3\u5408\u63d0\u793a\u94fe\u548c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u4eceRFC\u6587\u6863\u4e2d\u63d0\u53d6FSM\u5e76\u6784\u5efa\u7ed3\u6784\u5316\u89c4\u5219\u4e66\u3002", "result": "\u5728FTP\u548cRTSP\u534f\u8bae\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cFlowFSM\u63d0\u53d6\u7cbe\u5ea6\u9ad8\uff0c\u5e7b\u89c9\u8f6c\u79fb\u5c11\uff0c\u6548\u679c\u663e\u8457\u3002", "conclusion": "FlowFSM\u5c55\u793a\u4e86\u57fa\u4e8e\u4ee3\u7406\u7684LLM\u7cfb\u7edf\u5728\u534f\u8bae\u5206\u6790\u548cFSM\u63a8\u65ad\u4e2d\u7684\u6f5c\u529b\uff0c\u9002\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u548c\u9006\u5411\u5de5\u7a0b\u3002", "keywords": "Finite-State Machines, LLM, RFC documents, protocol analysis, cybersecurity"}}
{"id": "2507.11323", "pdf": "https://arxiv.org/pdf/2507.11323", "abs": "https://arxiv.org/abs/2507.11323", "authors": ["Xiang Yin", "Nico Potyka", "Antonio Rago", "Timotheus Kampik", "Francesca Toni"], "title": "Contestability in Quantitative Argumentation", "categories": ["cs.AI"], "comment": null, "summary": "Contestable AI requires that AI-driven decisions align with human\npreferences. While various forms of argumentation have been shown to support\ncontestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks\n(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs\ncan be deployed for this purpose. Specifically, we introduce the contestability\nproblem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)\nto achieve a desired strength for a specific argument of interest (i.e., a\ntopic argument). To address this problem, we propose gradient-based relation\nattribution explanations (G-RAEs), which quantify the sensitivity of the topic\nargument's strength to changes in individual edge weights, thus providing\ninterpretable guidance for weight adjustments towards contestability. Building\non G-RAEs, we develop an iterative algorithm that progressively adjusts the\nedge weights to attain the desired strength. We evaluate our approach\nexperimentally on synthetic EW-QBAFs that simulate the structural\ncharacteristics of personalised recommender systems and multi-layer\nperceptrons, and demonstrate that it can solve the problem effectively.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5728\u8fb9\u7f18\u52a0\u6743\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff08EW-QBAF\uff09\u4e2d\u5b9e\u73b0AI\u51b3\u7b56\u7684\u53ef\u4e89\u8bae\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u7684\u5173\u7cfb\u5f52\u56e0\u89e3\u91ca\u65b9\u6cd5\uff08G-RAE\uff09\u6765\u6307\u5bfc\u6743\u91cd\u8c03\u6574\u3002", "motivation": "\u4e3a\u4e86\u786e\u4fddAI\u9a71\u52a8\u7684\u51b3\u7b56\u4e0e\u4eba\u7c7b\u504f\u597d\u4e00\u81f4\uff0c\u6587\u7ae0\u63a2\u8ba8\u4e86EW-QBAF\u5728\u5b9e\u73b0\u53ef\u4e89\u8bae\u6027\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86G-RAE\u65b9\u6cd5\uff0c\u91cf\u5316\u4e3b\u9898\u8bba\u636e\u5f3a\u5ea6\u5bf9\u6743\u91cd\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u7b97\u6cd5\u9010\u6b65\u8c03\u6574\u6743\u91cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3EW-QBAF\u4e2d\u7684\u53ef\u4e89\u8bae\u6027\u95ee\u9898\u3002", "conclusion": "G-RAE\u548c\u8fed\u4ee3\u7b97\u6cd5\u4e3aEW-QBAF\u4e2d\u7684\u6743\u91cd\u8c03\u6574\u63d0\u4f9b\u4e86\u89e3\u91ca\u6027\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0AI\u51b3\u7b56\u7684\u53ef\u4e89\u8bae\u6027\u3002", "keywords": "\u53ef\u4e89\u8bae\u6027, EW-QBAF, G-RAE, \u6743\u91cd\u8c03\u6574, AI\u51b3\u7b56"}}
{"id": "2507.10718", "pdf": "https://arxiv.org/pdf/2507.10718", "abs": "https://arxiv.org/abs/2507.10718", "authors": ["Shuyao Li", "Ilias Diakonikolas", "Jelena Diakonikolas"], "title": "Distributionally Robust Optimization with Adversarial Data Contamination", "categories": ["cs.LG", "cs.DS", "math.OC"], "comment": null, "summary": "Distributionally Robust Optimization (DRO) provides a framework for\ndecision-making under distributional uncertainty, yet its effectiveness can be\ncompromised by outliers in the training data. This paper introduces a\nprincipled approach to simultaneously address both challenges. We focus on\noptimizing Wasserstein-1 DRO objectives for generalized linear models with\nconvex Lipschitz loss functions, where an $\\epsilon$-fraction of the training\ndata is adversarially corrupted. Our primary contribution lies in a novel\nmodeling framework that integrates robustness against training data\ncontamination with robustness against distributional shifts, alongside an\nefficient algorithm inspired by robust statistics to solve the resulting\noptimization problem. We prove that our method achieves an estimation error of\n$O(\\sqrt{\\epsilon})$ for the true DRO objective value using only the\ncontaminated data under the bounded covariance assumption. This work\nestablishes the first rigorous guarantees, supported by efficient computation,\nfor learning under the dual challenges of data contamination and distributional\nshifts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWasserstein-1 DRO\u6846\u67b6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5f02\u5e38\u503c\u548c\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u9ad8\u6548\u7b97\u6cd5\u5728\u6570\u636e\u6c61\u67d3\u4e0b\u5b9e\u73b0O(\u221a\u03b5)\u7684\u4f30\u8ba1\u8bef\u5dee\u3002", "motivation": "\u9762\u5bf9\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5f02\u5e38\u503c\u548c\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u7684DRO\u65b9\u6cd5\u53ef\u80fd\u5931\u6548\uff0c\u9700\u8981\u4e00\u79cd\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u79cd\u6311\u6218\u7684\u9c81\u68d2\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Wasserstein-1 DRO\u76ee\u6807\u4f18\u5316\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\uff0c\u7ed3\u5408\u9c81\u68d2\u7edf\u8ba1\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7b97\u6cd5\u5904\u7406\u6570\u636e\u6c61\u67d3\u548c\u5206\u5e03\u504f\u79fb\u3002", "result": "\u5728\u6570\u636e\u6c61\u67d3\u7387\u4e3a\u03b5\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86O(\u221a\u03b5)\u7684\u4f30\u8ba1\u8bef\u5dee\uff0c\u4e14\u5728\u534f\u65b9\u5dee\u6709\u754c\u5047\u8bbe\u4e0b\u6709\u6548\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u540c\u65f6\u5e94\u5bf9\u6570\u636e\u6c61\u67d3\u548c\u5206\u5e03\u504f\u79fb\u7684\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u9996\u4e2a\u7406\u8bba\u4fdd\u8bc1\u548c\u9ad8\u6548\u8ba1\u7b97\u65b9\u6848\u3002", "keywords": "\u9c81\u68d2\u4f18\u5316, Wasserstein\u8ddd\u79bb, \u6570\u636e\u6c61\u67d3, \u5206\u5e03\u504f\u79fb, \u5e7f\u4e49\u7ebf\u6027\u6a21\u578b"}}
{"id": "2507.11230", "pdf": "https://arxiv.org/pdf/2507.11230", "abs": "https://arxiv.org/abs/2507.11230", "authors": ["Lyzander Marciano Andrylie", "Inaya Rahmanisa", "Mahardika Krisna Ihsani", "Alfan Farizki Wicaksono", "Haryo Akbarianto Wibowo", "Alham Fikri Aji"], "title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages", "categories": ["cs.CL", "68T50"], "comment": null, "summary": "Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features .", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSAE-LAPE\u65b9\u6cd5\uff0c\u5229\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u8bc6\u522b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\uff0c\u53d1\u73b0\u8fd9\u4e9b\u7279\u5f81\u4e3b\u8981\u96c6\u4e2d\u5728\u6a21\u578b\u7684\u4e2d\u95f4\u81f3\u6700\u7ec8\u5c42\uff0c\u5e76\u5f71\u54cd\u6a21\u578b\u7684\u591a\u8bed\u8a00\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8bed\u8a00\u673a\u5236\uff0c\u4ee5\u7406\u89e3\u5176\u5982\u4f55\u5904\u7406\u4e0d\u540c\u8bed\u8a00\uff0c\u5c24\u5176\u662f\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\u7684\u8bc6\u522b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u548c\u63d0\u51fa\u7684SAE-LAPE\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7279\u5f81\u6fc0\u6d3b\u6982\u7387\u8bc6\u522b\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\u96c6\u4e2d\u5728\u6a21\u578b\u7684\u4e2d\u540e\u5c42\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u591a\u8bed\u8a00\u8868\u73b0\u548c\u8f93\u51fa\uff0c\u4e14\u53ef\u7528\u4e8e\u8bed\u8a00\u8bc6\u522b\uff0c\u6027\u80fd\u4e0efastText\u76f8\u5f53\u4f46\u66f4\u53ef\u89e3\u91ca\u3002", "conclusion": "SAE-LAPE\u65b9\u6cd5\u6709\u6548\u8bc6\u522b\u4e86\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u7279\u5f81\u5728\u6a21\u578b\u4e2d\u7684\u4f5c\u7528\uff0c\u4e3a\u591a\u8bed\u8a00\u673a\u5236\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u591a\u8bed\u8a00\u673a\u5236\u3001\u7a00\u758f\u81ea\u7f16\u7801\u5668\u3001\u8bed\u8a00\u7279\u5b9a\u7279\u5f81"}}
{"id": "2507.11334", "pdf": "https://arxiv.org/pdf/2507.11334", "abs": "https://arxiv.org/abs/2507.11334", "authors": ["Yuehao Huang", "Liang Liu", "Shuangming Lei", "Yukai Ma", "Hao Su", "Jianbiao Mei", "Pengxiang Zhao", "Yaqing Gu", "Yong Liu", "Jiajun Lv"], "title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted by ACM MM 2025", "summary": "Mobile robots are increasingly required to navigate and interact within\nunknown and unstructured environments to meet human demands. Demand-driven\nnavigation (DDN) enables robots to identify and locate objects based on\nimplicit human intent, even when object locations are unknown. However,\ntraditional data-driven DDN methods rely on pre-collected data for model\ntraining and decision-making, limiting their generalization capability in\nunseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that\nemulates the human cognitive and learning mechanisms by integrating fast and\nslow thinking systems and selectively identifying key objects essential to\nfulfilling user demands. CogDDN identifies appropriate target objects by\nsemantically aligning detected objects with the given instructions.\nFurthermore, it incorporates a dual-process decision-making module, comprising\na Heuristic Process for rapid, efficient decisions and an Analytic Process that\nanalyzes past errors, accumulates them in a knowledge base, and continuously\nimproves performance. Chain of Thought (CoT) reasoning strengthens the\ndecision-making process. Extensive closed-loop evaluations on the AI2Thor\nsimulator with the ProcThor dataset show that CogDDN outperforms single-view\ncamera-only methods by 15%, demonstrating significant improvements in\nnavigation accuracy and adaptability. The project page is available at\nhttps://yuehaohuang.github.io/CogDDN/.", "AI": {"tldr": "CogDDN\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u5b66\u4e60\u673a\u5236\uff0c\u7ed3\u5408\u5feb\u901f\u548c\u6162\u901f\u601d\u7ef4\u7cfb\u7edf\uff0c\u9009\u62e9\u6027\u5730\u8bc6\u522b\u5173\u952e\u5bf9\u8c61\u4ee5\u6ee1\u8db3\u7528\u6237\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u548c\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\u3002", "motivation": "\u673a\u5668\u4eba\u9700\u8981\u5728\u672a\u77e5\u548c\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5bfc\u822a\u548c\u4ea4\u4e92\uff0c\u4f20\u7edf\u7684\u9700\u6c42\u9a71\u52a8\u5bfc\u822a\uff08DDN\uff09\u65b9\u6cd5\u4f9d\u8d56\u9884\u6536\u96c6\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u672a\u89c1\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002CogDDN\u65e8\u5728\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "CogDDN\u6574\u5408\u4e86\u5feb\u901f\u548c\u6162\u901f\u601d\u7ef4\u7cfb\u7edf\uff0c\u8bed\u4e49\u5bf9\u9f50\u68c0\u6d4b\u5230\u7684\u5bf9\u8c61\u4e0e\u6307\u4ee4\uff0c\u5e76\u901a\u8fc7\u53cc\u8fc7\u7a0b\u51b3\u7b56\u6a21\u5757\uff08\u542f\u53d1\u5f0f\u548c\u89e3\u6790\u5f0f\uff09\u4f18\u5316\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7ed3\u5408Chain of Thought\uff08CoT\uff09\u63a8\u7406\u589e\u5f3a\u51b3\u7b56\u51c6\u786e\u6027\u3002", "result": "\u5728AI2Thor\u6a21\u62df\u5668\u4e0a\u4f7f\u7528ProcThor\u6570\u636e\u96c6\u7684\u95ed\u73af\u8bc4\u4f30\u4e2d\uff0cCogDDN\u76f8\u6bd4\u5355\u89c6\u89d2\u76f8\u673a\u65b9\u6cd5\u63d0\u5347\u4e8615%\u7684\u5bfc\u822a\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "CogDDN\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u673a\u5668\u4eba\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u548c\u4efb\u52a1\u5b8c\u6210\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "keywords": "\u79fb\u52a8\u673a\u5668\u4eba,\u9700\u6c42\u9a71\u52a8\u5bfc\u822a,\u89c6\u89c9\u8bed\u8a00\u6a21\u578b,\u5feb\u901f\u548c\u6162\u901f\u601d\u7ef4\u7cfb\u7edf,Chain of Thought\u63a8\u7406"}}
{"id": "2507.10741", "pdf": "https://arxiv.org/pdf/2507.10741", "abs": "https://arxiv.org/abs/2507.10741", "authors": ["Andrew C. Li", "Toryn Q. Klassen", "Andrew Wang", "Parand A. Alamdari", "Sheila A. McIlraith"], "title": "Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.4"], "comment": null, "summary": "Grounding language in complex perception (e.g. pixels) and action is a key\nchallenge when building situated agents that can interact with humans via\nlanguage. In past works, this is often solved via manual design of the language\ngrounding or by curating massive datasets relating language to elements of the\nenvironment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for\ngrounding formal language from data, and eliciting behaviours by directly\ntasking RL agents through this language. By virtue of data-driven learning, our\nframework avoids the manual design of domain-specific elements like reward\nfunctions or symbol detectors. By virtue of compositional formal language\nsemantics, our framework achieves data-efficient grounding and generalization\nto arbitrary language compositions. Experiments on an image-based gridworld and\na MuJoCo robotics domain show that our approach reliably maps formal language\ninstructions to behaviours with limited data while end-to-end, data-driven\napproaches fail.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Ground-Compose-Reinforce\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u8bed\u8a00\u63a5\u5730\uff0c\u5e76\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u6267\u884c\u8bed\u8a00\u6307\u4ee4\uff0c\u907f\u514d\u4e86\u624b\u52a8\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u7b49\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u611f\u77e5\uff08\u5982\u50cf\u7d20\uff09\u548c\u52a8\u4f5c\u4e2d\u8bed\u8a00\u63a5\u5730\u7684\u6311\u6218\uff0c\u6784\u5efa\u80fd\u4e0e\u4eba\u7c7b\u901a\u8fc7\u8bed\u8a00\u4ea4\u4e92\u7684\u60c5\u666f\u4ee3\u7406\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6846\u67b6Ground-Compose-Reinforce\uff0c\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u548c\u7ec4\u5408\u5f62\u5f0f\u8bed\u8a00\u8bed\u4e49\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u8bed\u8a00\u63a5\u5730\u548c\u6cdb\u5316\u3002", "result": "\u5728\u57fa\u4e8e\u56fe\u50cf\u7684\u7f51\u683c\u4e16\u754c\u548cMuJoCo\u673a\u5668\u4eba\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4ee5\u6709\u9650\u6570\u636e\u53ef\u9760\u5730\u5c06\u5f62\u5f0f\u8bed\u8a00\u6307\u4ee4\u6620\u5c04\u5230\u884c\u4e3a\uff0c\u800c\u7aef\u5230\u7aef\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5931\u8d25\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ec4\u5408\u8bed\u4e49\u548c\u6570\u636e\u9a71\u52a8\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8bed\u8a00\u63a5\u5730\u548c\u6307\u4ee4\u6267\u884c\uff0c\u9002\u7528\u4e8e\u590d\u6742\u73af\u5883\u4efb\u52a1\u3002", "keywords": "\u8bed\u8a00\u63a5\u5730,\u795e\u7ecf\u7b26\u53f7\u6846\u67b6,\u5f3a\u5316\u5b66\u4e60,\u7ec4\u5408\u8bed\u4e49,\u6570\u636e\u9a71\u52a8"}}
{"id": "2507.11273", "pdf": "https://arxiv.org/pdf/2507.11273", "abs": "https://arxiv.org/abs/2507.11273", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Guoming Liu", "Baoyuan Qi", "Hai Zhao"], "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding", "categories": ["cs.CL"], "comment": "To be published in The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "Large language models (LLMs) based on Transformer Decoders have become the\npreferred choice for conversational generative AI. Despite the overall\nsuperiority of the Decoder architecture, the gradually increasing Key-Value\n(KV) cache during inference has emerged as a primary efficiency bottleneck,\nboth in aspects of memory consumption and data transfer bandwidth limitations.\nTo address these challenges, we propose a paradigm called KV-Latent. By\ndown-sampling the Key-Value vector dimensions into a latent space, we can\nsignificantly reduce the KV Cache footprint and improve inference speed, only\nwith a small amount of extra training, less than 1\\% of pre-training takes.\nBesides, we enhanced the stability of Rotary Positional Embedding applied on\nlower-dimensional vectors by modifying its frequency sampling mechanism,\navoiding noise introduced by higher frequencies while retaining position\nattenuation. Our experiments, including both models with Grouped Query\nAttention and those without, have yielded satisfactory results. Finally, we\nconducted comparative experiments to study the impact of separately reducing\nKey and Value components on model's performance. Our approach allows for the\nconstruction of more efficient language model systems, and opens the new\npossibility on KV Cache saving and efficient LLMs. Our code is available at\nhttps://github.com/ShiLuohe/KV-Latent.", "AI": {"tldr": "\u63d0\u51faKV-Latent\u8303\u5f0f\uff0c\u901a\u8fc7\u964d\u91c7\u6837\u952e\u503c\u5411\u91cf\u7ef4\u5ea6\u6765\u51cf\u5c11KV\u7f13\u5b58\u5360\u7528\u5e76\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u6539\u8fdb\u4f4d\u7f6e\u7f16\u7801\u7684\u9891\u57df\u91c7\u6837\u673a\u5236\u589e\u5f3a\u7a33\u5b9a\u6027\u3002", "motivation": "\u89e3\u7801\u5668\u67b6\u6784\u4e2d\u9010\u6e10\u589e\u52a0\u7684KV\u7f13\u5b58\u6210\u4e3a\u63a8\u7406\u6548\u7387\u74f6\u9888\uff0c\u4e9f\u9700\u4f18\u5316\u3002", "method": "\u63d0\u51faKV-Latent\u8303\u5f0f\uff0c\u964d\u91c7\u6837\u952e\u503c\u5411\u91cf\u81f3\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u6539\u8fdbRotary\u4f4d\u7f6e\u7f16\u7801\u7684\u9891\u57df\u91c7\u6837\u673a\u5236\u3002", "result": "\u663e\u8457\u51cf\u5c11KV\u7f13\u5b58\u5360\u7528\u548c\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u5b9e\u9a8c\u6548\u679c\u6ee1\u610f\u3002", "conclusion": "KV-Latent\u65b9\u6cd5\u80fd\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff0c\u4e3aKV\u7f13\u5b58\u4f18\u5316\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "keywords": "KV\u7f13\u5b58\uff0c\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f4d\u7f6e\u7f16\u7801\uff0c\u63a8\u7406\u6548\u7387"}}
{"id": "2507.11352", "pdf": "https://arxiv.org/pdf/2507.11352", "abs": "https://arxiv.org/abs/2507.11352", "authors": ["Yunhao Yang", "Neel P. Bhatt", "Christian Ellis", "Alvaro Velasquez", "Zhangyang Wang", "Ufuk Topcu"], "title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces", "categories": ["cs.AI", "cs.FL"], "comment": null, "summary": "Logistics operators, from battlefield coordinators rerouting airlifts ahead\nof a storm to warehouse managers juggling late trucks, often face life-critical\ndecisions that demand both domain expertise and rapid and continuous\nreplanning. While popular methods like integer programming yield logistics\nplans that satisfy user-defined logical constraints, they are slow and assume\nan idealized mathematical model of the environment that does not account for\nuncertainty. On the other hand, large language models (LLMs) can handle\nuncertainty and promise to accelerate replanning while lowering the barrier to\nentry by translating free-form utterances into executable plans, yet they\nremain prone to misinterpretations and hallucinations that jeopardize safety\nand cost. We introduce a neurosymbolic framework that pairs the accessibility\nof natural-language dialogue with verifiable guarantees on goal interpretation.\nIt converts user requests into structured planning specifications, quantifies\nits own uncertainty at the field and token level, and invokes an interactive\nclarification loop whenever confidence falls below an adaptive threshold. A\nlightweight model, fine-tuned on just 100 uncertainty-filtered examples,\nsurpasses the zero-shot performance of GPT-4.1 while cutting inference latency\nby nearly 50%. These preliminary results highlight a practical path toward\ncertifiable, real-time, and user-aligned decision-making for complex logistics.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u7684\u53ef\u8bbf\u95ee\u6027\u4e0e\u76ee\u6807\u89e3\u91ca\u7684\u53ef\u9a8c\u8bc1\u4fdd\u8bc1\uff0c\u7528\u4e8e\u590d\u6742\u7269\u6d41\u51b3\u7b56\u3002", "motivation": "\u7269\u6d41\u64cd\u4f5c\u8005\u5e38\u9700\u5feb\u901f\u8c03\u6574\u8ba1\u5212\uff0c\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u6574\u6570\u89c4\u5212\uff09\u901f\u5ea6\u6162\u4e14\u73af\u5883\u6a21\u578b\u7406\u60f3\u5316\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6613\u8bef\u89e3\u548c\u5e7b\u89c9\uff0c\u5bfc\u81f4\u5b89\u5168\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u4e3a\u7ed3\u6784\u5316\u89c4\u5212\uff0c\u91cf\u5316\u81ea\u8eab\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u4fe1\u5fc3\u4e0d\u8db3\u65f6\u542f\u52a8\u4ea4\u4e92\u5f0f\u6f84\u6e05\u5faa\u73af\u3002\u8f7b\u91cf\u6a21\u578b\u57fa\u4e8e100\u4e2a\u6837\u672c\u5fae\u8c03\u3002", "result": "\u8be5\u6846\u67b6\u6027\u80fd\u8d85\u8fc7GPT-4.1\u96f6\u6837\u672c\u8868\u73b0\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u8fd150%\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u4e00\u6761\u53ef\u5b9e\u73b0\u5b9e\u65f6\u3001\u5b89\u5168\u4e0e\u7528\u6237\u5bf9\u9f50\u7684\u590d\u6742\u7269\u6d41\u51b3\u7b56\u8def\u5f84\u3002", "keywords": "\u795e\u7ecf\u7b26\u53f7\u6846\u67b6, \u7269\u6d41\u51b3\u7b56, \u4e0d\u786e\u5b9a\u6027\u91cf\u5316, \u4ea4\u4e92\u5f0f\u6f84\u6e05, \u8f7b\u91cf\u6a21\u578b"}}
{"id": "2507.10747", "pdf": "https://arxiv.org/pdf/2507.10747", "abs": "https://arxiv.org/abs/2507.10747", "authors": ["Kaustubh Tangsali", "Rishikesh Ranade", "Mohammad Amin Nabian", "Alexey Kamenev", "Peter Sharpe", "Neil Ashton", "Ram Cherukuri", "Sanjay Choudhry"], "title": "A Benchmarking Framework for AI models in Automotive Aerodynamics", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we introduce a benchmarking framework within the open-source\nNVIDIA PhysicsNeMo-CFD framework designed to systematically assess the\naccuracy, performance, scalability, and generalization capabilities of AI\nmodels for automotive aerodynamics predictions. The open extensible framework\nenables incorporation of a diverse set of metrics relevant to the\nComputer-Aided Engineering (CAE) community. By providing a standardized\nmethodology for comparing AI models, the framework enhances transparency and\nconsistency in performance assessment, with the overarching goal of improving\nthe understanding and development of these models to accelerate research and\ninnovation in the field. To demonstrate its utility, the framework includes\nevaluation of both surface and volumetric flow field predictions on three AI\nmodels: DoMINO, X-MeshGraphNet, and FIGConvNet using the DrivAerML dataset. It\nalso includes guidelines for integrating additional models and datasets, making\nit extensible for physically consistent metrics. This benchmarking study aims\nto enable researchers and industry professionals in selecting, refining, and\nadvancing AI-driven aerodynamic modeling approaches, ultimately fostering the\ndevelopment of more efficient, accurate, and interpretable solutions in\nautomotive aerodynamics", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u6a21\u578b\u5728\u6c7d\u8f66\u7a7a\u6c14\u52a8\u529b\u5b66\u9884\u6d4b\u4e2d\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u6a21\u578b\u5bf9\u6bd4\u7684\u900f\u660e\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u901a\u8fc7\u6807\u51c6\u5316\u65b9\u6cd5\u8bba\uff0c\u52a0\u901fAI\u6a21\u578b\u5728\u6c7d\u8f66\u7a7a\u6c14\u52a8\u529b\u5b66\u4e2d\u7684\u7814\u7a76\u548c\u521b\u65b0\u3002", "method": "\u5728NVIDIA PhysicsNeMo-CFD\u6846\u67b6\u4e2d\uff0c\u4f7f\u7528\u8868\u9762\u548c\u4f53\u79ef\u6d41\u573a\u9884\u6d4b\u8bc4\u4f30\u4e09\u79cdAI\u6a21\u578b\uff0c\u5e76\u652f\u6301\u6269\u5c55\u3002", "result": "\u5c55\u793a\u4e86\u6846\u67b6\u5728\u591a\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7269\u7406\u4e00\u81f4\u6027\u6307\u6807\u7684\u6269\u5c55\u6307\u5357\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u9009\u62e9\u548c\u4f18\u5316AI\u6a21\u578b\uff0c\u63a8\u52a8\u6c7d\u8f66\u7a7a\u6c14\u52a8\u529b\u5b66\u4e2d\u9ad8\u6548\u3001\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002", "keywords": "AI\u6a21\u578b,\u6c7d\u8f66\u7a7a\u6c14\u52a8\u529b\u5b66,\u5f00\u6e90\u6846\u67b6,\u6027\u80fd\u8bc4\u4f30,\u6807\u51c6\u5316"}}
{"id": "2507.11275", "pdf": "https://arxiv.org/pdf/2507.11275", "abs": "https://arxiv.org/abs/2507.11275", "authors": ["Jiaxuan Xie", "Chengwu Liu", "Ye Yuan", "Siqi Li", "Zhiping Xiao", "Ming Zhang"], "title": "FMC: Formalization of Natural Language Mathematical Competition Problems", "categories": ["cs.CL"], "comment": "Accepted in ICML 2025 AI4MATH Workshop", "summary": "Efficient and accurate autoformalization methods, which leverage large-scale\ndatasets of extensive natural language mathematical problems to construct\nformal language datasets, are key to advancing formal mathematical reasoning.\nIn this paper, we propose an autoformalization pipeline based on large language\nmodels with error feedback, achieving a fully automatic and training-free\nformalization approach. Using this pipeline, we curate an Olympiad-level\ndataset aligning natural language problems with Lean formalizations. The\ndataset comprises $3,922$ mathematical problems in natural language and $9,787$\nin Lean, of which $64.46\\%$ were assessed as at least above-average quality,\nmaking it suitable as a benchmark for automated theorem provers. Additionally,\nwe investigate the formalization and reasoning capabilities of various LLMs and\nempirically demonstrate that few-shot learning, error feedback, and increasing\nsampling numbers enhance the autoformalization process. Experiments of three\nautomated theorem provers on the \\dataset\\ dataset also highlight its\nchallenging nature and its value as a benchmark for formal reasoning tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5965\u6797\u5339\u514b\u7ea7\u522b\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u63a8\u52a8\u5f62\u5f0f\u5316\u6570\u5b66\u63a8\u7406\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u95ee\u9898\u6570\u636e\u96c6\u6784\u5efa\u5f62\u5f0f\u5316\u8bed\u8a00\u6570\u636e\u96c6\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u6d41\u7a0b\uff0c\u7ed3\u5408\u9519\u8bef\u53cd\u9988\u673a\u5236\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3,922\u4e2a\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u548c9,787\u4e2aLean\u5f62\u5f0f\u5316\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c64.46%\u4e3a\u9ad8\u8d28\u91cf\uff0c\u9002\u5408\u4f5c\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u57fa\u51c6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cfew-shot\u5b66\u4e60\u3001\u9519\u8bef\u53cd\u9988\u548c\u589e\u52a0\u91c7\u6837\u6570\u91cf\u80fd\u63d0\u5347\u5f62\u5f0f\u5316\u6548\u679c\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u5177\u6709\u6311\u6218\u6027\uff0c\u9002\u5408\u4f5c\u4e3a\u5f62\u5f0f\u5316\u63a8\u7406\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "keywords": "\u5f62\u5f0f\u5316\u6570\u5b66\u3001\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u3001\u5927\u8bed\u8a00\u6a21\u578b\u3001\u9519\u8bef\u53cd\u9988\u3001few-shot\u5b66\u4e60"}}
{"id": "2507.11467", "pdf": "https://arxiv.org/pdf/2507.11467", "abs": "https://arxiv.org/abs/2507.11467", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Harshitha Menon", "Brian R. Bartoldson", "Giorgis Georgakoudis", "Tal Ben-Nun", "Abhinav Bhatele"], "title": "Modeling Code: Is Text All You Need?", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ee3\u7801\u6587\u672c\u548c\u7ed3\u6784\u5316\u5f62\u5f0f\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u5f25\u8865\u73b0\u6709\u4ee3\u7801\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08Code LLMs\uff09\u5728\u7ed3\u6784\u5316\u5206\u6790\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u4ee3\u7801LLMs\u5728\u4ee3\u7801\u7684\u7ed3\u6784\u5316\u5206\u6790\uff08\u5982\u63a7\u5236\u548c\u6570\u636e\u6d41\uff09\u80fd\u529b\u6709\u9650\uff0c\u800c\u73b0\u6709\u7ed3\u6784\u5316\u65b9\u6cd5\u5219\u7f3a\u4e4f\u751f\u6210\u80fd\u529b\u548c\u89c4\u6a21\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u7ed3\u5408\u4e86\u4ee3\u7801\u6587\u672c\u548c\u7ed3\u6784\u5316\u5f62\u5f0f\u7684\u5efa\u6a21\u3002", "result": "\u8be5\u65b9\u6cd5\u65e8\u5728\u63d0\u5347\u4ee3\u7801LLMs\u5728\u7ed3\u6784\u5316\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u5176\u751f\u6210\u80fd\u529b\u548c\u89c4\u6a21\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u5408\u6587\u672c\u548c\u7ed3\u6784\u5316\u5efa\u6a21\u7684\u65b9\u6cd5\u6709\u671b\u5f25\u8865\u73b0\u6709\u6280\u672f\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u4ee3\u7801LLMs\u5728\u66f4\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "keywords": "Code LLMs, \u7ed3\u6784\u5316\u5206\u6790, \u4ee3\u7801\u751f\u6210, \u56fe\u795e\u7ecf\u7f51\u7edc"}}
{"id": "2507.10768", "pdf": "https://arxiv.org/pdf/2507.10768", "abs": "https://arxiv.org/abs/2507.10768", "authors": ["Bart Pogodzinski", "Christopher Wewer", "Bernt Schiele", "Jan Eric Lenssen"], "title": "Spatial Reasoners for Continuous Variables in Any Domain", "categories": ["cs.LG", "cs.CV"], "comment": "For the project documentation see https://spatialreasoners.github.io/\n  . The SRM project website is available at\n  https://geometric-rl.mpi-inf.mpg.de/srm/ . The work was published on ICML\n  2025 CODEML workshop", "summary": "We present Spatial Reasoners, a software framework to perform spatial\nreasoning over continuous variables with generative denoising models. Denoising\ngenerative models have become the de-facto standard for image generation, due\nto their effectiveness in sampling from complex, high-dimensional\ndistributions. Recently, they have started being explored in the context of\nreasoning over multiple continuous variables. Providing infrastructure for\ngenerative reasoning with such models requires a high effort, due to a wide\nrange of different denoising formulations, samplers, and inference strategies.\nOur presented framework aims to facilitate research in this area, providing\neasy-to-use interfaces to control variable mapping from arbitrary data domains,\ngenerative model paradigms, and inference strategies. Spatial Reasoners are\nopenly available at https://spatialreasoners.github.io/", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aSpatial Reasoners\u7684\u8f6f\u4ef6\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u751f\u6210\u5f0f\u53bb\u566a\u6a21\u578b\u5bf9\u8fde\u7eed\u53d8\u91cf\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\u3002", "motivation": "\u751f\u6210\u5f0f\u53bb\u566a\u6a21\u578b\u5728\u590d\u6742\u9ad8\u7ef4\u5206\u5e03\u91c7\u6837\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u8fde\u7eed\u53d8\u91cf\u63a8\u7406\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u4ecd\u7f3a\u4e4f\u57fa\u7840\u8bbe\u65bd\u652f\u6301\u3002", "method": "\u63d0\u4f9b\u4e86\u6613\u7528\u7684\u63a5\u53e3\uff0c\u652f\u6301\u53d8\u91cf\u6620\u5c04\u3001\u751f\u6210\u6a21\u578b\u8303\u5f0f\u548c\u63a8\u7406\u7b56\u7565\u7684\u7075\u6d3b\u63a7\u5236\u3002", "result": "\u5f00\u6e90\u6846\u67b6Spatial Reasoners\u65e8\u5728\u964d\u4f4e\u8be5\u9886\u57df\u7684\u7814\u7a76\u95e8\u69db\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u751f\u6210\u5f0f\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u4fbf\u5229\u5de5\u5177\u3002", "keywords": "\u7a7a\u95f4\u63a8\u7406,\u751f\u6210\u5f0f\u53bb\u566a\u6a21\u578b,\u8fde\u7eed\u53d8\u91cf,\u5f00\u6e90\u6846\u67b6"}}
{"id": "2507.11292", "pdf": "https://arxiv.org/pdf/2507.11292", "abs": "https://arxiv.org/abs/2507.11292", "authors": ["Zewen Bai", "Liang Yang", "Shengdi Yin", "Yuanyuan Sun", "Hongfei Lin"], "title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks", "categories": ["cs.CL"], "comment": null, "summary": "The proliferation of hate speech has inflicted significant societal harm,\nwith its intensity and directionality closely tied to specific targets and\narguments. In recent years, numerous machine learning-based methods have been\ndeveloped to detect hateful comments on online platforms automatically.\nHowever, research on Chinese hate speech detection lags behind, and\ninterpretability studies face two major challenges: first, the scarcity of\nspan-level fine-grained annotated datasets limits models' deep semantic\nunderstanding of hate speech; second, insufficient research on identifying and\ninterpreting coded hate speech restricts model explainability in complex\nreal-world scenarios. To address these, we make the following contributions:\n(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE\nToxiCN), the first span-level Chinese hate speech dataset, and evaluate the\nhate semantic understanding of existing models using it. (2) We conduct the\nfirst comprehensive study on Chinese coded hate terms, LLMs' ability to\ninterpret hate semantics. (3) We propose a method to integrate an annotated\nlexicon into models, significantly enhancing hate speech detection performance.\nOur work provides valuable resources and insights to advance the\ninterpretability of Chinese hate speech detection research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u4e2d\u6587\u7ec6\u7c92\u5ea6\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\uff08STATE ToxiCN\uff09\uff0c\u7814\u7a76\u4e86\u4e2d\u6587\u7f16\u7801\u4ec7\u6068\u672f\u8bed\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ec7\u6068\u8bed\u4e49\u89e3\u91ca\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u6807\u6ce8\u8bcd\u5178\u7684\u65b9\u6cd5\u4ee5\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u4ec7\u6068\u8a00\u8bba\u7684\u793e\u4f1a\u5371\u5bb3\u65e5\u76ca\u4e25\u91cd\uff0c\u4f46\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u53ca\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u9762\u4e34\u6570\u636e\u96c6\u7a00\u7f3a\u548c\u7f16\u7801\u4ec7\u6068\u672f\u8bed\u7814\u7a76\u4e0d\u8db3\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165STATE ToxiCN\u6570\u636e\u96c6\uff0c\u7814\u7a76\u4e2d\u6587\u7f16\u7801\u4ec7\u6068\u672f\u8bed\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\uff0c\u63d0\u51fa\u6574\u5408\u6807\u6ce8\u8bcd\u5178\u7684\u65b9\u6cd5\u3002", "result": "\u663e\u8457\u63d0\u5347\u4e86\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u8d44\u6e90\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u548c\u89c1\u89e3\u3002", "keywords": "\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u3001\u7ec6\u7c92\u5ea6\u6807\u6ce8\u3001\u7f16\u7801\u4ec7\u6068\u672f\u8bed\u3001\u53ef\u89e3\u91ca\u6027\u3001\u673a\u5668\u5b66\u4e60"}}
{"id": "2507.11473", "pdf": "https://arxiv.org/pdf/2507.11473", "abs": "https://arxiv.org/abs/2507.11473", "authors": ["Tomek Korbak", "Mikita Balesni", "Elizabeth Barnes", "Yoshua Bengio", "Joe Benton", "Joseph Bloom", "Mark Chen", "Alan Cooney", "Allan Dafoe", "Anca Dragan", "Scott Emmons", "Owain Evans", "David Farhi", "Ryan Greenblatt", "Dan Hendrycks", "Marius Hobbhahn", "Evan Hubinger", "Geoffrey Irving", "Erik Jenner", "Daniel Kokotajlo", "Victoria Krakovna", "Shane Legg", "David Lindner", "David Luan", "Aleksander M\u0105dry", "Julian Michael", "Neel Nanda", "Dave Orr", "Jakub Pachocki", "Ethan Perez", "Mary Phuong", "Fabien Roger", "Joshua Saxe", "Buck Shlegeris", "Mart\u00edn Soto", "Eric Steinberger", "Jasmine Wang", "Wojciech Zaremba", "Bowen Baker", "Rohin Shah", "Vlad Mikulik"], "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "AI systems that \"think\" in human language offer a unique opportunity for AI\nsafety: we can monitor their chains of thought (CoT) for the intent to\nmisbehave. Like all other known AI oversight methods, CoT monitoring is\nimperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows\npromise and we recommend further research into CoT monitorability and\ninvestment in CoT monitoring alongside existing safety methods. Because CoT\nmonitorability may be fragile, we recommend that frontier model developers\nconsider the impact of development decisions on CoT monitorability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u76d1\u63a7AI\u7684\u601d\u7ef4\u94fe\uff08CoT\uff09\u6765\u63d0\u9ad8AI\u5b89\u5168\u6027\uff0c\u5efa\u8bae\u8fdb\u4e00\u6b65\u7814\u7a76CoT\u53ef\u76d1\u63a7\u6027\uff0c\u5e76\u5f00\u53d1\u65f6\u8003\u8651\u5bf9CoT\u53ef\u76d1\u63a7\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76AI\u5b89\u5168\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u76d1\u63a7\u4eba\u7c7b\u8bed\u8a00\u7684\u601d\u7ef4\u94fe\u6765\u9884\u9632AI\u7684\u6f5c\u5728\u4e0d\u826f\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u76d1\u63a7AI\u7684\u601d\u7ef4\u94fe\uff08CoT\uff09\u65b9\u6cd5\uff0c\u8bc4\u4f30\u5176\u5bf9AI\u4e0d\u826f\u884c\u4e3a\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u5efa\u8bae\u5728\u5f00\u53d1\u4e2d\u4f18\u5148\u8003\u8651CoT\u7684\u53ef\u76d1\u63a7\u6027\u3002", "result": "CoT\u76d1\u63a7\u867d\u4e0d\u5b8c\u7f8e\uff0c\u4f46\u663e\u793a\u51fa\u6f5c\u5728\u4ef7\u503c\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5e94\u7528\u3002", "conclusion": "\u5efa\u8bae\u52a0\u5f3a\u5bf9CoT\u76d1\u63a7\u7684\u7814\u7a76\u548c\u5f00\u53d1\u6295\u5165\uff0c\u540c\u65f6\u63d0\u9192\u5f00\u53d1\u8005\u6ce8\u610f\u6280\u672f\u9009\u62e9\u5bf9CoT\u53ef\u76d1\u63a7\u6027\u7684\u5f71\u54cd\u3002", "keywords": "AI\u5b89\u5168\u6027,\u601d\u7ef4\u94fe\u76d1\u63a7,CoT,AI\u4e0d\u826f\u884c\u4e3a,\u524d\u6cbf\u6a21\u578b\u5f00\u53d1"}}
{"id": "2507.10792", "pdf": "https://arxiv.org/pdf/2507.10792", "abs": "https://arxiv.org/abs/2507.10792", "authors": ["Yuchen Wang", "Hongjue Zhao", "Haohong Lin", "Enze Xu", "Lifang He", "Huajie Shao"], "title": "A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments", "categories": ["cs.LG"], "comment": "8 pages, 6 figures, accepted in ICML 2025", "summary": "This work aims to address the problem of long-term dynamic forecasting in\ncomplex environments where data are noisy and irregularly sampled. While recent\nstudies have introduced some methods to improve prediction performance, these\napproaches still face a significant challenge in handling long-term\nextrapolation tasks under such complex scenarios. To overcome this challenge,\nwe propose Phy-SSM, a generalizable method that integrates partial physics\nknowledge into state space models (SSMs) for long-term dynamics forecasting in\ncomplex environments. Our motivation is that SSMs can effectively capture\nlong-range dependencies in sequential data and model continuous dynamical\nsystems, while the incorporation of physics knowledge improves generalization\nability. The key challenge lies in how to seamlessly incorporate partially\nknown physics into SSMs. To achieve this, we decompose partially known system\ndynamics into known and unknown state matrices, which are integrated into a\nPhy-SSM unit. To further enhance long-term prediction performance, we introduce\na physics state regularization term to make the estimated latent states align\nwith system dynamics. Besides, we theoretically analyze the uniqueness of the\nsolutions for our method. Extensive experiments on three real-world\napplications, including vehicle motion prediction, drone state prediction, and\nCOVID-19 epidemiology forecasting, demonstrate the superior performance of\nPhy-SSM over the baselines in both long-term interpolation and extrapolation\ntasks. The code is available at https://github.com/511205787/Phy_SSM-ICML2025.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPhy-SSM\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u90e8\u5206\u7269\u7406\u77e5\u8bc6\u6574\u5408\u5230\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\uff0c\u4ee5\u89e3\u51b3\u590d\u6742\u73af\u5883\u4e0b\u7684\u957f\u671f\u52a8\u6001\u9884\u6d4b\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u9488\u5bf9\u590d\u6742\u73af\u5883\u4e2d\u566a\u58f0\u548c\u4e0d\u89c4\u5219\u91c7\u6837\u6570\u636e\u7684\u957f\u671f\u9884\u6d4b\u95ee\u9898\uff0c\u5f53\u524d\u65b9\u6cd5\u5728\u957f\u671f\u5916\u63a8\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0cPhy-SSM\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u77e5\u8bc6\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "method": "Phy-SSM\u5c06\u5df2\u77e5\u548c\u672a\u77e5\u7cfb\u7edf\u52a8\u529b\u5b66\u5206\u89e3\u4e3a\u72b6\u6001\u77e9\u9635\uff0c\u5e76\u5f15\u5165\u7269\u7406\u72b6\u6001\u6b63\u5219\u5316\u9879\uff0c\u4ee5\u786e\u4fdd\u6f5c\u5728\u72b6\u6001\u4e0e\u7cfb\u7edf\u52a8\u529b\u5b66\u4e00\u81f4\u3002", "result": "\u5728\u8f66\u8f86\u8fd0\u52a8\u9884\u6d4b\u3001\u65e0\u4eba\u673a\u72b6\u6001\u9884\u6d4b\u548cCOVID-19\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u4e09\u4e2a\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cPhy-SSM\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Phy-SSM\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u77e5\u8bc6\u63d0\u5347\u4e86\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "keywords": "\u957f\u671f\u52a8\u6001\u9884\u6d4b,\u72b6\u6001\u7a7a\u95f4\u6a21\u578b,\u7269\u7406\u77e5\u8bc6,\u590d\u6742\u73af\u5883"}}
{"id": "2507.11299", "pdf": "https://arxiv.org/pdf/2507.11299", "abs": "https://arxiv.org/abs/2507.11299", "authors": ["Andrei Niculae", "Adrian Cosma", "Cosmin Dumitrache", "Emilian R\u01cedoi"], "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian", "categories": ["cs.CL"], "comment": "10 figures, 2 tables, 2 listings", "summary": "Text-based telemedicine has become increasingly common, yet the quality of\nmedical advice in doctor-patient interactions is often judged more on how\nadvice is communicated rather than its clinical accuracy. To address this, we\nintroduce Dr.Copilot , a multi-agent large language model (LLM) system that\nsupports Romanian-speaking doctors by evaluating and enhancing the presentation\nquality of their written responses. Rather than assessing medical correctness,\nDr.Copilot provides feedback along 17 interpretable axes. The system comprises\nof three LLM agents with prompts automatically optimized via DSPy. Designed\nwith low-resource Romanian data and deployed using open-weight models, it\ndelivers real-time specific feedback to doctors within a telemedicine platform.\nEmpirical evaluations and live deployment with 41 doctors show measurable\nimprovements in user reviews and response quality, marking one of the first\nreal-world deployments of LLMs in Romanian medical settings.", "AI": {"tldr": "Dr.Copilot\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff0c\u65e8\u5728\u63d0\u5347\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u533b\u751f\u5728\u8fdc\u7a0b\u533b\u7597\u4e2d\u6587\u7b54\u590d\u7684\u5448\u73b0\u8d28\u91cf\uff0c\u800c\u975e\u4e34\u5e8a\u51c6\u786e\u6027\u3002", "motivation": "\u8fdc\u7a0b\u533b\u7597\u4e2d\u6587\u7b54\u590d\u7684\u8d28\u91cf\u901a\u5e38\u53d6\u51b3\u4e8e\u6c9f\u901a\u65b9\u5f0f\u800c\u975e\u533b\u5b66\u51c6\u786e\u6027\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347\u533b\u751f\u7684\u8868\u8fbe\u8d28\u91cf\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff0c\u901a\u8fc7DSPy\u81ea\u52a8\u4f18\u5316\u63d0\u793a\uff0c\u652f\u6301\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u4f4e\u8d44\u6e90\u6570\u636e\uff0c\u5e76\u91c7\u7528\u5f00\u653e\u6743\u91cd\u6a21\u578b\u5b9e\u73b0\u5b9e\u65f6\u53cd\u9988\u3002", "result": "\u901a\u8fc741\u540d\u533b\u751f\u7684\u5b9e\u8bc1\u8bc4\u4f30\u548c\u5b9e\u9645\u90e8\u7f72\uff0c\u7528\u6237\u8bc4\u4ef7\u548c\u7b54\u590d\u8d28\u91cf\u5747\u663e\u8457\u63d0\u5347\u3002", "conclusion": "Dr.Copilot\u662f\u7f57\u9a6c\u5c3c\u4e9a\u533b\u7597\u73af\u5883\u4e2d\u65e9\u671f\u6210\u529f\u90e8\u7f72\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e4b\u4e00\u3002", "keywords": "\u8fdc\u7a0b\u533b\u7597, \u5927\u578b\u8bed\u8a00\u6a21\u578b, \u7f57\u9a6c\u5c3c\u4e9a\u8bed, \u591a\u4ee3\u7406\u7cfb\u7edf, DSPy"}}
{"id": "2507.11479", "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "categories": ["cs.AI", "cs.GR", "cs.HC"], "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems.", "AI": {"tldr": "PAiR\u6846\u67b6\u901a\u8fc7\u6574\u5408Perspective-Aware AI\uff08PAi\uff09\u4e0eXR\uff0c\u57fa\u4e8e\u7528\u6237\u8eab\u4efd\u6a21\u578b\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524dAI\u589e\u5f3a\u7684XR\u7cfb\u7edf\u56e0\u7528\u6237\u5efa\u6a21\u6d45\u5c42\u548c\u8ba4\u77e5\u4e0a\u4e0b\u6587\u6709\u9650\u800c\u672a\u80fd\u63d0\u4f9b\u7406\u60f3\u7684\u9002\u5e94\u6027\u6c89\u6d78\u4f53\u9a8c\u3002", "method": "\u63d0\u51faPAiR\u6846\u67b6\uff0c\u5229\u7528Chronicles\uff08\u57fa\u4e8e\u591a\u6a21\u6001\u6570\u5b57\u8db3\u8ff9\u7684\u7528\u6237\u8eab\u4efd\u6a21\u578b\uff09\u5728\u95ed\u73af\u7cfb\u7edf\u4e2d\u52a8\u6001\u94fe\u63a5\u7528\u6237\u72b6\u6001\u4e0e\u6c89\u6d78\u73af\u5883\u3002", "result": "\u901a\u8fc7Unity\u5f15\u64ce\u7684\u4e24\u4e2a\u9a8c\u8bc1\u573a\u666f\u5c55\u793a\u4e86PAiR\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "PAiR\u901a\u8fc7\u5d4c\u5165\u57fa\u4e8e\u89c6\u89d2\u7684\u8eab\u4efd\u6a21\u578b\uff0c\u4e3a\u4eba\u673a\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "keywords": "AI, XR, Perspective-Aware AI, user modeling, immersive systems"}}
{"id": "2507.10797", "pdf": "https://arxiv.org/pdf/2507.10797", "abs": "https://arxiv.org/abs/2507.10797", "authors": ["Mohammad Pedramfar", "Siamak Ravanbakhsh"], "title": "Multi-Armed Sampling Problem and the End of Exploration", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "This paper introduces the framework of multi-armed sampling, as the sampling\ncounterpart to the optimization problem of multi-arm bandits. Our primary\nmotivation is to rigorously examine the exploration-exploitation trade-off in\nthe context of sampling. We systematically define plausible notions of regret\nfor this framework and establish corresponding lower bounds. We then propose a\nsimple algorithm that achieves these optimal regret bounds. Our theoretical\nresults demonstrate that in contrast to optimization, sampling does not require\nexploration. To further connect our findings with those of multi-armed bandits,\nwe define a continuous family of problems and associated regret measures that\nsmoothly interpolates and unifies multi-armed sampling and multi-armed bandit\nproblems using a temperature parameter. We believe the multi-armed sampling\nframework, and our findings in this setting can have a foundational role in the\nstudy of sampling including recent neural samplers, akin to the role of\nmulti-armed bandits in reinforcement learning. In particular, our work sheds\nlight on the need for exploration and the convergence properties of algorithm\nfor entropy-regularized reinforcement learning, fine-tuning of pretrained\nmodels and reinforcement learning with human feedback (RLHF).", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u81c2\u91c7\u6837\u6846\u67b6\uff0c\u4f5c\u4e3a\u591a\u81c2\u8001\u864e\u673a\u4f18\u5316\u95ee\u9898\u7684\u62bd\u6837\u5bf9\u5e94\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u62bd\u6837\u4e2d\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u6743\u8861\u3002", "motivation": "\u4e3b\u8981\u52a8\u673a\u662f\u4e25\u683c\u7814\u7a76\u62bd\u6837\u4e2d\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u6743\u8861\u3002", "method": "\u7cfb\u7edf\u5b9a\u4e49\u4e86\u540e\u6094\u6982\u5ff5\u5e76\u5efa\u7acb\u4e86\u5bf9\u5e94\u4e0b\u754c\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7b97\u6cd5\u8fbe\u5230\u6700\u4f18\u540e\u6094\u754c\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f18\u5316\u4e0d\u540c\uff0c\u62bd\u6837\u4e0d\u9700\u8981\u63a2\u7d22\uff1b\u901a\u8fc7\u6e29\u5ea6\u53c2\u6570\u7edf\u4e00\u4e86\u591a\u81c2\u91c7\u6837\u4e0e\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u3002", "conclusion": "\u591a\u81c2\u91c7\u6837\u6846\u67b6\u5bf9\u7814\u7a76\u62bd\u6837\uff08\u5982\u795e\u7ecf\u91c7\u6837\u5668\uff09\u5177\u6709\u57fa\u7840\u6027\u610f\u4e49\uff0c\u5c24\u5176\u63ed\u793a\u4e86\u71b5\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u9700\u6c42\u548c\u7b97\u6cd5\u6536\u655b\u6027\u3002", "keywords": "\u591a\u81c2\u91c7\u6837,\u63a2\u7d22\u4e0e\u5229\u7528,\u540e\u6094\u754c,\u71b5\u6b63\u5219\u5316,RLHF"}}
{"id": "2507.11316", "pdf": "https://arxiv.org/pdf/2507.11316", "abs": "https://arxiv.org/abs/2507.11316", "authors": ["Haoran Jin", "Meng Li", "Xiting Wang", "Zhihao Xu", "Minlie Huang", "Yantao Jia", "Defu Lian"], "title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "25 pages, 14 figures. Accepted by ACL 2025 (main conference)", "summary": "Aligning Large Language Models (LLMs) with human values has attracted\nincreasing attention since it provides clarity, transparency, and the ability\nto adapt to evolving scenarios. In this paper, we introduce a Controlled Value\nVector Activation (ConVA) method that directly aligns the internal values of\nLLMs by interpreting how a value is encoded in their latent representations and\nmodifies relevant activations to ensure consistent values in LLMs. To ensure an\naccurate and unbiased interpretation, we propose a context-controlled value\nvector identification method. To consistently control values without\nsacrificing model performance, we introduce a gated value vector activation\nmethod for effective and minimum degree of value control. Experiments show that\nour method achieves the highest control success rate across 10 basic values\nwithout hurting LLM performance and fluency, and ensures target values even\nwith opposite and potentially malicious input prompts. Source code and data are\navailable at~ https://github.com/hr-jin/ConVA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aConVA\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u8c03\u6574\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u7684\u4ef7\u503c\u8868\u793a\u6765\u5bf9\u9f50\u4eba\u7c7b\u4ef7\u503c\u89c2\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u65e2\u9ad8\u6548\u53c8\u80fd\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e0a\u4e0b\u6587\u63a7\u5236\u7684\u4ef7\u503c\u5411\u91cf\u8bc6\u522b\u65b9\u6cd5\u548c\u95e8\u63a7\u4ef7\u503c\u5411\u91cf\u6fc0\u6d3b\u65b9\u6cd5\uff0c\u76f4\u63a5\u5e72\u9884\u6a21\u578b\u7684\u6f5c\u5728\u8868\u793a\u4ee5\u5b9e\u73b0\u4ef7\u503c\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cConVA\u572810\u79cd\u57fa\u672c\u4ef7\u503c\u89c2\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u63a7\u5236\u6210\u529f\u7387\uff0c\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u7684\u6027\u80fd\u548c\u6d41\u7545\u6027\u3002", "conclusion": "ConVA\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u4ef7\u503c\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u591f\u5e94\u5bf9\u590d\u6742\u751a\u81f3\u6076\u610f\u7684\u8f93\u5165\u63d0\u793a\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, \u4ef7\u503c\u5bf9\u9f50, \u4ef7\u503c\u5411\u91cf, \u95e8\u63a7\u6fc0\u6d3b, \u4e0a\u4e0b\u6587\u63a7\u5236"}}
{"id": "2507.11482", "pdf": "https://arxiv.org/pdf/2507.11482", "abs": "https://arxiv.org/abs/2507.11482", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "categories": ["cs.AI"], "comment": null, "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u53d7\u5f00\u653e\u6f14\u5316\u7406\u8bba\u542f\u53d1\u7684\u6846\u67b6\uff0c\u91cd\u65b0\u5ba1\u89c6\u5f3a\u5316\u5b66\u4e60\u7684\u4e09\u4e2a\u6838\u5fc3\u5047\u8bbe\uff0c\u5e76\u63a2\u8ba8\u5176\u7406\u8bba\u548c\u5e94\u7528\u610f\u4e49\u3002", "motivation": "\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\u957f\u671f\u5b58\u5728\u7684\u4e09\u4e2a\u6838\u5fc3\u5047\u8bbe\uff08\u5173\u4e8e\u4ee3\u7406\u5b9a\u4e49\u3001\u5b66\u4e60\u76ee\u6807\u548c\u5956\u52b1\u5047\u8bbe\u8303\u56f4\uff09\u63d0\u51fa\u4fee\u6b63\uff0c\u4ee5\u6539\u8fdb\u7406\u8bba\u548c\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u6f14\u5316\u7406\u8bba\u89c6\u89d2\u91cd\u65b0\u8bc4\u4f30\u8fd9\u4e09\u4e2a\u5047\u8bbe\uff0c\u63d0\u51fa\u5176\u9002\u7528\u4e8e\u751f\u7269\u5b66\u4e60\u7684\u53ef\u80fd\u6027\u3002\u9996\u5148\u9a8c\u8bc1\u6f14\u5316\u52a8\u6001\u5728\u4e2a\u4f53\u751f\u547d\u5468\u671f\u5185\u7684\u53ef\u884c\u6027\u3002", "result": "\u8bba\u8bc1\u4e86\u6f14\u5316\u89c6\u89d2\u80fd\u4e30\u5bcc\u5b66\u4e60\u89c2\u70b9\uff0c\u89e3\u51b3\u5956\u52b1\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u4f46\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u4ee3\u7406\u95ee\u9898\uff0c\u9700\u7ed3\u5408\u751f\u547d\u8d77\u6e90\u7406\u8bba\u3002", "conclusion": "\u63d0\u51fa\u6574\u5408\u751f\u547d\u8d77\u6e90\u7684\u70ed\u529b\u5b66\u7406\u8bba\uff0c\u4e3a\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u4ee3\u7406\u548c\u8d44\u6e90\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u65b0\u57fa\u7840\u3002", "keywords": "\u5f3a\u5316\u5b66\u4e60, \u6f14\u5316\u7406\u8bba, \u4ee3\u7406\u95ee\u9898, \u5956\u52b1\u5047\u8bbe, \u751f\u7269\u5b66\u4e60"}}
{"id": "2507.10809", "pdf": "https://arxiv.org/pdf/2507.10809", "abs": "https://arxiv.org/abs/2507.10809", "authors": ["Kazi Tasnim Zinat", "Yun Zhou", "Xiang Lyu", "Yawei Wang", "Zhicheng Liu", "Panpan Xu"], "title": "Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at ICANN 2025", "summary": "Inferring causal relationships between event pairs in a temporal sequence is\napplicable in many domains such as healthcare, manufacturing, and\ntransportation. Most existing work on causal inference primarily focuses on\nevent types within the designated domain, without considering the impact of\nexogenous out-of-domain interventions. In real-world settings, these\nout-of-domain interventions can significantly alter causal dynamics. To address\nthis gap, we propose a new causal framework to define average treatment effect\n(ATE), beyond independent and identically distributed (i.i.d.) data in classic\nRubin's causal framework, to capture the causal relation shift between events\nof temporal process under out-of-domain intervention. We design an unbiased ATE\nestimator, and devise a Transformer-based neural network model to handle both\nlong-range temporal dependencies and local patterns while integrating\nout-of-domain intervention information into process modeling. Extensive\nexperiments on both simulated and real-world datasets demonstrate that our\nmethod outperforms baselines in ATE estimation and goodness-of-fit under\nout-of-domain-augmented point processes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u6846\u67b6\uff0c\u7528\u4e8e\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u4e2d\u4e8b\u4ef6\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5c24\u5176\u662f\u5916\u6e90\u9886\u57df\u5e72\u9884\u4e0b\u7684\u56e0\u679c\u52a8\u6001\u53d8\u5316\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u5916\u6e90\u9886\u57df\u5e72\u9884\u5e38\u663e\u8457\u6539\u53d8\u4e8b\u4ef6\u95f4\u7684\u56e0\u679c\u52a8\u6001\uff0c\u800c\u73b0\u6709\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u591a\u5c40\u9650\u4e8e\u9886\u57df\u5185\u4e8b\u4ef6\u7c7b\u578b\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u6846\u67b6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65e0\u504f\u7684\u5e73\u5747\u5904\u7406\u6548\u5e94\uff08ATE\uff09\u4f30\u8ba1\u5668\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7ed3\u5408\u5916\u6e90\u5e72\u9884\u4fe1\u606f\uff0c\u5904\u7406\u957f\u65f6\u7a0b\u4f9d\u8d56\u4e0e\u5c40\u90e8\u6a21\u5f0f\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5916\u6e90\u5e72\u9884\u589e\u5f3a\u7684\u70b9\u8fc7\u7a0b\u4e2d\uff0cATE\u4f30\u8ba1\u548c\u62df\u5408\u4f18\u5ea6\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6355\u6349\u5916\u6e90\u5e72\u9884\u4e0b\u7684\u56e0\u679c\u52a8\u6001\u53d8\u5316\uff0c\u4e3a\u8de8\u57df\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002", "keywords": "\u56e0\u679c\u63a8\u65ad,\u5916\u6e90\u5e72\u9884,\u5e73\u5747\u5904\u7406\u6548\u5e94,Transformer,\u65f6\u95f4\u5e8f\u5217"}}
{"id": "2507.11330", "pdf": "https://arxiv.org/pdf/2507.11330", "abs": "https://arxiv.org/abs/2507.11330", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Yi Zhao"], "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "comment": "Journal of the Association for Information Science and Technology,\n  2025", "summary": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. The most common novelty in\nacademic papers is the introduction of new methods. In this paper, we propose\nleveraging human knowledge and LLM to assist pretrained language models (PLMs,\ne.g. BERT etc.) in predicting the method novelty of papers. Specifically, we\nextract sentences related to the novelty of the academic paper from peer review\nreports and use LLM to summarize the methodology section of the academic paper,\nwhich are then used to fine-tune PLMs. In addition, we have designed a\ntext-guided fusion module with novel Sparse-Attention to better integrate human\nand LLM knowledge. We compared the method we proposed with a large number of\nbaselines. Extensive experiments demonstrate that our method achieves superior\nperformance.", "AI": {"tldr": "\u7814\u7a76\u7ed3\u5408\u4eba\u7c7b\u4e13\u5bb6\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u77e5\u8bc6\u4e0e\u80fd\u529b\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\u8bc4\u4f30\u5b66\u672f\u8bba\u6587\u7684\u65b9\u6cd5\u65b0\u9896\u6027\u3002", "motivation": "\u4f20\u7edf\u65b0\u9896\u6027\u8bc4\u4f30\u65b9\u6cd5\uff08\u4e13\u5bb6\u8bc4\u5ba1\u548c\u5f15\u7528\u7ec4\u5408\uff09\u5b58\u5728\u5c40\u9650\u6027\uff0cLLM\u548c\u4eba\u7c7b\u4e13\u5bb6\u5404\u6709\u4f18\u52bf\uff0c\u9700\u7ed3\u5408\u4e24\u8005\u3002", "method": "\u4ece\u540c\u884c\u8bc4\u5ba1\u62a5\u544a\u4e2d\u63d0\u53d6\u65b0\u9896\u6027\u76f8\u5173\u53e5\u5b50\uff0c\u7528LLM\u603b\u7ed3\u8bba\u6587\u65b9\u6cd5\u90e8\u5206\uff0c\u5fae\u8c03\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\uff0c\u5e76\u8bbe\u8ba1\u6587\u672c\u5f15\u5bfc\u7684\u7a00\u758f\u6ce8\u610f\u529b\u878d\u5408\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f17\u591a\u57fa\u7ebf\u3002", "conclusion": "\u7ed3\u5408\u4eba\u7c7b\u4e0eLLM\u77e5\u8bc6\u7684\u65b9\u6cd5\u5728\u8bc4\u4f30\u8bba\u6587\u65b0\u9896\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "keywords": "\u65b0\u9896\u6027\u8bc4\u4f30\uff0c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u4eba\u7c7b\u4e13\u5bb6\uff0c\u7a00\u758f\u6ce8\u610f\u529b"}}
{"id": "2507.11527", "pdf": "https://arxiv.org/pdf/2507.11527", "abs": "https://arxiv.org/abs/2507.11527", "authors": ["Yinsheng Li", "Zhen Dong", "Yi Shao"], "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "categories": ["cs.AI", "cs.CE"], "comment": "Project page: https://github.com/Eason-Li-AIS/DrafterBench", "summary": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86DrafterBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u6280\u672f\u7ed8\u56fe\u4fee\u8ba2\u4efb\u52a1\u4e2d\u7684\u7efc\u5408\u6027\u80fd\u7684\u5f00\u6e90\u57fa\u51c6\u3002", "motivation": "\u9700\u8981\u66f4\u591a\u4ece\u5de5\u4e1a\u89d2\u5ea6\uff08\u5982\u571f\u6728\u5de5\u7a0b\uff09\u7cfb\u7edf\u8bc4\u4f30\u81ea\u52a8\u5316\u4ee3\u7406\u7684\u57fa\u51c6\u3002", "method": "DrafterBench\u5305\u542b12\u7c7b\u4efb\u52a1\u300146\u4e2a\u5b9a\u5236\u51fd\u6570\u548c1920\u4e2a\u4efb\u52a1\uff0c\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u590d\u6742\u6307\u4ee4\u89e3\u8bfb\u3001\u77e5\u8bc6\u5229\u7528\u548c\u52a8\u6001\u9002\u5e94\u7b49\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "DrafterBench\u80fd\u5168\u9762\u8bc4\u4f30\u4ee3\u7406\u7684\u591a\u9879\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4efb\u52a1\u51c6\u786e\u6027\u548c\u9519\u8bef\u7edf\u8ba1\u7684\u8be6\u7ec6\u5206\u6790\u3002", "conclusion": "DrafterBench\u4e3aLLM\u5728\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6df1\u5165\u89c1\u89e3\u548c\u6539\u8fdb\u76ee\u6807\u3002", "keywords": "Large Language Model, DrafterBench, \u6280\u672f\u7ed8\u56fe\u4fee\u8ba2, \u8bc4\u4f30\u57fa\u51c6"}}
{"id": "2507.10820", "pdf": "https://arxiv.org/pdf/2507.10820", "abs": "https://arxiv.org/abs/2507.10820", "authors": ["Robert M\u00fcller"], "title": "Semantic Context for Tool Orchestration", "categories": ["cs.LG", "cs.AI"], "comment": "Workshop on Computer Use Agents @ ICML2025", "summary": "This paper demonstrates that Semantic Context (SC), leveraging descriptive\ntool information, is a foundational component for robust tool orchestration.\nOur contributions are threefold. First, we provide a theoretical foundation\nusing contextual bandits, introducing SC-LinUCB and proving it achieves lower\nregret and adapts favourably in dynamic action spaces. Second, we provide\nparallel empirical validation with Large Language Models, showing that SC is\ncritical for successful in-context learning in both static (efficient learning)\nand non-stationary (robust adaptation) settings. Third, we propose the FiReAct\npipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based\nretrieval enables an LLM to effectively orchestrate over a large action space.\nThese findings provide a comprehensive guide to building more sample-efficient,\nadaptive, and scalable orchestration agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8bed\u4e49\u4e0a\u4e0b\u6587\uff08SC\uff09\u662f\u5de5\u5177\u7f16\u6392\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u7406\u8bba\u3001\u5b9e\u8bc1\u548c\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51faFiReAct\u7ba1\u9053\u4ee5\u63d0\u5347\u5927\u578b\u5de5\u5177\u96c6\u7684\u7f16\u6392\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5de5\u5177\u7f16\u6392\u4e2d\u7684\u6837\u672c\u6548\u7387\u3001\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5229\u7528SC\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u7ed3\u5408SC\u7684\u4e0a\u4e0b\u6587\u8001\u864e\u673a\u7406\u8bba\uff08SC-LinUCB\uff09\u3001\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u4ee5\u53caFiReAct\u7ba1\u9053\u5728\u5927\u89c4\u6a21\u5de5\u5177\u96c6\u4e0a\u7684\u5e94\u7528\u3002", "result": "SC-LinUCB\u5728\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8868\u73b0\u66f4\u4f4e\u9057\u61be\u548c\u66f4\u5f3a\u9002\u5e94\u6027\uff0cFiReAct\u6210\u529f\u7f16\u6392\u8d85\u8fc710,000\u4e2a\u5de5\u5177\u3002", "conclusion": "SC\u662f\u6784\u5efa\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u548c\u53ef\u6269\u5c55\u7f16\u6392\u4ee3\u7406\u7684\u5173\u952e\uff0c\u7814\u7a76\u6210\u679c\u4e3a\u5176\u63d0\u4f9b\u4e86\u5168\u9762\u6307\u5bfc\u3002", "keywords": "\u8bed\u4e49\u4e0a\u4e0b\u6587,\u5de5\u5177\u7f16\u6392,\u4e0a\u4e0b\u6587\u8001\u864e\u673a,\u5927\u8bed\u8a00\u6a21\u578b,FiReAct"}}
{"id": "2507.11356", "pdf": "https://arxiv.org/pdf/2507.11356", "abs": "https://arxiv.org/abs/2507.11356", "authors": ["Alexis Brissard", "Fr\u00e9d\u00e9ric Cuppens", "Amal Zouaq"], "title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models", "categories": ["cs.CL"], "comment": "12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings", "summary": "Large Language Models (LLMs) are increasingly applied for Process Modeling\n(PMo) tasks such as Process Model Generation (PMG). To support these tasks,\nresearchers have introduced a variety of Process Model Representations (PMRs)\nthat serve as model abstractions or generation targets. However, these PMRs\ndiffer widely in structure, complexity, and usability, and have never been\nsystematically compared. Moreover, recent PMG approaches rely on distinct\nevaluation strategies and generation techniques, making comparison difficult.\nThis paper presents the first empirical study that evaluates multiple PMRs in\nthe context of PMo with LLMs. We introduce the PMo Dataset, a new dataset\ncontaining 55 process descriptions paired with models in nine different PMRs.\nWe evaluate PMRs along two dimensions: suitability for LLM-based PMo and\nperformance on PMG. \\textit{Mermaid} achieves the highest overall score across\nsix PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in\nterms of process element similarity.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6d41\u7a0b\u5efa\u6a21\uff08PMo\uff09\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u6d41\u7a0b\u6a21\u578b\u8868\u793a\uff08PMRs\uff09\uff0c\u5e76\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728PMo\u4e2d\u7684\u9002\u7528\u6027\u548c\u6d41\u7a0b\u6a21\u578b\u751f\u6210\uff08PMG\uff09\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u73b0\u6709\u7684PMRs\u5728\u7ed3\u6784\u3001\u590d\u6742\u6027\u548c\u53ef\u7528\u6027\u4e0a\u5dee\u5f02\u8f83\u5927\uff0c\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6bd4\u8f83\uff0c\u540c\u65f6PMG\u65b9\u6cd5\u7684\u8bc4\u4f30\u7b56\u7565\u548c\u6280\u672f\u5404\u5f02\uff0c\u96be\u4ee5\u5bf9\u6bd4\u3002", "method": "\u63d0\u51fa\u4e86PMo\u6570\u636e\u96c6\uff0c\u5305\u542b55\u4e2a\u6d41\u7a0b\u63cf\u8ff0\u53ca\u5bf9\u5e94\u4e5d\u79cdPMRs\u7684\u6a21\u578b\uff0c\u5e76\u4ece\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30PMRs\uff1a\u9002\u7528\u4e8eLLM\u7684PMo\u80fd\u529b\u548cPMG\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cMermaid\u5728\u516d\u9879PMo\u6807\u51c6\u4e2d\u5f97\u5206\u6700\u9ad8\uff0c\u800cBPMN text\u5728\u6d41\u7a0b\u5143\u7d20\u76f8\u4f3c\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u7ed3\u8bba\u662fMermaid\u6574\u4f53\u8868\u73b0\u6700\u4f18\uff0cBPMN text\u5728PMG\u4efb\u52a1\u4e2d\u6548\u679c\u6700\u597d\uff0c\u4e3aLLM\u5728PMo\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u6d41\u7a0b\u5efa\u6a21,\u6d41\u7a0b\u6a21\u578b\u8868\u793a,\u6d41\u7a0b\u6a21\u578b\u751f\u6210,Mermaid,BPMN text"}}
{"id": "2507.11538", "pdf": "https://arxiv.org/pdf/2507.11538", "abs": "https://arxiv.org/abs/2507.11538", "authors": ["Daniel Jaroslawicz", "Brendan Whiting", "Parth Shah", "Karime Maamari"], "title": "How Many Instructions Can LLMs Follow at Once?", "categories": ["cs.AI"], "comment": null, "summary": "Production-grade LLM systems require robust adherence to dozens or even\nhundreds of instructions simultaneously. However, the instruction-following\ncapabilities of LLMs at high instruction densities have not yet been\ncharacterized, as existing benchmarks only evaluate models on tasks with a\nsingle or few instructions. We introduce IFScale, a simple benchmark of 500\nkeyword-inclusion instructions for a business report writing task to measure\nhow instruction-following performance degrades as instruction density\nincreases. We evaluate 20 state-of-the-art models across seven major providers\nand find that even the best frontier models only achieve 68% accuracy at the\nmax density of 500 instructions. Our analysis reveals model size and reasoning\ncapability to correlate with 3 distinct performance degradation patterns, bias\ntowards earlier instructions, and distinct categories of instruction-following\nerrors. Our insights can help inform design of instruction-dense prompts in\nreal-world applications and highlight important performance-latency tradeoffs.\nWe open-source the benchmark and all results for further analysis at\nhttps://distylai.github.io/IFScale.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u9ad8\u6307\u4ee4\u5bc6\u5ea6\u4e0b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u63d0\u51faIFScale\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728500\u6761\u6307\u4ee4\u4e0b\u7684\u51c6\u786e\u7387\u6700\u9ad8\u4ec568%\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u7684\u6a21\u5f0f\u53ca\u8bef\u5dee\u7c7b\u522b\u3002", "motivation": "\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\u4ec5\u9488\u5bf9\u5355\u4e00\u6216\u5c11\u91cf\u6307\u4ee4\u4efb\u52a1\uff0c\u65e0\u6cd5\u8bc4\u4f30LLM\u5728\u9ad8\u6307\u4ee4\u5bc6\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165\u5305\u542b500\u6761\u5173\u952e\u8bcd\u5305\u542b\u6307\u4ee4\u7684IFScale\u57fa\u51c6\uff0c\u7528\u4e8e\u5546\u4e1a\u62a5\u544a\u5199\u4f5c\u4efb\u52a1\uff0c\u6d4b\u91cf\u6307\u4ee4\u5bc6\u5ea6\u589e\u52a0\u65f6\u6027\u80fd\u4e0b\u964d\u60c5\u51b5\u3002", "result": "\u6d4b\u8bd520\u4e2a\u524d\u6cbf\u6a21\u578b\u53d1\u73b0\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u4ec568%\uff0c\u6a21\u578b\u89c4\u6a21\u548c\u63a8\u7406\u80fd\u529b\u4e0e\u6027\u80fd\u4e0b\u964d\u6a21\u5f0f\u76f8\u5173\u3002", "conclusion": "\u9ad8\u6307\u4ee4\u5bc6\u5ea6\u4e0bLLM\u8868\u73b0\u5b58\u5728\u660e\u663e\u5c40\u9650\uff0c\u7ed3\u679c\u5bf9\u5b9e\u9645\u5e94\u7528\u7684\u63d0\u793a\u8bbe\u8ba1\u548c\u6027\u80fd-\u5ef6\u8fdf\u6743\u8861\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002", "keywords": "LLM, \u6307\u4ee4\u9075\u5faa, IFScale\u57fa\u51c6, \u9ad8\u6307\u4ee4\u5bc6\u5ea6, \u5546\u4e1a\u62a5\u544a"}}
{"id": "2507.10834", "pdf": "https://arxiv.org/pdf/2507.10834", "abs": "https://arxiv.org/abs/2507.10834", "authors": ["Guokai Li", "Pin Gao", "Stefanus Jasin", "Zizhuo Wang"], "title": "From Small to Large: A Graph Convolutional Network Approach for Solving Assortment Optimization Problems", "categories": ["cs.LG"], "comment": "Conference version. The journal version will be updated soon", "summary": "Assortment optimization involves selecting a subset of substitutable products\n(subject to certain constraints) to maximize the expected revenue. It is a\nclassic problem in revenue management and finds applications across various\nindustries. However, the problem is usually NP-hard due to its combinatorial\nand non-linear nature. In this work, we explore how graph concolutional\nnetworks (GCNs) can be leveraged to efficiently solve constrained assortment\noptimization under the mixed multinomial logit choice model. We first develop a\ngraph representation of the assortment problem, then train a GCN to learn the\npatterns of optimal assortments, and lastly propose two inference policies\nbased on the GCN's output. Due to the GCN's inherent ability to generalize\nacross inputs of varying sizes, we can use a GCN trained on small-scale\ninstances to facilitate large-scale instances. Extensive numerical experiments\ndemonstrate that given a GCN trained on small-scale instances (e.g., with 20\nproducts), the proposed policies can achieve superior performance (90%+\noptimality) on large-scale instances (with up to 2,000 products) within\nseconds, which outperform existing heuristic policies in both performance and\nefficiency. Furthermore, we extend our framework to a model-free setting where\nthe underlying choice model is unknown but transaction data is available. We\nalso conduct numerical experiments to demonstrate the effectiveness and\nefficiency of our proposed policies in this setting.", "AI": {"tldr": "\u5229\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u9ad8\u6548\u89e3\u51b3\u6df7\u5408\u591a\u9879Logit\u9009\u62e9\u6a21\u578b\u4e0b\u7684\u53d7\u9650\u4ea7\u54c1\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u5c0f\u89c4\u6a21\u8bad\u7ec3\u5b9e\u73b0\u5927\u89c4\u6a21\u5b9e\u4f8b\u7684\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u4ea7\u54c1\u7ec4\u5408\u4f18\u5316\u662f\u4e00\u4e2a\u7ecf\u5178\u7684NP\u96be\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\uff0c\u56e0\u6b64\u63a2\u7d22GCN\u7684\u6cdb\u5316\u80fd\u529b\u4ee5\u63d0\u5347\u6c42\u89e3\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u5c06\u4ea7\u54c1\u7ec4\u5408\u95ee\u9898\u8868\u793a\u4e3a\u56fe\u7ed3\u6784\uff0c\u8bad\u7ec3GCN\u5b66\u4e60\u6700\u4f18\u7ec4\u5408\u6a21\u5f0f\uff0c\u5e76\u57fa\u4e8eGCN\u8f93\u51fa\u63d0\u51fa\u4e24\u79cd\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u5c0f\u89c4\u6a21\u8bad\u7ec3\uff08\u598220\u4e2a\u4ea7\u54c1\uff09\u7684GCN\u7b56\u7565\u53ef\u5728\u51e0\u79d2\u5185\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\uff082000\u4e2a\u4ea7\u54c1\uff09\u5e76\u8fbe\u523090%\u4ee5\u4e0a\u7684\u6700\u4f18\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "GCN\u65b9\u6cd5\u5728\u6a21\u578b\u5df2\u77e5\u548c\u672a\u77e5\uff08\u6570\u636e\u9a71\u52a8\uff09\u573a\u666f\u4e0b\u5747\u8868\u73b0\u51fa\u9ad8\u6548\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002", "keywords": "\u4ea7\u54c1\u7ec4\u5408\u4f18\u5316, \u56fe\u5377\u79ef\u7f51\u7edc, \u6df7\u5408\u591a\u9879Logit\u6a21\u578b, \u542f\u53d1\u5f0f\u7b56\u7565, \u5927\u89c4\u6a21\u5b9e\u4f8b"}}
{"id": "2507.11384", "pdf": "https://arxiv.org/pdf/2507.11384", "abs": "https://arxiv.org/abs/2507.11384", "authors": ["Xia Cui"], "title": "Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss", "categories": ["cs.CL"], "comment": "10 pages, 1 figure, SemEval 2025", "summary": "This paper explores the application of a simple weighted loss function to\nTransformer-based models for multi-label emotion detection in SemEval-2025\nShared Task 11. Our approach addresses data imbalance by dynamically adjusting\nclass weights, thereby enhancing performance on minority emotion classes\nwithout the computational burden of traditional resampling methods. We evaluate\nBERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such\nas Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients.\nThe results demonstrate that the weighted loss function improves performance on\nhigh-frequency emotion classes but shows limited impact on minority classes.\nThese findings underscore both the effectiveness and the challenges of applying\nthis approach to imbalanced multi-label emotion detection.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u52a0\u6743\u635f\u5931\u51fd\u6570\u5728Transformer\u6a21\u578b\u4e2d\u7528\u4e8e\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u7684\u6548\u679c\uff0c\u91cd\u70b9\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4f46\u6548\u679c\u5728\u5c11\u6570\u60c5\u611f\u7c7b\u522b\u4e0a\u6709\u9650\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u4e2d\u6570\u636e\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u7c7b\u522b\u6743\u91cd\u7684\u52a0\u6743\u635f\u5931\u51fd\u6570\uff0c\u907f\u514d\u4f20\u7edf\u91cd\u91c7\u6837\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5bf9BERT\u3001RoBERTa\u548cBART\u6a21\u578b\u5e94\u7528\u52a0\u6743\u635f\u5931\u51fd\u6570\uff0c\u5e76\u5728BRIGHTER\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528Micro F1\u3001Macro F1\u3001ROC-AUC\u3001Accuracy\u548cJaccard\u76f8\u4f3c\u7cfb\u6570\u7b49\u6307\u6807\u3002", "result": "\u52a0\u6743\u635f\u5931\u51fd\u6570\u663e\u8457\u63d0\u9ad8\u4e86\u9ad8\u9891\u60c5\u611f\u7c7b\u522b\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u4f46\u5bf9\u5c11\u6570\u7c7b\u522b\u7684\u6539\u8fdb\u6709\u9650\u3002", "conclusion": "\u52a0\u6743\u635f\u5931\u51fd\u6570\u5728\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u4e2d\u6709\u6548\u4f46\u4e5f\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5c11\u6570\u7c7b\u522b\u65f6\u6548\u679c\u4e0d\u660e\u663e\u3002", "keywords": "Transformer\u3001\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u3001\u52a0\u6743\u635f\u5931\u51fd\u6570\u3001\u6570\u636e\u4e0d\u5e73\u8861\u3001BRIGHTER\u6570\u636e\u96c6"}}
{"id": "2111.06614", "pdf": "https://arxiv.org/pdf/2111.06614", "abs": "https://arxiv.org/abs/2111.06614", "authors": ["Ilai Shraga", "Guy Azran", "Matthias Gerstgrasser", "Ofir Abu", "Jeffrey S. Rosenschein", "Sarah Keren"], "title": "Collaboration Promotes Group Resilience in Multi-Agent RL", "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.11; I.2.6"], "comment": "RLC 2025", "summary": "To effectively operate in various dynamic scenarios, RL agents must be\nresilient to unexpected changes in their environment. Previous work on this\nform of resilience has focused on single-agent settings. In this work, we\nintroduce and formalize a multi-agent variant of resilience, which we term\ngroup resilience. We further hypothesize that collaboration with other agents\nis key to achieving group resilience; collaborating agents adapt better to\nenvironmental perturbations in multi-agent reinforcement learning (MARL)\nsettings. We test our hypothesis empirically by evaluating different\ncollaboration protocols and examining their effect on group resilience. Our\nexperiments show that all the examined collaborative approaches achieve higher\ngroup resilience than their non-collaborative counterparts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684'\u7fa4\u4f53\u97e7\u6027'\u6982\u5ff5\uff0c\u5047\u8bbe\u534f\u4f5c\u662f\u63d0\u5347\u7fa4\u4f53\u97e7\u6027\u7684\u5173\u952e\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u534f\u4f5c\u534f\u8bae\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u97e7\u6027\uff0c\u7279\u522b\u662f\u534f\u4f5c\u5982\u4f55\u5e2e\u52a9\u63d0\u5347\u7fa4\u4f53\u97e7\u6027\u3002", "method": "\u5f62\u5f0f\u5316\u591a\u667a\u80fd\u4f53\u97e7\u6027\u6982\u5ff5\uff0c\u63d0\u51fa\u534f\u4f5c\u534f\u8bae\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u534f\u4f5c\u4e0e\u975e\u534f\u4f5c\u65b9\u6cd5\u7684\u97e7\u6027\u8868\u73b0\u3002", "result": "\u6240\u6709\u534f\u4f5c\u65b9\u6cd5\u7684\u7fa4\u4f53\u97e7\u6027\u5747\u4f18\u4e8e\u975e\u534f\u4f5c\u65b9\u6cd5\u3002", "conclusion": "\u534f\u4f5c\u662f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u63d0\u5347\u7fa4\u4f53\u97e7\u6027\u7684\u6709\u6548\u7b56\u7565\u3002", "keywords": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60, \u7fa4\u4f53\u97e7\u6027, \u534f\u4f5c\u534f\u8bae, \u52a8\u6001\u73af\u5883"}}
{"id": "2507.10843", "pdf": "https://arxiv.org/pdf/2507.10843", "abs": "https://arxiv.org/abs/2507.10843", "authors": ["Motoki Omura", "Yusuke Mukuta", "Kazuki Ota", "Takayuki Osa", "Tatsuya Harada"], "title": "Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Accepted at RLC 2025", "summary": "Offline reinforcement learning (RL) aims to learn an optimal policy from a\nstatic dataset, making it particularly valuable in scenarios where data\ncollection is costly, such as robotics. A major challenge in offline RL is\ndistributional shift, where the learned policy deviates from the dataset\ndistribution, potentially leading to unreliable out-of-distribution actions. To\nmitigate this issue, regularization techniques have been employed. While many\nexisting methods utilize density ratio-based measures, such as the\n$f$-divergence, for regularization, we propose an approach that utilizes the\nWasserstein distance, which is robust to out-of-distribution data and captures\nthe similarity between actions. Our method employs input-convex neural networks\n(ICNNs) to model optimal transport maps, enabling the computation of the\nWasserstein distance in a discriminator-free manner, thereby avoiding\nadversarial training and ensuring stable learning. Our approach demonstrates\ncomparable or superior performance to widely used existing methods on the D4RL\nbenchmark dataset. The code is available at\nhttps://github.com/motokiomura/Q-DOT .", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eWasserstein\u8ddd\u79bb\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528ICNNs\u5efa\u6a21\u6700\u4f18\u4f20\u8f93\u6620\u5c04\uff0c\u907f\u514d\u5bf9\u6297\u8bad\u7ec3\uff0c\u5728D4RL\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u7684\u573a\u666f\uff08\u5982\u673a\u5668\u4eba\u5b66\uff09\u4e2d\u5c24\u4e3a\u91cd\u8981\uff0c\u4f46\u5206\u5e03\u504f\u79fb\u95ee\u9898\u4f1a\u5bfc\u81f4\u7b56\u7565\u4e0d\u53ef\u9760\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u57fa\u4e8e\u5bc6\u5ea6\u6bd4\u6b63\u5219\u5316\uff0c\u672c\u6587\u63d0\u51fa\u66f4\u7a33\u5065\u7684Wasserstein\u8ddd\u79bb\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u8f93\u5165\u51f8\u795e\u7ecf\u7f51\u7edc\uff08ICNNs\uff09\u5efa\u6a21\u6700\u4f18\u4f20\u8f93\u6620\u5c04\uff0c\u8ba1\u7b97Wasserstein\u8ddd\u79bb\uff0c\u65e0\u9700\u5224\u522b\u5668\uff0c\u907f\u514d\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u6216\u53ef\u6bd4\u73b0\u6709\u5e7f\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\u3002", "conclusion": "Wasserstein\u8ddd\u79bb\u7ed3\u5408ICNNs\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "keywords": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u3001Wasserstein\u8ddd\u79bb\u3001ICNNs\u3001\u5206\u5e03\u504f\u79fb"}}
{"id": "2507.11405", "pdf": "https://arxiv.org/pdf/2507.11405", "abs": "https://arxiv.org/abs/2507.11405", "authors": ["Cheng Xu", "Nan Yan", "Shuhao Guan", "Changhong Jin", "Yuke Mei", "Yibing Guo", "M-Tahar Kechadi"], "title": "DCR: Quantifying Data Contamination in LLMs Evaluation", "categories": ["cs.CL"], "comment": null, "summary": "The rapid advancement of large language models (LLMs) has heightened concerns\nabout benchmark data contamination (BDC), where models inadvertently memorize\nevaluation data, inflating performance metrics and undermining genuine\ngeneralization assessment. This paper introduces the Data Contamination Risk\n(DCR) framework, a lightweight, interpretable pipeline designed to detect and\nquantify BDC across four granular levels: semantic, informational, data, and\nlabel. By synthesizing contamination scores via a fuzzy inference system, DCR\nproduces a unified DCR Factor that adjusts raw accuracy to reflect\ncontamination-aware performance. Validated on 9 LLMs (0.5B-72B) across\nsentiment analysis, fake news detection, and arithmetic reasoning tasks, the\nDCR framework reliably diagnoses contamination severity and with accuracy\nadjusted using the DCR Factor to within 4% average error across the three\nbenchmarks compared to the uncontaminated baseline. Emphasizing computational\nefficiency and transparency, DCR provides a practical tool for integrating\ncontamination assessment into routine evaluations, fostering fairer comparisons\nand enhancing the credibility of LLM benchmarking practices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u6570\u636e\u6c61\u67d3\u98ce\u9669\uff08DCR\uff09\u6846\u67b6\u7684\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u51c6\u6570\u636e\u6c61\u67d3\uff08BDC\uff09\u4e2d\u7684\u8868\u73b0\u3002\u901a\u8fc7\u878d\u5408\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\uff0cDCR\u91cf\u5316\u4e86\u56db\u79cd\u6c61\u67d3\u7ea7\u522b\uff0c\u5e76\u8c03\u6574\u539f\u59cb\u51c6\u786e\u7387\u4ee5\u53cd\u6620\u771f\u5b9e\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u5f15\u53d1\u4e86\u5bf9\u57fa\u51c6\u6570\u636e\u6c61\u67d3\uff08BDC\uff09\u7684\u62c5\u5fe7\uff0c\u5373\u6a21\u578b\u65e0\u610f\u4e2d\u8bb0\u4f4f\u4e86\u8bc4\u4f30\u6570\u636e\uff0c\u5bfc\u81f4\u6027\u80fd\u6307\u6807\u865a\u9ad8\uff0c\u5f71\u54cd\u4e86\u6cdb\u5316\u80fd\u529b\u7684\u771f\u5b9e\u8bc4\u4f30\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e86DCR\u6846\u67b6\u3002", "method": "DCR\u6846\u67b6\u901a\u8fc7\u68c0\u6d4b\u548c\u91cf\u5316\u56db\u79cd\u6c61\u67d3\u7ea7\u522b\uff08\u8bed\u4e49\u3001\u4fe1\u606f\u3001\u6570\u636e\u548c\u6807\u7b7e\uff09\uff0c\u7ed3\u5408\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u751f\u6210\u7edf\u4e00\u7684DCR\u56e0\u5b50\uff0c\u7528\u4e8e\u8c03\u6574\u539f\u59cb\u51c6\u786e\u7387\u3002\u8be5\u65b9\u6cd5\u57289\u79cd\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "DCR\u6846\u67b6\u5728\u60c5\u611f\u5206\u6790\u3001\u5047\u65b0\u95fb\u68c0\u6d4b\u548c\u7b97\u672f\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6c61\u67d3\u4e25\u91cd\u7a0b\u5ea6\u8bca\u65ad\u51c6\u786e\u4e14\u8c03\u6574\u540e\u7684\u51c6\u786e\u7387\u4e0e\u672a\u6c61\u67d3\u57fa\u51c6\u76f8\u6bd4\u5e73\u5747\u8bef\u5dee\u57284%\u4ee5\u5185\u3002", "conclusion": "DCR\u6846\u67b6\u5f3a\u8c03\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u900f\u660e\u5ea6\uff0c\u4e3a\u65e5\u5e38\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6c61\u67d3\u68c0\u6d4b\u5de5\u5177\uff0c\u4fc3\u8fdb\u4e86\u516c\u5e73\u7684\u6bd4\u8f83\uff0c\u5e76\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u4fe1\u5ea6\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b\u3001\u57fa\u51c6\u6570\u636e\u6c61\u67d3\u3001DCR\u6846\u67b6\u3001\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u3001\u6027\u80fd\u8bc4\u4f30"}}
{"id": "2507.10559", "pdf": "https://arxiv.org/pdf/2507.10559", "abs": "https://arxiv.org/abs/2507.10559", "authors": ["Shomir Wilson"], "title": "NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent developments in large language models (LLMs) have been accompanied by\nrapidly growing public interest in natural language processing (NLP). This\nattention is reflected by major news venues, which sometimes invite NLP\nresearchers to share their knowledge and views with a wide audience.\nRecognizing the opportunities of the present, for both the research field and\nfor individual researchers, this paper shares recommendations for communicating\nwith a general audience about LLMs' capabilities and limitations. These\nrecommendations cover three themes: vague terminology as an obstacle to public\nunderstanding, unreasonable expectations as obstacles to sustainable growth,\nand ethical failures as obstacles to continued support. Published NLP research\nand popular news coverage are cited to illustrate these themes with examples.\nThe recommendations promote effective, transparent communication with the\ngeneral public about NLP, in order to strengthen public understanding and\nencourage support for research.", "AI": {"tldr": "\u672c\u6587\u5206\u4eab\u4e86\u5173\u4e8e\u5982\u4f55\u5411\u516c\u4f17\u4f20\u8fbe\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u529b\u548c\u9650\u5236\u7684\u5efa\u8bae\uff0c\u6db5\u76d6\u4e86\u6a21\u7cca\u672f\u8bed\u3001\u4e0d\u5408\u7406\u671f\u671b\u548c\u4f26\u7406\u95ee\u9898\u4e09\u4e2a\u4e3b\u9898\uff0c\u65e8\u5728\u4fc3\u8fdb\u516c\u4f17\u7406\u89e3\u548c\u7814\u7a76\u652f\u6301\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u516c\u4f17\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u5174\u8da3\u6fc0\u589e\uff0c\u4f46\u540c\u65f6\u4e5f\u5b58\u5728\u5bf9LLMs\u80fd\u529b\u7684\u8bef\u89e3\u548c\u4e0d\u5408\u7406\u671f\u671b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63d0\u4f9b\u6c9f\u901a\u5efa\u8bae\uff0c\u589e\u5f3a\u516c\u4f17\u7406\u89e3\u5e76\u652f\u6301\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5df2\u53d1\u8868\u7684NLP\u7814\u7a76\u548c\u65b0\u95fb\u62a5\u9053\uff0c\u8bc6\u522b\u4e86\u4e09\u4e2a\u4e3b\u8981\u969c\u788d\uff08\u6a21\u7cca\u672f\u8bed\u3001\u4e0d\u5408\u7406\u671f\u671b\u3001\u4f26\u7406\u95ee\u9898\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u6c9f\u901a\u5efa\u8bae\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u516c\u4f17\u6c9f\u901a\u7684\u5177\u4f53\u5efa\u8bae\uff0c\u5f3a\u8c03\u4e86\u900f\u660e\u5ea6\u548c\u6709\u6548\u6027\uff0c\u4ee5\u51cf\u5c11\u8bef\u89e3\u5e76\u4fc3\u8fdb\u5bf9NLP\u7814\u7a76\u7684\u652f\u6301\u3002", "conclusion": "\u6709\u6548\u7684\u516c\u4f17\u6c9f\u901a\u5bf9\u4e8eLLMs\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u900f\u660e\u548c\u6e05\u6670\u7684\u8868\u8fbe\u6709\u52a9\u4e8e\u907f\u514d\u8bef\u89e3\u5e76\u7ef4\u6301\u7814\u7a76\u9886\u57df\u7684\u516c\u4fe1\u529b\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u516c\u4f17\u6c9f\u901a\u3001\u4f26\u7406\u95ee\u9898\u3001\u7814\u7a76\u652f\u6301"}}
{"id": "2507.10861", "pdf": "https://arxiv.org/pdf/2507.10861", "abs": "https://arxiv.org/abs/2507.10861", "authors": ["Edoardo Pinzuti", "Oliver T\u00fcscher", "Andr\u00e9 Ferreira Castro"], "title": "Visually grounded emotion regulation via diffusion models and user-driven reappraisal", "categories": ["cs.LG"], "comment": null, "summary": "Cognitive reappraisal is a key strategy in emotion regulation, involving\nreinterpretation of emotionally charged stimuli to alter affective responses.\nDespite its central role in clinical and cognitive science, real-world\nreappraisal interventions remain cognitively demanding, abstract, and primarily\nverbal. This reliance on higher-order cognitive and linguistic processes is\noften impaired in individuals with trauma or depression, limiting the\neffectiveness of standard approaches. Here, we propose a novel, visually based\naugmentation of cognitive reappraisal by integrating large-scale text-to-image\ndiffusion models into the emotional regulation process. Specifically, we\nintroduce a system in which users reinterpret emotionally negative images via\nspoken reappraisals, which are transformed into supportive, emotionally\ncongruent visualizations using stable diffusion models with a fine-tuned\nIP-adapter. This generative transformation visually instantiates users'\nreappraisals while maintaining structural similarity to the original stimuli,\nexternalizing and reinforcing regulatory intent. To test this approach, we\nconducted a within-subject experiment (N = 20) using a modified cognitive\nemotion regulation (CER) task. Participants reappraised or described aversive\nimages from the International Affective Picture System (IAPS), with or without\nAI-generated visual feedback. Results show that AI-assisted reappraisal\nsignificantly reduced negative affect compared to both non-AI and control\nconditions. Further analyses reveal that sentiment alignment between\nparticipant reappraisals and generated images correlates with affective relief,\nsuggesting that multimodal coherence enhances regulatory efficacy. These\nfindings demonstrate that generative visual input can support cogitive\nreappraisal and open new directions at the intersection of generative AI,\naffective computing, and therapeutic technology.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u7684\u8ba4\u77e5\u91cd\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7ed3\u5408\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u751f\u6210\u89c6\u89c9\u53cd\u9988\u63d0\u5347\u60c5\u7eea\u8c03\u8282\u6548\u679c\u3002\u5b9e\u9a8c\u8868\u660e\uff0cAI\u8f85\u52a9\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u8d1f\u9762\u60c5\u7eea\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u8ba4\u77e5\u91cd\u8bc4\u4f30\u5e72\u9884\u901a\u5e38\u4f9d\u8d56\u9ad8\u9636\u8ba4\u77e5\u548c\u8bed\u8a00\u8fc7\u7a0b\uff0c\u5bf9\u521b\u4f24\u6216\u6291\u90c1\u60a3\u8005\u6548\u679c\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u76f4\u89c2\u7684\u89c6\u89c9\u8f85\u52a9\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u7cfb\u7edf\uff0c\u7528\u6237\u901a\u8fc7\u8bed\u97f3\u91cd\u8bc4\u4f30\u8d1f\u9762\u60c5\u7eea\u56fe\u50cf\uff0c\u7cfb\u7edf\u5229\u7528\u7a33\u5b9a\u6269\u6563\u6a21\u578b\u751f\u6210\u652f\u6301\u6027\u89c6\u89c9\u53cd\u9988\u3002\u5b9e\u9a8c\u91c7\u7528\u7ec4\u5185\u8bbe\u8ba1\uff0c\u6bd4\u8f83\u6709\u65e0AI\u53cd\u9988\u7684\u6548\u679c\u3002", "result": "AI\u8f85\u52a9\u7684\u91cd\u8bc4\u4f30\u663e\u8457\u964d\u4f4e\u4e86\u8d1f\u9762\u60c5\u7eea\uff0c\u4e14\u751f\u6210\u56fe\u50cf\u4e0e\u7528\u6237\u91cd\u8bc4\u4f30\u7684\u60c5\u611f\u4e00\u81f4\u6027\u589e\u5f3a\u4e86\u8c03\u8282\u6548\u679c\u3002", "conclusion": "\u751f\u6210\u89c6\u89c9\u53cd\u9988\u80fd\u6709\u6548\u652f\u6301\u8ba4\u77e5\u91cd\u8bc4\u4f30\uff0c\u4e3a\u751f\u6210AI\u3001\u60c5\u611f\u8ba1\u7b97\u548c\u6cbb\u7597\u7684\u7ed3\u5408\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "keywords": "\u8ba4\u77e5\u91cd\u8bc4\u4f30,\u60c5\u7eea\u8c03\u8282,\u751f\u6210AI,\u89c6\u89c9\u53cd\u9988,\u60c5\u611f\u8ba1\u7b97"}}
{"id": "2507.11407", "pdf": "https://arxiv.org/pdf/2507.11407", "abs": "https://arxiv.org/abs/2507.11407", "authors": ["LG AI Research", ":", "Kyunghoon Bae", "Eunbi Choi", "Kibong Choi", "Stanley Jungkyu Choi", "Yemuk Choi", "Kyubeen Han", "Seokhee Hong", "Junwon Hwang", "Taewan Hwang", "Joonwon Jang", "Hyojin Jeon", "Kijeong Jeon", "Gerrard Jeongwon Jo", "Hyunjik Jo", "Jiyeon Jung", "Euisoon Kim", "Hyosang Kim", "Jihoon Kim", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Youchul Kim", "Edward Hwayoung Lee", "Gwangho Lee", "Haeju Lee", "Honglak Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Young Min Paik", "Yongmin Park", "Youngyong Park", "Sanghyun Seo", "Sihoon Yang", "Heuiyeen Yeen", "Sihyuk Yi", "Hyeongu Yun"], "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes", "categories": ["cs.CL", "cs.AI"], "comment": "Technical Report, 30 Pages", "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.", "AI": {"tldr": "EXAONE 4.0\u5f15\u5165\u975e\u63a8\u7406\u4e0e\u63a8\u7406\u6a21\u5f0f\uff0c\u63d0\u5347\u53ef\u7528\u6027\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff08\u5305\u62ec\u897f\u73ed\u7259\u8bed\uff09\uff0c\u63d0\u4f9b\u4e24\u79cd\u89c4\u6a21\u6a21\u578b\uff0832B\u548c1.2B\uff09\uff0c\u6027\u80fd\u4f18\u4e8e\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\u3002", "motivation": "\u4e3a\u8fce\u63a5\u4ee3\u7406AI\u65f6\u4ee3\uff0c\u7ed3\u5408EXAONE 3.5\u7684\u6613\u7528\u6027\u548cEXAONE Deep\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5f00\u53d1\u529f\u80fd\u66f4\u5f3a\u7684EXAONE 4.0\u3002", "method": "\u91c7\u7528\u975e\u63a8\u7406\u4e0e\u63a8\u7406\u6a21\u5f0f\u6574\u5408\uff0c\u6269\u5c55\u591a\u8bed\u8a00\u652f\u6301\uff08\u82f1\u8bed\u3001\u97e9\u8bed\u3001\u897f\u73ed\u7259\u8bed\uff09\uff0c\u63d0\u4f9b32B\uff08\u9ad8\u6027\u80fd\uff09\u548c1.2B\uff08\u8f7b\u91cf\u7ea7\uff09\u4e24\u79cd\u6a21\u578b\u89c4\u6a21\u3002", "result": "EXAONE 4.0\u6027\u80fd\u4f18\u4e8e\u540c\u7c7b\u5f00\u6e90\u6a21\u578b\uff0c\u5e76\u4e0e\u524d\u6cbf\u6a21\u578b\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u6a21\u578b\u5df2\u516c\u5f00\u4f9b\u7814\u7a76\u4e0b\u8f7d\u3002", "conclusion": "EXAONE 4.0\u901a\u8fc7\u591a\u6a21\u5f0f\u6574\u5408\u4e0e\u591a\u8bed\u8a00\u652f\u6301\uff0c\u4e3a\u4ee3\u7406AI\u65f6\u4ee3\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u4e14\u6613\u7528\u7684\u5de5\u5177\u3002", "keywords": "EXAONE 4.0, \u63a8\u7406\u6a21\u5f0f, \u591a\u8bed\u8a00\u652f\u6301, \u4ee3\u7406AI, \u6a21\u578b\u6027\u80fd"}}
{"id": "2507.10563", "pdf": "https://arxiv.org/pdf/2507.10563", "abs": "https://arxiv.org/abs/2507.10563", "authors": ["Antonis Messinis"], "title": "A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment", "categories": ["cs.NE", "cs.AI"], "comment": null, "summary": "With increasing wastewater rates, achieving energy-neutral purification is\nchallenging. We introduce a coral-reef-inspired Swarm Interaction Network for\ncarbon-neutral wastewater treatment, combining morphogenetic abstraction with\nmulti-task carbon awareness. Scalability stems from linear token complexity,\nmitigating the energy-removal problem. Compared with seven baselines, our\napproach achieves 96.7\\% removal efficiency, 0.31~kWh~m$^{-3}$ energy\nconsumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis\ndemonstrates robustness under sensor drift. Field scenarios--insular lagoons,\nbrewery spikes, and desert greenhouses--show potential diesel savings of up to\n22\\%. However, data-science staffing remains an impediment. Future work will\nintegrate AutoML wrappers within the project scope, although governance\nrestrictions pose interpretability challenges that require further visual\nanalytics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u73ca\u745a\u7901\u542f\u53d1\u7684\u7fa4\u4f53\u4ea4\u4e92\u7f51\u7edc\uff0c\u7528\u4e8e\u78b3\u4e2d\u6027\u5e9f\u6c34\u5904\u7406\uff0c\u7ed3\u5408\u5f62\u6001\u53d1\u751f\u548c\u591a\u4efb\u52a1\u78b3\u611f\u77e5\uff0c\u89e3\u51b3\u4e86\u80fd\u6e90\u53bb\u9664\u95ee\u9898\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5e9f\u6c34\u5904\u7406\u91cf\u589e\u52a0\uff0c\u5b9e\u73b0\u80fd\u6e90\u4e2d\u6027\u51c0\u5316\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5f15\u5165\u521b\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u73ca\u745a\u7901\u542f\u53d1\u7684\u7fa4\u4f53\u4ea4\u4e92\u7f51\u7edc\uff0c\u7ed3\u5408\u5f62\u6001\u53d1\u751f\u62bd\u8c61\u548c\u591a\u4efb\u52a1\u78b3\u611f\u77e5\uff0c\u901a\u8fc7\u7ebf\u6027\u4ee4\u724c\u590d\u6742\u5ea6\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002", "result": "\u4e0e\u4e03\u79cd\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e8696.7%\u7684\u53bb\u9664\u6548\u7387\u30010.31 kWh m\u207b\u00b3\u7684\u80fd\u8017\u548c14.2 g m\u207b\u00b3\u7684CO\u2082\u6392\u653e\u3002\u5728\u4f20\u611f\u5668\u6f02\u79fb\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u5b9e\u9645\u573a\u666f\u4e2d\u53ef\u8282\u770122%\u7684\u67f4\u6cb9\u6d88\u8017\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u78b3\u4e2d\u6027\u5e9f\u6c34\u5904\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6570\u636e\u79d1\u5b66\u4eba\u5458\u914d\u7f6e\u548c\u6cbb\u7406\u9650\u5236\u662f\u672a\u6765\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u3002", "keywords": "\u5e9f\u6c34\u5904\u7406, \u78b3\u4e2d\u6027, \u7fa4\u4f53\u4ea4\u4e92\u7f51\u7edc, \u591a\u4efb\u52a1\u78b3\u611f\u77e5, \u5f62\u6001\u53d1\u751f"}}
{"id": "2507.10871", "pdf": "https://arxiv.org/pdf/2507.10871", "abs": "https://arxiv.org/abs/2507.10871", "authors": ["Tsung Yeh Hsieh", "Yongjie Jessica Zhang"], "title": "GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.med-ph"], "comment": null, "summary": "Neurons exhibit intricate geometries within their neurite networks, which\nplay a crucial role in processes such as signaling and nutrient transport.\nAccurate simulation of material transport in the networks is essential for\nunderstanding these biological phenomena but poses significant computational\nchallenges because of the complex tree-like structures involved. Traditional\napproaches are time-intensive and resource-demanding, yet the inherent\nproperties of neuron trees, which consists primarily of pipes with steady-state\nparabolic velocity profiles and bifurcations, provide opportunities for\ncomputational optimization. To address these challenges, we propose a\nGraph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is\nspecifically designed to streamline the simulation of material transport in\nneural trees. GALDS employs a graph autoencoder to encode latent\nrepresentations of the network's geometry, velocity fields, and concentration\nprofiles. These latent space representations are then assembled into a global\ngraph, which is subsequently used to predict system dynamics in the latent\nspace via a trained graph latent space system dynamic model, inspired by the\nNeural Ordinary Differential Equations (Neural ODEs) concept. The integration\nof an autoencoder allows for the use of smaller graph neural network models\nwith reduced training data requirements. Furthermore, the Neural ODE component\neffectively mitigates the issue of error accumulation commonly encountered in\nrecurrent neural networks. The effectiveness of the GALDS model is demonstrated\nthrough results on eight unseen geometries and four abnormal transport\nexamples, where our approach achieves mean relative error of 3% with maximum\nrelative error <8% and demonstrates a 10-fold speed improvement compared to\nprevious surrogate model approaches.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6f5c\u5728\u52a8\u529b\u5b66\u66ff\u4ee3\u6a21\u578b\uff08GALDS\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u6a21\u62df\u795e\u7ecf\u5143\u6811\u72b6\u7f51\u7edc\u4e2d\u7684\u7269\u8d28\u8fd0\u8f93\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u7684\u95ee\u9898\u3002", "motivation": "\u795e\u7ecf\u5143\u7f51\u7edc\u7684\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u5bf9\u7269\u8d28\u8fd0\u8f93\u6a21\u62df\u63d0\u51fa\u4e86\u8ba1\u7b97\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u4e14\u8d44\u6e90\u5bc6\u96c6\u3002", "method": "GALDS\u7ed3\u5408\u56fe\u81ea\u52a8\u7f16\u7801\u5668\u548c\u56fe\u6f5c\u5728\u7a7a\u95f4\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5229\u7528\u5c0f\u89c4\u6a21\u56fe\u795e\u7ecf\u7f51\u7edc\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u9700\u6c42\uff0c\u5e76\u501f\u9274\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u6982\u5ff5\u3002", "result": "\u57288\u79cd\u672a\u89c1\u51e0\u4f55\u7ed3\u6784\u548c4\u79cd\u5f02\u5e38\u8fd0\u8f93\u6848\u4f8b\u4e2d\uff0cGALDS\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u4e3a3%\uff0c\u6700\u5927\u8bef\u5dee\u4f4e\u4e8e8%\uff0c\u901f\u5ea6\u6bd4\u4e4b\u524d\u66ff\u4ee3\u6a21\u578b\u5feb10\u500d\u3002", "conclusion": "GALDS\u4e3a\u795e\u7ecf\u5143\u7f51\u7edc\u4e2d\u7684\u7269\u8d28\u8fd0\u8f93\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "keywords": "\u795e\u7ecf\u5143\u7f51\u7edc, \u7269\u8d28\u8fd0\u8f93, \u56fe\u81ea\u52a8\u7f16\u7801\u5668, \u6f5c\u5728\u52a8\u529b\u5b66, \u6a21\u62df"}}
{"id": "2507.11408", "pdf": "https://arxiv.org/pdf/2507.11408", "abs": "https://arxiv.org/abs/2507.11408", "authors": ["Soumadeep Saha", "Akshay Chaturvedi", "Saptarshi Saha", "Utpal Garain", "Nicholas Asher"], "title": "KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "15 pages, 9 figures", "summary": "Chain-of-thought traces have been shown to improve performance of large\nlanguage models in a plethora of reasoning tasks, yet there is no consensus on\nthe mechanism through which this performance boost is achieved. To shed more\nlight on this, we introduce Causal CoT Graphs (CCGs), which are directed\nacyclic graphs automatically extracted from reasoning traces that model\nfine-grained causal dependencies in the language model output. A collection of\n$1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their\nassociated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed\nempirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in\nthe CCG are mediators for the final answer, a condition necessary for\nreasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating\nthat models internally realise structures akin to our graphs. KisMATH enables\ncontrolled, graph-aligned interventions and opens up avenues for further\ninvestigation into the role of chain-of-thought in LLM reasoning.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u94fe\u5f0f\u601d\u7ef4\u8ddf\u8e2a\uff08Chain-of-thought\uff09\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u673a\u5236\uff0c\u5e76\u63d0\u51fa\u4e86Causal CoT Graphs\uff08CCGs\uff09\u6765\u5efa\u6a21\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u63a2\u7d22\u94fe\u5f0f\u601d\u7ef4\u8ddf\u8e2a\u5982\u4f55\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5efa\u6a21\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u5f15\u5165\u4e86Causal CoT Graphs\uff08CCGs\uff09\uff0c\u4ece\u63a8\u7406\u8ddf\u8e2a\u4e2d\u81ea\u52a8\u63d0\u53d6\u6709\u5411\u65e0\u73af\u56fe\uff0c\u5efa\u6a21\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4e2d\u7684\u7ec6\u7c92\u5ea6\u56e0\u679c\u4f9d\u8d56\u3002\u4f7f\u7528MATH500\u3001GSM8K\u548cAIME\u4e2d\u76841671\u4e2a\u6570\u5b66\u63a8\u7406\u95ee\u9898\u53ca\u5176CCGs\uff0c\u6784\u5efa\u4e86\u6570\u636e\u96c6KisMATH\u3002\u901a\u8fc715\u4e2a\u5f00\u6e90\u6743\u91cd\u7684LLMs\u8fdb\u884c\u4e86\u8be6\u7ec6\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u53d1\u73b0\uff08i\uff09CCG\u4e2d\u7684\u63a8\u7406\u8282\u70b9\u662f\u6700\u7ec8\u7b54\u6848\u7684\u4e2d\u4ecb\u8005\uff0c\u8fd9\u662f\u63a8\u7406\u7684\u5fc5\u8981\u6761\u4ef6\uff1b\uff08ii\uff09LLMs\u5f3a\u8c03CCG\u7ed9\u51fa\u7684\u63a8\u7406\u8def\u5f84\uff0c\u8868\u660e\u6a21\u578b\u5185\u90e8\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u4e8eCCG\u7684\u7ed3\u6784\u3002", "conclusion": "KisMATH\u652f\u6301\u53d7\u63a7\u7684\u3001\u56fe\u5bf9\u9f50\u7684\u5e72\u9884\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u94fe\u5f0f\u601d\u7ef4\u5728LLM\u63a8\u7406\u4e2d\u7684\u4f5c\u7528\u5f00\u8f9f\u4e86\u65b0\u7684\u9014\u5f84\u3002", "keywords": "Chain-of-thought, reasoning tasks, large language models, Causal CoT Graphs, KisMATH, LLM reasoning"}}
{"id": "2507.10880", "pdf": "https://arxiv.org/pdf/2507.10880", "abs": "https://arxiv.org/abs/2507.10880", "authors": ["Souvik Nath", "Sumit Wadhwa", "Luiz Perez"], "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages, 3 figures", "summary": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\uff0c\u7528\u4e8e\u589e\u5f3a\u4ea7\u54c1\u548c\u670d\u52a1\u7684\u7a0e\u52a1\u4ee3\u7801\u9884\u6d4b\uff0c\u89e3\u51b3\u7a0e\u52a1\u5408\u89c4\u6027\u95ee\u9898\u3002", "motivation": "\u8de8\u56fd\u4f01\u4e1a\u6bcf\u5929\u5904\u7406\u5927\u91cf\u4ea4\u6613\uff0c\u9700\u9075\u5b88\u590d\u6742\u7684\u7a0e\u52a1\u6cd5\u89c4\uff0c\u51c6\u786e\u7684\u7a0e\u52a1\u4ee3\u7801\u9884\u6d4b\u5bf9\u907f\u514d\u7f5a\u6b3e\u81f3\u5173\u91cd\u8981\u3002", "method": "\u91c7\u7528\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684SLM\uff0c\u901a\u8fc7\u5e8f\u5217\u751f\u6210\u6355\u6349\u7a0e\u52a1\u4ee3\u7801\u7684\u5c42\u6b21\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u7a0e\u52a1\u4ee3\u7801\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5206\u7c7b\u5668\u548c\u5355\u7f16\u7801\u5668\u6216\u5355\u89e3\u7801\u5668\u67b6\u6784\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u653f\u5e9c\u89c4\u5b9a\u7684\u7a0e\u52a1\u5546\u54c1\u4ee3\u7801\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "keywords": "\u7a0e\u52a1\u4ee3\u7801\u9884\u6d4b, \u5c0f\u578b\u8bed\u8a00\u6a21\u578b, \u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784, HSN, UNSPSC"}}
{"id": "2507.11412", "pdf": "https://arxiv.org/pdf/2507.11412", "abs": "https://arxiv.org/abs/2507.11412", "authors": ["Orion Weller", "Kathryn Ricci", "Marc Marone", "Antoine Chaffin", "Dawn Lawrie", "Benjamin Van Durme"], "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "The large language model (LLM) community focuses almost exclusively on\ndecoder-only language models, since they are easier to use for text generation.\nHowever, a large subset of the community still uses encoder-only models for\ntasks such as classification or retrieval. Previous work has attempted to\ncompare these architectures, but is forced to make comparisons with models that\nhave different numbers of parameters, training techniques, and datasets. We\nintroduce the SOTA open-data Ettin suite of models: paired encoder-only and\ndecoder-only models ranging from 17 million parameters to 1 billion, trained on\nup to 2 trillion tokens. Using the same recipe for both encoder-only and\ndecoder-only models produces SOTA recipes in both categories for their\nrespective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as\ndecoders. Like previous work, we find that encoder-only models excel at\nclassification and retrieval tasks while decoders excel at generative tasks.\nHowever, we show that adapting a decoder model to encoder tasks (and vice\nversa) through continued training is subpar compared to using only the reverse\nobjective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa\nfor generative tasks). We open-source all artifacts of this study including\ntraining data, training order segmented by checkpoint, and 200+ checkpoints to\nallow future work to analyze or extend all aspects of training.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86SOTA\u5f00\u6e90\u6570\u636e\u96c6Ettin\u5957\u4ef6\uff0c\u6bd4\u8f83\u4e86\u7f16\u7801\u5668-\u4ec5\u548c\u89e3\u7801\u5668-\u4ec5\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u7f16\u7801\u5668\u5728\u5206\u7c7b\u548c\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u89e3\u7801\u5668\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u66f4\u4f18\u3002", "motivation": "\u7814\u7a76\u7f16\u7801\u5668-\u4ec5\u548c\u89e3\u7801\u5668-\u4ec5\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u6a21\u578b\u89c4\u6a21\u548c\u8bad\u7ec3\u65b9\u6cd5\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u76f8\u540c\u8bad\u7ec3\u914d\u65b9\u548c\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u4ece1700\u4e07\u523010\u4ebf\u53c2\u6570\u7684\u7f16\u7801\u5668-\u4ec5\u548c\u89e3\u7801\u5668-\u4ec5\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u4efb\u52a1\u9002\u914d\u5b9e\u9a8c\u3002", "result": "\u7f16\u7801\u5668-\u4ec5\u6a21\u578b\u5728\u5206\u7c7b\u548c\u68c0\u7d22\u4efb\u52a1\u4e2d\u4f18\u4e8e\u89e3\u7801\u5668-\u4ec5\u6a21\u578b\uff0c\u800c\u89e3\u7801\u5668-\u4ec5\u6a21\u578b\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff1b\u4efb\u52a1\u9002\u914d\u6548\u679c\u4e0d\u4f73\u3002", "conclusion": "\u4e0d\u540c\u67b6\u6784\u7684\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u5404\u6709\u4f18\u52bf\uff0c\u8de8\u4efb\u52a1\u9002\u914d\u6548\u679c\u6709\u9650\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, \u7f16\u7801\u5668-\u4ec5, \u89e3\u7801\u5668-\u4ec5, \u4efb\u52a1\u9002\u914d, \u5f00\u6e90\u6570\u636e\u96c6"}}
{"id": "2507.10884", "pdf": "https://arxiv.org/pdf/2507.10884", "abs": "https://arxiv.org/abs/2507.10884", "authors": ["Hyunwoo Cho", "Hyeontae Jo", "Hyung Ju Hwang"], "title": "Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model", "categories": ["cs.LG", "math.DS", "68T07, 68T05, 70G60"], "comment": null, "summary": "System inference for nonlinear dynamic models, represented by ordinary\ndifferential equations (ODEs), remains a significant challenge in many fields,\nparticularly when the data are noisy, sparse, or partially observable. In this\npaper, we propose a Simulation-based Generative Model for Imperfect Data\n(SiGMoID) that enables precise and robust inference for dynamic systems. The\nproposed approach integrates two key methods: (1) physics-informed neural\nnetworks with hyper-networks that constructs an ODE solver, and (2) Wasserstein\ngenerative adversarial networks that estimates ODE parameters by effectively\ncapturing noisy data distributions. We demonstrate that SiGMoID quantifies data\nnoise, estimates system parameters, and infers unobserved system components.\nIts effectiveness is validated validated through realistic experimental\nexamples, showcasing its broad applicability in various domains, from\nscientific research to engineered systems, and enabling the discovery of full\nsystem dynamics.", "AI": {"tldr": "SiGMoID \u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u62df\u7684\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u975e\u7ebf\u6027\u52a8\u6001\u6a21\u578b\u5728\u566a\u58f0\u3001\u7a00\u758f\u6216\u90e8\u5206\u53ef\u89c2\u6d4b\u6570\u636e\u4e0b\u7684\u63a8\u65ad\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u975e\u7ebf\u6027\u52a8\u6001\u6a21\u578b\u5728\u566a\u58f0\u3001\u7a00\u758f\u6216\u90e8\u5206\u53ef\u89c2\u6d4b\u6570\u636e\u4e0b\u7684\u63a8\u65ad\u5177\u6709\u6311\u6218\u6027\uff0c\u672c\u6587\u63d0\u51fa SiGMoID \u4ee5\u5b9e\u73b0\u7cbe\u786e\u4e14\u9c81\u68d2\u7684\u52a8\u6001\u7cfb\u7edf\u63a8\u65ad\u3002", "method": "SiGMoID \u7ed3\u5408\u4e86\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u4e0e\u8d85\u7f51\u7edc\u6784\u5efa ODE \u6c42\u89e3\u5668\uff0c\u4ee5\u53ca Wasserstein \u751f\u6210\u5bf9\u6297\u7f51\u7edc\u4ee5\u4f30\u8ba1 ODE \u53c2\u6570\u5e76\u6355\u83b7\u566a\u58f0\u6570\u636e\u5206\u5e03\u3002", "result": "SiGMoID \u80fd\u591f\u91cf\u5316\u6570\u636e\u566a\u58f0\u3001\u4f30\u8ba1\u7cfb\u7edf\u53c2\u6570\u5e76\u63a8\u65ad\u672a\u89c2\u6d4b\u7cfb\u7edf\u7ec4\u4ef6\uff0c\u5176\u6709\u6548\u6027\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "conclusion": "SiGMoID \u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u53ef\u7528\u4e8e\u79d1\u5b66\u7814\u7a76\u4e0e\u5de5\u7a0b\u7cfb\u7edf\uff0c\u5e2e\u52a9\u53d1\u73b0\u5b8c\u6574\u7cfb\u7edf\u52a8\u6001\u3002", "keywords": "\u975e\u7ebf\u6027\u52a8\u6001\u6a21\u578b, ODE, \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc, \u751f\u6210\u5bf9\u6297\u7f51\u7edc, \u7cfb\u7edf\u63a8\u65ad"}}
{"id": "2507.11423", "pdf": "https://arxiv.org/pdf/2507.11423", "abs": "https://arxiv.org/abs/2507.11423", "authors": ["Yanjian Zhang", "Guillaume Wisniewski", "Nadi Tomeh", "Thierry Charnois"], "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "categories": ["cs.CL"], "comment": null, "summary": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u63d0\u793a\u53ef\u4ee5\u5f71\u54cd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u7b56\u7565\uff0c\u4f46\u5355\u4e00\u7b56\u7565\u65e0\u6cd5\u6301\u7eed\u63d0\u5347\u51c6\u786e\u6027\uff0c\u9002\u5e94\u6027\u7b56\u7565\u9009\u62e9\u53ef\u80fd\u4f18\u5316\u6548\u679c\u3002", "motivation": "\u63a2\u7d22LLMs\u63a8\u7406\u7b56\u7565\u7684\u591a\u6837\u6027\uff0c\u89e3\u51b3\u5176\u5728\u591a\u6837\u5316\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u63d0\u793a\u63a7\u5236LLMs\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u65b9\u6cd5\u5f15\u5bfc\u5176\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5355\u4e00\u7b56\u7565\u65e0\u6cd5\u6301\u7eed\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u9002\u5e94\u6027\u7b56\u7565\u9009\u62e9\u53ef\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u5f15\u5bfcLLMs\u81ea\u9002\u5e94\u9009\u62e9\u63a8\u7406\u7b56\u7565\u662f\u4f18\u5316\u5176\u63a8\u7406\u80fd\u529b\u7684\u65b0\u65b9\u5411\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b, \u63a8\u7406\u7b56\u7565, \u63d0\u793a, \u9002\u5e94\u6027\u9009\u62e9, \u903b\u8f91\u95ee\u9898"}}
{"id": "2507.10576", "pdf": "https://arxiv.org/pdf/2507.10576", "abs": "https://arxiv.org/abs/2507.10576", "authors": ["Bhakti Khera", "Rezvan Alamian", "Pascal A. Scherz", "Stephan M. Goetz"], "title": "Can Large Language Models Understand As Well As Apply Patent Regulations to Pass a Hands-On Patent Attorney Test?", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.ET"], "comment": "39 pages, 21 figures", "summary": "The legal field already uses various large language models (LLMs) in actual\napplications, but their quantitative performance and reasons for it are\nunderexplored. We evaluated several open-source and proprietary LLMs --\nincluding GPT-series, Anthropic, Deepseek and Llama-3, variants -- on parts of\nthe European Qualifying Examination (EQE) for future European Patent Attorneys.\nOpenAI o1 led with 0.82 accuracy and 0.81 F1 score, whereas (Amazon Web\nServices) AWS Llama 3.1 8B lagged at 0.50 accuracy, and a Python-deployed Llama\n3.1 8B scored 0.55. The latter two are within the range of mere guessing for\nthe two-answer forced-choice design. None of the evaluated models could have\npassed the examination fully, as accuracy never exceeded the average threshold\nof 0.90 required for professional-level standards -- also not models that are\nregularly promoted for their assumed beyond-PhD- and bar-admitted-lawyer-level\nperformance. GPT-4o excelled at integrating text and graphics, while Claude 3\nOpus often lost formatting coherence. Human patent experts evaluated the\ntextual justifications and uncovered various critical shortcomings of each\nmodel. They valued clarity and legal rationale over the raw correctness of the\nanswers, which revealed misalignment between automatic metrics and expert\njudgment. Model outputs were sensitive to modest temperature changes and prompt\nwording, which underscores the remaining necessity of expert oversight. Future\nwork should target logical consistency, robust multimodality, and adaptive\nprompting to approach human-level patent proficiency. In summary, despite the\noutstanding performance of recent large models, the general public might\noverestimate their performance. The field has a long way to go to develop a\nvirtual patent attorney. This paper wants to point out several specific\nlimitations that need solutions.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u8868\u73b0\u88ab\u9ad8\u4f30\uff0c\u73b0\u6709\u6a21\u578b\u5728\u4e13\u5229\u5f8b\u5e08\u8003\u8bd5\u4e2d\u672a\u80fd\u8fbe\u5230\u4e13\u4e1a\u6807\u51c6\uff0c\u672a\u6765\u9700\u6539\u8fdb\u903b\u8f91\u4e00\u81f4\u6027\u548c\u591a\u6a21\u6001\u80fd\u529b\u3002", "motivation": "\u8bc4\u4f30\u5f00\u6e90\u548c\u4e13\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b27\u6d32\u4e13\u5229\u5f8b\u5e08\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5176\u5c40\u9650\u6027\u3002", "method": "\u6d4b\u8bd5\u591a\u79cdLLM\uff08\u5982GPT\u7cfb\u5217\u3001Anthropic\u3001Deepseek\u3001Llama-3\u7b49\uff09\u5728\u6b27\u6d32\u4e13\u5229\u5f8b\u5e08\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u51c6\u786e\u6027\u548cF1\u5206\u6570\uff0c\u5e76\u7ed3\u5408\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u3002", "result": "OpenAI o1\u8868\u73b0\u6700\u4f73\uff080.82\u51c6\u786e\u7387\uff09\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5747\u672a\u8fbe\u5230\u4e13\u4e1a\u6807\u51c6\uff080.90\u51c6\u786e\u7387\uff09\uff0c\u4e14\u5b58\u5728\u683c\u5f0f\u4e00\u81f4\u6027\u548c\u903b\u8f91\u95ee\u9898\u3002", "conclusion": "\u867d\u7136\u6a21\u578b\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u79bb\u5b9e\u9645\u5e94\u7528\u4ecd\u6709\u5dee\u8ddd\uff0c\u9700\u6539\u8fdb\u903b\u8f91\u4e00\u81f4\u6027\u3001\u591a\u6a21\u6001\u80fd\u529b\u548c\u63d0\u793a\u9002\u5e94\u6027\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b\u3001\u4e13\u5229\u5f8b\u5e08\u8003\u8bd5\u3001\u6027\u80fd\u8bc4\u4f30\u3001\u591a\u6a21\u6001\u3001\u4e13\u5bb6\u76d1\u7763"}}
{"id": "2507.10886", "pdf": "https://arxiv.org/pdf/2507.10886", "abs": "https://arxiv.org/abs/2507.10886", "authors": ["Patryk Jasiorski", "Marek Klonowski", "Micha\u0142 Wo\u017aniak"], "title": "How to Protect Models against Adversarial Unlearning?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "AI models need to be unlearned to fulfill the requirements of legal acts such\nas the AI Act or GDPR, and also because of the need to remove toxic content,\ndebiasing, the impact of malicious instances, or changes in the data\ndistribution structure in which a model works. Unfortunately, removing\nknowledge may cause undesirable side effects, such as a deterioration in model\nperformance. In this paper, we investigate the problem of adversarial\nunlearning, where a malicious party intentionally sends unlearn requests to\ndeteriorate the model's performance maximally. We show that this phenomenon and\nthe adversary's capabilities depend on many factors, primarily on the backbone\nmodel itself and strategy/limitations in selecting data to be unlearned. The\nmain result of this work is a new method of protecting model performance from\nthese side effects, both in the case of unlearned behavior resulting from\nspontaneous processes and adversary actions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5bf9\u6297\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5373\u6076\u610f\u65b9\u6545\u610f\u53d1\u9001\u9057\u5fd8\u8bf7\u6c42\u4ee5\u6700\u5927\u5316\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "AI\u6a21\u578b\u9700\u8981\u9057\u5fd8\u4ee5\u6ee1\u8db3\u6cd5\u5f8b\u6cd5\u89c4\u9700\u6c42\uff08\u5982AI\u6cd5\u6848\u6216GDPR\uff09\uff0c\u5e76\u89e3\u51b3\u6709\u6bd2\u5185\u5bb9\u3001\u53bb\u504f\u89c1\u3001\u6076\u610f\u5b9e\u4f8b\u5f71\u54cd\u6216\u6570\u636e\u5206\u5e03\u53d8\u5316\u7b49\u95ee\u9898\u3002\u4f46\u9057\u5fd8\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u7814\u7a76\u4e86\u5bf9\u6297\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5206\u6790\u4e86\u5bf9\u624b\u80fd\u529b\u53d7\u6a21\u578b\u672c\u8eab\u53ca\u9009\u62e9\u9057\u5fd8\u6570\u636e\u7b56\u7565\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u81ea\u53d1\u8fc7\u7a0b\u6216\u5bf9\u6297\u884c\u4e3a\u5bfc\u81f4\u7684\u9057\u5fd8\u4e2d\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u6297\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u4fdd\u62a4\u4e86\u6a21\u578b\u6027\u80fd\u3002", "keywords": "\u5bf9\u6297\u6027\u9057\u5fd8,\u6a21\u578b\u4fdd\u62a4,AI\u4f26\u7406,GDPR"}}
{"id": "2507.11502", "pdf": "https://arxiv.org/pdf/2507.11502", "abs": "https://arxiv.org/abs/2507.11502", "authors": ["Sirui Han", "Junqi Zhu", "Ruiyuan Zhang", "Yike Guo"], "title": "HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong", "categories": ["cs.CL", "cs.CE", "cs.LG"], "comment": null, "summary": "This paper presents the development of HKGAI-V1, a foundational sovereign\nlarge language model (LLM), developed as part of an initiative to establish\nvalue-aligned AI infrastructure specifically tailored for Hong Kong. Addressing\nthe region's unique multilingual environment (Cantonese, Mandarin, and\nEnglish), its distinct socio-legal context under the \"one country, two systems\"\nframework, and specific local cultural and value considerations, the model is\nbuilt upon the DeepSeek architecture and systematically aligned with regional\nnorms through a multifaceted full parameter fine-tuning process. It is further\nintegrated with a retrieval-augmented generation (RAG) system to ensure timely\nand factually grounded information access. The core contribution lies in the\ndesign and implementation of a comprehensive, region-specific AI alignment and\nsafety framework, demonstrated through two key achievements: 1) The successful\ndevelopment of HKGAI-V1 itself - which outper-forms general-purpose models in\nhandling Hong Kong-specific culturally sensitive queries, and embodies a\n\"governance-embedded\" approach to digital sovereignty - empowers Hong Kong to\nexercise control over AI applications in critical sectors including public\nservices, legal systems, and edu-cation. 2) The development of the proprietary\nAdversarial HK Value Benchmark, a rigorous tool for evaluating model alignment\nwith local ethical and legal stand-ards under challenging conditions. By\ndocumenting these achievements, the paper provides not only a technological\nartifact but also a replicable blueprint for developing advanced, regionally\nfocused AI systems deeply rooted in their local identities.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86HKGAI-V1\u7684\u5f00\u53d1\uff0c\u8fd9\u662f\u4e00\u79cd\u4e3a\u9999\u6e2f\u5b9a\u5236\u7684\u3001\u57fa\u4e8eDeepSeek\u67b6\u6784\u5e76\u878d\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u7684\u4e3b\u6743\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u9999\u6e2f\u7684\u591a\u8bed\u8a00\u548c\u72ec\u7279\u793e\u4f1a\u6cd5\u5f8b\u73af\u5883\u3002", "motivation": "\u4e3a\u9999\u6e2f\u5efa\u7acb\u7b26\u5408\u672c\u5730\u6587\u5316\u548c\u6cd5\u5f8b\u8981\u6c42\u7684AI\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u5173\u952e\u9886\u57df\u7684AI\u5e94\u7528\u3002", "method": "\u91c7\u7528DeepSeek\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u53c2\u6570\u5fae\u8c03\u548c\u5bf9\u9f50\u533a\u57df\u89c4\u8303\uff0c\u7ed3\u5408RAG\u7cfb\u7edf\u786e\u4fdd\u4fe1\u606f\u51c6\u786e\u6027\u3002", "result": "HKGAI-V1\u5728\u5904\u7406\u9999\u6e2f\u7279\u6709\u7684\u6587\u5316\u654f\u611f\u67e5\u8be2\u65f6\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u8bc4\u4f30\u672c\u5730\u4f26\u7406\u548c\u6cd5\u5f8b\u6807\u51c6\u7684\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6280\u672f\u6210\u679c\uff0c\u8fd8\u4e3a\u5f00\u53d1\u5176\u4ed6\u5730\u533a\u5b9a\u5236\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u84dd\u56fe\u3002", "keywords": "HKGAI-V1, \u5927\u578b\u8bed\u8a00\u6a21\u578b, \u4e3b\u6743AI, \u591a\u8bed\u8a00, \u9999\u6e2f, RAG, \u4f26\u7406\u5bf9\u9f50"}}
{"id": "2507.10890", "pdf": "https://arxiv.org/pdf/2507.10890", "abs": "https://arxiv.org/abs/2507.10890", "authors": ["Riccardo Savorgnan", "Udaya Ghai", "Carson Eisenach", "Dean Foster"], "title": "Outbound Modeling for Inventory Management", "categories": ["cs.LG"], "comment": "KDD - AI for Supply Chain Workshop", "summary": "We study the problem of forecasting the number of units fulfilled (or\n``drained'') from each inventory warehouse to meet customer demand, along with\nthe associated outbound shipping costs. The actual drain and shipping costs are\ndetermined by complex production systems that manage the planning and execution\nof customers' orders fulfillment, i.e. from where and how to ship a unit to be\ndelivered to a customer. Accurately modeling these processes is critical for\nregional inventory planning, especially when using Reinforcement Learning (RL)\nto develop control policies. For the RL usecase, a drain model is incorporated\ninto a simulator to produce long rollouts, which we desire to be\ndifferentiable. While simulating the calls to the internal software systems can\nbe used to recover this transition, they are non-differentiable and too slow\nand costly to run within an RL training environment. Accordingly, we frame this\nas a probabilistic forecasting problem, modeling the joint distribution of\noutbound drain and shipping costs across all warehouses at each time period,\nconditioned on inventory positions and exogenous customer demand. To ensure\nrobustness in an RL environment, the model must handle out-of-distribution\nscenarios that arise from off-policy trajectories. We propose a validation\nscheme that leverages production systems to evaluate the drain model on\ncounterfactual inventory states induced by RL policies. Preliminary results\ndemonstrate the model's accuracy within the in-distribution setting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u805a\u7126\u4e8e\u9884\u6d4b\u5e93\u5b58\u4ed3\u5e93\u7684\u8d27\u7269\u6d88\u8017\u91cf\u548c\u76f8\u5173\u8fd0\u8f93\u6210\u672c\uff0c\u4e3a\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u63a7\u5236\u7b56\u7565\u63d0\u4f9b\u652f\u6301\u3002\u901a\u8fc7\u5efa\u6a21\u8054\u5408\u5206\u5e03\u5e76\u7ed3\u5408\u9a8c\u8bc1\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5e93\u5b58\u89c4\u5212\u548cRL\u63a7\u5236\u7b56\u7565\u4e2d\u8d27\u7269\u6d88\u8017\u91cf\u548c\u8fd0\u8f93\u6210\u672c\u9884\u6d4b\u7684\u590d\u6742\u6027\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u6a21\u62df\u65b9\u6cd5\uff0c\u4ee5\u66ff\u4ee3\u9ad8\u6210\u672c\u7684\u975e\u53ef\u5fae\u5206\u5185\u90e8\u8f6f\u4ef6\u7cfb\u7edf\u8c03\u7528\u3002", "method": "\u7814\u7a76\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6982\u7387\u9884\u6d4b\u95ee\u9898\uff0c\u5efa\u6a21\u4e86\u8054\u5408\u5206\u5e03\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9a8c\u8bc1\u65b9\u6848\uff0c\u5229\u7528\u751f\u4ea7\u7cfb\u7edf\u8bc4\u4f30RL\u7b56\u7565\u5f15\u8d77\u7684\u53cd\u4e8b\u5b9e\u5e93\u5b58\u72b6\u6001\u4e0b\u7684\u6a21\u578b\u8868\u73b0\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e0b\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u9a8c\u8bc1\u65b9\u6848\u4e3a\u5e93\u5b58\u89c4\u5212\u548cRL\u63a7\u5236\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u5de5\u5177\u3002", "keywords": "\u5e93\u5b58\u89c4\u5212, \u5f3a\u5316\u5b66\u4e60, \u6982\u7387\u9884\u6d4b, \u8fd0\u8f93\u6210\u672c, \u53cd\u4e8b\u5b9e\u9a8c\u8bc1"}}
{"id": "2507.11508", "pdf": "https://arxiv.org/pdf/2507.11508", "abs": "https://arxiv.org/abs/2507.11508", "authors": ["Patr\u00edcia Schmidtov\u00e1", "Ond\u0159ej Du\u0161ek", "Saad Mahamood"], "title": "Real-World Summarization: When Evaluation Reaches Its Limits", "categories": ["cs.CL"], "comment": null, "summary": "We examine evaluation of faithfulness to input data in the context of hotel\nhighlights: brief LLM-generated summaries that capture unique features of\naccommodations. Through human evaluation campaigns involving categorical error\nassessment and span-level annotation, we compare traditional metrics, trainable\nmethods, and LLM-as-a-judge approaches. Our findings reveal that simpler\nmetrics like word overlap correlate surprisingly well with human judgments\n(Spearman correlation rank of 0.63), often outperforming more complex methods\nwhen applied to out-of-domain data. We further demonstrate that while LLMs can\ngenerate high-quality highlights, they prove unreliable for evaluation as they\ntend to severely under- or over-annotate. Our analysis of real-world business\nimpacts shows incorrect and non-checkable information pose the greatest risks.\nWe also highlight challenges in crowdsourced evaluations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86LLM\u751f\u6210\u7684\u9152\u5e97\u4eae\u70b9\u6458\u8981\u5982\u4f55\u5fe0\u5b9e\u4e8e\u8f93\u5165\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\u6bd4\u8f83\u4e86\u4f20\u7edf\u6307\u6807\u3001\u53ef\u8bad\u7ec3\u65b9\u6cd5\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u5de5\u5177\u7684\u6548\u679c\u3002", "motivation": "\u63a2\u8ba8LLM\u751f\u6210\u7684\u6458\u8981\u662f\u5426\u5fe0\u5b9e\u4e8e\u8f93\u5165\u6570\u636e\uff0c\u4ee5\u53ca\u4e0d\u540c\u8bc4\u4ef7\u65b9\u6cd5\u7684\u6548\u679c\u3002", "method": "\u901a\u8fc7\u4eba\u5de5\u8bc4\u4f30\uff08\u5206\u7c7b\u9519\u8bef\u8bc4\u4f30\u548c\u7247\u6bb5\u7ea7\u6807\u6ce8\uff09\u6bd4\u8f83\u4f20\u7edf\u6307\u6807\u3001\u53ef\u8bad\u7ec3\u65b9\u6cd5\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u5de5\u5177\u3002", "result": "\u7b80\u5355\u6307\u6807\uff08\u5982\u8bcd\u91cd\u53e0\uff09\u4e0e\u4eba\u7c7b\u5224\u65ad\u76f8\u5173\u6027\u9ad8\uff08Spearman\u76f8\u5173\u79e90.63\uff09\uff0cLLM\u5728\u8bc4\u4f30\u4e2d\u4e0d\u53ef\u9760\uff0c\u6613\u9ad8\u4f30\u6216\u4f4e\u4f30\u9519\u8bef\u3002", "conclusion": "LLM\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u6458\u8981\uff0c\u4f46\u4e0d\u9002\u5408\u8bc4\u4f30\uff1b\u4e0d\u6b63\u786e\u548c\u4e0d\u53ef\u9a8c\u8bc1\u7684\u4fe1\u606f\u98ce\u9669\u6700\u9ad8\u3002", "keywords": "LLM, \u6458\u8981, \u5fe0\u5b9e\u6027, \u8bc4\u4f30, \u4eba\u5de5\u6807\u6ce8"}}
{"id": "2507.10578", "pdf": "https://arxiv.org/pdf/2507.10578", "abs": "https://arxiv.org/abs/2507.10578", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "title": "When and Where do Data Poisons Attack Textual Inversion?", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted to ICCV", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u6269\u6563\u6a21\u578b\uff08DMs\uff09\u4e2d\u9488\u5bf9\u6587\u672c\u53cd\u8f6c\uff08TI\uff09\u7684\u6295\u6bd2\u653b\u51fb\u884c\u4e3a\uff0c\u63d0\u51fa\u4e86\u65b0\u65b9\u6cd5Semantic Sensitivity Maps\u53ef\u89c6\u5316\u653b\u51fb\u5f71\u54cd\uff0c\u63ed\u793a\u4e86DMs\u5728\u65f6\u95f4\u6b65\u4e0a\u7684\u4e0d\u5747\u5300\u5b66\u4e60\u7279\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSafe-Zone Training\uff08SZT\uff09\u7684\u65b0\u578b\u9632\u5fa1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86TI\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u7814\u7a76\u6269\u6563\u6a21\u578b\u5728\u6587\u672c\u53cd\u8f6c\u8fc7\u7a0b\u4e2d\u5bf9\u6295\u6bd2\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u4ee5\u63d0\u5347\u5176\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165Semantic Sensitivity Maps\u53ef\u89c6\u5316\u653b\u51fb\u5f71\u54cd\uff0c\u63d0\u51faSafe-Zone Training\uff08SZT\uff09\u9632\u5fa1\u673a\u5236\uff0c\u5305\u62ecJPEG\u538b\u7f29\u3001\u9650\u5236\u9ad8\u65f6\u95f4\u6b65\u8bad\u7ec3\u548c\u635f\u5931\u63a9\u7801\u3002", "result": "SZT\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5bf9\u6295\u6bd2\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u751f\u6210\u8d28\u91cf\u4f18\u4e8e\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7SZT\uff0c\u53ef\u4ee5\u6709\u6548\u9632\u5fa1\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6295\u6bd2\u653b\u51fb\uff0c\u63d0\u5347\u5176\u5b89\u5168\u6027\u548c\u751f\u6210\u6548\u679c\u3002", "keywords": "\u6295\u6bd2\u653b\u51fb,\u6269\u6563\u6a21\u578b,\u6587\u672c\u53cd\u8f6c,Safe-Zone Training,\u9632\u5fa1\u673a\u5236,\u9c81\u68d2\u6027"}}
{"id": "2507.10904", "pdf": "https://arxiv.org/pdf/2507.10904", "abs": "https://arxiv.org/abs/2507.10904", "authors": ["Elisa Tsai", "Haizhong Zheng", "Atul Prakash"], "title": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted to the ICCV 2025 Workshop on Curated\n  Data for Efficient Learning (CDEL)", "summary": "High-quality training data is essential for building reliable and efficient\nmachine learning systems. One-shot coreset selection addresses this by pruning\nthe dataset while maintaining or even improving model performance, often\nrelying on training-dynamics-based data difficulty scores. However, most\nexisting methods implicitly assume class-wise homogeneity in data difficulty,\noverlooking variation in data difficulty across different classes.\n  In this work, we challenge this assumption by showing that, in domains such\nas network intrusion detection and medical imaging, data difficulty often\nclusters by class. We formalize this as class-difficulty separability and\nintroduce the Class Difficulty Separability Coefficient (CDSC) as a\nquantitative measure. We demonstrate that high CDSC values correlate with\nperformance degradation in class-agnostic coreset methods, which tend to\noverrepresent easy majority classes while neglecting rare but informative ones.\n  To address this, we introduce class-proportional variants of multiple\nsampling strategies. Evaluated on five diverse datasets spanning security and\nmedical domains, our methods consistently achieve state-of-the-art data\nefficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a\nclass-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows\nremarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and\nrecall 0.19%. In contrast, the class-agnostic CCS baseline, the next best\nmethod, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and\n4.11% in recall.\n  We further show that aggressive pruning enhances generalization in noisy,\nimbalanced, and large-scale datasets. Our results underscore that explicitly\nmodeling class-difficulty separability leads to more effective, robust, and\ngeneralizable data pruning, particularly in high-stakes scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7c7b\u522b\u96be\u5ea6\u53ef\u5206\u6027\u7684\u6570\u636e\u4fee\u526a\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u7c7b\u522b\u95f4\u6570\u636e\u96be\u5ea6\u5dee\u5f02\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u7c7b\u522b\u6bd4\u4f8b\u8c03\u6574\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u6837\u672c\u6838\u5fc3\u96c6\u9009\u62e9\u65b9\u6cd5\u5047\u8bbe\u6570\u636e\u5728\u7c7b\u522b\u95f4\u96be\u5ea6\u662f\u540c\u8d28\u7684\uff0c\u4f46\u5b9e\u9645\u4e0a\u8bb8\u591a\u9886\u57df\uff08\u5982\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u548c\u533b\u5b66\u5f71\u50cf\uff09\u4e2d\u6570\u636e\u96be\u5ea6\u5f80\u5f80\u6309\u7c7b\u522b\u805a\u7c7b\uff0c\u5bfc\u81f4\u4f20\u7edf\u65b9\u6cd5\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u7c7b\u522b\u96be\u5ea6\u53ef\u5206\u6027\u7cfb\u6570\uff08CDSC\uff09\u4f5c\u4e3a\u91cf\u5316\u6307\u6807\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7c7b\u522b\u6bd4\u4f8b\u8c03\u6574\u7684\u591a\u79cd\u91c7\u6837\u7b56\u7565\uff08\u5982CCS-CP\uff09\u3002", "result": "\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u6781\u7aef\u7684\u4fee\u526a\u7387\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u4f8b\u5982\u572899%\u4fee\u526a\u7387\u4e0b\uff0cCCS-CP\u7684\u7cbe\u5ea6\u4ec5\u4e0b\u964d0.49%\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u7c7b\u522b\u96be\u5ea6\u53ef\u5206\u6027\u80fd\u663e\u8457\u63d0\u5347\u6570\u636e\u4fee\u526a\u7684\u6548\u679c\uff0c\u5c24\u5176\u5728\u566a\u58f0\u5927\u3001\u4e0d\u5e73\u8861\u6216\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u66f4\u4f73\u3002", "keywords": "\u4e00\u7c7b\u6837\u672c\u6838\u5fc3\u96c6\u3001\u6570\u636e\u96be\u5ea6\u3001\u7c7b\u522b\u53ef\u5206\u6027\u3001\u6570\u636e\u4fee\u526a\u3001\u673a\u5668\u5b66\u4e60"}}
{"id": "2507.10579", "pdf": "https://arxiv.org/pdf/2507.10579", "abs": "https://arxiv.org/abs/2507.10579", "authors": ["Ekaterina Kochmar", "Kaushal Kumar Maurya", "Kseniia Petukhova", "KV Aditya Srivatsa", "Ana\u00efs Tack", "Justin Vasselli"], "title": "Findings of the BEA 2025 Shared Task on Pedagogical Ability Assessment of AI-powered Tutors", "categories": ["cs.CY", "cs.AI", "cs.CL"], "comment": "Proceedings of the 20th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "summary": "This shared task has aimed to assess pedagogical abilities of AI tutors\npowered by large language models (LLMs), focusing on evaluating the quality of\ntutor responses aimed at student's mistake remediation within educational\ndialogues. The task consisted of five tracks designed to automatically evaluate\nthe AI tutor's performance across key dimensions of mistake identification,\nprecise location of the mistake, providing guidance, and feedback\nactionability, grounded in learning science principles that define good and\neffective tutor responses, as well as the track focusing on detection of the\ntutor identity. The task attracted over 50 international teams across all\ntracks. The submitted models were evaluated against gold-standard human\nannotations, and the results, while promising, show that there is still\nsignificant room for improvement in this domain: the best results for the four\npedagogical ability assessment tracks range between macro F1 scores of 58.34\n(for providing guidance) and 71.81 (for mistake identification) on three-class\nproblems, with the best F1 score in the tutor identification track reaching\n96.98 on a 9-class task. In this paper, we overview the main findings of the\nshared task, discuss the approaches taken by the teams, and analyze their\nperformance. All resources associated with this task are made publicly\navailable to support future research in this critical domain.", "AI": {"tldr": "\u8be5\u8bba\u6587\u603b\u7ed3\u4e86\u4e00\u4e2a\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684AI\u5bfc\u5e08\u6559\u5b66\u80fd\u529b\u7684\u5171\u4eab\u4efb\u52a1\uff0c\u91cd\u70b9\u5173\u6ce8\u5176\u5bf9\u5b66\u751f\u9519\u8bef\u4fee\u6b63\u7684\u54cd\u5e94\u8d28\u91cf\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u591a\u7ef4\u5ea6\u8bc4\u4f30AI\u5bfc\u5e08\u7684\u6559\u5b66\u80fd\u529b\uff0c\u63a8\u52a8\u5176\u5728\u5b9e\u9645\u6559\u80b2\u4e2d\u7684\u6709\u6548\u6027\u63d0\u5347\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u4efb\u52a1\u8f68\u9053\uff0c\u6db5\u76d6\u9519\u8bef\u8bc6\u522b\u3001\u5b9a\u4f4d\u3001\u6307\u5bfc\u63d0\u4f9b\u548c\u53cd\u9988\u53ef\u64cd\u4f5c\u6027\u7b49\u7ef4\u5ea6\uff0c\u5e76\u4f7f\u7528\u4eba\u7c7b\u6807\u6ce8\u7684\u91d1\u6807\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728\u5404\u4efb\u52a1\u8f68\u9053\u4e0a\u7684\u5b8fF1\u5206\u6570\u4ece58.34\u523071.81\u4e0d\u7b49\uff0c\u5bfc\u5e08\u8eab\u4efd\u8bc6\u522b\u4efb\u52a1\u7684F1\u5206\u6570\u8fbe96.98\uff0c\u663e\u793a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u8d44\u6e90\u516c\u5f00\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\uff0cAI\u5bfc\u5e08\u7684\u6559\u5b66\u80fd\u529b\u867d\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "keywords": "AI\u5bfc\u5e08, \u5927\u8bed\u8a00\u6a21\u578b, \u6559\u5b66\u80fd\u529b\u8bc4\u4f30, \u5171\u4eab\u4efb\u52a1"}}
{"id": "2507.10955", "pdf": "https://arxiv.org/pdf/2507.10955", "abs": "https://arxiv.org/abs/2507.10955", "authors": ["Chi-en Amy Tai", "Alexander Wong"], "title": "Diffusion Decoding for Peptide De Novo Sequencing", "categories": ["cs.LG"], "comment": null, "summary": "Peptide de novo sequencing is a method used to reconstruct amino acid\nsequences from tandem mass spectrometry data without relying on existing\nprotein sequence databases. Traditional deep learning approaches, such as\nCasanovo, mainly utilize autoregressive decoders and predict amino acids\nsequentially. Subsequently, they encounter cascading errors and fail to\nleverage high-confidence regions effectively. To address these issues, this\npaper investigates using diffusion decoders adapted for the discrete data\ndomain. These decoders provide a different approach, allowing sequence\ngeneration to start from any peptide segment, thereby enhancing prediction\naccuracy. We experiment with three different diffusion decoder designs,\nknapsack beam search, and various loss functions. We find knapsack beam search\ndid not improve performance metrics and simply replacing the transformer\ndecoder with a diffusion decoder lowered performance. Although peptide\nprecision and recall were still 0, the best diffusion decoder design with the\nDINOISER loss function obtained a statistically significant improvement in\namino acid recall by 0.373 compared to the baseline autoregressive\ndecoder-based Casanovo model. These findings highlight the potential of\ndiffusion decoders to not only enhance model sensitivity but also drive\nsignificant advancements in peptide de novo sequencing.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u4f7f\u7528\u6269\u6563\u89e3\u7801\u5668\u6539\u8fdb\u80bd\u6bb5\u4ece\u5934\u6d4b\u5e8f\u7684\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u81ea\u56de\u5f52\u89e3\u7801\u5668\uff0c\u6269\u6563\u89e3\u7801\u5668\u901a\u8fc7\u4ece\u4efb\u610f\u80bd\u6bb5\u5f00\u59cb\u751f\u6210\u5e8f\u5217\uff0c\u63d0\u9ad8\u4e86\u6c28\u57fa\u9178\u53ec\u56de\u7387\u3002", "motivation": "\u4f20\u7edf\u81ea\u56de\u5f52\u89e3\u7801\u5668\u5728\u80bd\u6bb5\u6d4b\u5e8f\u4e2d\u5b58\u5728\u7ea7\u8054\u9519\u8bef\u548c\u672a\u80fd\u6709\u6548\u5229\u7528\u9ad8\u7f6e\u4fe1\u533a\u57df\u7684\u5c40\u9650\u6027\uff0c\u6269\u6563\u89e3\u7801\u5668\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "method": "\u8bba\u6587\u5c1d\u8bd5\u4e86\u4e09\u79cd\u6269\u6563\u89e3\u7801\u5668\u8bbe\u8ba1\u3001\u80cc\u5305\u675f\u641c\u7d22\u548c\u591a\u79cd\u635f\u5931\u51fd\u6570\uff0c\u5176\u4e2d\u5305\u62ecDINOISER\u635f\u5931\u51fd\u6570\u3002", "result": "\u867d\u7136\u80bd\u6bb5\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4ecd\u4e3a0\uff0c\u4f46\u6700\u4f73\u6269\u6563\u89e3\u7801\u5668\u8bbe\u8ba1\u5728\u6c28\u57fa\u9178\u53ec\u56de\u7387\u4e0a\u6bd4\u81ea\u56de\u5f52\u89e3\u7801\u5668\u57fa\u7ebf\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e860.373\u3002", "conclusion": "\u6269\u6563\u89e3\u7801\u5668\u4e0d\u4ec5\u589e\u5f3a\u4e86\u6a21\u578b\u654f\u611f\u6027\uff0c\u8fd8\u4e3a\u80bd\u6bb5\u4ece\u5934\u6d4b\u5e8f\u6280\u672f\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002", "keywords": "\u80bd\u6bb5\u4ece\u5934\u6d4b\u5e8f\u3001\u6269\u6563\u89e3\u7801\u5668\u3001DINOISER\u3001\u81ea\u56de\u5f52\u89e3\u7801\u5668\u3001\u6c28\u57fa\u9178\u53ec\u56de\u7387"}}
{"id": "2507.10983", "pdf": "https://arxiv.org/pdf/2507.10983", "abs": "https://arxiv.org/abs/2507.10983", "authors": ["Tao Han", "Zahra Taheri", "Hyunwoong Ko"], "title": "Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review", "categories": ["cs.LG"], "comment": "11 pages, 1 figure, 3 tables, IDETC-CIE 2025", "summary": "Semiconductor manufacturing relies heavily on film deposition processes, such\nas Chemical Vapor Deposition and Physical Vapor Deposition. These complex\nprocesses require precise control to achieve film uniformity, proper adhesion,\nand desired functionality. Recent advancements in Physics-Informed Neural\nNetworks (PINNs), an innovative machine learning (ML) approach, have shown\nsignificant promise in addressing challenges related to process control,\nquality assurance, and predictive modeling within semiconductor film deposition\nand other manufacturing domains. This paper provides a comprehensive review of\nML applications targeted at semiconductor film deposition processes. Through a\nthematic analysis, we identify key trends, existing limitations, and research\ngaps, offering insights into both the advantages and constraints of current\nmethodologies. Our structured analysis aims to highlight the potential\nintegration of these ML techniques to enhance interpretability, accuracy, and\nrobustness in film deposition processes. Additionally, we examine\nstate-of-the-art PINN methods, discussing strategies for embedding physical\nknowledge, governing laws, and partial differential equations into advanced\nneural network architectures tailored for semiconductor manufacturing. Based on\nthis detailed review, we propose novel research directions that integrate the\nstrengths of PINNs to significantly advance film deposition processes. The\ncontributions of this study include establishing a clear pathway for future\nresearch in integrating physics-informed ML frameworks, addressing existing\nmethodological gaps, and ultimately improving precision, scalability, and\noperational efficiency within semiconductor manufacturing.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u7684\u7cbe\u786e\u63a7\u5236\u5bf9\u8584\u819c\u5747\u5300\u6027\u3001\u7c98\u9644\u6027\u548c\u529f\u80fd\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u6311\u6218\u3002", "method": "\u901a\u8fc7\u4e3b\u9898\u5206\u6790\uff0c\u8bc6\u522b\u8d8b\u52bf\u3001\u5c40\u9650\u6027\u548c\u7814\u7a76\u7a7a\u767d\uff0c\u63a2\u8ba8PINNs\u5982\u4f55\u5d4c\u5165\u7269\u7406\u77e5\u8bc6\u4ee5\u63d0\u9ad8ML\u7684\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0PINNs\u5728\u589e\u5f3a\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u7684\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u4e3a\u672a\u6765\u7814\u7a76\u6307\u51fa\u4e86\u6574\u5408PINNs\u7684\u6e05\u6670\u8def\u5f84\uff0c\u65e8\u5728\u63d0\u5347\u534a\u5bfc\u4f53\u5236\u9020\u7684\u7cbe\u786e\u6027\u548c\u6548\u7387\u3002", "keywords": "\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef, \u673a\u5668\u5b66\u4e60, \u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc, \u8fc7\u7a0b\u63a7\u5236"}}
{"id": "2507.10986", "pdf": "https://arxiv.org/pdf/2507.10986", "abs": "https://arxiv.org/abs/2507.10986", "authors": ["Tianyu Su", "Zhiqiang Zou", "Ali Luo", "Xiao Kong", "Qingyu Lu", "Min Li"], "title": "StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data", "categories": ["cs.LG"], "comment": null, "summary": "Stellar flare forecasting, a critical research frontier in astronomy, offers\nprofound insights into stellar activity. However, the field is constrained by\nboth the sparsity of recorded flare events and the absence of domain-specific\nlarge-scale predictive models. To address these challenges, this study\nintroduces StellarF (Stellar Flare Forecasting), a novel large model that\nleverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient\nlearning for stellar flare forecasting. At its core, StellarF integrates an\nflare statistical information module with a historical flare record module,\nenabling multi-scale pattern recognition from observational data. Extensive\nexperiments on our self-constructed datasets (derived from Kepler and TESS\nlight curves) demonstrate that StellarF achieves state-of-the-art performance\ncompared to existing methods. The proposed prediction paradigm establishes a\nnovel methodological framework for advancing astrophysical research and\ncross-disciplinary applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86StellarF\u6a21\u578b\uff0c\u5229\u7528LoRA\u548cAdapter\u6280\u672f\u8fdb\u884c\u9ad8\u6548\u7684\u6052\u661f\u8000\u6591\u9884\u6d4b\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u6a21\u5f0f\u8bc6\u522b\uff0c\u5728\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u6052\u661f\u8000\u6591\u9884\u6d4b\u662f\u5929\u6587\u5b66\u7684\u91cd\u8981\u7814\u7a76\u9886\u57df\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u89c2\u6d4b\u6570\u636e\u7a00\u5c11\u548c\u7f3a\u4e4f\u5927\u89c4\u6a21\u9884\u6d4b\u6a21\u578b\u3002", "method": "StellarF\u7ed3\u5408LoRA\u548cAdapter\u6280\u672f\uff0c\u96c6\u6210\u4e86\u8000\u6591\u7edf\u8ba1\u4fe1\u606f\u548c\u5386\u53f2\u8bb0\u5f55\u6a21\u5757\uff0c\u5b9e\u73b0\u591a\u5c3a\u5ea6\u6a21\u5f0f\u8bc6\u522b\u3002", "result": "\u5728Kepler\u548cTESS\u5149\u53d8\u66f2\u7ebf\u6570\u636e\u4e0a\uff0cStellarF\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "StellarF\u4e3a\u5929\u4f53\u7269\u7406\u7814\u7a76\u548c\u8de8\u5b66\u79d1\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u8bba\u6846\u67b6\u3002", "keywords": "\u6052\u661f\u8000\u6591\u9884\u6d4b, LoRA, Adapter, \u591a\u5c3a\u5ea6\u6a21\u5f0f\u8bc6\u522b, \u5929\u4f53\u7269\u7406"}}
{"id": "2507.10583", "pdf": "https://arxiv.org/pdf/2507.10583", "abs": "https://arxiv.org/abs/2507.10583", "authors": ["Daniil Orel", "Indraneil Paul", "Iryna Gurevych", "Preslav Nakov"], "title": "$\\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection", "categories": ["cs.SE", "cs.AI", "cs.CY"], "comment": null, "summary": "In this work, we compile $\\textbf{$\\texttt{DroidCollection}$}$, the most\nextensive open data suite for training and evaluating machine-generated code\ndetectors, comprising over a million code samples, seven programming languages,\noutputs from 43 coding models, and over three real-world coding domains.\nAlongside fully AI-generated samples, our collection includes human-AI\nco-authored code, as well as adversarial samples explicitly crafted to evade\ndetection. Subsequently, we develop $\\textbf{$\\texttt{DroidDetect}$}$, a suite\nof encoder-only detectors trained using a multi-task objective over\n$\\texttt{DroidCollection}$. Our experiments show that existing detectors'\nperformance fails to generalise to diverse coding domains and programming\nlanguages outside of their narrow training data. Additionally, we demonstrate\nthat while most detectors are easily compromised by humanising the output\ndistributions using superficial prompting and alignment approaches, this\nproblem can be easily amended by training on a small amount of adversarial\ndata. Finally, we demonstrate the effectiveness of metric learning and\nuncertainty-based resampling as means to enhance detector training on possibly\nnoisy distributions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u6700\u5927\u7684\u5f00\u6e90\u6570\u636e\u96c6DroidCollection\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u673a\u5668\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u5668\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u4efb\u52a1\u76ee\u6807\u7684\u68c0\u6d4b\u5668DroidDetect\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u68c0\u6d4b\u5668\u5728\u591a\u6837\u7f16\u7a0b\u8bed\u8a00\u548c\u9886\u57df\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u5bb9\u6613\u88ab\u5bf9\u6297\u6027\u653b\u51fb\u7834\u574f\uff0c\u4f46\u901a\u8fc7\u5c11\u91cf\u5bf9\u6297\u6570\u636e\u8bad\u7ec3\u53ef\u6539\u5584\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u5668\u5728\u591a\u6837\u7f16\u7a0b\u8bed\u8a00\u548c\u771f\u5b9e\u9886\u57df\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u5bb9\u6613\u88ab\u5bf9\u6297\u6027\u653b\u51fb\u7834\u574f\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u68c0\u6d4b\u5668\u3002", "method": "1. \u6784\u5efaDroidCollection\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u3001\u6a21\u578b\u8f93\u51fa\u548c\u771f\u5b9e\u9886\u57df\u4ee3\u7801\uff1b2. \u5f00\u53d1\u57fa\u4e8e\u591a\u4efb\u52a1\u76ee\u6807\u7684\u68c0\u6d4b\u5668DroidDetect\uff1b3. \u63a2\u7d22\u5bf9\u6297\u8bad\u7ec3\u3001\u5ea6\u91cf\u5b66\u4e60\u548c\u4e0d\u786e\u5b9a\u6027\u91cd\u91c7\u6837\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "result": "\u73b0\u6709\u68c0\u6d4b\u5668\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4f46DroidDetect\u901a\u8fc7\u5bf9\u6297\u6570\u636e\u548c\u65b0\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5168\u9762\u6570\u636e\u96c6\u548c\u591a\u4efb\u52a1\u8bad\u7ec3\uff0c\u53ef\u663e\u8457\u63d0\u5347\u673a\u5668\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u5668\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "keywords": "\u673a\u5668\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u3001\u6570\u636e\u96c6\u3001\u5bf9\u6297\u8bad\u7ec3\u3001\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u5ea6\u91cf\u5b66\u4e60"}}
{"id": "2507.10990", "pdf": "https://arxiv.org/pdf/2507.10990", "abs": "https://arxiv.org/abs/2507.10990", "authors": ["Rodney Lafuente-Mercado"], "title": "High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Scaling reinforcement learning (RL) workloads often requires distributing\nenvironment simulation across compute clusters. Existing frameworks entangle\nsimulation, learning logic, and orchestration into monolithic systems, limiting\nmodularity and reusability. We present ClusterEnv, a lightweight,\nlearner-agnostic interface for distributed environment execution that mirrors\nthe Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples\nsimulation from training by offloading reset() and step() operations to remote\nworkers while keeping learning centralized. To address policy staleness in\ndistributed execution, we propose Adaptive Actor Policy Synchronization (AAPS),\na divergence-triggered update mechanism that reduces synchronization overhead\nwithout sacrificing performance. ClusterEnv integrates cleanly into existing RL\npipelines, supports both on-policy and off-policy methods, and requires minimal\ncode changes. Experiments on discrete control tasks demonstrate that AAPS\nachieves high sample efficiency with significantly fewer weight updates. Source\ncode is available at https://github.com/rodlaf/ClusterEnv.", "AI": {"tldr": "ClusterEnv\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u5206\u5e03\u5f0f\u73af\u5883\u6267\u884c\u63a5\u53e3\uff0c\u91c7\u7528DETACH\u6a21\u5f0f\u89e3\u8026\u6a21\u62df\u4e0e\u8bad\u7ec3\uff0c\u5e76\u63d0\u51faAAPS\u673a\u5236\u4ee5\u51cf\u5c11\u540c\u6b65\u5f00\u9500\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709RL\u6846\u67b6\u5728\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7ClusterEnv\u63a5\u53e3\u548cDETACH\u6a21\u5f0f\u5b9e\u73b0\u6a21\u62df\u4e0e\u8bad\u7ec3\u7684\u5206\u79bb\uff0c\u5e76\u5f15\u5165AAPS\u673a\u5236\u4f18\u5316\u540c\u6b65\u3002", "result": "\u5b9e\u9a8c\u663e\u793aAAPS\u5728\u79bb\u6563\u63a7\u5236\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6837\u672c\u6548\u7387\u4e14\u51cf\u5c11\u4e86\u6743\u91cd\u66f4\u65b0\u6b21\u6570\u3002", "conclusion": "ClusterEnv\u63d0\u4f9b\u4e86\u6a21\u5757\u5316\u4e14\u9ad8\u6548\u7684\u5206\u5e03\u5f0fRL\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u5f3a\u5316\u5b66\u4e60,\u5206\u5e03\u5f0f\u73af\u5883,\u6a21\u5757\u5316,AAPS,DETACH"}}
{"id": "2507.10584", "pdf": "https://arxiv.org/pdf/2507.10584", "abs": "https://arxiv.org/abs/2507.10584", "authors": ["Francesco Romeo", "Luigi Arena", "Francesco Blefari", "Francesco Aurelio Pironti", "Matteo Lupinacci", "Angelo Furfaro"], "title": "ARPaCCino: An Agentic-RAG for Policy as Code Compliance", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Policy as Code (PaC) is a paradigm that encodes security and compliance\npolicies into machine-readable formats, enabling automated enforcement in\nInfrastructure as Code (IaC) environments. However, its adoption is hindered by\nthe complexity of policy languages and the risk of misconfigurations. In this\nwork, we present ARPaCCino, an agentic system that combines Large Language\nModels (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation\nto automate the generation and verification of PaC rules. Given natural\nlanguage descriptions of the desired policies, ARPaCCino generates formal Rego\nrules, assesses IaC compliance, and iteratively refines the IaC configurations\nto ensure conformance. Thanks to its modular agentic architecture and\nintegration with external tools and knowledge bases, ARPaCCino supports policy\nvalidation across a wide range of technologies, including niche or emerging IaC\nframeworks. Experimental evaluation involving a Terraform-based case study\ndemonstrates ARPaCCino's effectiveness in generating syntactically and\nsemantically correct policies, identifying non-compliant infrastructures, and\napplying corrective modifications, even when using smaller, open-weight LLMs.\nOur results highlight the potential of agentic RAG architectures to enhance the\nautomation, reliability, and accessibility of PaC workflows.", "AI": {"tldr": "ARPaCCino\u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u5de5\u5177\u9a8c\u8bc1\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u548c\u9a8c\u8bc1\u2018\u653f\u7b56\u5373\u4ee3\u7801\u2019\uff08PaC\uff09\u89c4\u5219\uff0c\u63d0\u5347IaC\u73af\u5883\u4e2d\u7684\u5b89\u5168\u4e0e\u5408\u89c4\u6027\u3002", "motivation": "PaC\u7684\u91c7\u7528\u53d7\u5230\u653f\u7b56\u8bed\u8a00\u590d\u6742\u6027\u548c\u914d\u7f6e\u9519\u8bef\u98ce\u9669\u7684\u963b\u788d\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u7b80\u5316\u653f\u7b56\u751f\u6210\u4e0e\u9a8c\u8bc1\u3002", "method": "ARPaCCino\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u751f\u6210Rego\u89c4\u5219\uff0c\u9a8c\u8bc1IaC\u5408\u89c4\u6027\uff0c\u5e76\u8fed\u4ee3\u4f18\u5316\u914d\u7f6e\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u591a\u79cd\u6280\u672f\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cARPaCCino\u80fd\u751f\u6210\u6b63\u786e\u8bed\u6cd5\u548c\u8bed\u4e49\u7684\u653f\u7b56\uff0c\u8bc6\u522b\u4e0d\u5408\u89c4\u57fa\u7840\u8bbe\u65bd\uff0c\u5e76\u63d0\u51fa\u4fee\u6b63\uff0c\u5373\u4f7f\u4f7f\u7528\u8f83\u5c0f\u7684\u5f00\u6e90LLM\u3002", "conclusion": "ARPaCCino\u8bc1\u660e\u4e86\u4ee3\u7406\u5f0fRAG\u67b6\u6784\u5728\u63d0\u5347PaC\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u3001\u53ef\u9760\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002", "keywords": "Policy as Code, Infrastructure as Code, Large Language Models, Retrieval-Augmented-Generation, compliance"}}
{"id": "2507.10995", "pdf": "https://arxiv.org/pdf/2507.10995", "abs": "https://arxiv.org/abs/2507.10995", "authors": ["Henrik Marklund", "Alex Infanger", "Benjamin Van Roy"], "title": "Misalignment from Treating Means as Ends", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reward functions, learned or manually specified, are rarely perfect. Instead\nof accurately expressing human goals, these reward functions are often\ndistorted by human beliefs about how best to achieve those goals. Specifically,\nthese reward functions often express a combination of the human's terminal\ngoals -- those which are ends in themselves -- and the human's instrumental\ngoals -- those which are means to an end. We formulate a simple example in\nwhich even slight conflation of instrumental and terminal goals results in\nsevere misalignment: optimizing the misspecified reward function results in\npoor performance when measured by the true reward function. This example\ndistills the essential properties of environments that make reinforcement\nlearning highly sensitive to conflation of instrumental and terminal goals. We\ndiscuss how this issue can arise with a common approach to reward learning and\nhow it can manifest in real environments.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5956\u52b1\u51fd\u6570\u4e2d\u7ec8\u7aef\u76ee\u6807\u548c\u5de5\u5177\u6027\u76ee\u6807\u7684\u6df7\u6dc6\u95ee\u9898\uff0c\u6307\u51fa\u8fd9\u79cd\u6df7\u6dc6\u4f1a\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4e25\u91cd\u5bf9\u9f50\u9519\u8bef\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\uff0c\u5956\u52b1\u51fd\u6570\uff08\u65e0\u8bba\u662f\u5b66\u4e60\u5f97\u5230\u7684\u8fd8\u662f\u624b\u52a8\u6307\u5b9a\u7684\uff09\u5f80\u5f80\u4e0d\u5b8c\u7f8e\uff0c\u56e0\u4e3a\u5b83\u4eec\u6df7\u6dc6\u4e86\u4eba\u7c7b\u7684\u7ec8\u7aef\u76ee\u6807\u548c\u5de5\u5177\u6027\u76ee\u6807\uff0c\u5bfc\u81f4\u76ee\u6807\u65e0\u6cd5\u51c6\u786e\u5b9e\u73b0\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u5c55\u793a\u4e86\u5373\u4f7f\u8f7b\u5fae\u7684\u6df7\u6dc6\u4e5f\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86\u73af\u5883\u7279\u6027\u5982\u4f55\u52a0\u5267\u8fd9\u4e00\u95ee\u9898\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4f18\u5316\u9519\u8bef\u7684\u5956\u52b1\u51fd\u6570\u4f1a\u5bfc\u81f4\u5728\u5b9e\u9645\u5956\u52b1\u51fd\u6570\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u8bba\u6587\u6307\u51fa\u4e86\u5956\u52b1\u5b66\u4e60\u4e2d\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "keywords": "\u5956\u52b1\u51fd\u6570\uff0c\u5f3a\u5316\u5b66\u4e60\uff0c\u7ec8\u7aef\u76ee\u6807\uff0c\u5de5\u5177\u6027\u76ee\u6807\uff0c\u5bf9\u9f50\u95ee\u9898"}}
{"id": "2507.10998", "pdf": "https://arxiv.org/pdf/2507.10998", "abs": "https://arxiv.org/abs/2507.10998", "authors": ["Zhipeng He", "Alexander Stevens", "Chun Ouyang", "Johannes De Smedt", "Alistair Barros", "Catarina Moreira"], "title": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "32 pages", "summary": "Adversarial attacks on tabular data present fundamental challenges distinct\nfrom image or text domains due to the heterogeneous nature of mixed categorical\nand numerical features. Unlike images where pixel perturbations maintain visual\nsimilarity, tabular data lacks intuitive similarity metrics, making it\ndifficult to define imperceptible modifications. Additionally, traditional\ngradient-based methods prioritise $\\ell_p$-norm constraints, often producing\nadversarial examples that deviate from the original data distributions, making\nthem detectable. We propose a latent space perturbation framework using a\nmixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial\nexamples. The proposed VAE integrates categorical embeddings and numerical\nfeatures into a unified latent manifold, enabling perturbations that preserve\nstatistical consistency. We specify In-Distribution Success Rate (IDSR) to\nmeasure the proportion of adversarial examples that remain statistically\nindistinguishable from the input distribution. Evaluation across six publicly\navailable datasets and three model architectures demonstrates that our method\nachieves substantially lower outlier rates and more consistent performance\ncompared to traditional input-space attacks and other VAE-based methods adapted\nfrom image domain approaches. Our comprehensive analysis includes\nhyperparameter sensitivity, sparsity control mechanisms, and generative\narchitectural comparisons, revealing that VAE-based attacks depend critically\non reconstruction quality but offer superior practical utility when sufficient\ntraining data is available. This work highlights the importance of on-manifold\nperturbations for realistic adversarial attacks on tabular data, offering a\nrobust approach for practical deployment. The source code can be accessed\nthrough https://github.com/ZhipengHe/VAE-TabAttack.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u8f93\u5165\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u6f5c\u5728\u7a7a\u95f4\u6270\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u4e0d\u53ef\u5bdf\u89c9\u7684\u5bf9\u6297\u6837\u672c\uff0c\u89e3\u51b3\u4e86\u8868\u683c\u6570\u636e\u4e2d\u7531\u4e8e\u5f02\u6784\u7279\u5f81\u5bfc\u81f4\u7684\u5bf9\u6297\u653b\u51fb\u96be\u9898\u3002", "motivation": "\u8868\u683c\u6570\u636e\u7684\u5f02\u8d28\u6027\uff08\u6df7\u5408\u5206\u7c7b\u548c\u6570\u503c\u7279\u5f81\uff09\u4f7f\u5f97\u5bf9\u6297\u653b\u51fb\u7684\u5b9a\u4e49\u548c\u751f\u6210\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u4f20\u7edf\u68af\u5ea6\u65b9\u6cd5\u53ef\u80fd\u751f\u6210\u504f\u79bb\u539f\u59cb\u6570\u636e\u5206\u5e03\u7684\u5bf9\u6297\u6837\u672c\u3002", "method": "\u901a\u8fc7\u6df7\u5408\u8f93\u5165VAE\u5c06\u5206\u7c7b\u5d4c\u5165\u548c\u6570\u503c\u7279\u5f81\u7edf\u4e00\u5230\u4e00\u4e2a\u6f5c\u5728\u7684\u6d41\u5f62\u4e2d\uff0c\u751f\u6210\u4fdd\u6301\u7edf\u8ba1\u4e00\u81f4\u6027\u7684\u5bf9\u6297\u6270\u52a8\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e09\u79cd\u6a21\u578b\u67b6\u6784\u4e0a\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u79bb\u7fa4\u7387\u548c\u66f4\u4e00\u81f4\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u5176\u4f18\u4e8e\u4f20\u7edf\u8f93\u5165\u7a7a\u95f4\u653b\u51fb\u548c\u5176\u4ed6VAE\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eVAE\u7684\u6f5c\u5728\u7a7a\u95f4\u6270\u52a8\u662f\u751f\u6210\u73b0\u5b9e\u5bf9\u6297\u653b\u51fb\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u6d41\u5f62\u6270\u52a8\u5728\u8868\u683c\u6570\u636e\u4e2d\u7684\u91cd\u8981\u6027\u3002", "keywords": "\u5bf9\u6297\u653b\u51fb, \u53d8\u5206\u81ea\u7f16\u7801\u5668, \u8868\u683c\u6570\u636e, \u6f5c\u5728\u7a7a\u95f4, \u7edf\u8ba1\u4e00\u81f4\u6027"}}
{"id": "2507.10773", "pdf": "https://arxiv.org/pdf/2507.10773", "abs": "https://arxiv.org/abs/2507.10773", "authors": ["Samuel Rhys Cox"], "title": "Theory of Mind and Self-Disclosure to CUIs", "categories": ["cs.HC", "cs.CL"], "comment": "Workshop paper presented at ToMinHAI at CUI'2025: Theory of Mind in\n  Human-CUI Interaction, held in conjunction with the 2025 ACM conference on\n  Conversational User Interfaces, July 8th, 2025. 4 pages. 3 figures", "summary": "Self-disclosure is important to help us feel better, yet is often difficult.\nThis difficulty can arise from how we think people are going to react to our\nself-disclosure. In this workshop paper, we briefly discuss self-disclosure to\nconversational user interfaces (CUIs) in relation to various social cues. We\nthen, discuss how expressions of uncertainty or representation of a CUI's\nreasoning could help encourage self-disclosure, by making a CUI's intended\n\"theory of mind\" more transparent to users.", "AI": {"tldr": "\u63a2\u8ba8\u4e86\u5728\u5bf9\u8bdd\u7528\u6237\u754c\u9762(CUIs)\u4e2d\u5982\u4f55\u901a\u8fc7\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u6216\u900f\u660e\u5316\u63a8\u7406\u6765\u4fc3\u8fdb\u81ea\u6211\u62ab\u9732\u3002", "motivation": "\u81ea\u6211\u62ab\u9732\u5bf9\u5fc3\u7406\u5065\u5eb7\u6709\u76ca\uff0c\u4f46\u5e38\u56e0\u62c5\u5fc3\u4ed6\u4eba\u53cd\u5e94\u800c\u96be\u4ee5\u5b9e\u73b0\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22CUIs\u4e2d\u5982\u4f55\u901a\u8fc7\u793e\u4ea4\u7ebf\u7d22\u9f13\u52b1\u81ea\u6211\u62ab\u9732\u3002", "method": "\u5206\u6790\u4e86CUIs\u4e2d\u7684\u793e\u4ea4\u7ebf\u7d22\uff0c\u7279\u522b\u662f\u8868\u8fbe\u4e0d\u786e\u5b9a\u6027\u548c\u900f\u660e\u5316\u63a8\u7406\u5bf9\u7528\u6237\u81ea\u6211\u62ab\u9732\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u8ba9CUI\u7684\u601d\u7ef4\u65b9\u5f0f\u66f4\u900f\u660e\uff0c\u53ef\u4ee5\u589e\u5f3a\u7528\u6237\u7684\u81ea\u6211\u62ab\u9732\u610f\u613f\u3002", "conclusion": "\u900f\u660e\u5316CUI\u7684\u201c\u5fc3\u667a\u7406\u8bba\u201d\u6709\u52a9\u4e8e\u7f13\u89e3\u7528\u6237\u7684\u7126\u8651\uff0c\u4fc3\u8fdb\u81ea\u6211\u62ab\u9732\u3002", "keywords": "\u81ea\u6211\u62ab\u9732, \u5bf9\u8bdd\u7528\u6237\u754c\u9762, \u793e\u4ea4\u7ebf\u7d22, \u4e0d\u786e\u5b9a\u6027, \u5fc3\u667a\u7406\u8bba"}}
{"id": "2507.11005", "pdf": "https://arxiv.org/pdf/2507.11005", "abs": "https://arxiv.org/abs/2507.11005", "authors": ["Chongjie Si", "Debing Zhang", "Wei Shen"], "title": "AdaMuon: Adaptive Muon Optimizer", "categories": ["cs.LG"], "comment": null, "summary": "We propose AdaMuon, an adaptive learning-rate framework built upon the\nrecently validated Muon optimizer, which has demonstrated substantial\nefficiency gains over AdamW in large-scale model training. AdaMuon augments\nMuon with two mutually dependent modules: (1) a per-parameter second-moment\nmodulation that captures orthogonal gradient updates to ensure update-level\nadaptivity, and (2) a RMS-aligned rescaling that regulates the overall update\nmagnitude by aligning it with the intrinsic structure of the parameter space.\nEmpirical results on multiple model scales and learning-rate regimes confirm\nthat AdaMuon consistently outperforms the original Muon, delivering higher\nacceleration in convergence while maintaining training stability. Our method\nintroduces no additional tuning burden and can be seamlessly integrated into\nexisting Muon training pipelines.", "AI": {"tldr": "AdaMuon\u662f\u4e00\u79cd\u57fa\u4e8eMuon\u4f18\u5316\u5668\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u4e2a\u6a21\u5757\u63d0\u5347\u6548\u7387\uff0c\u9a8c\u8bc1\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u539f\u59cbMuon\u4e14\u6613\u4e8e\u96c6\u6210\u3002", "motivation": "\u901a\u8fc7\u6539\u8fdbMuon\u4f18\u5316\u5668\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "1) \u53c2\u6570\u7ea7\u7b2c\u4e8c\u77e9\u8c03\u5236\uff0c\u6355\u6349\u6b63\u4ea4\u68af\u5ea6\u66f4\u65b0\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\uff1b2) RMS\u5bf9\u9f50\u7684\u91cd\u7f29\u653e\uff0c\u8c03\u8282\u6574\u4f53\u66f4\u65b0\u5e45\u5ea6\u3002", "result": "\u5728\u591a\u6a21\u578b\u89c4\u6a21\u548c\u5b66\u4e60\u7387\u4e0b\uff0cAdaMuon\u6027\u80fd\u4f18\u4e8e\u539f\u59cbMuon\uff0c\u6536\u655b\u66f4\u5feb\u4e14\u7a33\u5b9a\u3002", "conclusion": "AdaMuon\u65e0\u9700\u989d\u5916\u8c03\u53c2\uff0c\u53ef\u8f7b\u677e\u96c6\u6210\u73b0\u6709Muon\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6027\u80fd\u4f18\u8d8a\u3002", "keywords": "AdaMuon, Muon, \u81ea\u9002\u5e94\u5b66\u4e60\u7387, \u4f18\u5316\u5668, \u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3"}}
{"id": "2507.11012", "pdf": "https://arxiv.org/pdf/2507.11012", "abs": "https://arxiv.org/abs/2507.11012", "authors": ["Dipak Dulal", "Joseph J. Charney", "Michael R. Gallagher", "Pitambar Acharya", "Carmeliza Navasca", "Nicholas S. Skowronski"], "title": "Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2311.05128", "summary": "This study explores the potential for predicting turbulent kinetic energy\n(TKE) from more readily acquired temperature data using temperature profiles\nand turbulence data collected concurrently at 10 Hz during a small experimental\nprescribed burn in the New Jersey Pine Barrens. Machine learning models,\nincluding Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and\nGaussian Process Regressor, were employed to assess the potential to predict\nTKE from temperature perturbations and explore temporal and spatial dynamics of\ncorrelations. Data visualization and correlation analyses revealed patterns and\nrelationships between thermocouple temperatures and TKE, providing insight into\nthe underlying dynamics. More accurate predictions of TKE were achieved by\nemploying various machine learning models despite a weak correlation between\nthe predictors and the target variable. The results demonstrate significant\nsuccess, particularly from regression models, in accurately predicting the TKE.\nThe findings of this study demonstrate a novel numerical approach to\nidentifying new relationships between temperature and airflow processes in and\naround the fire environment. These relationships can help refine our\nunderstanding of combustion environment processes and the coupling and\ndecoupling of fire environment processes necessary for improving fire\noperations strategy and fire and smoke model predictions. The findings of this\nstudy additionally highlight the valuable role of machine learning techniques\nin analyzing the complex large datasets of the fire environments, showcasing\ntheir potential to advance fire research and management practices.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6e29\u5ea6\u6570\u636e\u9884\u6d4b\u6e4d\u6d41\u52a8\u80fd\uff08TKE\uff09\uff0c\u4f7f\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u6e29\u5ea6\u4e0eTKE\u4e4b\u95f4\u7684\u65b0\u5173\u7cfb\uff0c\u4e3a\u706b\u707e\u73af\u5883\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u6e29\u5ea6\u6570\u636e\u4e0eTKE\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u706b\u707e\u73af\u5883\u4e2d\u71c3\u70e7\u548c\u6c14\u6d41\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u706b\u707e\u6a21\u578b\u9884\u6d4b\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u5728\u5b9e\u9a8c\u706b\u707e\u4e2d\u91c7\u96c6\u6e29\u5ea6\u548c\u6e4d\u6d41\u6570\u636e\uff0c\u91c7\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3001\u968f\u673a\u68ee\u6797\u56de\u5f52\u3001\u68af\u5ea6\u63d0\u5347\u548c\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u6790\u6570\u636e\u3002", "result": "\u5c3d\u7ba1\u9884\u6d4b\u56e0\u5b50\u4e0e\u76ee\u6807\u53d8\u91cf\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ecd\u80fd\u51c6\u786e\u9884\u6d4bTKE\uff0c\u56de\u5f52\u6a21\u578b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u706b\u707e\u73af\u5883\u6570\u636e\u5206\u6790\u4e2d\u7684\u4ef7\u503c\uff0c\u4e3a\u6539\u8fdb\u706b\u707e\u7ba1\u7406\u548c\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "keywords": "\u6e4d\u6d41\u52a8\u80fd\uff08TKE\uff09, \u673a\u5668\u5b66\u4e60, \u6e29\u5ea6\u6570\u636e, \u706b\u707e\u73af\u5883, \u9884\u6d4b\u6a21\u578b"}}
{"id": "2507.10859", "pdf": "https://arxiv.org/pdf/2507.10859", "abs": "https://arxiv.org/abs/2507.10859", "authors": ["Ramaneswaran Selvakumar", "Ashish Seth", "Nishit Anand", "Utkarsh Tyagi", "Sonal Kumar", "Sreyan Ghosh", "Dinesh Manocha"], "title": "MultiVox: Benchmarking Voice Assistants for Multimodal Interactions", "categories": ["cs.MM", "cs.CL", "cs.HC"], "comment": "Work In Progress", "summary": "The rapid progress of Large Language Models (LLMs) has empowered omni models\nto act as voice assistants capable of understanding spoken dialogues. These\nmodels can process multimodal inputs beyond text, such as speech and visual\ndata, enabling more context-aware interactions. However, current benchmarks\nfall short in comprehensively evaluating how well these models generate\ncontext-aware responses, particularly when it comes to implicitly understanding\nfine-grained speech characteristics, such as pitch, emotion, timbre, and volume\nor the environmental acoustic context such as background sounds. Additionally,\nthey inadequately assess the ability of models to align paralinguistic cues\nwith complementary visual signals to inform their responses. To address these\ngaps, we introduce MultiVox, the first omni voice assistant benchmark designed\nto evaluate the ability of voice assistants to integrate spoken and visual cues\nincluding paralinguistic speech features for truly multimodal understanding.\nSpecifically, MultiVox includes 1000 human-annotated and recorded speech\ndialogues that encompass diverse paralinguistic features and a range of visual\ncues such as images and videos. Our evaluation on 9 state-of-the-art models\nreveals that, although humans excel at these tasks, current models consistently\nstruggle to produce contextually grounded responses.", "AI": {"tldr": "MultiVox\u662f\u4e00\u4e2a\u65b0\u7684\u5168\u606f\u8bed\u97f3\u52a9\u624b\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e8\u5728\u8bc4\u4f30\u6a21\u578b\u6574\u5408\u8bed\u97f3\u548c\u89c6\u89c9\u7ebf\u7d22\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u526f\u8bed\u8a00\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5168\u9762\u8bc4\u4f30\u8bed\u97f3\u52a9\u624b\u5728\u7406\u89e3\u526f\u8bed\u97f3\u7279\u5f81\u548c\u73af\u5883\u58f0\u97f3\u7b49\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e5f\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5176\u4e0e\u89c6\u89c9\u4fe1\u53f7\u7684\u7ed3\u5408\u80fd\u529b\u3002", "method": "\u5f15\u5165MultiVox\u57fa\u51c6\uff0c\u5305\u542b1000\u6761\u4eba\u5de5\u6807\u6ce8\u7684\u8bed\u97f3\u5bf9\u8bdd\uff0c\u6db5\u76d6\u591a\u6837\u5316\u7684\u526f\u8bed\u8a00\u7279\u5f81\u548c\u89c6\u89c9\u7ebf\u7d22\u3002", "result": "\u5bf99\u79cd\u5148\u8fdb\u6a21\u578b\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u4eba\u7c7b\u8868\u73b0\u51fa\u8272\uff0c\u800c\u73b0\u6709\u6a21\u578b\u5728\u751f\u6210\u4e0a\u4e0b\u6587\u76f8\u5173\u56de\u5e94\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u5f53\u524d\u6a21\u578b\u5728\u7ed3\u5408\u8bed\u97f3\u548c\u89c6\u89c9\u7ebf\u7d22\u7684\u7406\u89e3\u80fd\u529b\u4e0a\u4ecd\u6709\u4e0d\u8db3\uff0cMultiVox\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "keywords": "\u591a\u6a21\u6001\u6a21\u578b,\u8bed\u97f3\u52a9\u624b,\u526f\u8bed\u8a00\u7279\u5f81,\u89c6\u89c9\u7ebf\u7d22,\u57fa\u51c6\u6d4b\u8bd5"}}
{"id": "2507.10589", "pdf": "https://arxiv.org/pdf/2507.10589", "abs": "https://arxiv.org/abs/2507.10589", "authors": ["Gaurav Singh"], "title": "Comparative Analysis of Vision Transformers and Traditional Deep Learning Approaches for Automated Pneumonia Detection in Chest X-Rays", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.NE"], "comment": null, "summary": "Pneumonia, particularly when induced by diseases like COVID-19, remains a\ncritical global health challenge requiring rapid and accurate diagnosis. This\nstudy presents a comprehensive comparison of traditional machine learning and\nstate-of-the-art deep learning approaches for automated pneumonia detection\nusing chest X-rays (CXRs). We evaluate multiple methodologies, ranging from\nconventional machine learning techniques (PCA-based clustering, Logistic\nRegression, and Support Vector Classification) to advanced deep learning\narchitectures including Convolutional Neural Networks (Modified LeNet,\nDenseNet-121) and various Vision Transformer (ViT) implementations (Deep-ViT,\nCompact Convolutional Transformer, and Cross-ViT). Using a dataset of 5,856\npediatric CXR images, we demonstrate that Vision Transformers, particularly the\nCross-ViT architecture, achieve superior performance with 88.25% accuracy and\n99.42% recall, surpassing traditional CNN approaches. Our analysis reveals that\narchitectural choices impact performance more significantly than model size,\nwith Cross-ViT's 75M parameters outperforming larger models. The study also\naddresses practical considerations including computational efficiency, training\nrequirements, and the critical balance between precision and recall in medical\ndiagnostics. Our findings suggest that Vision Transformers offer a promising\ndirection for automated pneumonia detection, potentially enabling more rapid\nand accurate diagnosis during health crises.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u80ba\u708e\u81ea\u52a8\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Vision Transformers\uff08\u5c24\u5176\u662fCross-ViT\uff09\u5728\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u80ba\u708e\uff08\u5982COVID-19\u5f15\u8d77\u7684\uff09\u662f\u5168\u7403\u5065\u5eb7\u6311\u6218\uff0c\u9700\u8981\u5feb\u901f\u51c6\u786e\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u8bc4\u4f30\u4e86\u591a\u79cd\u65b9\u6cd5\uff0c\u5305\u62ec\u4f20\u7edf\u673a\u5668\u5b66\u4e60\uff08PCA\u805a\u7c7b\u3001\u903b\u8f91\u56de\u5f52\u3001\u652f\u6301\u5411\u91cf\u673a\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08CNN\u3001Vision Transformers\uff09\u3002", "result": "Cross-ViT\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u738788.25%\uff0c\u53ec\u56de\u738799.42%\uff0c\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "Vision Transformers\u5728\u80ba\u708e\u81ea\u52a8\u68c0\u6d4b\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662fCross-ViT\u67b6\u6784\u3002", "keywords": "\u80ba\u708e, \u673a\u5668\u5b66\u4e60, \u6df1\u5ea6\u5b66\u4e60, Vision Transformers, \u80f8\u90e8X\u5149"}}
{"id": "2507.11017", "pdf": "https://arxiv.org/pdf/2507.11017", "abs": "https://arxiv.org/abs/2507.11017", "authors": ["Xingyu Zheng", "Haotong Qin", "Yuye Li", "Jiakai Wang", "Jinyang Guo", "Michele Magno", "Xianglong Liu"], "title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Post-training quantization (PTQ) offers an efficient approach to compressing\nlarge language models (LLMs), significantly reducing memory access and\ncomputational costs. Existing compensation-based weight calibration methods\noften rely on a second-order Taylor expansion to model quantization error,\nunder the assumption that the first-order term is negligible in well-trained\nfull-precision models. However, we reveal that the progressive compensation\nprocess introduces accumulated first-order deviations between latent weights\nand their full-precision counterparts, making this assumption fundamentally\nflawed. To address this, we propose FOEM, a novel PTQ method that explicitly\nincorporates first-order gradient terms to improve quantization error\ncompensation. FOEM approximates gradients by directly computing the difference\nbetween latent and full-precision weights, avoiding the high cost and limited\ngeneralization of backpropagation-based gradient computation. This approach\nintroduces minimal additional computational overhead. Moreover, FOEM leverages\nprecomputed Cholesky factors to efficiently recover the inverse of Hessian\nsubmatrices in real time. Extensive experiments across a wide range of models\nand benchmarks demonstrate that FOEM consistently outperforms the classical\nGPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of\nLlama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from\n51.7% to 74.9%, approaching the full-precision performance of 78.6%.\nFurthermore, FOEM can be seamlessly integrated with advanced techniques such as\nGPTAQ and SpinQuant, yielding additional improvements under the challenging\nW4A4KV4 setting, and further narrowing the accuracy gap with full-precision\nbaselines beyond what current state-of-the-art methods achieve. The code is\navailable at https://github.com/Xingyu-Zheng/FOEM.", "AI": {"tldr": "FOEM\u662f\u4e00\u79cd\u65b0\u578b\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5730\u7eb3\u5165\u4e00\u9636\u68af\u5ea6\u9879\u6765\u6539\u8fdb\u91cf\u5316\u8bef\u5dee\u8865\u507f\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u8865\u507f\u5f0f\u6743\u91cd\u6821\u51c6\u65b9\u6cd5\u5047\u8bbe\u4e00\u9636\u9879\u5728\u91cf\u5316\u8bef\u5dee\u4e2d\u53ef\u5ffd\u7565\uff0c\u4f46\u5b9e\u9645\u4e0a\u4e00\u9636\u504f\u5dee\u4f1a\u7d2f\u79ef\uff0c\u5bfc\u81f4\u8fd9\u4e00\u5047\u8bbe\u5b58\u5728\u6839\u672c\u7f3a\u9677\u3002", "method": "FOEM\u901a\u8fc7\u76f4\u63a5\u8ba1\u7b97\u6f5c\u5728\u6743\u91cd\u4e0e\u5168\u7cbe\u5ea6\u6743\u91cd\u7684\u5dee\u503c\u6765\u8fd1\u4f3c\u68af\u5ea6\uff0c\u907f\u514d\u4e86\u53cd\u5411\u4f20\u64ad\u7684\u9ad8\u6210\u672c\uff0c\u5e76\u5229\u7528\u9884\u8ba1\u7b97\u7684Cholesky\u56e0\u5b50\u9ad8\u6548\u6062\u590dHessian\u5b50\u77e9\u9635\u7684\u9006\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFOEM\u57283\u4f4d\u6743\u91cd\u91cf\u5316\u4e0b\u663e\u8457\u964d\u4f4e\u56f0\u60d1\u5ea6\u5e76\u63d0\u5347\u51c6\u786e\u7387\uff0c\u63a5\u8fd1\u5168\u7cbe\u5ea6\u6027\u80fd\uff0c\u4e14\u80fd\u4e0e\u5176\u4ed6\u5148\u8fdb\u6280\u672f\u65e0\u7f1d\u96c6\u6210\u3002", "conclusion": "FOEM\u901a\u8fc7\u6539\u8fdb\u91cf\u5316\u8bef\u5dee\u8865\u507f\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u7f29\u5c0f\u4e86\u4e0e\u5168\u7cbe\u5ea6\u57fa\u51c6\u7684\u5dee\u8ddd\u3002", "keywords": "\u540e\u8bad\u7ec3\u91cf\u5316, \u5927\u8bed\u8a00\u6a21\u578b, \u68af\u5ea6\u8865\u507f, \u4e00\u9636\u504f\u5dee, \u91cf\u5316\u8bef\u5dee"}}
{"id": "2507.10865", "pdf": "https://arxiv.org/pdf/2507.10865", "abs": "https://arxiv.org/abs/2507.10865", "authors": ["Nick Craswell", "Bhaskar Mitra", "Emine Yilmaz", "Daniel Campos", "Jimmy Lin", "Ellen M. Voorhees", "Ian Soboroff"], "title": "Overview of the TREC 2022 deep learning track", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191,\n  arXiv:2507.08890", "summary": "This is the fourth year of the TREC Deep Learning track. As in previous\nyears, we leverage the MS MARCO datasets that made hundreds of thousands of\nhuman annotated training labels available for both passage and document ranking\ntasks. In addition, this year we also leverage both the refreshed passage and\ndocument collections that were released last year leading to a nearly $16$\ntimes increase in the size of the passage collection and nearly four times\nincrease in the document collection size. Unlike previous years, in 2022 we\nmainly focused on constructing a more complete test collection for the passage\nretrieval task, which has been the primary focus of the track. The document\nranking task was kept as a secondary task, where document-level labels were\ninferred from the passage-level labels. Our analysis shows that similar to\nprevious years, deep neural ranking models that employ large scale pretraining\ncontinued to outperform traditional retrieval methods. Due to the focusing our\njudging resources on passage judging, we are more confident in the quality of\nthis year's queries and judgments, with respect to our ability to distinguish\nbetween runs and reuse the dataset in future. We also see some surprises in\noverall outcomes. Some top-performing runs did not do dense retrieval. Runs\nthat did single-stage dense retrieval were not as competitive this year as they\nwere last year.", "AI": {"tldr": "TREC Deep Learning 2022 track\u805a\u7126\u4e8e\u6784\u5efa\u66f4\u5b8c\u6574\u7684\u6d4b\u8bd5\u96c6\u5408\uff0c\u6df1\u5ea6\u5b66\u4e60\u6392\u540d\u6a21\u578b\u7ee7\u7eed\u9886\u5148\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5728\u5bc6\u96c6\u68c0\u7d22\u65b9\u9762\u6709\u610f\u5916\u7ed3\u679c\u3002", "motivation": "\u5229\u7528MS MARCO\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u6784\u5efa\u66f4\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u96c6\uff0c\u63d0\u5347\u68c0\u7d22\u4efb\u52a1\u7684\u533a\u5206\u5ea6\u548c\u6570\u636e\u53ef\u590d\u7528\u6027\u3002", "method": "\u4e3b\u8981\u901a\u8fc7\u5237\u65b0\u548c\u6269\u5c55MS MARCO\u6570\u636e\u96c6\uff0c\u96c6\u4e2d\u8d44\u6e90\u4e8e\u6bb5\u843d\u68c0\u7d22\u4efb\u52a1\u7684\u6807\u6ce8\uff0c\u6587\u6863\u4efb\u52a1\u6807\u7b7e\u4ece\u6bb5\u843d\u6807\u7b7e\u63a8\u65ad\u3002", "result": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4ecd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5bc6\u96c6\u68c0\u7d22\u8868\u73b0\u4e0d\u5982\u53bb\u5e74\uff0c\u90e8\u5206\u975e\u5bc6\u96c6\u68c0\u7d22\u65b9\u6cd5\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u5c3d\u7ba1\u8d44\u6e90\u96c6\u4e2d\u4e8e\u6bb5\u843d\u4efb\u52a1\u6807\u6ce8\uff0c\u4f46\u6570\u636e\u8d28\u91cf\u63d0\u5347\uff0c\u65b0\u53d1\u73b0\u8868\u660e\u68c0\u7d22\u65b9\u6cd5\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "keywords": "TREC, Deep Learning, MS MARCO, passage retrieval, document ranking, dense retrieval"}}
{"id": "2507.10590", "pdf": "https://arxiv.org/pdf/2507.10590", "abs": "https://arxiv.org/abs/2507.10590", "authors": ["Mojtaba Eshghie"], "title": "Repairing Language Model Pipelines by Meta Self-Refining Competing Constraints at Runtime", "categories": ["cs.SE", "cs.AI", "cs.IR"], "comment": null, "summary": "Language Model (LM) pipelines can dynamically refine their outputs against\nprogrammatic constraints. However, their effectiveness collapses when faced\nwith competing soft constraints, leading to inefficient backtracking loops\nwhere satisfying one constraint violates another. We introduce Meta\nSelf-Refining, a framework that equips LM pipelines with a meta-corrective\nlayer to repair these competitions at runtime/inference-time. Our approach\nmonitors the pipeline's execution history to detect oscillatory failures. Upon\ndetection, it invokes a meta-repairer LM that analyzes the holistic state of\nthe backtracking attempts and synthesizes a strategic instruction to balance\nthe competing requirements. This self-repair instruction guides the original LM\nout of a failing refining loop towards a successful output. Our results show\nMeta Self-Refining can successfully repair these loops, leading to more\nefficient LM programs.", "AI": {"tldr": "Meta Self-Refining\u6846\u67b6\u89e3\u51b3\u4e86\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u4e2d\u7ade\u4e89\u8f6f\u7ea6\u675f\u5bfc\u81f4\u7684\u4f4e\u6548\u56de\u6eaf\u95ee\u9898\uff0c\u901a\u8fc7\u5143\u4fee\u6b63\u5c42\u548c\u6307\u4ee4\u5408\u6210\u5b9e\u73b0\u9ad8\u6548\u4fee\u590d\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u5728\u9762\u5bf9\u7ade\u4e89\u8f6f\u7ea6\u675f\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u5bb9\u6613\u9677\u5165\u65e0\u6548\u56de\u6eaf\u5faa\u73af\u3002", "method": "\u5f15\u5165Meta Self-Refining\u6846\u67b6\uff0c\u901a\u8fc7\u76d1\u63a7\u6267\u884c\u5386\u53f2\u68c0\u6d4b\u632f\u8361\u6545\u969c\uff0c\u5e76\u8c03\u7528\u5143\u4fee\u590d\u5668\u5408\u6210\u6307\u4ee4\uff0c\u5e73\u8861\u7ade\u4e89\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u6709\u6548\u4fee\u590d\u56de\u6eaf\u5faa\u73af\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7a0b\u5e8f\u7684\u6548\u7387\u3002", "conclusion": "Meta Self-Refining\u4e3a\u89e3\u51b3\u7ade\u4e89\u7ea6\u675f\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7ba1\u9053\u7684\u6027\u80fd\u3002", "keywords": "\u8bed\u8a00\u6a21\u578b,\u7ade\u4e89\u7ea6\u675f,\u5143\u4fee\u6b63,\u56de\u6eaf\u5faa\u73af,\u52a8\u6001\u4fee\u590d"}}
{"id": "2507.11019", "pdf": "https://arxiv.org/pdf/2507.11019", "abs": "https://arxiv.org/abs/2507.11019", "authors": ["Claas Voelcker", "Axel Brunnbauer", "Marcel Hussing", "Michal Nauman", "Pieter Abbeel", "Eric Eaton", "Radu Grosu", "Amir-massoud Farahmand", "Igor Gilitschenski"], "title": "Relative Entropy Pathwise Policy Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Score-function policy gradients have delivered strong results in\ngame-playing, robotics and language-model fine-tuning. Yet its high-variance\noften undermines training stability. On the other hand, pathwise policy\ngradients alleviate the training variance, but are reliable only when driven by\nan accurate action-conditioned value function which is notoriously hard to\ntrain without relying on past off-policy data. In this paper, we discuss how to\nconstruct a value-gradient driven, on-policy algorithm that allow training\nQ-value models purely from on-policy data, unlocking the possibility of using\npathwise policy updates in the context of on-policy learning. We show how to\nbalance stochastic policies for exploration with constrained policy updates for\nstable training, and evaluate important architectural components that\nfacilitate accurate value function learning. Building on these insights, we\npropose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient\non-policy algorithm that combines the sample-efficiency of pathwise policy\ngradients with the simplicity and minimal memory footprint of standard\non-policy learning. We demonstrate that REPPO provides strong empirical\nperformance at decreased sample requirements, wall-clock time, memory footprint\nas well as high hyperparameter robustness in a set of experiments on two\nstandard GPU-parallelized benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ef7\u503c\u68af\u5ea6\u7684on-policy\u7b97\u6cd5REPPO\uff0c\u7ed3\u5408\u4e86\u8def\u5f84\u7b56\u7565\u68af\u5ea6\u7684\u6837\u672c\u6548\u7387\u548c\u6807\u51c6on-policy\u5b66\u4e60\u7684\u7b80\u5355\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u65b9\u5dee\u548c\u8d44\u6e90\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3score-function\u7b56\u7565\u68af\u5ea6\u7684\u9ad8\u65b9\u5dee\u95ee\u9898\u4ee5\u53ca\u8def\u5f84\u7b56\u7565\u68af\u5ea6\u5bf9\u51c6\u786e\u52a8\u4f5c\u6761\u4ef6\u4ef7\u503c\u51fd\u6570\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u5728on-policy\u5b66\u4e60\u4e2d\u9ad8\u6548\u8bad\u7ec3\u4ef7\u503c\u51fd\u6570\u6a21\u578b\u3002", "method": "\u63d0\u51faREPPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u5e73\u8861\u968f\u673a\u7b56\u7565\u63a2\u7d22\u548c\u7ea6\u675f\u7b56\u7565\u66f4\u65b0\uff0c\u7ed3\u5408\u8def\u5f84\u7b56\u7565\u68af\u5ea6\u548con-policy\u5b66\u4e60\u7684\u4f18\u70b9\uff0c\u4f18\u5316\u4ef7\u503c\u51fd\u6570\u5b66\u4e60\u67b6\u6784\u3002", "result": "REPPO\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u964d\u4f4e\u4e86\u6837\u672c\u9700\u6c42\u3001\u8bad\u7ec3\u65f6\u95f4\u3001\u5185\u5b58\u5360\u7528\uff0c\u5e76\u5c55\u793a\u4e86\u9ad8\u5ea6\u7684\u8d85\u53c2\u6570\u9c81\u68d2\u6027\u3002", "conclusion": "REPPO\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684on-policy\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u9700\u8981\u4f4e\u65b9\u5dee\u548c\u9ad8\u6837\u672c\u6548\u7387\u7684\u573a\u666f\u3002", "keywords": "\u7b56\u7565\u68af\u5ea6, on-policy\u5b66\u4e60, \u8def\u5f84\u7b56\u7565\u68af\u5ea6, \u6837\u672c\u6548\u7387, REPPO"}}
{"id": "2507.11053", "pdf": "https://arxiv.org/pdf/2507.11053", "abs": "https://arxiv.org/abs/2507.11053", "authors": ["Danish Gufran", "Sudeep Pasricha"], "title": "GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate indoor localization is crucial for enabling spatial context in smart\nenvironments and navigation systems. Wi-Fi Received Signal Strength (RSS)\nfingerprinting is a widely used indoor localization approach due to its\ncompatibility with mobile embedded devices. Deep Learning (DL) models improve\naccuracy in localization tasks by learning RSS variations across locations, but\nthey assume fingerprint vectors exist in a Euclidean space, failing to\nincorporate spatial relationships and the non-uniform distribution of\nreal-world RSS noise. This results in poor generalization across heterogeneous\nmobile devices, where variations in hardware and signal processing distort RSS\nreadings. Graph Neural Networks (GNNs) can improve upon conventional DL models\nby encoding indoor locations as nodes and modeling their spatial and signal\nrelationships as edges. However, GNNs struggle with non-Euclidean noise\ndistributions and suffer from the GNN blind spot problem, leading to degraded\naccuracy in environments with dense access points (APs). To address these\nchallenges, we propose GATE, a novel framework that constructs an adaptive\ngraph representation of fingerprint vectors while preserving an indoor\nstate-space topology, modeling the non-Euclidean structure of RSS noise to\nmitigate environmental noise and address device heterogeneity. GATE introduces\n1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a\nnovel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind\nspot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic\ngraph adaptation. Extensive real-world evaluations across multiple indoor\nspaces with varying path lengths, AP densities, and heterogeneous devices\ndemonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and\n1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor\nlocalization frameworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGATE\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u56fe\u8868\u793a\u548c\u521b\u65b0\u7684\u5411\u91cf\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5ba4\u5185\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u6297\u5e72\u6270\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3Wi-Fi RSS\u6307\u7eb9\u5b9a\u4f4d\u4e2d\u56e0\u975e\u6b27\u51e0\u91cc\u5f97\u566a\u58f0\u5206\u5e03\u548c\u8bbe\u5907\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u95ee\u9898\u3002", "method": "\u7ed3\u5408\u4e86\u6ce8\u610f\u529b\u8d85\u7a7a\u95f4\u5411\u91cf\uff08AHV\uff09\u3001\u591a\u7ef4\u8d85\u7a7a\u95f4\u5411\u91cf\uff08MDHV\uff09\u548c\u5b9e\u65f6\u8fb9\u6784\u5efa\uff08RTEC\uff09\u6280\u672f\uff0c\u6784\u5efa\u81ea\u9002\u5e94\u56fe\u8868\u793a\u6a21\u578b\u3002", "result": "\u5728\u5b9e\u9645\u6d4b\u8bd5\u4e2d\uff0cGATE\u7684\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u73b0\u6709\u65b9\u6cd5\u4f4e1.6x\u81f34.72x\uff0c\u6700\u574f\u60c5\u51b5\u8bef\u5dee\u4f4e1.85x\u81f34.57x\u3002", "conclusion": "GATE\u901a\u8fc7\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u65b0\u578b\u5411\u91cf\u6280\u672f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5ba4\u5185\u5b9a\u4f4d\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "keywords": "\u5ba4\u5185\u5b9a\u4f4d, \u56fe\u795e\u7ecf\u7f51\u7edc, \u975e\u6b27\u51e0\u91cc\u5f97\u566a\u58f0, \u8bbe\u5907\u5f02\u8d28\u6027"}}
{"id": "2507.10593", "pdf": "https://arxiv.org/pdf/2507.10593", "abs": "https://arxiv.org/abs/2507.10593", "authors": ["Peng Ding"], "title": "ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) applications are increasingly relying on external\ntools to extend their capabilities beyond text generation. However, current\ntool integration approaches suffer from fragmentation, protocol limitations,\nand implementation complexity, leading to substantial development overhead.\nThis paper presents Toolregistry, a protocol-agnostic tool management library\nthat simplifies tool registration, representation, execution, and lifecycle\nmanagement via a unified interface. Our evaluation demonstrates that\n\\toolregistry achieves 60-80% reduction in tool integration code, up to 3.1x\nperformance improvements through concurrent execution, and 100% compatibility\nwith OpenAI function calling standards. Real-world case studies show\nsignificant improvements in development efficiency and code maintainability\nacross diverse integration scenarios. \\toolregistry is open-source and\navailable at https://github.com/Oaklight/ToolRegistry, with comprehensive\ndocumentation at https://toolregistry.readthedocs.io/.", "AI": {"tldr": "Toolregistry\u662f\u4e00\u4e2a\u534f\u8bae\u65e0\u5173\u7684\u5de5\u5177\u7ba1\u7406\u5e93\uff0c\u7b80\u5316\u5de5\u5177\u96c6\u6210\u6d41\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u4ee3\u7801\u91cf\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5de5\u5177\u96c6\u6210\u65b9\u6cd5\u5b58\u5728\u788e\u7247\u5316\u3001\u534f\u8bae\u9650\u5236\u548c\u5b9e\u73b0\u590d\u6742\u6027\u7b49\u95ee\u9898\uff0c\u589e\u52a0\u4e86\u5f00\u53d1\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7\u7edf\u4e00\u63a5\u53e3\u5b9e\u73b0\u5de5\u5177\u7684\u6ce8\u518c\u3001\u8868\u793a\u3001\u6267\u884c\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\u3002", "result": "Toolregistry\u51cf\u5c11\u4e8660-80%\u7684\u96c6\u6210\u4ee3\u7801\uff0c\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe3.1\u500d\uff0c\u4e14100%\u517c\u5bb9OpenAI\u51fd\u6570\u8c03\u7528\u6807\u51c6\u3002", "conclusion": "Toolregistry\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u96c6\u6210\u573a\u666f\u3002", "keywords": "LLM, \u5de5\u5177\u96c6\u6210, \u6027\u80fd\u63d0\u5347, \u5f00\u53d1\u6548\u7387"}}
{"id": "2507.11063", "pdf": "https://arxiv.org/pdf/2507.11063", "abs": "https://arxiv.org/abs/2507.11063", "authors": ["Gwen Maudet", "Gr\u00e9goire Danoy"], "title": "A Distance Metric for Mixed Integer Programming Instances", "categories": ["cs.LG", "math.OC"], "comment": "Accepted to ECAI 2025", "summary": "Mixed-integer linear programming (MILP) is a powerful tool for addressing a\nwide range of real-world problems, but it lacks a clear structure for comparing\ninstances. A reliable similarity metric could establish meaningful\nrelationships between instances, enabling more effective evaluation of instance\nset heterogeneity and providing better guidance to solvers, particularly when\nmachine learning is involved. Existing similarity metrics often lack precision\nin identifying instance classes or rely heavily on labeled data, which limits\ntheir applicability and generalization. To bridge this gap, this paper\nintroduces the first mathematical distance metric for MILP instances, derived\ndirectly from their mathematical formulations. By discretizing right-hand\nsides, weights, and variables into classes, the proposed metric draws\ninspiration from the Earth mover's distance to quantify mismatches in\nweight-variable distributions for constraint comparisons. This approach\nnaturally extends to enable instance-level comparisons. We evaluate both an\nexact and a greedy variant of our metric under various parameter settings,\nusing the StrIPLIB dataset. Results show that all components of the metric\ncontribute to class identification, and that the greedy version achieves\naccuracy nearly identical to the exact formulation while being nearly 200 times\nfaster. Compared to state-of-the-art baselines, including feature-based,\nimage-based, and neural network models, our unsupervised method consistently\noutperforms all non-learned approaches and rivals the performance of a\nsupervised classifier on class and subclass grouping tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u6570\u5b66\u5b9a\u4e49\u7684\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u5b9e\u4f8b\u8ddd\u79bb\u5ea6\u91cf\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u53f3\u7aef\u9879\u3001\u6743\u91cd\u548c\u53d8\u91cf\u6765\u91cf\u5316\u7ea6\u675f\u7684\u6743\u91cd-\u53d8\u91cf\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u5e76\u901a\u8fc7\u8d2a\u5fc3\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u76f8\u4f3c\u6027\u5ea6\u91cf\u5728\u8bc6\u522b\u5b9e\u4f8b\u7c7b\u522b\u65f6\u7f3a\u4e4f\u7cbe\u786e\u6027\u6216\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u9002\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u5c06\u53f3\u7aef\u9879\u3001\u6743\u91cd\u548c\u53d8\u91cf\u79bb\u6563\u5316\uff0c\u501f\u9274\u5730\u7403\u79fb\u52a8\u8ddd\u79bb\u7684\u601d\u60f3\u91cf\u5316\u7ea6\u675f\u7684\u6743\u91cd-\u53d8\u91cf\u5206\u5e03\u4e0d\u5339\u914d\uff0c\u63d0\u51fa\u7cbe\u786e\u548c\u8d2a\u5fc3\u4e24\u79cd\u8ba1\u7b97\u53d8\u4f53\u3002", "result": "\u5728StrIPLIB\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8d2a\u5fc3\u7b97\u6cd5\u5728\u51e0\u4e4e\u4e0d\u635f\u5931\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u901f\u5ea6\u63d0\u5347\u4e86\u8fd1200\u500d\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u975e\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u5728\u7c7b\u522b\u548c\u5b50\u7c7b\u5206\u7ec4\u4efb\u52a1\u4e0a\u4f18\u4e8e\u975e\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u4e0e\u76d1\u7763\u5206\u7c7b\u5668\u6027\u80fd\u76f8\u5f53\u3002", "keywords": "\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212, \u8ddd\u79bb\u5ea6\u91cf, \u65e0\u76d1\u7763\u5b66\u4e60, \u8d2a\u5fc3\u7b97\u6cd5, \u5b9e\u4f8b\u76f8\u4f3c\u6027"}}
{"id": "2507.10903", "pdf": "https://arxiv.org/pdf/2507.10903", "abs": "https://arxiv.org/abs/2507.10903", "authors": ["Parisa Fard Moshiri", "Xinyu Zhu", "Poonam Lohan", "Burak Kantarci", "Emil Janulewicz"], "title": "LiLM-RDB-SFC: Lightweight Language Model with Relational Database-Guided DRL for Optimized SFC Provisioning", "categories": ["cs.NI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, Accepted to IEEE 16th International Conference on\n  Network of the Future (NoF) 2025", "summary": "Effective management of Service Function Chains (SFCs) and optimal Virtual\nNetwork Function (VNF) placement are critical challenges in modern\nSoftware-Defined Networking (SDN) and Network Function Virtualization (NFV)\nenvironments. Although Deep Reinforcement Learning (DRL) is widely adopted for\ndynamic network decision-making, its inherent dependency on structured data and\nfixed action rules often limits adaptability and responsiveness, particularly\nunder unpredictable network conditions. This paper introduces LiLM-RDB-SFC, a\nnovel approach combining Lightweight Language Model (LiLM) with Relational\nDatabase (RDB) to answer network state queries to guide DRL model for efficient\nSFC provisioning. Our proposed approach leverages two LiLMs, Bidirectional and\nAuto-Regressive Transformers (BART) and the Fine-tuned Language Net T5\n(FLAN-T5), to interpret network data and support diverse query types related to\nSFC demands, data center resources, and VNF availability. Results demonstrate\nthat FLAN-T5 outperforms BART with a lower test loss (0.00161 compared to\n0.00734), higher accuracy (94.79% compared to 80.2%), and less processing time\n(2h 2min compared to 2h 38min). Moreover, when compared to the large language\nmodel SQLCoder, FLAN-T5 matches the accuracy of SQLCoder while cutting\nprocessing time by 96% (SQLCoder: 54 h 43 min; FLAN-T5: 2 h 2 min).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u548c\u5173\u7cfb\u6570\u636e\u5e93\u7684\u65b0\u65b9\u6cd5LiLM-RDB-SFC\uff0c\u4ee5\u63d0\u9ad8SDN\u548cNFV\u73af\u5883\u4e2d\u670d\u52a1\u529f\u80fd\u94fe\u7ba1\u7406\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u7f51\u7edc\u51b3\u7b56\u4e2d\u7684\u9002\u5e94\u6027\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u53ef\u9884\u6d4b\u7684\u7f51\u7edc\u6761\u4ef6\u4e0b\u3002", "method": "\u901a\u8fc7\u7ed3\u5408BART\u548cFLAN-T5\u4e24\u79cd\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u6790\u7f51\u7edc\u6570\u636e\u5e76\u652f\u6301\u591a\u6837\u5316\u67e5\u8be2\u3002", "result": "FLAN-T5\u8868\u73b0\u4f18\u4e8eBART\uff0c\u6d4b\u8bd5\u635f\u5931\u66f4\u4f4e\uff080.00161 vs. 0.00734\uff09\uff0c\u51c6\u786e\u7387\u66f4\u9ad8\uff0894.79% vs. 80.2%\uff09\uff0c\u5904\u7406\u65f6\u95f4\u66f4\u77ed\uff082h 2min vs. 2h 38min\uff09\u3002\u4e0eSQLCoder\u76f8\u6bd4\uff0cFLAN-T5\u5728\u4fdd\u6301\u76f8\u540c\u51c6\u786e\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u5904\u7406\u65f6\u95f4\u51cf\u5c1196%\u3002", "conclusion": "LiLM-RDB-SFC\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u670d\u52a1\u529f\u80fd\u94fe\u7ba1\u7406\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "keywords": "\u670d\u52a1\u529f\u80fd\u94fe,\u865a\u62df\u7f51\u7edc\u529f\u80fd,\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b,\u7f51\u7edc\u529f\u80fd\u865a\u62df\u5316"}}
{"id": "2507.11071", "pdf": "https://arxiv.org/pdf/2507.11071", "abs": "https://arxiv.org/abs/2507.11071", "authors": ["Isaiah Thompson Ocansey", "Ritwik Bhattacharya", "Tanmay Sen"], "title": "LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Log anomaly detection using traditional rule based or deep learning based\nmethods is often challenging due to the large volume and highly complex nature\nof log sequence. So effective way of detection of anomalous sequence of logs is\ncrucial for system maintenance and development. This paper proposes parameter\nefficient finetuning specifically low rank adaptation (LoRA) and adapter based\napproaches for finding contextual anomalies in sequence of logs in large log\ndata set. It compares different tiny large language models (LLMs) on the\nThunderbird dataset. The results show that LoRA based finetuning provides\nsubstantial performance improvements of 18 to 19 percentage over LogBert based\nfull finetuning approach, achieving accuracy scores between 97.76% and 98.83%\ncompared to 79.37%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff08\u5982LoRA\u548c\u9002\u914d\u5668\uff09\uff0c\u7528\u4e8e\u5728\u5927\u89c4\u6a21\u65e5\u5fd7\u6570\u636e\u4e2d\u68c0\u6d4b\u5f02\u5e38\u65e5\u5fd7\u5e8f\u5217\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u7531\u4e8e\u65e5\u5fd7\u6570\u636e\u91cf\u5927\u4e14\u590d\u6742\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u5f02\u5e38\u5e8f\u5217\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff08LoRA\u548c\u9002\u914d\u5668\uff09\uff0c\u5e76\u5728Thunderbird\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83\u4e0d\u540c\u5c0f\u578b\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002", "result": "LoRA\u5fae\u8c03\u65b9\u6cd5\u7684\u6027\u80fd\u6bd4LogBert\u5168\u5fae\u8c03\u65b9\u6cd5\u63d0\u5347\u4e8618\u523019\u4e2a\u767e\u5206\u70b9\uff0c\u51c6\u786e\u7387\u8fbe\u523097.76%\u81f398.83%\uff0c\u800cLogBert\u4e3a79.37%\u3002", "conclusion": "\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff08\u5c24\u5176\u662fLoRA\uff09\u5728\u5927\u89c4\u6a21\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "keywords": "\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u3001LoRA\u3001\u9002\u914d\u5668\u3001\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3001LLMs"}}
{"id": "2507.11173", "pdf": "https://arxiv.org/pdf/2507.11173", "abs": "https://arxiv.org/abs/2507.11173", "authors": ["Deepak Kumar Panda", "Weisi Guo"], "title": "Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction", "categories": ["cs.LG"], "comment": null, "summary": "Autonomous unmanned aerial vehicles (UAVs) rely on global navigation\nsatellite system (GNSS) pseudorange measurements for accurate real-time\nlocalization and navigation. However, this dependence exposes them to\nsophisticated spoofing threats, where adversaries manipulate pseudoranges to\ndeceive UAV receivers. Among these, drift-evasive spoofing attacks subtly\nperturb measurements, gradually diverting the UAVs trajectory without\ntriggering conventional signal-level anti-spoofing mechanisms. Traditional\ndistributional shift detection techniques often require accumulating a\nthreshold number of samples, causing delays that impede rapid detection and\ntimely response. Consequently, robust temporal-scale detection methods are\nessential to identify attack onset and enable contingency planning with\nalternative sensing modalities, improving resilience against stealthy\nadversarial manipulations. This study explores a Bayesian online change point\ndetection (BOCPD) approach that monitors temporal shifts in value estimates\nfrom a reinforcement learning (RL) critic network to detect subtle behavioural\ndeviations in UAV navigation. Experimental results show that this temporal\nvalue-based framework outperforms conventional GNSS spoofing detectors,\ntemporal semi-supervised learning frameworks, and the Page-Hinkley test,\nachieving higher detection accuracy and lower false-positive and false-negative\nrates for drift-evasive spoofing attacks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5728\u7ebf\u53d8\u5316\u70b9\u68c0\u6d4b\uff08BOCPD\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u76d1\u6d4b\u65e0\u4eba\u673a\u5728GNSS\u4fe1\u53f7\u4e2d\u7684\u5fae\u5c0f\u884c\u4e3a\u504f\u5dee\uff0c\u4ee5\u68c0\u6d4b\u9690\u853d\u7684\u6b3a\u9a97\u653b\u51fb\u3002\u6b64\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u8bef\u62a5\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u65e0\u4eba\u673a\u4f9d\u8d56GNSS\u4fe1\u53f7\u8fdb\u884c\u5bfc\u822a\uff0c\u4f46\u6613\u53d7\u9690\u853d\u6b3a\u9a97\u653b\u51fb\u3002\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u5ef6\u8fdf\u9ad8\uff0c\u9700\u5feb\u901f\u4e14\u51c6\u786e\u7684\u68c0\u6d4b\u624b\u6bb5\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6279\u5224\u7f51\u7edc\u7684\u4ef7\u503c\u4f30\u8ba1\uff0c\u7ed3\u5408BOCPD\u6280\u672f\uff0c\u76d1\u6d4b\u65f6\u95f4\u4e0a\u7684\u884c\u4e3a\u53d8\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u6bd4\u4f20\u7edfGNSS\u6b3a\u9a97\u68c0\u6d4b\u5668\u3001\u534a\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u548cPage-Hinkley\u6d4b\u8bd5\u8868\u73b0\u66f4\u4f18\uff0c\u68c0\u6d4b\u51c6\u786e\u6027\u66f4\u9ad8\uff0c\u8bef\u62a5\u7387\u548c\u6f0f\u62a5\u7387\u66f4\u4f4e\u3002", "conclusion": "\u57fa\u4e8e\u65f6\u95f4\u4ef7\u503c\u7684BOCPD\u6846\u67b6\u80fd\u6709\u6548\u68c0\u6d4b\u9690\u853d\u7684\u6b3a\u9a97\u653b\u51fb\uff0c\u63d0\u5347\u65e0\u4eba\u673a\u5bfc\u822a\u7684\u9c81\u68d2\u6027\u3002", "keywords": "\u65e0\u4eba\u673a\uff0cGNSS\uff0c\u6b3a\u9a97\u653b\u51fb\uff0c\u8d1d\u53f6\u65af\u5728\u7ebf\u53d8\u5316\u70b9\u68c0\u6d4b\uff0c\u5f3a\u5316\u5b66\u4e60"}}
{"id": "2507.11059", "pdf": "https://arxiv.org/pdf/2507.11059", "abs": "https://arxiv.org/abs/2507.11059", "authors": ["Pavel Adamenko", "Mikhail Ivanov", "Aidar Valeev", "Rodion Levichev", "Pavel Zadorozhny", "Ivan Lopatin", "Dmitry Babayev", "Alena Fenogenova", "Valentin Malykh"], "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) in software engineering\nhas revealed critical limitations in existing benchmarks, particularly the\nwidely used SWE-bench dataset. Recent studies have uncovered severe data\ncontamination issues, e.g. SWE-bench reports 32.67% of successful patches\ninvolve direct solution leakage and 31.08\\% pass due to inadequate test cases.\nWe introduce SWE-MERA, a dynamic, continuously updated benchmark designed to\naddress these fundamental challenges through an automated collection of\nreal-world GitHub issues and rigorous quality validation. Our approach\nimplements a reliable pipeline that ensures quality while minimizing\ncontamination risks, resulting in approximately 10,000 potential tasks with 300\nsamples currently available. Evaluation using the Aider coding agent\ndemonstrates strong discriminative power in state-of-the-art models. We report\nperformance across a dozen recent LLMs evaluated on tasks collected between\nSeptember 2024 and June 2025.", "AI": {"tldr": "SWE-MERA\u662f\u4e00\u4e2a\u52a8\u6001\u66f4\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709SWE-bench\u6570\u636e\u96c6\u7684\u6c61\u67d3\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6536\u96c6GitHub\u95ee\u9898\u548c\u4e25\u683c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u8bc4\u4f30LLMs\u65b9\u9762\u7684\u533a\u5206\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u8bc4\u4f30\u5b58\u5728\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u5982SWE-bench\u6570\u636e\u96c6\u4e2d\u7684\u89e3\u51b3\u65b9\u6848\u6cc4\u6f0f\u548c\u6d4b\u8bd5\u7528\u4f8b\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86SWE-MERA\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6536\u96c6\u771f\u5b9eGitHub\u95ee\u9898\u5e76\u4e25\u683c\u9a8c\u8bc1\u8d28\u91cf\uff0c\u6784\u5efa\u4e86\u7ea610,000\u4e2a\u6f5c\u5728\u4efb\u52a1\u7684\u52a8\u6001\u57fa\u51c6\u3002", "result": "\u4f7f\u7528Aider\u7f16\u7801\u4ee3\u7406\u8bc4\u4f30\u4e8612\u79cd\u6700\u65b0\u7684LLMs\uff0c\u7ed3\u679c\u663e\u793aSWE-MERA\u5177\u6709\u8f83\u5f3a\u7684\u533a\u5206\u80fd\u529b\u3002", "conclusion": "SWE-MERA\u662f\u4e00\u4e2a\u53ef\u9760\u7684\u52a8\u6001\u57fa\u51c6\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u5e76\u4e3aLLMs\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u8f6f\u4ef6\u5de5\u7a0b,\u57fa\u51c6\u6d4b\u8bd5,\u6570\u636e\u6c61\u67d3,GitHub\u95ee\u9898"}}
{"id": "2507.11178", "pdf": "https://arxiv.org/pdf/2507.11178", "abs": "https://arxiv.org/abs/2507.11178", "authors": ["Meiliang Liu", "Huiwen Dong", "Xiaoxiao Yang", "Yunfang Xu", "Zijin Li", "Zhengye Si", "Xinyue Yang", "Zhiwen Zhao"], "title": "Gradient Regularization-based Neural Granger Causality", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages,3 figures, conference", "summary": "With the advancement of deep learning technologies, various neural\nnetwork-based Granger causality models have been proposed. Although these\nmodels have demonstrated notable improvements, several limitations remain. Most\nexisting approaches adopt the component-wise architecture, necessitating the\nconstruction of a separate model for each time series, which results in\nsubstantial computational costs. In addition, imposing the sparsity-inducing\npenalty on the first-layer weights of the neural network to extract causal\nrelationships weakens the model's ability to capture complex interactions. To\naddress these limitations, we propose Gradient Regularization-based Neural\nGranger Causality (GRNGC), which requires only one time series prediction model\nand applies $L_{1}$ regularization to the gradient between model's input and\noutput to infer Granger causality. Moreover, GRNGC is not tied to a specific\ntime series forecasting model and can be implemented with diverse architectures\nsuch as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical\nsimulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC\noutperforms existing baselines and significantly reduces computational\noverhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder\nurothelial carcinoma datasets further validate the model's effectiveness in\nreconstructing gene regulatory networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u6b63\u5219\u5316\u7684\u795e\u7ecf\u683c\u5170\u6770\u56e0\u679c\u6a21\u578b\uff08GRNGC\uff09\uff0c\u901a\u8fc7\u5355\u4e00\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u548c$L_{1}$\u6b63\u5219\u5316\u68af\u5ea6\u63a8\u65ad\u56e0\u679c\u5173\u7cfb\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u683c\u5170\u6770\u56e0\u679c\u6a21\u578b\u91c7\u7528\u9010\u5206\u91cf\u67b6\u6784\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6355\u6349\u590d\u6742\u4ea4\u4e92\u3002", "method": "\u4f7f\u7528\u5355\u4e00\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u5bf9\u8f93\u5165\u8f93\u51fa\u68af\u5ea6\u65bd\u52a0$L_{1}$\u6b63\u5219\u5316\uff0c\u53ef\u9002\u914d\u591a\u79cd\u67b6\u6784\uff08\u5982KAN\u3001MLP\u3001LSTM\uff09\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cGRNGC\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u8ba1\u7b97\u5f00\u9500\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "GRNGC\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\u91cd\u5efa\u7b49\u4efb\u52a1\u3002", "keywords": "\u795e\u7ecf\u683c\u5170\u6770\u56e0\u679c, \u68af\u5ea6\u6b63\u5219\u5316, \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b, \u57fa\u56e0\u8c03\u63a7\u7f51\u7edc"}}
{"id": "2507.11515", "pdf": "https://arxiv.org/pdf/2507.11515", "abs": "https://arxiv.org/abs/2507.11515", "authors": ["Shiyi Yang", "Xiaoxue Yu", "Rongpeng Li", "Jianhang Zhu", "Zhifeng Zhao", "Honggang Zhang"], "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 8 figures", "summary": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.", "AI": {"tldr": "AirLLM \u662f\u4e00\u79cd\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8fdc\u7a0b\u7cbe\u7ec6\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u6269\u6563\u6a21\u578b\uff0c\u52a8\u6001\u8c03\u6574LoRA\u79e9\u914d\u7f6e\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4f20\u8f93\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u8fb9\u7f18\u8bbe\u5907\u7684\u901a\u4fe1\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\uff0c\u4f20\u7edf\u7684LoRA\u65b9\u6cd5\u4f7f\u7528\u56fa\u5b9a\u6216\u542f\u53d1\u5f0f\u79e9\u914d\u7f6e\u4ee5\u53ca\u4f20\u8f93\u6240\u6709LoRA\u53c2\u6570\u7684\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u8fdc\u7a0b\u7cbe\u7ec6\u8c03\u4f18\u65b9\u6848\u3002", "method": "AirLLM \u91c7\u7528\u5206\u5c42\u6269\u6563\u7b56\u7565\u6846\u67b6\uff0c\u5c06\u79e9\u914d\u7f6e\u5efa\u6a21\u4e3a\u7ed3\u6784\u5316\u52a8\u4f5c\u5411\u91cf\uff0c\u901a\u8fc7PPO\u751f\u6210\u7c97\u7c92\u5ea6\u51b3\u7b56\uff0c\u518d\u901a\u8fc7DDIM\u7ec6\u5316\uff0c\u6700\u7ec8\u751f\u6210\u4efb\u52a1\u548c\u4fe1\u9053\u81ea\u9002\u5e94\u7684\u79e9\u5411\u91cf\u3002", "result": "\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u4e0b\u7684\u5b9e\u9a8c\u4e2d\uff0cAirLLM \u663e\u8457\u63d0\u5347\u4e86\u7cbe\u7ec6\u8c03\u4f18\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u4f20\u8f93\u6210\u672c\u3002", "conclusion": "AirLLM \u5c55\u793a\u4e86\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u6269\u6563\u6a21\u578b\u5728\u8fdc\u7a0b\u7cbe\u7ec6\u8c03\u4f18\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548LLM\u64cd\u4f5c\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09, \u8fb9\u7f18\u8bbe\u5907, \u8fdc\u7a0b\u7cbe\u7ec6\u8c03\u4f18, LoRA, PPO, DDIM, \u5206\u5c42\u6269\u6563\u7b56\u7565"}}
{"id": "2507.11181", "pdf": "https://arxiv.org/pdf/2507.11181", "abs": "https://arxiv.org/abs/2507.11181", "authors": ["Danyang Zhang", "Junhao Song", "Ziqian Bi", "Yingfang Yuan", "Tianyang Wang", "Joe Yeong", "Junfeng Hao"], "title": "Mixture of Experts in Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a comprehensive review of the Mixture-of-Experts (MoE)\narchitecture in large language models, highlighting its ability to\nsignificantly enhance model performance while maintaining minimal computational\noverhead. Through a systematic analysis spanning theoretical foundations, core\narchitectural designs, and large language model (LLM) applications, we examine\nexpert gating and routing mechanisms, hierarchical and sparse MoE\nconfigurations, meta-learning approaches, multimodal and multitask learning\nscenarios, real-world deployment cases, and recent advances and challenges in\ndeep learning. Our analysis identifies key advantages of MoE, including\nsuperior model capacity compared to equivalent Bayesian approaches, improved\ntask-specific performance, and the ability to scale model capacity efficiently.\nWe also underscore the importance of ensuring expert diversity, accurate\ncalibration, and reliable inference aggregation, as these are essential for\nmaximizing the effectiveness of MoE architectures. Finally, this review\noutlines current research limitations, open challenges, and promising future\ndirections, providing a foundation for continued innovation in MoE architecture\nand its applications.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u67b6\u6784\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u5206\u6790\u4e86\u5176\u4f18\u52bf\u3001\u914d\u7f6e\u3001\u6311\u6218\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8MoE\u67b6\u6784\u5982\u4f55\u63d0\u5347\u6a21\u578b\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u7cfb\u7edf\u5316\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u3001\u67b6\u6784\u8bbe\u8ba1\u548c\u5e94\u7528\u6848\u4f8b\uff0c\u7814\u7a76MoE\u7684\u4e13\u5bb6\u95e8\u63a7\u3001\u8def\u7531\u673a\u5236\u53ca\u591a\u4efb\u52a1\u5b66\u4e60\u3002", "result": "\u53d1\u73b0MoE\u5728\u6a21\u578b\u5bb9\u91cf\u3001\u4efb\u52a1\u6027\u80fd\u53ca\u6269\u5c55\u6027\u65b9\u9762\u4f18\u4e8e\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u4f46\u9700\u89e3\u51b3\u4e13\u5bb6\u591a\u6837\u6027\u548c\u63a8\u7406\u805a\u5408\u95ee\u9898\u3002", "conclusion": "MoE\u67b6\u6784\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u4ecd\u9762\u4e34\u7814\u7a76\u5c40\u9650\u548c\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u521b\u65b0\u3002", "keywords": "\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u3001\u5927\u8bed\u8a00\u6a21\u578b\u3001\u4e13\u5bb6\u95e8\u63a7\u3001\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u6df1\u5ea6\u5b66\u4e60"}}
{"id": "2507.10602", "pdf": "https://arxiv.org/pdf/2507.10602", "abs": "https://arxiv.org/abs/2507.10602", "authors": ["Maximilian St\u00f6lzle", "T. Konstantin Rusch", "Zach J. Patterson", "Rodrigo P\u00e9rez-Dattari", "Francesco Stella", "Josie Hughes", "Cosimo Della Santina", "Daniela Rus"], "title": "Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees", "categories": ["cs.RO", "cs.AI"], "comment": "73 pages", "summary": "Learning from demonstration provides a sample-efficient approach to acquiring\ncomplex behaviors, enabling robots to move robustly, compliantly, and with\nfluidity. In this context, Dynamic Motion Primitives offer built - in stability\nand robustness to disturbances but often struggle to capture complex periodic\nbehaviors. Moreover, they are limited in their ability to interpolate between\ndifferent tasks. These shortcomings substantially narrow their applicability,\nexcluding a wide class of practically meaningful tasks such as locomotion and\nrhythmic tool use. In this work, we introduce Orbitally Stable Motion\nPrimitives (OSMPs) - a framework that combines a learned diffeomorphic encoder\nwith a supercritical Hopf bifurcation in latent space, enabling the accurate\nacquisition of periodic motions from demonstrations while ensuring formal\nguarantees of orbital stability and transverse contraction. Furthermore, by\nconditioning the bijective encoder on the task, we enable a single learned\npolicy to represent multiple motion objectives, yielding consistent zero-shot\ngeneralization to unseen motion objectives within the training distribution. We\nvalidate the proposed approach through extensive simulation and real-world\nexperiments across a diverse range of robotic platforms - from collaborative\narms and soft manipulators to a bio-inspired rigid-soft turtle robot -\ndemonstrating its versatility and effectiveness in consistently outperforming\nstate-of-the-art baselines such as diffusion policies, among others.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5Orbitally Stable Motion Primitives (OSMPs)\uff0c\u7528\u4e8e\u89e3\u51b3Dynamic Motion Primitives\u5728\u6355\u6349\u590d\u6742\u5468\u671f\u6027\u884c\u4e3a\u548c\u4efb\u52a1\u95f4\u63d2\u503c\u65f6\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u5230\u7684\u5fae\u5206\u540c\u80da\u7f16\u7801\u5668\u548c\u8d85\u4e34\u754cHopf\u5206\u5c94\uff0c\u5b9e\u73b0\u4e86\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u5468\u671f\u6027\u8fd0\u52a8\u5b66\u4e60\u3002", "motivation": "Dynamic Motion Primitives\u5728\u6355\u6349\u590d\u6742\u5468\u671f\u6027\u884c\u4e3a\u548c\u4efb\u52a1\u95f4\u63d2\u503c\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86OSMPs\u6846\u67b6\u3002", "method": "\u7ed3\u5408\u5b66\u4e60\u5230\u7684\u5fae\u5206\u540c\u80da\u7f16\u7801\u5668\u548c\u8d85\u4e34\u754cHopf\u5206\u5c94\uff0c\u901a\u8fc7\u4efb\u52a1\u6761\u4ef6\u5316\u7684\u53cc\u5c04\u7f16\u7801\u5668\u5b9e\u73b0\u591a\u8fd0\u52a8\u76ee\u6807\u7684\u7edf\u4e00\u8868\u793a\u3002", "result": "OSMPs\u5728\u4eff\u771f\u548c\u771f\u5b9e\u673a\u5668\u4eba\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u4f18\u5f02\u6027\u80fd\uff0c\u80fd\u591f\u96f6\u6837\u672c\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u8fd0\u52a8\u76ee\u6807\uff0c\u5e76\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OSMPs\u4e3a\u5b66\u4e60\u590d\u6742\u7684\u5468\u671f\u6027\u8fd0\u52a8\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u4eba\u884c\u4e3a\u7684\u9002\u5e94\u6027\u548c\u8868\u73b0\u529b\u3002", "keywords": "Learning from demonstration, Dynamic Motion Primitives, Orbital Stability, Hopf bifurcation, zero-shot generalization"}}
{"id": "2507.11183", "pdf": "https://arxiv.org/pdf/2507.11183", "abs": "https://arxiv.org/abs/2507.11183", "authors": ["Dimitrios Kritsiolis", "Constantine Kotropoulos"], "title": "Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications", "categories": ["cs.LG"], "comment": "In Proceedings of the 2025 IARIA Annual Congress on Frontiers in\n  Science, Technology, Services, and Applications (IARIA Congress 2025),\n  Venice, Italy, July 6-10, 2025", "summary": "Federated learning is a machine learning approach that enables multiple\ndevices (i.e., agents) to train a shared model cooperatively without exchanging\nraw data. This technique keeps data localized on user devices, ensuring privacy\nand security, while each agent trains the model on their own data and only\nshares model updates. The communication overhead is a significant challenge due\nto the frequent exchange of model updates between the agents and the central\nserver. In this paper, we propose a communication-efficient federated learning\nscheme that utilizes low-rank approximation of neural network gradients and\nquantization to significantly reduce the network load of the decentralized\nlearning process with minimal impact on the model's accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6848\uff0c\u901a\u8fc7\u4f4e\u79e9\u8fd1\u4f3c\u548c\u91cf\u5316\u6280\u672f\u663e\u8457\u964d\u4f4e\u7f51\u7edc\u8d1f\u8f7d\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u9891\u7e41\u4ea4\u6362\u6a21\u578b\u66f4\u65b0\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u5927\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u9ad8\u6548\u901a\u4fe1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u68af\u5ea6\u7684\u4f4e\u79e9\u8fd1\u4f3c\u548c\u91cf\u5316\u6280\u672f\u6765\u51cf\u5c11\u901a\u4fe1\u6570\u636e\u91cf\u3002", "result": "\u663e\u8457\u964d\u4f4e\u4e86\u7f51\u7edc\u8d1f\u8f7d\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u7cbe\u5ea6\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6027\u80fd\u3002", "keywords": "\u8054\u90a6\u5b66\u4e60,\u4f4e\u79e9\u8fd1\u4f3c,\u91cf\u5316,\u901a\u4fe1\u6548\u7387"}}
{"id": "2507.11185", "pdf": "https://arxiv.org/pdf/2507.11185", "abs": "https://arxiv.org/abs/2507.11185", "authors": ["Md. Emon Akter Sourov", "Md. Sabbir Hossen", "Pabon Shaha", "Mohammad Minoar Hossain", "Md Sadiq Iqbal"], "title": "An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted at the IEEE QPAIN 2025. The final\n  version will be available in the IEEE Xplore Digital Library", "summary": "Heart disease remains a major global health concern, particularly in regions\nwith limited access to medical resources and diagnostic facilities. Traditional\ndiagnostic methods often fail to accurately identify and manage heart disease\nrisks, leading to adverse outcomes. Machine learning has the potential to\nsignificantly enhance the accuracy, efficiency, and speed of heart disease\ndiagnosis. In this study, we proposed a comprehensive framework that combines\nclassification models for heart disease detection and regression models for\nrisk prediction. We employed the Heart Disease dataset, which comprises 1,035\ncases. To address the issue of class imbalance, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, resulting in the generation of an\nadditional 100,000 synthetic data points. Performance metrics, including\naccuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to\nevaluate the model's effectiveness. Among the classification models, Random\nForest emerged as the standout performer, achieving an accuracy of 97.2% on\nreal data and 97.6% on synthetic data. For regression tasks, Linear Regression\ndemonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic\ndatasets, respectively, with the lowest error metrics. Additionally,\nExplainable AI techniques were employed to enhance the interpretability of the\nmodels. This study highlights the potential of machine learning to\nrevolutionize heart disease diagnosis and risk prediction, thereby facilitating\nearly intervention and enhancing clinical decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5206\u7c7b\u548c\u56de\u5f52\u6a21\u578b\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5fc3\u810f\u75c5\u7684\u68c0\u6d4b\u548c\u98ce\u9669\u9884\u6d4b\uff0c\u4f7f\u7528SMOTE\u6280\u672f\u89e3\u51b3\u4e86\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u968f\u673a\u68ee\u6797\u548c\u7ebf\u6027\u56de\u5f52\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u4f20\u7edf\u5fc3\u810f\u75c5\u8bca\u65ad\u65b9\u6cd5\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u673a\u5668\u5b66\u4e60\u53ef\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u7ed3\u5408\u5206\u7c7b\u548c\u56de\u5f52\u6a21\u578b\uff0c\u4f7f\u7528SMOTE\u6280\u672f\u751f\u6210\u5408\u6210\u6570\u636e\uff0c\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u51c6\u786e\u738797.2%\uff0c\u7ebf\u6027\u56de\u5f52R2\u503c0.992\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u53ef\u9769\u65b0\u5fc3\u810f\u75c5\u8bca\u65ad\u4e0e\u98ce\u9669\u9884\u6d4b\uff0c\u652f\u6301\u65e9\u671f\u5e72\u9884\u3002", "keywords": "\u5fc3\u810f\u75c5\u8bca\u65ad, \u673a\u5668\u5b66\u4e60, SMOTE, \u968f\u673a\u68ee\u6797, \u7ebf\u6027\u56de\u5f52"}}
{"id": "2507.11187", "pdf": "https://arxiv.org/pdf/2507.11187", "abs": "https://arxiv.org/abs/2507.11187", "authors": ["Shao-Bo Lin", "Xiaotong Liu", "Yao Wang"], "title": "Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms", "categories": ["cs.LG"], "comment": null, "summary": "Online collaborative medical prediction platforms offer convenience and\nreal-time feedback by leveraging massive electronic health records. However,\ngrowing concerns about privacy and low prediction quality can deter patient\nparticipation and doctor cooperation. In this paper, we first clarify the\nprivacy attacks, namely attribute attacks targeting patients and model\nextraction attacks targeting doctors, and specify the corresponding privacy\nprinciples. We then propose a privacy-preserving mechanism and integrate it\ninto a novel one-shot distributed learning framework, aiming to simultaneously\nmeet both privacy requirements and prediction performance objectives. Within\nthe framework of statistical learning theory, we theoretically demonstrate that\nthe proposed distributed learning framework can achieve the optimal prediction\nperformance under specific privacy requirements. We further validate the\ndeveloped privacy-preserving collaborative medical prediction platform through\nboth toy simulations and real-world data experiments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9690\u79c1\u4fdd\u62a4\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5728\u7ebf\u534f\u4f5c\u533b\u7597\u9884\u6d4b\u5e73\u53f0\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5e76\u4fdd\u8bc1\u4e86\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u533b\u7597\u9884\u6d4b\u5e73\u53f0\u4e2d\u60a3\u8005\u9690\u79c1\u548c\u6570\u636e\u8d28\u91cf\u95ee\u9898\uff0c\u4ee5\u4fc3\u8fdb\u60a3\u8005\u548c\u533b\u751f\u7684\u53c2\u4e0e\u3002", "method": "\u63d0\u51fa\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u5e76\u96c6\u6210\u5230\u4e00\u6b21\u6027\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u6700\u4f18\u6027\u3002", "result": "\u5728\u73a9\u5177\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u9884\u6d4b\u6027\u80fd\u7684\u53cc\u91cd\u76ee\u6807\u3002", "conclusion": "\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\u80fd\u540c\u65f6\u6ee1\u8db3\u9690\u79c1\u9700\u6c42\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u4fc3\u8fdb\u534f\u4f5c\u533b\u7597\u5e73\u53f0\u7684\u53d1\u5c55\u3002", "keywords": "\u9690\u79c1\u4fdd\u62a4,\u5206\u5e03\u5f0f\u5b66\u4e60,\u533b\u7597\u9884\u6d4b,\u534f\u4f5c\u5e73\u53f0"}}
{"id": "2507.10607", "pdf": "https://arxiv.org/pdf/2507.10607", "abs": "https://arxiv.org/abs/2507.10607", "authors": ["Qian Qi"], "title": "Neural Expectation Operators", "categories": ["math.PR", "cs.AI", "cs.LG"], "comment": null, "summary": "This paper introduces \\textbf{Measure Learning}, a paradigm for modeling\nambiguity via non-linear expectations. We define Neural Expectation Operators\nas solutions to Backward Stochastic Differential Equations (BSDEs) whose\ndrivers are parameterized by neural networks. The main mathematical\ncontribution is a rigorous well-posedness theorem for BSDEs whose drivers\nsatisfy a local Lipschitz condition in the state variable $y$ and quadratic\ngrowth in its martingale component $z$. This result circumvents the classical\nglobal Lipschitz assumption, is applicable to common neural network\narchitectures (e.g., with ReLU activations), and holds for exponentially\nintegrable terminal data, which is the sharp condition for this setting. Our\nprimary innovation is to build a constructive bridge between the abstract, and\noften restrictive, assumptions of the deep theory of quadratic BSDEs and the\nworld of machine learning, demonstrating that these conditions can be met by\nconcrete, verifiable neural network designs. We provide constructive methods\nfor enforcing key axiomatic properties, such as convexity, by architectural\ndesign. The theory is extended to the analysis of fully coupled\nForward-Backward SDE systems and to the asymptotic analysis of large\ninteracting particle systems, for which we establish both a Law of Large\nNumbers (propagation of chaos) and a Central Limit Theorem. This work provides\nthe foundational mathematical framework for data-driven modeling under\nambiguity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6d4b\u91cf\u5b66\u4e60\u201d\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u671f\u671b\u5efa\u6a21\u6a21\u7cca\u6027\uff0c\u5e76\u5b9a\u4e49\u795e\u7ecf\u671f\u671b\u7b97\u5b50\u4f5c\u4e3aBSDE\u7684\u89e3\u3002\u5176\u6838\u5fc3\u6570\u5b66\u8d21\u732e\u662f\u89e3\u51b3\u4e86\u5c40\u90e8Lipschitz\u6761\u4ef6\u4e0b\u7684BSDE\u9002\u5b9a\u6027\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u5230\u673a\u5668\u5b66\u4e60\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u3002", "motivation": "\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u6570\u5b66\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u6ee1\u8db3\u590d\u6742BSDE\u7684\u7406\u8bba\u6761\u4ef6\uff0c\u4ece\u800c\u5c06\u7406\u8bba\u5206\u6790\u4e0e\u673a\u5668\u5b66\u4e60\u5b9e\u8df5\u7ed3\u5408\u3002", "method": "\u5b9a\u4e49\u795e\u7ecf\u671f\u671b\u7b97\u5b50\u4f5c\u4e3a\u6ee1\u8db3\u5c40\u90e8Lipschitz\u6761\u4ef6\u548c\u4e8c\u6b21\u589e\u957f\u6761\u4ef6\u7684BSDE\u7684\u89e3\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u9a71\u52a8\u51fd\u6570\u3002\u63d0\u4f9b\u6784\u9020\u6027\u65b9\u6cd5\u5b9e\u73b0\u51f8\u6027\u7b49\u6027\u8d28\u3002", "result": "\u8bc1\u660e\u4e86\u5c40\u90e8Lipschitz\u6761\u4ef6\u4e0b\u7684BSDE\u9002\u5b9a\u6027\uff0c\u5e76\u6269\u5c55\u5230\u5b8c\u5168\u8026\u5408\u7684\u524d\u5411-\u540e\u5411SDE\u7cfb\u7edf\u53ca\u5927\u5c3a\u5ea6\u4ea4\u4e92\u7c92\u5b50\u7cfb\u7edf\u7684\u6e10\u8fd1\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u5927\u6570\u5b9a\u5f8b\u548c\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u3002", "conclusion": "\u4e3a\u6570\u636e\u9a71\u52a8\u7684\u6a21\u7cca\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u6570\u5b66\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u6865\u6881\u3002", "keywords": "\u6d4b\u91cf\u5b66\u4e60, BSDE, \u795e\u7ecf\u671f\u671b\u7b97\u5b50, \u5c40\u90e8Lipschitz\u6761\u4ef6, \u673a\u5668\u5b66\u4e60"}}
{"id": "2507.11228", "pdf": "https://arxiv.org/pdf/2507.11228", "abs": "https://arxiv.org/abs/2507.11228", "authors": ["Si Yi Meng", "Baptiste Goujaud", "Antonio Orvieto", "Christopher De Sa"], "title": "Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Gradient descent (GD) on logistic regression has many fascinating properties.\nWhen the dataset is linearly separable, it is known that the iterates converge\nin direction to the maximum-margin separator regardless of how large the step\nsize is. In the non-separable case, however, it has been shown that GD can\nexhibit a cycling behaviour even when the step sizes is still below the\nstability threshold $2/\\lambda$, where $\\lambda$ is the largest eigenvalue of\nthe Hessian at the solution. This short paper explores whether restricting the\ndata to have equal magnitude is a sufficient condition for global convergence,\nunder any step size below the stability threshold. We prove that this is true\nin a one dimensional space, but in higher dimensions cycling behaviour can\nstill occur. We hope to inspire further studies on quantifying how common these\ncycles are in realistic datasets, as well as finding sufficient conditions to\nguarantee global convergence with large step sizes.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u903b\u8f91\u56de\u5f52\u4e2d\u68af\u5ea6\u4e0b\u964d\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u6536\u655b\u6027\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7b49\u5e45\u6761\u4ef6\u4e0b\u662f\u5426\u80fd\u4fdd\u8bc1\u5168\u5c40\u6536\u655b\u3002", "motivation": "\u63a2\u8ba8\u68af\u5ea6\u4e0b\u964d\u5728\u903b\u8f91\u56de\u5f52\u4e2d\u7684\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u5728\u975e\u53ef\u5206\u6570\u636e\u96c6\u4e0a\u7684\u5faa\u73af\u884c\u4e3a\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u6570\u636e\u7b49\u5e45\u6761\u4ef6\u907f\u514d\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u4e86\u4e00\u7ef4\u4e0e\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u68af\u5ea6\u4e0b\u964d\u7684\u884c\u4e3a\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6570\u636e\u7b49\u5e45\u6761\u4ef6\u7684\u5f71\u54cd\u3002", "result": "\u5728\u4e00\u7ef4\u7a7a\u95f4\u4e2d\u7b49\u5e45\u6570\u636e\u53ef\u4fdd\u8bc1\u5168\u5c40\u6536\u655b\uff0c\u4f46\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u4ecd\u53ef\u80fd\u51fa\u73b0\u5faa\u73af\u884c\u4e3a\u3002", "conclusion": "\u8868\u660e\u6570\u636e\u7b49\u5e45\u6761\u4ef6\u4e0d\u8db3\u4ee5\u5728\u9ad8\u7ef4\u4e2d\u4fdd\u8bc1\u5168\u5c40\u6536\u655b\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5b9e\u9645\u6570\u636e\u4e2d\u7684\u5faa\u73af\u884c\u4e3a\u53ca\u6536\u655b\u6761\u4ef6\u3002", "keywords": "\u68af\u5ea6\u4e0b\u964d, \u903b\u8f91\u56de\u5f52, \u6700\u5927\u95f4\u9694, \u5168\u5c40\u6536\u655b, \u5faa\u73af\u884c\u4e3a"}}
{"id": "2507.10610", "pdf": "https://arxiv.org/pdf/2507.10610", "abs": "https://arxiv.org/abs/2507.10610", "authors": ["Zihe Yan", "Zhuosheng Zhang"], "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages, 9 figures", "summary": "Graphical user interface (GUI) agents built on multimodal large language\nmodels (MLLMs) have recently demonstrated strong decision-making abilities in\nscreen-based interaction tasks. However, they remain highly vulnerable to\npop-up-based environmental injection attacks, where malicious visual elements\ndivert model attention and lead to unsafe or incorrect actions. Existing\ndefense methods either require costly retraining or perform poorly under\ninductive interference. In this work, we systematically study how such attacks\nalter the attention behavior of GUI agents and uncover a layer-wise attention\ndivergence pattern between correct and incorrect outputs. Based on this\ninsight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that\nselectively amplifies attention and MLP modules in critical layers. LaSM\nimproves the alignment between model saliency and task-relevant regions without\nadditional training. Extensive experiments across 12 types of pop-up\nperturbations and 4 different model backbones show that LaSM consistently\nenhances the defense success rate. When combined with prompt-level alerts, LaSM\nachieves over 98\\% robustness even under strong inductive attacks. Our findings\nreveal that attention misalignment is a core vulnerability in MLLM agents and\ncan be effectively addressed through selective layer-wise modulation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u4ee3\u7406\u5728\u9762\u5bf9\u5f39\u51fa\u5f0f\u73af\u5883\u6ce8\u5165\u653b\u51fb\u65f6\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u5c42\u95f4\u7f29\u653e\u673a\u5236\uff08LaSM\uff09\u6765\u589e\u5f3a\u6a21\u578b\u7684\u9632\u5fa1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u5728\u5c4f\u5e55\u4ea4\u4e92\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u6076\u610f\u89c6\u89c9\u5143\u7d20\u7684\u5f39\u51fa\u653b\u51fb\u9ad8\u5ea6\u8106\u5f31\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u9ad8\u6210\u672c\u91cd\u65b0\u8bad\u7ec3\uff0c\u8981\u4e48\u5728\u5f52\u7eb3\u5e72\u6270\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u6ce8\u610f\u529b\u884c\u4e3a\u6765\u63d0\u5347\u9632\u5fa1\u80fd\u529b\u6210\u4e3a\u5173\u952e\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5206\u6790\u653b\u51fb\u5bf9GUI\u4ee3\u7406\u6ce8\u610f\u529b\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6b63\u786e\u548c\u9519\u8bef\u8f93\u51fa\u4e4b\u95f4\u5b58\u5728\u5c42\u95f4\u6ce8\u610f\u529b\u5dee\u5f02\u6a21\u5f0f\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5c42\u95f4\u7f29\u653e\u673a\u5236\uff08LaSM\uff09\uff0c\u9009\u62e9\u6027\u653e\u5927\u5173\u952e\u5c42\u7684\u6ce8\u610f\u529b\u548cMLP\u6a21\u5757\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u6a21\u578b\u5bf9\u4efb\u52a1\u76f8\u5173\u533a\u57df\u7684\u5173\u6ce8\u3002", "result": "\u572812\u79cd\u5f39\u51fa\u6270\u52a8\u548c4\u79cd\u6a21\u578b\u4e3b\u5e72\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLaSM\u80fd\u663e\u8457\u63d0\u9ad8\u9632\u5fa1\u6210\u529f\u7387\uff0c\u7ed3\u5408\u63d0\u793a\u7ea7\u8b66\u62a5\u540e\uff0c\u5373\u4f7f\u5728\u5f3a\u5f52\u7eb3\u653b\u51fb\u4e0b\u4e5f\u80fd\u8fbe\u523098%\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u6ce8\u610f\u529b\u4e0d\u5339\u914d\u662fMLLM\u4ee3\u7406\u7684\u6838\u5fc3\u6f0f\u6d1e\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5c42\u95f4\u8c03\u5236\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "keywords": "GUI\u4ee3\u7406,\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b,\u6ce8\u610f\u529b\u673a\u5236,\u5f39\u51fa\u653b\u51fb,\u9632\u5fa1\u65b9\u6cd5"}}
{"id": "2507.11246", "pdf": "https://arxiv.org/pdf/2507.11246", "abs": "https://arxiv.org/abs/2507.11246", "authors": ["Lingwei Kong", "Lu Wang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "title": "Generative Click-through Rate Prediction with Applications to Search Advertising", "categories": ["cs.LG"], "comment": "This work was first submitted on February 9, 2024", "summary": "Click-Through Rate (CTR) prediction models are integral to a myriad of\nindustrial settings, such as personalized search advertising. Current methods\ntypically involve feature extraction from users' historical behavior sequences\ncombined with product information, feeding into a discriminative model that is\ntrained on user feedback to estimate CTR. With the success of models such as\nGPT, the potential for generative models to enrich expressive power beyond\ndiscriminative models has become apparent. In light of this, we introduce a\nnovel model that leverages generative models to enhance the precision of CTR\npredictions in discriminative models. To reconcile the disparate data\naggregation needs of both model types, we design a two-stage training process:\n1) Generative pre-training for next-item prediction with the given item\ncategory in user behavior sequences; 2) Fine-tuning the well-trained generative\nmodel within a discriminative CTR prediction framework. Our method's efficacy\nis substantiated through extensive experiments on a new dataset, and its\nsignificant utility is further corroborated by online A/B testing results.\nCurrently, the model is deployed on one of the world's largest e-commerce\nplatforms, and we intend to release the associated code and dataset in the\nfuture.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u6210\u6a21\u578b\u63d0\u5347\u70b9\u51fb\u7387\u9884\u6d4b\u7cbe\u5ea6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5c06\u751f\u6210\u6a21\u578b\u4e0e\u5224\u522b\u6a21\u578b\u7ed3\u5408\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u70b9\u51fb\u7387\u9884\u6d4b\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u5224\u522b\u6a21\u578b\uff0c\u751f\u6210\u6a21\u578b\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u6709\u6f5c\u529b\u8d85\u8d8a\u5224\u522b\u6a21\u578b\uff0c\u56e0\u6b64\u63a2\u7d22\u751f\u6210\u6a21\u578b\u5728\u70b9\u51fb\u7387\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a1)\u751f\u6210\u6a21\u578b\u9884\u8bad\u7ec3\u7528\u4e8e\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u4e0b\u4e00\u9879\u9884\u6d4b\uff1b2)\u5728\u5224\u522b\u6a21\u578b\u6846\u67b6\u4e2d\u5bf9\u751f\u6210\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u5e76\u5df2\u90e8\u7f72\u5728\u5168\u7403\u6700\u5927\u7535\u5546\u5e73\u53f0\u4e4b\u4e00\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u80fd\u663e\u8457\u63d0\u5347\u70b9\u51fb\u7387\u9884\u6d4b\u7cbe\u5ea6\uff0c\u672a\u6765\u5c06\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002", "keywords": "\u70b9\u51fb\u7387\u9884\u6d4b,\u751f\u6210\u6a21\u578b,\u5224\u522b\u6a21\u578b,\u4e24\u9636\u6bb5\u8bad\u7ec3,\u7535\u5b50\u5546\u52a1"}}
{"id": "2507.11262", "pdf": "https://arxiv.org/pdf/2507.11262", "abs": "https://arxiv.org/abs/2507.11262", "authors": ["Elmira Mirzabeigi", "Sepehr Rezaee", "Kourosh Parand"], "title": "LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Training deep neural networks, particularly in computer vision tasks, often\nsuffers from noisy gradients and unstable convergence, which hinder performance\nand generalization. In this paper, we propose LyAm, a novel optimizer that\nintegrates Adam's adaptive moment estimation with Lyapunov-based stability\nmechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability\ntheory to enhance convergence robustness and mitigate training noise. We\nprovide a rigorous theoretical framework proving the convergence guarantees of\nLyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10\nand CIFAR-100 show that LyAm consistently outperforms state-of-the-art\noptimizers in terms of accuracy, convergence speed, and stability, establishing\nit as a strong candidate for robust deep learning optimization.", "AI": {"tldr": "\u63d0\u51faLyAm\u4f18\u5316\u5668\uff0c\u7ed3\u5408Adam\u548cLyapunov\u7a33\u5b9a\u6027\u7406\u8bba\uff0c\u63d0\u5347\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u68af\u5ea6\u566a\u58f0\u548c\u6536\u655b\u4e0d\u7a33\u5b9a\u95ee\u9898\u5f71\u54cd\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faLyAm\u4f18\u5316\u5668\uff0c\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u901a\u8fc7Lyapunov\u7a33\u5b9a\u6027\u7406\u8bba\u589e\u5f3a\u6536\u655b\u9c81\u68d2\u6027\u3002", "result": "\u5728CIFAR-10\u548cCIFAR-100\u4e0a\u9a8c\u8bc1LyAm\u4f18\u4e8e\u73b0\u6709\u4f18\u5316\u5668\uff0c\u51c6\u786e\u6027\u3001\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u5747\u66f4\u4f18\u3002", "conclusion": "LyAm\u662f\u4e00\u79cd\u9c81\u68d2\u7684\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u5668\u3002", "keywords": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc,\u4f18\u5316\u5668,Lyapunov\u7a33\u5b9a\u6027,Adam,\u6536\u655b\u6027"}}
{"id": "2507.11269", "pdf": "https://arxiv.org/pdf/2507.11269", "abs": "https://arxiv.org/abs/2507.11269", "authors": ["Tal Fiskus", "Uri Shaham"], "title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound", "categories": ["cs.LG", "cs.AI"], "comment": "51 pages, 16 figures", "summary": "Deep reinforcement learning (DRL) agents excel in solving complex\ndecision-making tasks across various domains. However, they often require a\nsubstantial number of training steps and a vast experience replay buffer,\nleading to significant computational and resource demands. To address these\nchallenges, we introduce a novel theoretical result that leverages the\nNeyman-Rubin potential outcomes framework into DRL. Unlike most methods that\nfocus on bounding the counterfactual loss, we establish a causal bound on the\nfactual loss, which is analogous to the on-policy loss in DRL. This bound is\ncomputed by storing past value network outputs in the experience replay buffer,\neffectively utilizing data that is usually discarded. Extensive experiments\nacross the Atari 2600 and MuJoCo domains on various agents, such as DQN and\nSAC, achieve up to 2,427% higher reward ratio, outperforming the same agents\nwithout our proposed term, and reducing the experience replay buffer size by up\nto 96%, significantly improving sample efficiency at negligible cost.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eNeyman-Rubin\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed1\u5b9a\u4e8b\u5b9e\u635f\u5931\uff08\u7c7b\u4f3c\u4e8eDRL\u4e2d\u7684\u5728\u7ebf\u7b56\u7565\u635f\u5931\uff09\u6765\u51cf\u5c11\u8bad\u7ec3\u6b65\u9aa4\u548c\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u7684\u9700\u6c42\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Atari 2600\u548cMuJoCo\u9886\u57df\u663e\u8457\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u5956\u52b1\u6bd4\u4f8b\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u6b65\u9aa4\u548c\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\uff0c\u5bfc\u81f4\u8ba1\u7b97\u548c\u8d44\u6e90\u9700\u6c42\u8f83\u9ad8\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u5229\u7528Neyman-Rubin\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u6765\u4f18\u5316DRL\u7684\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5c06Neyman-Rubin\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u5f15\u5165DRL\uff0c\u4f5c\u8005\u5efa\u7acb\u4e86\u4e00\u4e2a\u5173\u4e8e\u4e8b\u5b9e\u635f\u5931\u7684\u56e0\u679c\u754c\u9650\uff0c\u5e76\u5229\u7528\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u4e2d\u5b58\u50a8\u7684\u8fc7\u53bb\u503c\u7f51\u7edc\u8f93\u51fa\u6765\u8ba1\u7b97\u8fd9\u4e00\u754c\u9650\u3002\u8fd9\u79cd\u65b9\u6cd5\u907f\u514d\u4e86\u901a\u5e38\u88ab\u4e22\u5f03\u7684\u6570\u636e\u6d6a\u8d39\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Atari 2600\u548cMuJoCo\u9886\u57df\u7684\u591a\u79cd\u4ee3\u7406\uff08\u5982DQN\u548cSAC\uff09\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe2,427%\u7684\u5956\u52b1\u6bd4\u4f8b\u63d0\u5347\uff0c\u4e14\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u5927\u5c0f\u51cf\u5c11\u4e8696%\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u51cf\u5c11\u8ba1\u7b97\u548c\u8d44\u6e90\u9700\u6c42\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "keywords": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60, Neyman-Rubin\u6f5c\u5728\u7ed3\u679c\u6846\u67b6, \u4e8b\u5b9e\u635f\u5931, \u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a, \u6837\u672c\u6548\u7387"}}
{"id": "2507.11274", "pdf": "https://arxiv.org/pdf/2507.11274", "abs": "https://arxiv.org/abs/2507.11274", "authors": ["Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren"], "title": "Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "27 pages", "summary": "We study population convergence guarantees of stochastic gradient descent\n(SGD) for smooth convex objectives in the interpolation regime, where the noise\nat optimum is zero or near zero. The behavior of the last iterate of SGD in\nthis setting -- particularly with large (constant) stepsizes -- has received\ngrowing attention in recent years due to implications for the training of\nover-parameterized models, as well as to analyzing forgetting in continual\nlearning and to understanding the convergence of the randomized Kaczmarz method\nfor solving linear systems. We establish that after $T$ steps of SGD on\n$\\beta$-smooth convex loss functions with stepsize $\\eta \\leq 1/\\beta$, the\nlast iterate exhibits expected excess risk $\\widetilde{O}(1/(\\eta\nT^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$, where\n$\\sigma_\\star^2$ denotes the variance of the stochastic gradients at the\noptimum. In particular, for a well-tuned stepsize we obtain a near optimal\n$\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$ rate for the last iterate,\nextending the results of Varre et al. (2021) beyond least squares regression;\nand when $\\sigma_\\star=0$ we obtain a rate of $O(1/\\sqrt{T})$ with\n$\\eta=1/\\beta$, improving upon the best-known $O(T^{-1/4})$ rate recently\nestablished by Evron et al. (2025) in the special case of realizable linear\nregression.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u5728\u5e73\u6ed1\u51f8\u76ee\u6807\u51fd\u6570\u7684\u63d2\u503c\u6a21\u5f0f\u4e0b\u7684\u4eba\u53e3\u6536\u655b\u6027\uff0c\u7279\u522b\u662f\u5728\u6700\u4f18\u89e3\u9644\u8fd1\u566a\u58f0\u4e3a\u96f6\u6216\u63a5\u8fd1\u96f6\u7684\u60c5\u51b5\u3002\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u4f18\u5316\u6b65\u9aa4\u5927\u5c0f\uff0cSGD\u7684\u6700\u7ec8\u8fed\u4ee3\u53ef\u4ee5\u63a5\u8fd1\u6700\u4f18\u6536\u655b\u901f\u7387\u3002", "motivation": "\u7814\u7a76SGD\u5728\u63d2\u503c\u6a21\u5f0f\u4e0b\u7684\u6700\u540e\u8fed\u4ee3\u884c\u4e3a\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u8bad\u7ec3\u3001\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9057\u5fd8\u95ee\u9898\u4ee5\u53ca\u968f\u673aKaczmarz\u65b9\u6cd5\u6c42\u89e3\u7ebf\u6027\u7cfb\u7edf\u7684\u5e94\u7528\u3002", "method": "\u5206\u6790SGD\u5728\u03b2-\u5e73\u6ed1\u51f8\u635f\u5931\u51fd\u6570\u4e0a\u7684\u6536\u655b\u6027\uff0c\u6b65\u9aa4\u5927\u5c0f\u4e3a\u03b7\u22641/\u03b2\uff0c\u5f97\u51fa\u6700\u540e\u8fed\u4ee3\u7684\u671f\u671b\u8d85\u989d\u98ce\u9669\u516c\u5f0f\u3002", "result": "\u901a\u8fc7\u4f18\u5316\u6b65\u9aa4\u5927\u5c0f\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6536\u655b\u901f\u7387\uff0c\u5c24\u5176\u5728\u566a\u58f0\u4e3a\u96f6\u65f6\uff0c\u6536\u655b\u901f\u7387\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7814\u7a76\u3002", "conclusion": "\u5728\u63d2\u503c\u6a21\u5f0f\u4e0b\uff0cSGD\u7684\u6700\u540e\u8fed\u4ee3\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7814\u7a76\uff0c\u5e76\u4e14\u901a\u8fc7\u8c03\u6574\u6b65\u9aa4\u5927\u5c0f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u6536\u655b\u901f\u7387\u3002", "keywords": "\u968f\u673a\u68af\u5ea6\u4e0b\u964d, \u51f8\u4f18\u5316, \u63d2\u503c\u6a21\u5f0f, \u6536\u655b\u901f\u7387, \u8fc7\u53c2\u6570\u5316\u6a21\u578b"}}
{"id": "2507.11344", "pdf": "https://arxiv.org/pdf/2507.11344", "abs": "https://arxiv.org/abs/2507.11344", "authors": ["Zara Hall", "Melanie Subbiah", "Thomas P Zollo", "Kathleen McKeown", "Richard Zemel"], "title": "Guiding LLM Decision-Making with Fairness Reward Models", "categories": ["cs.LG"], "comment": null, "summary": "Large language models are increasingly used to support high-stakes decisions,\npotentially influencing who is granted bail or receives a loan. Naive\nchain-of-thought sampling can improve average decision accuracy, but has also\nbeen shown to amplify unfair bias. To address this challenge and enable the\ntrustworthy use of reasoning models in high-stakes decision-making, we propose\na framework for training a generalizable Fairness Reward Model (FRM). Our model\nassigns a fairness score to LLM reasoning, enabling the system to down-weight\nbiased trajectories and favor equitable ones when aggregating decisions across\nreasoning chains. We show that a single Fairness Reward Model, trained on\nweakly supervised, LLM-annotated examples of biased versus unbiased reasoning,\ntransfers across tasks, domains, and model families without additional\nfine-tuning. Applied to real-world decision-making tasks including recidivism\nprediction and social media moderation, we show that our approach consistently\nimproves fairness while matching, or even surpassing, baseline accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u516c\u5e73\u6027\u5956\u52b1\u6a21\u578b\uff08FRM\uff09\uff0c\u7528\u4e8e\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4ee5\u51cf\u5c11\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u53ef\u80fd\u653e\u5927\u504f\u89c1\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u5176\u516c\u5e73\u4f7f\u7528\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u516c\u5e73\u6027\u5956\u52b1\u6a21\u578b\uff08FRM\uff09\uff0c\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u94fe\u8fdb\u884c\u8bc4\u5206\uff0c\u4ee5\u51cf\u5c11\u504f\u89c1\u5e76\u63d0\u5347\u516c\u5e73\u6027\u3002", "result": "FRM\u80fd\u591f\u8de8\u4efb\u52a1\u3001\u9886\u57df\u548c\u6a21\u578b\u5bb6\u65cf\u8fc1\u79fb\uff0c\u4e14\u5728\u771f\u5b9e\u51b3\u7b56\u4efb\u52a1\u4e2d\u63d0\u5347\u4e86\u516c\u5e73\u6027\u5e76\u4fdd\u6301\u6216\u8d85\u8d8a\u4e86\u57fa\u7ebf\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684FRM\u6846\u67b6\u662f\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u516c\u5e73\u6027\u3002", "keywords": "\u516c\u5e73\u6027\u5956\u52b1\u6a21\u578b, \u9ad8\u98ce\u9669\u51b3\u7b56, \u8bed\u8a00\u6a21\u578b, \u504f\u89c1\u51cf\u8f7b"}}
{"id": "2507.11357", "pdf": "https://arxiv.org/pdf/2507.11357", "abs": "https://arxiv.org/abs/2507.11357", "authors": ["Emile van Krieken", "Pasquale Minervini", "Edoardo Ponti", "Antonio Vergari"], "title": "Neurosymbolic Reasoning Shortcuts under the Independence Assumption", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at NeSy 2025", "summary": "The ubiquitous independence assumption among symbolic concepts in\nneurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors\nuse it to speed up probabilistic reasoning. Recent works like van Krieken et\nal. (2024) and Marconato et al. (2024) argued that the independence assumption\ncan hinder learning of NeSy predictors and, more crucially, prevent them from\ncorrectly modelling uncertainty. There is, however, scepticism in the NeSy\ncommunity around the scenarios in which the independence assumption actually\nlimits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle\nthis question by formally showing that assuming independence among symbolic\nconcepts entails that a model can never represent uncertainty over certain\nconcept combinations. Thus, the model fails to be aware of reasoning shortcuts,\ni.e., the pathological behaviour of NeSy predictors that predict correct\ndownstream tasks but for the wrong reasons.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u5668\u4e2d\u7b26\u53f7\u6982\u5ff5\u72ec\u7acb\u6027\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u6b63\u5f0f\u8bc1\u660e\u4e86\u8fd9\u79cd\u5047\u8bbe\u4f1a\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u8868\u793a\u67d0\u4e9b\u6982\u5ff5\u7ec4\u5408\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u65e0\u6cd5\u5bdf\u89c9\u63a8\u7406\u6377\u5f84\u95ee\u9898\u3002", "motivation": "\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u5668\u4e2d\u5e38\u7528\u7684\u7b26\u53f7\u6982\u5ff5\u72ec\u7acb\u6027\u5047\u8bbe\u867d\u7136\u7b80\u5316\u4e86\u6982\u7387\u63a8\u7406\uff0c\u4f46\u53ef\u80fd\u963b\u788d\u5b66\u4e60\u5e76\u5f71\u54cd\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3002\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u662f\u5426\u786e\u5b9e\u9650\u5236\u4e86\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u6b63\u5f0f\u8bc1\u660e\u4e86\u7b26\u53f7\u6982\u5ff5\u72ec\u7acb\u6027\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u4e0d\u786e\u5b9a\u6027\u8868\u793a\u7684\u7f3a\u5931\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u72ec\u7acb\u6027\u5047\u8bbe\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u8868\u793a\u7279\u5b9a\u6982\u5ff5\u7ec4\u5408\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u65e0\u6cd5\u8bc6\u522b\u63a8\u7406\u6377\u5f84\u95ee\u9898\u3002", "conclusion": "\u72ec\u7acb\u6027\u5047\u8bbe\u5728\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u5668\u4e2d\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u672a\u6765\u7814\u7a76\u9700\u6539\u8fdb\u8fd9\u4e00\u5047\u8bbe\u3002", "keywords": "\u795e\u7ecf\u7b26\u53f7\u9884\u6d4b\u5668, \u72ec\u7acb\u6027\u5047\u8bbe, \u4e0d\u786e\u5b9a\u6027\u5efa\u6a21, \u63a8\u7406\u6377\u5f84"}}
{"id": "2507.11367", "pdf": "https://arxiv.org/pdf/2507.11367", "abs": "https://arxiv.org/abs/2507.11367", "authors": ["Daniel Tanneberg"], "title": "Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "accepted at the European Conference on Artificial Intelligence (ECAI\n  2025)", "summary": "Training neural networks with reinforcement learning (RL) typically relies on\nbackpropagation (BP), necessitating storage of activations from the forward\npass for subsequent backward updates. Furthermore, backpropagating error\nsignals through multiple layers often leads to vanishing or exploding\ngradients, which can degrade learning performance and stability. We propose a\nnovel approach that trains each layer of the neural network using local signals\nduring the forward pass in RL settings. Our approach introduces local,\nlayer-wise losses leveraging the principle of matching pairwise distances from\nmulti-dimensional scaling, enhanced with optional reward-driven guidance. This\nmethod allows each hidden layer to be trained using local signals computed\nduring forward propagation, thus eliminating the need for backward passes and\nstoring intermediate activations. Our experiments, conducted with policy\ngradient methods across common RL benchmarks, demonstrate that this\nbackpropagation-free method achieves competitive performance compared to their\nclassical BP-based counterpart. Additionally, the proposed method enhances\nstability and consistency within and across runs, and improves performance\nespecially in challenging environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u7684\u5c42\u95f4\u5c40\u90e8\u4fe1\u53f7\u8bad\u7ec3\u65b9\u6cd5\uff0c\u9002\u7528\u4e8eRL\u4e2d\u7684\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\uff0c\u6027\u80fd\u4e0e\u4f20\u7edfBP\u65b9\u6cd5\u76f8\u5f53\u3002", "motivation": "\u89e3\u51b3\u53cd\u5411\u4f20\u64ad\u5728RL\u4e2d\u5b58\u50a8\u6fc0\u6d3b\u503c\u548c\u68af\u5ea6\u6d88\u5931/\u7206\u70b8\u95ee\u9898\u3002", "method": "\u5229\u7528\u5c40\u90e8\u635f\u5931\u548c\u591a\u7ef4\u7f29\u653e\u7684\u8ddd\u79bb\u5339\u914d\u539f\u5219\uff0c\u7ed3\u5408\u5956\u52b1\u9a71\u52a8\u6307\u5bfc\uff0c\u6bcf\u5c42\u5728\u6b63\u5411\u4f20\u64ad\u4e2d\u8bad\u7ec3\u3002", "result": "\u5728RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4e0e\u4f20\u7edfBP\u76f8\u5f53\uff0c\u63d0\u5347\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u53cd\u5411\u4f20\u64ad\uff0c\u9002\u5408\u5177\u6709\u6311\u6218\u6027\u7684\u73af\u5883\u3002", "keywords": "\u5f3a\u5316\u5b66\u4e60, \u53cd\u5411\u4f20\u64ad, \u5c42\u95f4\u8bad\u7ec3, \u591a\u7ef4\u7f29\u653e"}}
{"id": "2507.11371", "pdf": "https://arxiv.org/pdf/2507.11371", "abs": "https://arxiv.org/abs/2507.11371", "authors": ["Gabriel Bo", "Koa Chang", "Justin Gu"], "title": "Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs", "categories": ["cs.LG", "cs.MA"], "comment": "12 pages, 4 figures", "summary": "We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel\nreinforcement learning framework that teaches large language models to explore\ndiverse tool usage patterns beyond conventional high-temperature sampling.\nBuilding on recent advances in step-wise reinforcement learning, we introduce a\ndual-objective reward system that simultaneously optimizes for answer quality\nand tool diversity, training a Llama-3.1 8B model through offline PPO on\nsynthetically generated trajectories from the MMLU-Pro dataset. Our approach\nuniquely employs a rarity-first exploitation strategy where a GPT-4o judge\nscores candidate actions across eight distinct tools plus chain-of-thought\nreasoning, with the policy favoring less-frequently used but still viable tools\nto encourage systematic exploration. Empirical results demonstrate that SPaRK\nachieves competitive performance across 14 MMLU-Pro categories while exhibiting\nsignificantly higher entropy in tool selection compared to both baseline and\nsupervised fine-tuning approaches, suggesting that algorithmic exploration\nthrough explicit tool diversity can enhance reasoning capabilities without\nsacrificing accuracy.", "AI": {"tldr": "SPaRK\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u76ee\u6807\u5956\u52b1\u7cfb\u7edf\u4f18\u5316\u7b54\u6848\u8d28\u91cf\u548c\u5de5\u5177\u591a\u6837\u6027\uff0c\u9f13\u52b1\u5927\u8bed\u8a00\u6a21\u578b\u63a2\u7d22\u591a\u6837\u5316\u7684\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u3002", "motivation": "\u4f20\u7edf\u7684\u9ad8\u6e29\u91c7\u6837\u65b9\u6cd5\u9650\u5236\u4e86\u5de5\u5177\u4f7f\u7528\u7684\u591a\u6837\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u6846\u67b6\u6765\u63a2\u7d22\u66f4\u591a\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u53cc\u76ee\u6807\u5956\u52b1\u7cfb\u7edf\uff0c\u7ed3\u5408\u79bb\u7ebfPPO\u8bad\u7ec3Llama-3.1 8B\u6a21\u578b\uff0c\u5e76\u5229\u7528GPT-4o\u8bc4\u5206\u7b56\u7565\u4f18\u5148\u9009\u62e9\u4f7f\u7528\u9891\u7387\u8f83\u4f4e\u4f46\u53ef\u884c\u7684\u5de5\u5177\u3002", "result": "\u572814\u4e2aMMLU-Pro\u7c7b\u522b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5de5\u5177\u9009\u62e9\u71b5\u663e\u8457\u9ad8\u4e8e\u57fa\u7ebf\uff0c\u8868\u660e\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5de5\u5177\u591a\u6837\u6027\u9f13\u52b1\u63a2\u7d22\uff0c\u53ef\u4ee5\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "keywords": ""}}
{"id": "2507.10621", "pdf": "https://arxiv.org/pdf/2507.10621", "abs": "https://arxiv.org/abs/2507.10621", "authors": ["Quanyan Zhu"], "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "comment": null, "summary": "Protecting cyberspace requires not only advanced tools but also a shift in\nhow we reason about threats, trust, and autonomy. Traditional cybersecurity\nmethods rely on manual responses and brittle heuristics. To build proactive and\nintelligent defense systems, we need integrated theoretical frameworks and\nsoftware tools. Game theory provides a rigorous foundation for modeling\nadversarial behavior, designing strategic defenses, and enabling trust in\nautonomous systems. Meanwhile, software tools process cyber data, visualize\nattack surfaces, verify compliance, and suggest mitigations. Yet a disconnect\nremains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to\nbridge this gap. LLM-powered agents can operationalize abstract strategies into\nreal-world decisions. Conversely, game theory can inform the reasoning and\ncoordination of these agents across complex workflows. LLMs also challenge\nclassical game-theoretic assumptions, such as perfect rationality or static\npayoffs, prompting new models aligned with cognitive and computational\nrealities. This co-evolution promises richer theoretical foundations and novel\nsolution concepts. Agentic AI also reshapes software design: systems must now\nbe modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and\ncybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic,\nBayesian, and signaling games) and solution concepts. We then examine how LLM\nagents can enhance cyber defense and introduce LLM-driven games that embed\nreasoning into AI agents. Finally, we explore multi-agent workflows and\ncoordination games, outlining how this convergence fosters secure, intelligent,\nand adaptive cyber systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u535a\u5f08\u8bba\u3001\u81ea\u4e3bAI\u4e0e\u7f51\u7edc\u5b89\u5168\u7684\u7ed3\u5408\uff0c\u63d0\u51fa\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u81ea\u4e3bAI\u5b9e\u73b0\u7406\u8bba\u6846\u67b6\u5230\u5b9e\u9645\u5e94\u7528\u7684\u6865\u6881\u3002", "motivation": "\u4f20\u7edf\u7684\u7f51\u7edc\u5b89\u5168\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u54cd\u5e94\u548c\u8106\u5f31\u542f\u53d1\u5f0f\uff0c\u8feb\u5207\u9700\u8981\u667a\u80fd\u5316\u7684\u9632\u5fa1\u7cfb\u7edf\u3002\u535a\u5f08\u8bba\u63d0\u4f9b\u4e86\u5efa\u6a21\u5bf9\u6297\u884c\u4e3a\u7684\u57fa\u7840\uff0c\u800cLLMs\u80fd\u591f\u5c06\u62bd\u8c61\u7b56\u7565\u8f6c\u5316\u4e3a\u5b9e\u9645\u51b3\u7b56\u3002", "method": "\u6587\u7ae0\u56de\u987e\u4e86\u535a\u5f08\u8bba\u6846\u67b6\uff08\u5982\u9759\u6001\u3001\u52a8\u6001\u3001\u8d1d\u53f6\u65af\u548c\u4fe1\u53f7\u535a\u5f08\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7LLM\u9a71\u52a8\u7684\u4ee3\u7406\u589e\u5f3a\u7f51\u7edc\u9632\u5fa1\uff0c\u8bbe\u8ba1\u5d4c\u5165\u63a8\u7406\u7684AI\u4ee3\u7406\u6e38\u620f\u3002", "result": "\u7814\u7a76\u6307\u51fa\u4e86\u7406\u8bba\u548c\u5b9e\u9645\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7LLMs\u548c\u81ea\u4e3bAI\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u57fa\u7840\u548c\u65b0\u578b\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u535a\u5f08\u8bba\u4e0e\u81ea\u4e3bAI\u7684\u534f\u540c\u53d1\u5c55\u6709\u52a9\u4e8e\u6784\u5efa\u5b89\u5168\u3001\u667a\u80fd\u548c\u81ea\u9002\u5e94\u7684\u7f51\u7edc\u7cfb\u7edf\u3002", "keywords": "\u7f51\u7edc\u5b89\u5168, \u535a\u5f08\u8bba, \u5927\u8bed\u8a00\u6a21\u578b, \u81ea\u4e3bAI, \u667a\u80fd\u9632\u5fa1"}}
{"id": "2507.11393", "pdf": "https://arxiv.org/pdf/2507.11393", "abs": "https://arxiv.org/abs/2507.11393", "authors": ["James P Jun", "Vijay Marupudi", "Raj Sanjay Shah", "Sashank Varma"], "title": "A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning", "categories": ["cs.LG"], "comment": "Accepted to CogSci 2025. 7 pages, 7 figures", "summary": "Learning new information without forgetting prior knowledge is central to\nhuman intelligence. In contrast, neural network models suffer from catastrophic\nforgetting: a significant degradation in performance on previously learned\ntasks when acquiring new information. The Complementary Learning Systems (CLS)\ntheory offers an explanation for this human ability, proposing that the brain\nhas distinct systems for pattern separation (encoding distinct memories) and\npattern completion (retrieving complete memories from partial cues). To capture\nthese complementary functions, we leverage the representational generalization\ncapabilities of variational autoencoders (VAEs) and the robust memory storage\nproperties of Modern Hopfield networks (MHNs), combining them into a neurally\nplausible continual learning model. We evaluate this model on the Split-MNIST\ntask, a popular continual learning benchmark, and achieve close to\nstate-of-the-art accuracy (~90%), substantially reducing forgetting.\nRepresentational analyses empirically confirm the functional dissociation: the\nVAE underwrites pattern completion, while the MHN drives pattern separation. By\ncapturing pattern separation and completion in scalable architectures, our work\nprovides a functional template for modeling memory consolidation,\ngeneralization, and continual learning in both biological and artificial\nsystems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u73b0\u4ee3Hopfield\u7f51\u7edc\uff08MHN\uff09\u7684\u6301\u7eed\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u51cf\u5c11\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5e76\u5728Split-MNIST\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u53d7\u4eba\u7c7b\u5927\u8111\u4e92\u8865\u5b66\u4e60\u7cfb\u7edf\uff08CLS\uff09\u7406\u8bba\u7684\u542f\u53d1\u3002", "method": "\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u7684\u6a21\u5f0f\u6cdb\u5316\u80fd\u529b\u548c\u73b0\u4ee3Hopfield\u7f51\u7edc\uff08MHN\uff09\u7684\u7a33\u5065\u8bb0\u5fc6\u5b58\u50a8\u7279\u6027\uff0c\u6784\u5efa\u795e\u7ecf\u53ef\u5851\u7684\u6301\u7eed\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u5728Split-MNIST\u4efb\u52a1\u4e0a\u8fbe\u5230\u63a5\u8fd1\u6700\u4f18\u7684\u51c6\u786e\u7387\uff08~90%\uff09\uff0c\u663e\u8457\u51cf\u5c11\u9057\u5fd8\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u751f\u7269\u548c\u4eba\u5de5\u7cfb\u7edf\u4e2d\u7684\u8bb0\u5fc6\u5de9\u56fa\u3001\u6cdb\u5316\u548c\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u529f\u80fd\u6a21\u677f\u3002", "keywords": "\u6301\u7eed\u5b66\u4e60, \u707e\u96be\u6027\u9057\u5fd8, \u73b0\u4ee3Hopfield\u7f51\u7edc, \u53d8\u5206\u81ea\u7f16\u7801\u5668, Split-MNIST"}}
{"id": "2507.10622", "pdf": "https://arxiv.org/pdf/2507.10622", "abs": "https://arxiv.org/abs/2507.10622", "authors": ["HyeYoung Lee", "Muhammad Nadeem", "Pavel Tsoi"], "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs", "categories": ["cs.CR", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) networks has led to a surge\nin security vulnerabilities, emphasizing the critical need for robust anomaly\ndetection and classification techniques. In this work, we propose a novel\napproach for identifying anomalies in IoT network traffic by leveraging the\nMel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model\nknown for its effectiveness in feature extraction and image-based tasks.\nLearnable MFCCs enable adaptive spectral feature representation, capturing the\ntemporal patterns inherent in network traffic more effectively than traditional\nfixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the\ndata into a higher-dimensional space, enhancing class separability and enabling\nmore effective multiclass classification. Our approach combines the strengths\nof MFCCs with the robust feature extraction capabilities of ResNet-18, offering\na powerful framework for anomaly detection. The proposed model is evaluated on\nthree widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and\nIoTID20. The experimental results highlight the potential of integrating\nadaptive signal processing techniques with deep learning architectures to\nachieve robust and scalable anomaly detection in heterogeneous IoT network\nlandscapes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408MFCC\u548cResNet-18\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u7269\u8054\u7f51\uff08IoT\uff09\u7f51\u7edc\u6d41\u91cf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u7f51\u7edc\u7684\u5feb\u901f\u6269\u5c55\uff0c\u5b89\u5168\u6f0f\u6d1e\u6fc0\u589e\uff0c\u6025\u9700\u9ad8\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5206\u7c7b\u6280\u672f\u4ee5\u63d0\u9ad8\u7f51\u7edc\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528Mel\u9891\u7387\u5012\u8c31\u7cfb\u6570\uff08MFCC\uff09\u8fdb\u884c\u81ea\u9002\u5e94\u9891\u8c31\u7279\u5f81\u8868\u793a\uff0c\u7ed3\u5408ResNet-18\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u5728CICIoT2023\u3001NSL-KDD\u548cIoTID20\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u81ea\u9002\u5e94\u4fe1\u53f7\u5904\u7406\u4e0e\u6df1\u5ea6\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5f02\u6784\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u5f02\u5e38\u7684\u9c81\u68d2\u68c0\u6d4b\u4e0e\u5206\u7c7b\u3002", "keywords": "\u7269\u8054\u7f51\u5b89\u5168, \u5f02\u5e38\u68c0\u6d4b, MFCC, ResNet-18, \u6df1\u5ea6\u5b66\u4e60"}}
{"id": "2507.11411", "pdf": "https://arxiv.org/pdf/2507.11411", "abs": "https://arxiv.org/abs/2507.11411", "authors": ["Seyedsaman Emami", "Gonzalo Mart\u00ednez-Mu\u00f1oz", "Daniel Hern\u00e1ndez-Lobato"], "title": "Robust-Multi-Task Gradient Boosting", "categories": ["cs.LG"], "comment": null, "summary": "Multi-task learning (MTL) has shown effectiveness in exploiting shared\ninformation across tasks to improve generalization. MTL assumes tasks share\nsimilarities that can improve performance. In addition, boosting algorithms\nhave demonstrated exceptional performance across diverse learning problems,\nprimarily due to their ability to focus on hard-to-learn instances and\niteratively reduce residual errors. This makes them a promising approach for\nlearning multi-task problems. However, real-world MTL scenarios often involve\ntasks that are not well-aligned (known as outlier or adversarial tasks), which\ndo not share beneficial similarities with others and can, in fact, deteriorate\nthe performance of the overall model. To overcome this challenge, we propose\nRobust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that\nexplicitly models and adapts to task heterogeneity during training. R-MTGB\nstructures the learning process into three sequential blocks: (1) learning\nshared patterns, (2) partitioning tasks into outliers and non-outliers with\nregularized parameters, and (3) fine-tuning task-specific predictors. This\narchitecture enables R-MTGB to automatically detect and penalize outlier tasks\nwhile promoting effective knowledge transfer among related tasks. Our method\nintegrates these mechanisms seamlessly within gradient boosting, allowing\nrobust handling of noisy or adversarial tasks without sacrificing accuracy.\nExtensive experiments on both synthetic benchmarks and real-world datasets\ndemonstrate that our approach successfully isolates outliers, transfers\nknowledge, and consistently reduces prediction errors for each task\nindividually, and achieves overall performance gains across all tasks. These\nresults highlight robustness, adaptability, and reliable convergence of R-MTGB\nin challenging MTL environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aR-MTGB\u7684\u65b0\u578b\u591a\u4efb\u52a1\u68af\u5ea6\u63d0\u5347\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5757\u5b66\u4e60\u5171\u4eab\u6a21\u5f0f\u3001\u8bc6\u522b\u5e76\u5904\u7406\u5f02\u5e38\u4efb\u52a1\uff0c\u4ee5\u53ca\u5fae\u8c03\u4efb\u52a1\u7279\u5b9a\u9884\u6d4b\u5668\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u4efb\u52a1\u5f02\u6784\u6027\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u4e2d\u5f02\u5e38\u4efb\u52a1\u7684\u5b58\u5728\u4f1a\u964d\u4f4e\u6a21\u578b\u6574\u4f53\u6027\u80fd\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u52a8\u8bc6\u522b\u5e76\u5904\u7406\u8fd9\u4e9b\u4efb\u52a1\u7684\u9c81\u68d2\u65b9\u6cd5\u3002", "method": "R-MTGB\u6846\u67b6\u5206\u4e3a\u4e09\u6b65\uff1a\u5b66\u4e60\u5171\u4eab\u6a21\u5f0f\u3001\u6b63\u5219\u5316\u53c2\u6570\u5212\u5206\u4efb\u52a1\u3001\u5fae\u8c03\u4efb\u52a1\u7279\u5b9a\u9884\u6d4b\u5668\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cR-MTGB\u80fd\u6709\u6548\u9694\u79bb\u5f02\u5e38\u4efb\u52a1\u5e76\u63d0\u5347\u5404\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "R-MTGB\u5728\u591a\u4efb\u52a1\u5f02\u6784\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u5b9e\u73b0\u4e86\u6574\u4f53\u6027\u80fd\u63d0\u5347\u3002", "keywords": "\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u68af\u5ea6\u63d0\u5347\u3001\u5f02\u5e38\u4efb\u52a1\u3001\u9c81\u68d2\u6027"}}
{"id": "2507.11436", "pdf": "https://arxiv.org/pdf/2507.11436", "abs": "https://arxiv.org/abs/2507.11436", "authors": ["Behtom Adeli", "John McLinden", "Pankaj Pandey", "Ming Shao", "Yalda Shahriari"], "title": "Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Activation functions are critical to the performance of deep neural networks,\nparticularly in domains such as functional near-infrared spectroscopy (fNIRS),\nwhere nonlinearity, low signal-to-noise ratio (SNR), and signal variability\nposes significant challenges to model accuracy. However, the impact of\nactivation functions on deep learning (DL) performance in the fNIRS domain\nremains underexplored and lacks systematic investigation in the current\nliterature. This study evaluates a range of conventional and field-specific\nactivation functions for fNIRS classification tasks using multiple deep\nlearning architectures, including the domain-specific fNIRSNet, AbsoluteNet,\nMDNN, and shallowConvNet (as the baseline), all tested on a single dataset\nrecorded during an auditory task. To ensure fair a comparison, all networks\nwere trained and tested using standardized preprocessing and consistent\ntraining parameters. The results show that symmetrical activation functions\nsuch as Tanh and the Absolute value function Abs(x) can outperform commonly\nused functions like the Rectified Linear Unit (ReLU), depending on the\narchitecture. Additionally, a focused analysis of the role of symmetry was\nconducted using a Modified Absolute Function (MAF), with results further\nsupporting the effectiveness of symmetrical activation functions on performance\ngains. These findings underscore the importance of selecting proper activation\nfunctions that align with the signal characteristics of fNIRS data.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6fc0\u6d3b\u51fd\u6570\u5728fNIRS\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5bf9\u79f0\u6027\u6fc0\u6d3b\u51fd\u6570\uff08\u5982Tanh\u548cAbs(x\uff09\u5728\u67d0\u4e9b\u67b6\u6784\u4e2d\u4f18\u4e8e\u5e38\u7528ReLU\uff0c\u5e76\u5f3a\u8c03\u4e86\u9009\u62e9\u9002\u5408fNIRS\u4fe1\u53f7\u7279\u6027\u7684\u6fc0\u6d3b\u51fd\u6570\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u9488\u5bf9fNIRS\u4fe1\u53f7\u7684\u975e\u7ebf\u6027\u3001\u4f4e\u4fe1\u566a\u6bd4\u548c\u53ef\u53d8\u6027\u7b49\u6311\u6218\uff0c\u5f53\u524d\u6587\u732e\u7f3a\u4e4f\u5bf9\u6fc0\u6d3b\u51fd\u6570\u5f71\u54cd\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u5728fNIRS\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08\u5305\u62ecfNIRSNet\u3001AbsoluteNet\u3001MDNN\u548c\u6d45\u5c42ConvNet\uff09\uff0c\u5728\u7edf\u4e00\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u53c2\u6570\u4e0b\uff0c\u8bc4\u4f30\u4f20\u7edf\u548c\u9886\u57df\u7279\u5b9a\u6fc0\u6d3b\u51fd\u6570\u7684\u6027\u80fd\uff0c\u5e76\u7279\u522b\u5206\u6790\u4e86\u5bf9\u79f0\u6027\u7684\u4f5c\u7528\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u79f0\u6027\u6fc0\u6d3b\u51fd\u6570\uff08\u5982Tanh\u548cAbs(x\uff09\u5728\u67d0\u4e9b\u67b6\u6784\u4e2d\u4f18\u4e8eReLU\uff0c\u4e14\u4fee\u6539\u7248\u7edd\u5bf9\u51fd\u6570\uff08MAF\uff09\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5bf9\u79f0\u6027\u5bf9\u6027\u80fd\u63d0\u5347\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u9009\u62e9\u4e0efNIRS\u4fe1\u53f7\u7279\u6027\u5339\u914d\u7684\u6fc0\u6d3b\u51fd\u6570\u5bf9\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u5bf9\u79f0\u6027\u6fc0\u6d3b\u51fd\u6570\u5728\u8be5\u9886\u57df\u5177\u6709\u6f5c\u5728\u4f18\u52bf\u3002", "keywords": "fNIRS, deep learning, activation functions, symmetry, signal characteristics"}}
{"id": "2507.11439", "pdf": "https://arxiv.org/pdf/2507.11439", "abs": "https://arxiv.org/abs/2507.11439", "authors": ["Hongming Tan", "Ting Chen", "Ruochong Jin", "Wai Kin Chan"], "title": "Data Augmentation in Time Series Forecasting through Inverted Framework", "categories": ["cs.LG"], "comment": null, "summary": "Currently, iTransformer is one of the most popular and effective models for\nmultivariate time series (MTS) forecasting. Thanks to its inverted framework,\niTransformer effectively captures multivariate correlation. However, the\ninverted framework still has some limitations. It diminishes temporal\ninterdependency information, and introduces noise in cases of nonsignificant\nvariable correlation. To address these limitations, we introduce a novel data\naugmentation method on inverted framework, called DAIF. Unlike previous data\naugmentation methods, DAIF stands out as the first real-time augmentation\nspecifically designed for the inverted framework in MTS forecasting. We first\ndefine the structure of the inverted sequence-to-sequence framework, then\npropose two different DAIF strategies, Frequency Filtering and Cross-variation\nPatching to address the existing challenges of the inverted framework.\nExperiments across multiple datasets and inverted models have demonstrated the\neffectiveness of our DAIF.", "AI": {"tldr": "DAIF\u662f\u4e00\u79cd\u9488\u5bf9iTransformer\u6846\u67b6\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u9996\u6b21\u4e3aMTS\u9884\u6d4b\u4e2d\u7684\u5012\u7f6e\u6846\u67b6\u8bbe\u8ba1\u5b9e\u65f6\u589e\u5f3a\u65b9\u6848\uff0c\u901a\u8fc7Frequency Filtering\u548cCross-variation Patching\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "iTransformer\u5728MTS\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5012\u7f6e\u6846\u67b6\u4f1a\u524a\u5f31\u65f6\u95f4\u4f9d\u8d56\u4fe1\u606f\u5e76\u5f15\u5165\u566a\u58f0\uff0cDAIF\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u79cdDAIF\u7b56\u7565\uff1aFrequency Filtering\u548cCross-variation Patching\uff0c\u5bf9\u5012\u7f6e\u5e8f\u5217\u6846\u67b6\u8fdb\u884c\u5b9e\u65f6\u6570\u636e\u589e\u5f3a\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u5012\u7f6e\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660eDAIF\u7684\u6709\u6548\u6027\u3002", "conclusion": "DAIF\u663e\u8457\u6539\u5584\u4e86iTransformer\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u4e3aMTS\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u589e\u5f3a\u65b9\u6848\u3002", "keywords": "iTransformer, MTS forecasting, data augmentation, DAIF, inverted framework"}}
{"id": "2507.10629", "pdf": "https://arxiv.org/pdf/2507.10629", "abs": "https://arxiv.org/abs/2507.10629", "authors": ["Song Cheng", "Qiannan Cheng", "Linbo Jin", "Lei Yi", "Guannan Zhang"], "title": "SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition", "categories": ["cs.DB", "cs.AI", "I.2.7"], "comment": "WWW '25: Companion Proceedings of the ACM on Web Conference 2025\n  Pages 919 - 923 https://doi.org/10.1145/3701716.3715541", "summary": "Transforming natural language into SQL queries (NL2SQL) is crucial for\ndata-driven business applications. Existing frameworks, trained on open-source\ndatasets, struggle with complex business logic and lack domain-specific data\nfor fine-tuning. Additionally, evaluation methods often require annotated data\nand executable database environments, which are scarce in real-world scenarios.\nTo address these challenges, we propose SQLord, an enterprise-level NL2SQL\nframework. First, SQLord introduces a data reverse generation approach to\nconvert raw SQL statements into annotated data for supervised fine-tuning\n(SFT). Second, it proposes a decomposition method for complex queries using an\nautomated workflow generator. Additionally, SQLord features a comprehensive\nGPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL\nEvaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios.\nOffline tests significantly outperform state of the art baselines, and online\naccuracy consistently exceeds 90, highlighting SQLord's advantages and\neffectiveness in complex real world scenarios. SQLord has been successfully\napplied across multiple scenarios on the world's largest B2B e-commerce\nplatform.", "AI": {"tldr": "SQLord\u662f\u4e00\u79cd\u4f01\u4e1a\u7ea7NL2SQL\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u636e\u9006\u5411\u751f\u6210\u548c\u590d\u6742\u67e5\u8be2\u5206\u89e3\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u5728\u590d\u6742\u4e1a\u52a1\u903b\u8f91\u548c\u9886\u57df\u6570\u636e\u4e0d\u8db3\u4e0a\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709NL2SQL\u6846\u67b6\u5728\u590d\u6742\u4e1a\u52a1\u903b\u8f91\u548c\u9886\u57df\u6570\u636e\u4e0d\u8db3\u4e0a\u7684\u56f0\u5883\uff0c\u4ee5\u53ca\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\u548c\u53ef\u6267\u884c\u6570\u636e\u5e93\u73af\u5883\u7684\u95ee\u9898\uff0c\u63d0\u51faSQLord\u6846\u67b6\u3002", "method": "1. \u6570\u636e\u9006\u5411\u751f\u6210\u5c06\u539f\u59cbSQL\u8f6c\u6362\u4e3a\u6807\u6ce8\u6570\u636e\u7528\u4e8e\u76d1\u7763\u5fae\u8c03\uff1b2. \u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u751f\u6210\u5668\u5206\u89e3\u590d\u6742\u67e5\u8be2\uff1b3. \u63d0\u51faGPT-Judge\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ecEXE\u3001QSE\u548cSSE\u3002", "result": "\u79bb\u7ebf\u6d4b\u8bd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u7ebf\u51c6\u786e\u7387\u7a33\u5b9a\u8d85\u8fc790%\uff0c\u5728\u5168\u7403\u6700\u5927B2B\u7535\u5546\u5e73\u53f0\u591a\u573a\u666f\u4e2d\u6210\u529f\u5e94\u7528\u3002", "conclusion": "SQLord\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u9886\u57df\u6570\u636e\u548c\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "keywords": "NL2SQL, SQLord, \u6570\u636e\u9006\u5411\u751f\u6210, \u590d\u6742\u67e5\u8be2\u5206\u89e3, GPT-Judge"}}
{"id": "2507.11457", "pdf": "https://arxiv.org/pdf/2507.11457", "abs": "https://arxiv.org/abs/2507.11457", "authors": ["Yaoxian Dong", "Yifan Gao", "Haoyue Li", "Yanfen Cui", "Xin Gao"], "title": "LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer", "categories": ["cs.LG", "eess.IV"], "comment": null, "summary": "Accurate preoperative assessment of lymph node (LN) metastasis in rectal\ncancer guides treatment decisions, yet conventional MRI evaluation based on\nmorphological criteria shows limited diagnostic performance. While some\nartificial intelligence models have been developed, they often operate as black\nboxes, lacking the interpretability needed for clinical trust. Moreover, these\nmodels typically evaluate nodes in isolation, overlooking the patient-level\ncontext. To address these limitations, we introduce LRMR, an LLM-Driven\nRelational Multi-node Ranking framework. This approach reframes the diagnostic\ntask from a direct classification problem into a structured reasoning and\nranking process. The LRMR framework operates in two stages. First, a multimodal\nlarge language model (LLM) analyzes a composite montage image of all LNs from a\npatient, generating a structured report that details ten distinct radiological\nfeatures. Second, a text-based LLM performs pairwise comparisons of these\nreports between different patients, establishing a relative risk ranking based\non the severity and number of adverse features. We evaluated our method on a\nretrospective cohort of 117 rectal cancer patients. LRMR achieved an area under\nthe curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of\ndeep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies\nconfirmed the value of our two main contributions: removing the relational\nranking stage or the structured prompting stage led to a significant\nperformance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our\nwork demonstrates that decoupling visual perception from cognitive reasoning\nthrough a two-stage LLM framework offers a powerful, interpretable, and\neffective new paradigm for assessing lymph node metastasis in rectal cancer.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLRMR\u7684\u4e24\u9636\u6bb5LLM\u9a71\u52a8\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u76f4\u80a0\u764c\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u7684\u8bca\u65ad\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u7684MRI\u8bc4\u4f30\u6027\u80fd\u6709\u9650\uff0c\u4e14\u73b0\u6709AI\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u60a3\u8005\u6574\u4f53\u60c5\u51b5\u7684\u8003\u8651\u3002", "method": "LRMR\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u901a\u8fc7\u591a\u6a21\u6001LLM\u5206\u6790\u6dcb\u5df4\u7ed3\u7684\u590d\u5408\u56fe\u50cf\uff0c\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\uff1b2\uff09\u901a\u8fc7\u6587\u672cLLM\u5bf9\u62a5\u544a\u8fdb\u884c\u6210\u5bf9\u6bd4\u8f83\uff0c\u5efa\u7acb\u76f8\u5bf9\u98ce\u9669\u6392\u540d\u3002", "result": "\u5728117\u540d\u60a3\u8005\u7684\u56de\u987e\u6027\u961f\u5217\u4e2d\uff0cLRMR\u7684AUC\u4e3a0.7917\uff0cF1\u5206\u6570\u4e3a0.7200\uff0c\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u4e24\u9636\u6bb5\u7684LLM\u6846\u67b6\u4e3a\u76f4\u80a0\u764c\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u65b0\u65b9\u6cd5\u3002", "keywords": "\u6dcb\u5df4\u7ed3\u8f6c\u79fb, \u76f4\u80a0\u764c, LLM, \u591a\u6a21\u6001, \u53ef\u89e3\u91ca\u6027"}}
{"id": "2507.11471", "pdf": "https://arxiv.org/pdf/2507.11471", "abs": "https://arxiv.org/abs/2507.11471", "authors": ["Harsha Varun Marisetty", "Manik Gupta", "Yogesh Simmhan"], "title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data", "categories": ["cs.LG", "cs.DC"], "comment": "Preprint of paper to appear in the proceedings of IEEE INTERNATIONAL\n  CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS EDGE 2025", "summary": "With advancements in computing and communication technologies, the Internet\nof Things (IoT) has seen significant growth. IoT devices typically collect data\nfrom various sensors, such as temperature, humidity, and energy meters. Much of\nthis data is temporal in nature. Traditionally, data from IoT devices is\ncentralized for analysis, but this approach introduces delays and increased\ncommunication costs. Federated learning (FL) has emerged as an effective\nalternative, allowing for model training across distributed devices without the\nneed to centralize data. In many applications, such as smart home energy and\nenvironmental monitoring, the data collected by IoT devices across different\nlocations can exhibit significant variation in trends and seasonal patterns.\nAccurately forecasting such non-stationary, non-linear time-series data is\ncrucial for applications like energy consumption estimation and weather\nforecasting. However, these data variations can severely impact prediction\naccuracy. The key contributions of this paper are: (1) Investigating how\nnon-linear, non-stationary time-series data distributions, like generalized\nextreme value (gen-extreme) and log norm distributions, affect FL performance.\n(2) Analyzing how different detrending techniques for non-linear time-series\ndata influence the forecasting model's performance in a FL setup. We generated\nseveral synthetic time-series datasets using non-linear data distributions and\ntrained an LSTM-based forecasting model using both centralized and FL\napproaches. Additionally, we evaluated the impact of detrending on real-world\ndatasets with non-linear time-series data distributions. Our experimental\nresults show that: (1) FL performs worse than centralized approaches when\ndealing with non-linear data distributions. (2) The use of appropriate\ndetrending techniques improves FL performance, reducing loss across different\ndata distributions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u5904\u7406\u975e\u7ebf\u6027\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u6570\u636e\u5206\u5e03\u548c\u53bb\u8d8b\u52bf\u6280\u672f\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0FL\u5728\u975e\u7ebf\u6027\u6570\u636e\u5206\u5e03\u4e0b\u8868\u73b0\u8f83\u5dee\uff0c\u4f46\u9002\u5f53\u7684\u53bb\u8d8b\u52bf\u6280\u672f\u80fd\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\uff08IoT\uff09\u7684\u53d1\u5c55\uff0c\u5176\u8bbe\u5907\u6536\u96c6\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5177\u6709\u975e\u7ebf\u6027\u3001\u975e\u5e73\u7a33\u7279\u6027\u3002\u4f20\u7edf\u96c6\u4e2d\u5f0f\u5206\u6790\u5b58\u5728\u5ef6\u8fdf\u548c\u901a\u4fe1\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0cFL\u6210\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u6570\u636e\u5206\u5e03\u5dee\u5f02\u4f1a\u5f71\u54cd\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u751f\u6210\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff08\u57fa\u4e8e\u5e7f\u4e49\u6781\u503c\u548c\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff09\uff0c\u5bf9\u6bd4\u96c6\u4e2d\u5f0f\u548cFL\u65b9\u6cd5\u8bad\u7ec3LSTM\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u8bc4\u4f30\u53bb\u8d8b\u52bf\u6280\u672f\u5bf9\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1. \u5728\u975e\u7ebf\u6027\u6570\u636e\u5206\u5e03\u4e0b\uff0cFL\u6027\u80fd\u4f4e\u4e8e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff1b2. \u5408\u9002\u7684\u53bb\u8d8b\u52bf\u6280\u672f\u80fd\u51cf\u5c11\u635f\u5931\uff0c\u63d0\u5347FL\u6027\u80fd\u3002", "conclusion": "FL\u5728\u5904\u7406\u975e\u7ebf\u6027\u975e\u5e73\u7a33\u6570\u636e\u65f6\u9700\u7ed3\u5408\u53bb\u8d8b\u52bf\u6280\u672f\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "keywords": "\u8054\u90a6\u5b66\u4e60, \u7269\u8054\u7f51, \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b, \u975e\u7ebf\u6027\u5206\u5e03, \u53bb\u8d8b\u52bf\u6280\u672f"}}
{"id": "2507.11486", "pdf": "https://arxiv.org/pdf/2507.11486", "abs": "https://arxiv.org/abs/2507.11486", "authors": ["Jeremi Levesque", "Antoine Th\u00e9berge", "Maxime Descoteaux", "Pierre-Marc Jodoin"], "title": "Exploring the robustness of TractOracle methods in RL-based tractography", "categories": ["cs.LG", "I.2.1"], "comment": "38 pages, 8 figures. Submitted to Medical Image Analysis", "summary": "Tractography algorithms leverage diffusion MRI to reconstruct the fibrous\narchitecture of the brain's white matter. Among machine learning approaches,\nreinforcement learning (RL) has emerged as a promising framework for\ntractography, outperforming traditional methods in several key aspects.\nTractOracle-RL, a recent RL-based approach, reduces false positives by\nincorporating anatomical priors into the training process via a reward-based\nmechanism. In this paper, we investigate four extensions of the original\nTractOracle-RL framework by integrating recent advances in RL, and we evaluate\ntheir performance across five diverse diffusion MRI datasets. Results\ndemonstrate that combining an oracle with the RL framework consistently leads\nto robust and reliable tractography, regardless of the specific method or\ndataset used. We also introduce a novel RL training scheme called Iterative\nReward Training (IRT), inspired by the Reinforcement Learning from Human\nFeedback (RLHF) paradigm. Instead of relying on human input, IRT leverages\nbundle filtering methods to iteratively refine the oracle's guidance throughout\ntraining. Experimental results show that RL methods trained with oracle\nfeedback significantly outperform widely used tractography techniques in terms\nof accuracy and anatomical validity.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7ea4\u7ef4\u8ffd\u8e2a\u7b97\u6cd5TractOracle-RL\u7684\u56db\u79cd\u6269\u5c55\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6848IRT\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u901a\u8fc7\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u548c\u89e3\u5256\u5b66\u5148\u9a8c\u77e5\u8bc6\uff0c\u63d0\u5347\u7ea4\u7ef4\u8ffd\u8e2a\u7b97\u6cd5\u7684\u51c6\u786e\u6027\u548c\u89e3\u5256\u5b66\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u79cdTractOracle-RL\u7684\u6269\u5c55\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u65b9\u6848IRT\uff0c\u7ed3\u5408\u675f\u8fc7\u6ee4\u65b9\u6cd5\u8fed\u4ee3\u4f18\u5316\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408oracle\u7684RL\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u51c6\u786e\u6027\u548c\u89e3\u5256\u5b66\u6709\u6548\u6027\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u89e3\u5256\u5b66\u5148\u9a8c\u7684oracle\u663e\u8457\u63d0\u9ad8\u4e86\u7ea4\u7ef4\u8ffd\u8e2a\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002", "keywords": "\u7ea4\u7ef4\u8ffd\u8e2a,\u5f3a\u5316\u5b66\u4e60,\u89e3\u5256\u5b66\u5148\u9a8c,TractOracle-RL,Iterative Reward Training"}}
{"id": "2507.11493", "pdf": "https://arxiv.org/pdf/2507.11493", "abs": "https://arxiv.org/abs/2507.11493", "authors": ["Majid Darehmiraki"], "title": "A parametric activation function based on Wendland RBF", "categories": ["cs.LG", "cs.NE", "68T07"], "comment": "11 pages, 2 figures", "summary": "This paper introduces a novel parametric activation function based on\nWendland radial basis functions (RBFs) for deep neural networks. Wendland RBFs,\nknown for their compact support, smoothness, and positive definiteness in\napproximation theory, are adapted to address limitations of traditional\nactivation functions like ReLU, sigmoid, and tanh. The proposed enhanced\nWendland activation combines a standard Wendland component with linear and\nexponential terms, offering tunable locality, improved gradient propagation,\nand enhanced stability during training. Theoretical analysis highlights its\nmathematical properties, including smoothness and adaptability, while empirical\nexperiments on synthetic tasks (e.g., sine wave approximation) and benchmark\ndatasets (MNIST, Fashion-MNIST) demonstrate competitive performance. Results\nshow that the Wendland-based activation achieves superior accuracy in certain\nscenarios, particularly in regression tasks, while maintaining computational\nefficiency. The study bridges classical RBF theory with modern deep learning,\nsuggesting that Wendland activations can mitigate overfitting and improve\ngeneralization through localized, smooth transformations. Future directions\ninclude hybrid architectures and domain-specific adaptations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWendland\u5f84\u5411\u57fa\u51fd\u6570\uff08RBFs\uff09\u7684\u65b0\u578b\u53c2\u6570\u5316\u6fc0\u6d3b\u51fd\u6570\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u6fc0\u6d3b\u51fd\u6570\uff08\u5982ReLU\u3001sigmoid\u548ctanh\uff09\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u6fc0\u6d3b\u51fd\u6570\u5982ReLU\u3001sigmoid\u548ctanh\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800cWendland RBFs\u56e0\u5176\u7d27\u652f\u6491\u6027\u3001\u5149\u6ed1\u6027\u548c\u6b63\u5b9a\u6027\u5728\u8fd1\u4f3c\u7406\u8bba\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u56e0\u6b64\u88ab\u5f15\u5165\u6df1\u5ea6\u5b66\u4e60\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u7ed3\u5408\u6807\u51c6Wendland\u5206\u91cf\u4e0e\u7ebf\u6027\u53ca\u6307\u6570\u9879\uff0c\u63d0\u51fa\u589e\u5f3a\u578bWendland\u6fc0\u6d3b\u51fd\u6570\uff0c\u5177\u6709\u53ef\u8c03\u5c40\u90e8\u6027\u3001\u6539\u8fdb\u7684\u68af\u5ea6\u4f20\u64ad\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u5408\u6210\u4efb\u52a1\uff08\u5982\u6b63\u5f26\u6ce2\u8fd1\u4f3c\uff09\u548c\u57fa\u51c6\u6570\u636e\u96c6\uff08MNIST\u3001Fashion-MNIST\uff09\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u5c24\u5176\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u66f4\u4f18\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u7ecf\u5178RBF\u7406\u8bba\u4e0e\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\uff0c\u8868\u660eWendland\u6fc0\u6d3b\u53ef\u901a\u8fc7\u5c40\u90e8\u5149\u6ed1\u53d8\u6362\u7f13\u89e3\u8fc7\u62df\u5408\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u672a\u6765\u65b9\u5411\u5305\u62ec\u6df7\u5408\u67b6\u6784\u548c\u9886\u57df\u7279\u5b9a\u9002\u914d\u3002", "keywords": "Wendland\u5f84\u5411\u57fa\u51fd\u6570, \u6fc0\u6d3b\u51fd\u6570, \u6df1\u5ea6\u5b66\u4e60, \u68af\u5ea6\u4f20\u64ad, \u8fc7\u62df\u5408"}}
{"id": "2507.10639", "pdf": "https://arxiv.org/pdf/2507.10639", "abs": "https://arxiv.org/abs/2507.10639", "authors": ["Simon Nau", "Jan Krummenauer", "Andr\u00e9 Zimmermann"], "title": "SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies", "categories": ["cs.AR", "cs.AI", "cs.ET"], "comment": "11 pages, 10 figures", "summary": "State-of-the-art large language models (LLMs) show high performance across a\nwide range of tasks in many domains of science. In the field of electronic\ndesign automation (EDA), it is yet to be determined to what extent they are\ncapable to understand, adapt, and dimension electronic circuits. This paper\nfocuses on the application of LLMs to switched-mode power supply (SMPS) design\non printed circuit boards (PCBs). Particular challenges for LLMs in this\ncontext include their limited ability to interpret results from key simulation\ntools like SPICE and the multi-step design process. To address these\nchallenges, we suggest SPICEAssistant, a framework that provides a broad\nselection of tools to an LLM. The tools serve as an interface to SPICE,\nallowing the LLM to interact flexibly with the simulator to estimate the impact\nof its modifications to the circuit. To evaluate the performance of\nSPICEAssistant, we defined a benchmark consisting of 256 questions testing the\nability to adapt circuit netlists to fulfil different SMPS design tasks. The\nbenchmarking results show that simulation feedback effectively improves SMPS\ndesign capabilities of LLMs. An increasing number of simulation iterations\nleads to enhanced performance. The SPICEAssistant framework significantly\noutperforms the standalone LLM GPT-4o on the benchmark by approximately 38%.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86LLMs\u5728\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316(EDA)\u4e2d\u7279\u522b\u662f\u5f00\u5173\u6a21\u5f0f\u7535\u6e90(SMPS)\u8bbe\u8ba1\u4e0a\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86SPICEAssistant\u6846\u67b6\u4ee5\u63d0\u5347LLMs\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8LLMs\u5728EDA\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u7279\u522b\u662f\u5728SMPS\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u89e3\u51b3LLMs\u5728\u89e3\u6790SPICE\u4eff\u771f\u7ed3\u679c\u548c\u591a\u6b65\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faSPICEAssistant\u6846\u67b6\uff0c\u4e3aLLMs\u63d0\u4f9b\u5de5\u5177\u63a5\u53e3\uff0c\u4f7f\u5176\u80fd\u7075\u6d3b\u5730\u4e0eSPICE\u4eff\u771f\u5668\u4ea4\u4e92\uff0c\u4f18\u5316\u7535\u8def\u8bbe\u8ba1\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0cSPICEAssistant\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u6027\u80fd\uff0c\u8f83GPT-4o\u63d0\u9ad8\u4e86\u7ea638%\u3002", "conclusion": "\u4eff\u771f\u53cd\u9988\u80fd\u6709\u6548\u63d0\u5347LLMs\u5728SMPS\u8bbe\u8ba1\u4e2d\u7684\u80fd\u529b\uff0c\u4e14\u591a\u6b21\u4eff\u771f\u8fed\u4ee3\u4f1a\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "keywords": "LLMs, EDA, SMPS, SPICE, SPICEAssistant"}}
{"id": "2507.10641", "pdf": "https://arxiv.org/pdf/2507.10641", "abs": "https://arxiv.org/abs/2507.10641", "authors": ["Jayant Havare", "Saurav Chaudhary", "Ganesh Ramakrishnan", "Kaushik Maharajan", "Srikanth Tamilselvam"], "title": "A Code Comprehension Benchmark for Large Language Models for Code", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "10 Pages, 5 Figures", "summary": "Large Language Models have shown impressive capabilities in coding tasks like\ncode generation and code completion, as they have been trained on a large\namount of code data. Also, since one of the core pretraining objectives is Next\nToken Prediction, these models tends to learn surface-level syntactic patterns\nin code. However, this does not guarantee code comprehension ability i.e. the\nability to capture the semantics of the code. In our opinion, this is the\nreason why these models often underperform on tasks that require deeper\nsemantic understanding, such as code debugging and code optimization. To\naddress this, we propose fine-tuning these models specifically for code\ncomprehension tasks using large-scale datasets, enabling them to develop a more\nrobust understanding of code semantics. We evaluate three code models of\nvarying sizes on a suite of code comprehension tasks designed to assess\nsemantic understanding beyond surface-level syntactic pattern matching. In\nparticular, we analyze performance on the Subjectivity Grading Task and observe\nthat model performance improves after fine-tuning on relevant downstream tasks.\nThe most significant improvement is seen in the QWQ-32B model, where accuracy\nincreases from 70% to 83.47%. A similar or explainable trend is observed across\nother models, clearly indicating an enhancement in code comprehension ability.\nAmong the models studied, the DPO-fine-tuned Codestral-22B achieves the highest\nmicro-accuracy of 87.66% on the Subjectivity Grading Task.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u901a\u8fc7\u5fae\u8c03\u6765\u63d0\u5347\u5176\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u548c\u8865\u5168\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9700\u8981\u6df1\u5c42\u8bed\u4e49\u7406\u89e3\u7684\u4efb\u52a1\uff08\u5982\u4ee3\u7801\u8c03\u8bd5\u548c\u4f18\u5316\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347\u5176\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u6a21\u578b\uff0c\u4f7f\u5176\u4e13\u6ce8\u4e8e\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\uff0c\u4ece\u800c\u63d0\u5347\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "result": "\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662fQWQ-32B\u6a21\u578b\u51c6\u786e\u7387\u4ece70%\u63d0\u5347\u81f383.47%\uff0c\u800cCodestral-22B\u8fbe\u5230\u4e86\u6700\u9ad8\u768487.66%\u51c6\u786e\u7387\u3002", "conclusion": "\u5fae\u8c03\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u6df1\u5c42\u8bed\u4e49\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "keywords": "\u5927\u8bed\u8a00\u6a21\u578b\u3001\u4ee3\u7801\u7406\u89e3\u3001\u5fae\u8c03\u3001\u8bed\u4e49\u7406\u89e3\u3001\u4ee3\u7801\u4efb\u52a1"}}
{"id": "2507.11531", "pdf": "https://arxiv.org/pdf/2507.11531", "abs": "https://arxiv.org/abs/2507.11531", "authors": ["Yue Song", "T. Anderson Keller", "Yisong Yue", "Pietro Perona", "Max Welling"], "title": "Langevin Flows for Modeling Neural Latent Dynamics", "categories": ["cs.LG", "q-bio.NC"], "comment": "Full version of the Cognitive Computational Neuroscience (CCN) 2025\n  poster", "summary": "Neural populations exhibit latent dynamical structures that drive\ntime-evolving spiking activities, motivating the search for models that capture\nboth intrinsic network dynamics and external unobserved influences. In this\nwork, we introduce LangevinFlow, a sequential Variational Auto-Encoder where\nthe time evolution of latent variables is governed by the underdamped Langevin\nequation. Our approach incorporates physical priors -- such as inertia,\ndamping, a learned potential function, and stochastic forces -- to represent\nboth autonomous and non-autonomous processes in neural systems. Crucially, the\npotential function is parameterized as a network of locally coupled\noscillators, biasing the model toward oscillatory and flow-like behaviors\nobserved in biological neural populations. Our model features a recurrent\nencoder, a one-layer Transformer decoder, and Langevin dynamics in the latent\nspace. Empirically, our method outperforms state-of-the-art baselines on\nsynthetic neural populations generated by a Lorenz attractor, closely matching\nground-truth firing rates. On the Neural Latents Benchmark (NLB), the model\nachieves superior held-out neuron likelihoods (bits per spike) and forward\nprediction accuracy across four challenging datasets. It also matches or\nsurpasses alternative methods in decoding behavioral metrics such as hand\nvelocity. Overall, this work introduces a flexible, physics-inspired,\nhigh-performing framework for modeling complex neural population dynamics and\ntheir unobserved influences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLangevinFlow\u7684\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u7269\u7406\u5148\u9a8c\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u6355\u6349\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u6001\u7279\u6027\u548c\u5916\u90e8\u5f71\u54cd\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u6001\u884c\u4e3a\u5177\u6709\u590d\u6742\u7684\u6f5c\u5728\u7ed3\u6784\uff0c\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u5176\u5185\u90e8\u52a8\u6001\u548c\u5916\u90e8\u672a\u89c2\u6d4b\u5230\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51faLangevinFlow\u6a21\u578b\uff0c\u4f7f\u7528\u6b20\u963b\u5c3cLangevin\u65b9\u7a0b\u63cf\u8ff0\u6f5c\u53d8\u91cf\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u5e76\u5f15\u5165\u7269\u7406\u5148\u9a8c\uff08\u5982\u60ef\u6027\u3001\u963b\u5c3c\u3001\u968f\u673a\u529b\u7b49\uff09\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548cNLB\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u9884\u6d4b\u7cbe\u5ea6\u548c\u89e3\u7801\u884c\u4e3a\u6307\u6807\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LangevinFlow\u4e3a\u795e\u7ecf\u52a8\u6001\u5efa\u6a21\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6027\u80fd\u7684\u6846\u67b6\u3002", "keywords": "LangevinFlow, \u53d8\u5206\u81ea\u7f16\u7801\u5668, \u795e\u7ecf\u7f51\u7edc\u52a8\u6001"}}
{"id": "2507.10560", "pdf": "https://arxiv.org/pdf/2507.10560", "abs": "https://arxiv.org/abs/2507.10560", "authors": ["Shreel Golwala"], "title": "Tangma: A Tanh-Guided Activation Function with Learnable Parameters", "categories": ["cs.NE", "cs.CV", "cs.LG"], "comment": null, "summary": "Activation functions are key to effective backpropagation and expressiveness\nin deep neural networks. This work introduces Tangma, a new activation function\nthat combines the smooth shape of the hyperbolic tangent with two learnable\nparameters: $\\alpha$, which shifts the curve's inflection point to adjust\nneuron activation, and $\\gamma$, which adds linearity to preserve weak\ngradients and improve training stability. Tangma was evaluated on MNIST and\nCIFAR-10 using custom networks composed of convolutional and linear layers, and\ncompared against ReLU, Swish, and GELU. On MNIST, Tangma achieved the highest\nvalidation accuracy of 99.09% and the lowest validation loss, demonstrating\nfaster and more stable convergence than the baselines. On CIFAR-10, Tangma\nreached a top validation accuracy of 78.15%, outperforming all other activation\nfunctions while maintaining a competitive training loss. Tangma also showed\nimproved training efficiency, with lower average epoch runtimes compared to\nSwish and GELU. These results suggest that Tangma performs well on standard\nvision tasks and enables reliable, efficient training. Its learnable design\ngives more control over activation behavior, which may benefit larger models in\ntasks such as image recognition or language modeling.", "AI": {"tldr": "Tangma\u662f\u4e00\u79cd\u65b0\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u7ed3\u5408\u4e86\u53cc\u66f2\u6b63\u5207\u7684\u5e73\u6ed1\u6027\u548c\u4e24\u4e2a\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u5728MNIST\u548cCIFAR-10\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eReLU\u3001Swish\u548cGELU\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u9a8c\u8bc1\u7cbe\u5ea6\u548c\u66f4\u4f4e\u7684\u635f\u5931\u3002", "motivation": "\u7814\u7a76\u6fc0\u6d3b\u51fd\u6570\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5e73\u6ed1\u6027\u548c\u53ef\u5b66\u4e60\u53c2\u6570\u7684\u65b0\u6fc0\u6d3b\u51fd\u6570Tangma\uff0c\u4ee5\u4f18\u5316\u795e\u7ecf\u5143\u6fc0\u6d3b\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faTangma\u6fc0\u6d3b\u51fd\u6570\uff0c\u5f15\u5165\u53ef\u5b66\u4e60\u53c2\u6570\u03b1\u548c\u03b3\uff0c\u5206\u522b\u8c03\u6574\u6fc0\u6d3b\u66f2\u7ebf\u7684\u62d0\u70b9\u5e76\u589e\u5f3a\u7ebf\u6027\u6027\uff1b\u5728MNIST\u548cCIFAR-10\u4efb\u52a1\u4e2d\u6d4b\u8bd5\u5176\u6027\u80fd\u3002", "result": "\u5728MNIST\u4e0a\u8fbe\u523099.09%\u7684\u6700\u9ad8\u9a8c\u8bc1\u7cbe\u5ea6\u548c\u6700\u4f4e\u635f\u5931\uff0cCIFAR-10\u4e0a\u4e3a78.15%\uff0c\u540c\u65f6\u8bad\u7ec3\u6548\u7387\u4f18\u4e8eSwish\u548cGELU\u3002", "conclusion": "Tangma\u5728\u6807\u51c6\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u5176\u53ef\u5b66\u4e60\u8bbe\u8ba1\u4e3a\u66f4\u5927\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u591a\u7075\u6d3b\u6027\uff0c\u6709\u671b\u5728\u56fe\u50cf\u8bc6\u522b\u548c\u8bed\u8a00\u5efa\u6a21\u4e2d\u53d1\u6325\u4f5c\u7528\u3002", "keywords": "\u6fc0\u6d3b\u51fd\u6570, \u53ef\u5b66\u4e60\u53c2\u6570, \u53cc\u66f2\u6b63\u5207, MNIST, CIFAR-10"}}
{"id": "2507.10643", "pdf": "https://arxiv.org/pdf/2507.10643", "abs": "https://arxiv.org/abs/2507.10643", "authors": ["Yuchi Tang", "I\u00f1aki Esnaola", "Suzanne Mason", "George Panoutsos"], "title": "TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc Attributions for Opaque Models", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "17 pages, 6 figures, Submitted to NeurIPS 2025", "summary": "Existing post-hoc model-agnostic methods generate external explanations for\nopaque models, primarily by locally attributing the model output to its input\nfeatures. However, they often lack an explicit and systematic framework for\nquantifying the contribution of individual features. Building on the Taylor\nexpansion framework introduced by Deng et al. (2024) to unify existing local\nattribution methods, we propose a rigorous set of postulates -- \"precision\",\n\"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific\nattribution. Guided by these postulates, we introduce TaylorPODA (Taylor\nexpansion-derived imPortance-Order aDapted Attribution), which incorporates an\nadditional \"adaptation\" property. This property enables alignment with\ntask-specific goals, especially in post-hoc settings lacking ground-truth\nexplanations. Empirical evaluations demonstrate that TaylorPODA achieves\ncompetitive results against baseline methods, providing principled and\nvisualization-friendly explanations. This work represents a step toward the\ntrustworthy deployment of opaque models by offering explanations with stronger\ntheoretical grounding.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6cf0\u52d2\u5c55\u5f00\u7684\u65b0\u578b\u6a21\u578b\u89e3\u91ca\u65b9\u6cd5TaylorPODA\uff0c\u901a\u8fc7\u2018\u7cbe\u786e\u6027\u2019\u3001\u2018\u8054\u5408\u6027\u2019\u548c\u2018\u96f6\u5dee\u5f02\u2019\u4e09\u4e2a\u516c\u7406\u6765\u91cf\u5316\u7279\u5f81\u8d21\u732e\uff0c\u5e76\u5f15\u5165\u2018\u9002\u5e94\u6027\u2019\u4ee5\u5bf9\u9f50\u4efb\u52a1\u76ee\u6807\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u540e\u6a21\u578b\u65e0\u5173\u89e3\u91ca\u65b9\u6cd5\u7f3a\u4e4f\u91cf\u5316\u7279\u5f81\u8d21\u732e\u7684\u660e\u786e\u6846\u67b6\uff0c\u8bba\u6587\u65e8\u5728\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u66f4\u5f3a\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u5bf9\u4e0d\u900f\u660e\u6a21\u578b\u7684\u4fe1\u4efb\u3002", "method": "\u57fa\u4e8e\u6cf0\u52d2\u5c55\u5f00\u6846\u67b6\uff0c\u63d0\u51faTaylorPODA\u65b9\u6cd5\uff0c\u5f15\u5165\u2018\u7cbe\u786e\u6027\u2019\u3001\u2018\u8054\u5408\u6027\u2019\u3001\u2018\u96f6\u5dee\u5f02\u2019\u548c\u2018\u9002\u5e94\u6027\u2019\u56db\u4e2a\u516c\u7406\uff0c\u91cf\u5316\u7279\u5f81\u8d21\u732e\u5e76\u9002\u5e94\u4efb\u52a1\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTaylorPODA\u5728\u89e3\u91ca\u8d28\u91cf\u548c\u53ef\u89c6\u5316\u53cb\u597d\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "TaylorPODA\u4e3a\u4e0d\u900f\u660e\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u66f4\u5f3a\u7684\u89e3\u91ca\uff0c\u63a8\u52a8\u5176\u53ef\u4fe1\u90e8\u7f72\u3002", "keywords": "\u6a21\u578b\u89e3\u91ca\u3001\u6cf0\u52d2\u5c55\u5f00\u3001\u7279\u5f81\u8d21\u732e\u3001TaylorPODA\u3001\u4fe1\u4efb\u90e8\u7f72"}}
{"id": "2507.10646", "pdf": "https://arxiv.org/pdf/2507.10646", "abs": "https://arxiv.org/abs/2507.10646", "authors": ["Myeongsoo Kim", "Shweta Garg", "Baishakhi Ray", "Varun Kumar", "Anoop Deoras"], "title": "CodeAssistBench (CAB): Dataset & Benchmarking for Multi-turn Chat-Based Code Assistance", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Programming assistants powered by large language models have transformed\nsoftware development, yet most benchmarks focus narrowly on code generation\ntasks. Recent efforts like InfiBench and StackEval attempt to address this gap\nusing Stack Overflow data but remain limited to single-turn interactions in\nisolated contexts, require significant manual curation, and fail to represent\ncomplete project environments. We introduce CodeAssistBench (CAB), the first\nbenchmark framework for evaluating multi-turn programming assistance in\nrealistic settings that address real-world questions about actual codebases.\nUnlike existing programming Q&A benchmarks, CAB automatically generates\nscalable datasets from question-related GitHub issues using configurable\nparameters (e.g., repository creation date, star count, programming languages),\nand includes automatic containerization of codebases for evaluation. It then\nevaluates models through simulated users in these containerized environments\nwith full codebase access. Using this framework, we constructed a test set of\n3,286 real-world programming questions across 231 repositories, spanning seven\nprogramming languages and diverse problem domains. Our evaluation of leading\nLLMs reveals a substantial capability gap: while models perform well on Stack\nOverflow questions with success rates of 70-83%, they resolve only up to 16.49%\nof CAB's recent issues. This discrepancy highlights the challenges of providing\nassistance in complex, project-specific contexts versus answering standalone\nquestions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CodeAssistBench\uff08CAB\uff09\uff0c\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u8f6e\u7f16\u7a0b\u8f85\u52a9\u7684\u73b0\u5b9e\u573a\u666f\u57fa\u51c6\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u9879\u76ee\u73af\u5883\u4e2d\u7684\u80fd\u529b\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7f16\u7a0b\u52a9\u624b\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u73b0\u5b9e\u73af\u5883\u4e2d\u591a\u8f6e\u4ea4\u4e92\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u4e9f\u9700\u4e00\u4e2a\u66f4\u5168\u9762\u7684\u6d4b\u8bd5\u6846\u67b6\u3002", "method": "CAB\u901a\u8fc7\u81ea\u52a8\u4eceGitHub\u95ee\u9898\u751f\u6210\u53ef\u6269\u5c55\u6570\u636e\u96c6\uff0c\u5305\u62ec\u4ee3\u7801\u5e93\u5bb9\u5668\u5316\u548c\u6a21\u62df\u7528\u6237\u8bc4\u4f30\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3,286\u4e2a\u771f\u5b9e\u95ee\u9898\u7684\u6d4b\u8bd5\u96c6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u6a21\u578b\u5728Stack Overflow\u95ee\u9898\u4e0a\u6210\u529f\u738770-83%\uff0c\u4f46\u5728CAB\u7684\u590d\u6742\u95ee\u9898\u4e2d\u4ec5\u89e3\u51b316.49%\uff0c\u80fd\u529b\u5dee\u8ddd\u663e\u8457\u3002", "conclusion": "CAB\u51f8\u663e\u4e86\u5728\u590d\u6742\u9879\u76ee\u73af\u5883\u4e2d\u63d0\u4f9b\u7f16\u7a0b\u8f85\u52a9\u7684\u6311\u6218\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "keywords": "\u7f16\u7a0b\u52a9\u624b,\u57fa\u51c6\u6d4b\u8bd5,\u591a\u8f6e\u4ea4\u4e92,\u4ee3\u7801\u5e93\u73af\u5883,\u5927\u8bed\u8a00\u6a21\u578b"}}
{"id": "2507.10567", "pdf": "https://arxiv.org/pdf/2507.10567", "abs": "https://arxiv.org/abs/2507.10567", "authors": ["Miranda Christ", "Daniel Reichman", "Jonathan Shafer"], "title": "Protocols for Verifying Smooth Strategies in Bandits and Games", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "We study protocols for verifying approximate optimality of strategies in\nmulti-armed bandits and normal-form games. As the number of actions available\nto each player is often large, we seek protocols where the number of queries to\nthe utility oracle is sublinear in the number of actions. We prove that such\nverification is possible for sufficiently smooth strategies that do not put too\nmuch probability mass on any specific action. We provide protocols for\nverifying that a smooth policy for a multi-armed bandit is\n$\\varepsilon$-optimal. Our verification protocols require provably fewer arm\nqueries than learning. Furthermore, we establish a nearly-tight lower bound on\nthe query complexity of verification in our settings. As an application, we\nshow how to use verification for bandits to achieve verification in normal-form\ngames. This gives a protocol for verifying whether a given strategy profile is\nan approximate strong smooth Nash equilibrium, with a query complexity that is\nsublinear in the number of actions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u591a\u81c2\u8001\u864e\u673a\u548c\u6807\u51c6\u535a\u5f08\u4e2d\u9a8c\u8bc1\u7b56\u7565\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u534f\u8bae\uff0c\u63d0\u51fa\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u4f4e\u4e8e\u5b66\u4e60\u6210\u672c\u7684\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8e\u9a8c\u8bc1\u8fd1\u4f3c\u5f3a\u5e73\u6ed1\u7eb3\u4ec0\u5747\u8861\u3002", "motivation": "\u7531\u4e8e\u73a9\u5bb6\u53ef\u9009\u52a8\u4f5c\u6570\u91cf\u5e9e\u5927\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u8bbe\u8ba1\u51fa\u67e5\u8be2\u590d\u6742\u5ea6\u4f4e\u4e8e\u52a8\u4f5c\u6570\u91cf\u7684\u9a8c\u8bc1\u534f\u8bae\u3002", "method": "\u8bbe\u8ba1\u4e86\u9488\u5bf9\u5e73\u6ed1\u7b56\u7565\u7684\u9a8c\u8bc1\u534f\u8bae\uff0c\u8bc1\u660e\u5176\u67e5\u8be2\u590d\u6742\u5ea6\u4f4e\u4e8e\u5b66\u4e60\u6210\u672c\uff0c\u5e76\u5efa\u7acb\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u7684\u4e0b\u9650\u3002", "result": "\u9a8c\u8bc1\u534f\u8bae\u5728\u591a\u81c2\u8001\u864e\u673a\u548c\u6807\u51c6\u535a\u5f08\u4e2d\u6709\u6548\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u4f4e\u4e8e\u5b66\u4e60\u6210\u672c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u52a8\u4f5c\u96c6\u7684\u7b56\u7565\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9ad8\u6548\u9014\u5f84\u3002", "keywords": "\u591a\u81c2\u8001\u864e\u673a, \u6807\u51c6\u535a\u5f08, \u9a8c\u8bc1\u534f\u8bae, \u67e5\u8be2\u590d\u6742\u5ea6, \u5e73\u6ed1\u7b56\u7565"}}
{"id": "2507.10695", "pdf": "https://arxiv.org/pdf/2507.10695", "abs": "https://arxiv.org/abs/2507.10695", "authors": ["Jabari Kwesi", "Jiaxun Cao", "Riya Manchanda", "Pardis Emami-Naeini"], "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.ET", "cs.HC"], "comment": "Accepted to the 34th USENIX Security Symposium", "summary": "Individuals are increasingly relying on large language model (LLM)-enabled\nconversational agents for emotional support. While prior research has examined\nprivacy and security issues in chatbots specifically designed for mental health\npurposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not\nleverage generative AI. Little empirical research currently measures users'\nprivacy and security concerns, attitudes, and expectations when using\ngeneral-purpose LLM-enabled chatbots to manage and improve mental health.\nThrough 21 semi-structured interviews with U.S. participants, we identified\ncritical misconceptions and a general lack of risk awareness. Participants\nconflated the human-like empathy exhibited by LLMs with human-like\naccountability and mistakenly believed that their interactions with these\nchatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures\nwith a licensed therapist. We introduce the concept of \"intangible\nvulnerability,\" where emotional or psychological disclosures are undervalued\ncompared to more tangible forms of information (e.g., financial or\nlocation-based data). To address this, we propose recommendations to safeguard\nuser mental health disclosures with general-purpose LLM-enabled chatbots more\neffectively.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u7528\u6237\u5728\u4f7f\u7528\u901a\u7528LLM\u652f\u6301\u7684\u804a\u5929\u673a\u5668\u4eba\u8fdb\u884c\u5fc3\u7406\u5065\u5eb7\u7ba1\u7406\u65f6\u7684\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\uff0c\u53d1\u73b0\u7528\u6237\u5b58\u5728\u8bef\u89e3\u548c\u98ce\u9669\u610f\u8bc6\u4e0d\u8db3\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u586b\u8865\u73b0\u6709\u6587\u732e\u4e2d\u5173\u4e8e\u901a\u7528LLM\u804a\u5929\u673a\u5668\u4eba\u5728\u5fc3\u7406\u5065\u5eb7\u652f\u6301\u65b9\u9762\u7684\u9690\u79c1\u548c\u5b89\u5168\u95ee\u9898\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc721\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5206\u6790\u4e86\u7f8e\u56fd\u53c2\u4e0e\u8005\u5bf9LLM\u804a\u5929\u673a\u5668\u4eba\u7684\u9690\u79c1\u548c\u5b89\u5168\u7684\u770b\u6cd5\u3002", "result": "\u53d1\u73b0\u4e86\u7528\u6237\u5bf9LLM\u804a\u5929\u673a\u5668\u4eba\u7684\u8bef\u89e3\uff0c\u5982\u5c06\u5176\u4eba\u673a\u540c\u7406\u5fc3\u4e0e\u4eba\u7c7b\u8d23\u4efb\u6df7\u6dc6\uff0c\u5e76\u63d0\u51fa\u201c\u65e0\u5f62\u8106\u5f31\u6027\u201d\u6982\u5ff5\u3002", "conclusion": "\u7814\u7a76\u547c\u5401\u52a0\u5f3a\u5bf9\u901a\u7528LLM\u804a\u5929\u673a\u5668\u4eba\u4e2d\u5fc3\u7406\u5065\u5eb7\u62ab\u9732\u7684\u4fdd\u62a4\u63aa\u65bd\u3002", "keywords": "LLM, \u5fc3\u7406\u5065\u5eb7, \u9690\u79c1\u5b89\u5168, \u65e0\u5f62\u8106\u5f31\u6027, \u7528\u6237\u8bef\u89e3"}}
{"id": "2507.10601", "pdf": "https://arxiv.org/pdf/2507.10601", "abs": "https://arxiv.org/abs/2507.10601", "authors": ["Ruixi Zheng", "Wei Zhang", "Yijie Li", "Xi Zhu", "Zhou Lan", "Jarrett Rushmore", "Yogesh Rathi", "Nikos Makris", "Lauren J. O'Donnell", "Fan Zhang"], "title": "AGFS-Tractometry: A Novel Atlas-Guided Fine-Scale Tractometry Approach for Enhanced Along-Tract Group Statistical Comparison Using Diffusion MRI Tractography", "categories": ["q-bio.QM", "cs.CV", "cs.LG", "eess.IV", "stat.ME"], "comment": "31 pages and 7 figures", "summary": "Diffusion MRI (dMRI) tractography is currently the only method for in vivo\nmapping of the brain's white matter (WM) connections. Tractometry is an\nadvanced tractography analysis technique for along-tract profiling to\ninvestigate the morphology and microstructural properties along the fiber\ntracts. Tractometry has become an essential tool for studying local along-tract\ndifferences between different populations (e.g., health vs disease). In this\nstudy, we propose a novel atlas-guided fine-scale tractometry method, namely\nAGFS-Tractometry, that leverages tract spatial information and permutation\ntesting to enhance the along-tract statistical analysis between populations.\nThere are two major contributions in AGFS-Tractometry. First, we create a novel\natlas-guided tract profiling template that enables consistent, fine-scale,\nalong-tract parcellation of subject-specific fiber tracts. Second, we propose a\nnovel nonparametric permutation testing group comparison method to enable\nsimultaneous analysis across all along-tract parcels while correcting for\nmultiple comparisons. We perform experimental evaluations on synthetic datasets\nwith known group differences and in vivo real data. We compare AGFS-Tractometry\nwith two state-of-the-art tractometry methods, including Automated Fiber-tract\nQuantification (AFQ) and BUndle ANalytics (BUAN). Our results show that the\nproposed AGFS-Tractometry obtains enhanced sensitivity and specificity in\ndetecting local WM differences. In the real data analysis experiments,\nAGFS-Tractometry can identify more regions with significant differences, which\nare anatomically consistent with the existing literature. Overall, these\ndemonstrate the ability of AGFS-Tractometry to detect subtle or spatially\nlocalized WM group-level differences. The created tract profiling template and\nrelated code are available at:\nhttps://github.com/ZhengRuixi/AGFS-Tractometry.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684ATLAS\u5f15\u5bfc\u7ec6\u5c3a\u5ea6\u7ea4\u7ef4\u675f\u6d4b\u91cf\u65b9\u6cd5AGFS-Tractometry\uff0c\u901a\u8fc7\u5229\u7528\u7ea4\u7ef4\u675f\u7a7a\u95f4\u4fe1\u606f\u548c\u7f6e\u6362\u6d4b\u8bd5\u6765\u589e\u5f3a\u7fa4\u4f53\u95f4\u7684\u6cbf\u675f\u7edf\u8ba1\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u6539\u8fdb\u73b0\u6709\u7ea4\u7ef4\u675f\u6d4b\u91cf\u6280\u672f\uff0c\u4ee5\u66f4\u654f\u611f\u548c\u7279\u5f02\u6027\u5730\u68c0\u6d4b\u767d\u8d28\u5c40\u90e8\u5dee\u5f02\u3002", "method": "\u521b\u5efaATLAS\u5f15\u5bfc\u7684\u7ea4\u7ef4\u675f\u5206\u6790\u6a21\u677f\u5e76\u63d0\u51fa\u975e\u53c2\u6570\u7f6e\u6362\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u6cbf\u675f\u591a\u6bd4\u8f83\u6821\u6b63\u7684\u7fa4\u4f53\u5206\u6790\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0cAGFS-Tractometry\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u654f\u611f\u6027\u548c\u7279\u5f02\u6027\uff0c\u80fd\u68c0\u6d4b\u66f4\u591a\u89e3\u5256\u4e00\u81f4\u7684\u663e\u8457\u5dee\u5f02\u533a\u57df\u3002", "conclusion": "AGFS-Tractometry\u80fd\u591f\u68c0\u6d4b\u7ec6\u5fae\u6216\u5c40\u90e8\u767d\u8d28\u7fa4\u4f53\u5dee\u5f02\uff0c\u4e3a\u7ea4\u7ef4\u675f\u6d4b\u91cf\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002", "keywords": "dMRI, tractography, tractometry, along-tract analysis, permutation testing"}}
{"id": "2507.10755", "pdf": "https://arxiv.org/pdf/2507.10755", "abs": "https://arxiv.org/abs/2507.10755", "authors": ["Rina Khan", "Catherine Stinson"], "title": "Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Facial expression recognition (FER) algorithms classify facial expressions\ninto emotions such as happy, sad, or angry. An evaluative challenge facing FER\nalgorithms is the fall in performance when detecting spontaneous expressions\ncompared to posed expressions. An ethical (and evaluative) challenge facing FER\nalgorithms is that they tend to perform poorly for people of some races and\nskin colors. These challenges are linked to the data collection practices\nemployed in the creation of FER datasets. In this study, we audit two\nstate-of-the-art FER datasets. We take random samples from each dataset and\nexamine whether images are spontaneous or posed. In doing so, we propose a\nmethodology for identifying spontaneous or posed images. We discover a\nsignificant number of images that were posed in the datasets purporting to\nconsist of in-the-wild images. Since performance of FER models vary between\nspontaneous and posed images, the performance of models trained on these\ndatasets will not represent the true performance if such models were to be\ndeployed in in-the-wild applications. We also observe the skin color of\nindividuals in the samples, and test three models trained on each of the\ndatasets to predict facial expressions of people from various races and skin\ntones. We find that the FER models audited were more likely to predict people\nlabeled as not white or determined to have dark skin as showing a negative\nemotion such as anger or sadness even when they were smiling. This bias makes\nsuch models prone to perpetuate harm in real life applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5ba1\u8ba1\u4e86\u4e24\u4e2aFER\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5176\u4e2d\u5b58\u5728\u5927\u91cf\u6446\u62cd\u56fe\u50cf\uff0c\u4e14\u6a21\u578b\u5bf9\u975e\u767d\u4eba\u6216\u6df1\u8272\u76ae\u80a4\u4eba\u7fa4\u5b58\u5728\u60c5\u611f\u8bc6\u522b\u504f\u5dee\u3002", "motivation": "\u89e3\u51b3FER\u7b97\u6cd5\u5728\u81ea\u53d1\u8868\u60c5\u548c\u80a4\u8272\u5dee\u5f02\u4e0a\u7684\u6027\u80fd\u4e0e\u4f26\u7406\u6311\u6218\u3002", "method": "\u4ece\u6570\u636e\u96c6\u4e2d\u968f\u673a\u62bd\u6837\uff0c\u5206\u6790\u56fe\u50cf\u662f\u5426\u4e3a\u81ea\u53d1\u6216\u6446\u62cd\uff0c\u5e76\u6d4b\u8bd5\u6a21\u578b\u5728\u4e0d\u540c\u80a4\u8272\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u6570\u636e\u96c6\u5b58\u5728\u6446\u62cd\u56fe\u50cf\uff0c\u6a21\u578b\u5bf9\u975e\u767d\u4eba\u6216\u6df1\u8272\u76ae\u80a4\u4eba\u7fa4\u6709\u8d1f\u9762\u60c5\u611f\u8bc6\u522b\u504f\u5dee\u3002", "conclusion": "\u6570\u636e\u96c6\u548c\u6a21\u578b\u7684\u504f\u5dee\u53ef\u80fd\u5bfc\u81f4\u73b0\u5b9e\u5e94\u7528\u4e2d\u6f5c\u5728\u5371\u5bb3\u3002", "keywords": "\u9762\u90e8\u8868\u60c5\u8bc6\u522b,\u6570\u636e\u96c6\u5ba1\u8ba1,\u80a4\u8272\u504f\u5dee,\u4f26\u7406\u6311\u6218"}}
{"id": "2507.10775", "pdf": "https://arxiv.org/pdf/2507.10775", "abs": "https://arxiv.org/abs/2507.10775", "authors": ["Jeffrey Joan Sam", "Janhavi Sathe", "Nikhil Chigali", "Naman Gupta", "Radhey Ruparel", "Yicheng Jiang", "Janmajay Singh", "James W. Berck", "Arko Barman"], "title": "A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers", "categories": ["cs.CV", "cs.AI", "eess.IV"], "comment": null, "summary": "Spacecraft deployed in outer space are routinely subjected to various forms\nof damage due to exposure to hazardous environments. In addition, there are\nsignificant risks to the subsequent process of in-space repairs through human\nextravehicular activity or robotic manipulation, incurring substantial\noperational costs. Recent developments in image segmentation could enable the\ndevelopment of reliable and cost-effective autonomous inspection systems. While\nthese models often require large amounts of training data to achieve\nsatisfactory results, publicly available annotated spacecraft segmentation data\nare very scarce. Here, we present a new dataset of nearly 64k annotated\nspacecraft images that was created using real spacecraft models, superimposed\non a mixture of real and synthetic backgrounds generated using NASA's TTALOS\npipeline. To mimic camera distortions and noise in real-world image\nacquisition, we also added different types of noise and distortion to the\nimages. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to\ngenerate performance benchmarks for the dataset under well-defined hardware and\ninference time constraints to mimic real-world image segmentation challenges\nfor real-time onboard applications in space on NASA's inspector spacecraft. The\nresulting models, when tested under these constraints, achieved a Dice score of\n0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.\nThe dataset and models for performance benchmark are available at\nhttps://github.com/RiceD2KLab/SWiM.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u822a\u5929\u5668\u56fe\u50cf\u6570\u636e\u96c6\uff0864k\u6807\u6ce8\u56fe\u50cf\uff09\uff0c\u7528\u4e8e\u8bad\u7ec3\u56fe\u50cf\u5206\u5272\u6a21\u578b\uff0c\u5e76\u5728NASA\u7684TTALOS\u6d41\u7a0b\u4e2d\u751f\u6210\u5408\u6210\u80cc\u666f\u3002\u6a21\u578b\u5728\u771f\u5b9e\u786c\u4ef6\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u822a\u5929\u5668\u5728\u592a\u7a7a\u73af\u5883\u4e2d\u6613\u53d7\u635f\uff0c\u4eba\u5de5\u6216\u673a\u5668\u4eba\u7ef4\u4fee\u6210\u672c\u9ad8\uff0c\u9700\u5f00\u53d1\u4f4e\u6210\u672c\u3001\u53ef\u9760\u7684\u81ea\u4e3b\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4f46\u73b0\u6709\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u822a\u5929\u5668\u6a21\u578b\u4e0e\u5408\u6210\u80cc\u666f\u751f\u6210\u6570\u636e\u96c6\uff0c\u6dfb\u52a0\u566a\u58f0\u6a21\u62df\u771f\u5b9e\u56fe\u50cf\u5931\u771f\uff0c\u5e76\u5fae\u8c03YOLOv8\u548cYOLOv11\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u8fbe\u5230Dice\u5206\u65700.92\u3001Hausdorff\u8ddd\u79bb0.69\uff0c\u63a8\u7406\u65f6\u95f4\u7ea60.5\u79d2\u3002", "conclusion": "\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e3a\u822a\u5929\u5668\u5b9e\u65f6\u56fe\u50cf\u5206\u5272\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u51c6\u3002", "keywords": "\u822a\u5929\u5668\u56fe\u50cf\u5206\u5272,\u5408\u6210\u6570\u636e\u96c6,YOLO\u6a21\u578b,\u81ea\u4e3b\u68c0\u6d4b"}}
{"id": "2507.10608", "pdf": "https://arxiv.org/pdf/2507.10608", "abs": "https://arxiv.org/abs/2507.10608", "authors": ["Danny Butvinik", "Ofir Yakobi", "Michal Einhorn Cohen", "Elina Maliarsky"], "title": "The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns", "categories": ["cs.SI", "cs.LG", "stat.AP"], "comment": null, "summary": "Conventional anti-money laundering (AML) systems predominantly focus on\nidentifying anomalous entities or transactions, flagging them for manual\ninvestigation based on statistical deviation or suspicious behavior. This\nparadigm, however, misconstrues the true nature of money laundering, which is\nrarely anomalous but often deliberate, repeated, and concealed within\nconsistent behavioral routines. In this paper, we challenge the entity-centric\napproach and propose a network-theoretic perspective that emphasizes detecting\npredefined laundering patterns across directed transaction networks. We\nintroduce the notion of behavioral consistency as the core trait of laundering\nactivity, and argue that such patterns are better captured through subgraph\nstructures expressing semantic and functional roles - not solely geometry.\nCrucially, we explore the concept of pattern fragility: the sensitivity of\nlaundering patterns to small attribute changes and, conversely, their semantic\nrobustness even under drastic topological transformations. We claim that\nlaundering detection should not hinge on statistical outliers, but on\npreservation of behavioral essence, and propose a reconceptualization of\npattern similarity grounded in this insight. This philosophical and practical\nshift has implications for how AML systems model, scan, and interpret networks\nin the fight against financial crime.", "AI": {"tldr": "\u4f20\u7edf\u53cd\u6d17\u94b1\uff08AML\uff09\u7cfb\u7edf\u901a\u5e38\u5173\u6ce8\u5f02\u5e38\u5b9e\u4f53\u6216\u4ea4\u6613\uff0c\u800c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u7406\u8bba\u7684\u89c6\u89d2\uff0c\u5f3a\u8c03\u901a\u8fc7\u9884\u5b9a\u4e49\u7684\u6d17\u94b1\u6a21\u5f0f\u5728\u6709\u5411\u4ea4\u6613\u7f51\u7edc\u4e2d\u68c0\u6d4b\uff0c\u6838\u5fc3\u662f\u884c\u4e3a\u4e00\u81f4\u6027\u800c\u975e\u5f02\u5e38\u3002", "motivation": "\u4f20\u7edfAML\u7cfb\u7edf\u8bef\u5224\u4e86\u6d17\u94b1\u7684\u672c\u8d28\uff0c\u6d17\u94b1\u884c\u4e3a\u5e76\u975e\u5f02\u5e38\uff0c\u800c\u662f\u6709\u610f\u7684\u3001\u91cd\u590d\u7684\uff0c\u5e76\u9690\u85cf\u5728\u4e00\u81f4\u7684\u884c\u4e3a\u6a21\u5f0f\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u7f51\u7edc\u7406\u8bba\u89c6\u89d2\uff0c\u5173\u6ce8\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u9884\u5b9a\u4e49\u7684\u6d17\u94b1\u6a21\u5f0f\uff0c\u5f15\u5165\u5b50\u56fe\u7ed3\u6784\u4ee5\u6355\u6349\u8bed\u4e49\u548c\u529f\u80fd\u89d2\u8272\uff0c\u800c\u975e\u4ec5\u51e0\u4f55\u7279\u5f81\u3002\u63d0\u51fa\u6a21\u5f0f\u8106\u5f31\u6027\u6982\u5ff5\uff0c\u5f3a\u8c03\u884c\u4e3a\u672c\u8d28\u7684\u4fdd\u6301\u3002", "result": "\u63d0\u51faAML\u7cfb\u7edf\u5e94\u91cd\u65b0\u5b9a\u4e49\u6a21\u5f0f\u76f8\u4f3c\u6027\uff0c\u5173\u6ce8\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u8bed\u4e49\u9c81\u68d2\u6027\uff0c\u800c\u975e\u7edf\u8ba1\u5f02\u5e38\u3002", "conclusion": "\u7406\u8bba\u548c\u65b9\u6cd5\u4e0a\u7684\u8f6c\u53d8\u4e3aAML\u7cfb\u7edf\u5728\u68c0\u6d4b\u91d1\u878d\u72af\u7f6a\u65f6\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002", "keywords": "\u53cd\u6d17\u94b1, \u7f51\u7edc\u7406\u8bba, \u884c\u4e3a\u4e00\u81f4\u6027, \u5b50\u56fe\u7ed3\u6784, \u6a21\u5f0f\u8106\u5f31\u6027"}}
{"id": "2507.10778", "pdf": "https://arxiv.org/pdf/2507.10778", "abs": "https://arxiv.org/abs/2507.10778", "authors": ["Hsiang-Wei Huang", "Jen-Hao Cheng", "Kuang-Ming Chen", "Cheng-Yen Yang", "Bahaa Alattar", "Yi-Ru Lin", "Pyongkun Kim", "Sangwon Kim", "Kwangju Kim", "Chung-I Huang", "Jenq-Neng Hwang"], "title": "Warehouse Spatial Question Answering with LLM Agent", "categories": ["cs.CV", "cs.AI"], "comment": "1st Place Solution of the 9th AI City Challenge Track 3", "summary": "Spatial understanding has been a challenging task for existing Multi-modal\nLarge Language Models~(MLLMs). Previous methods leverage large-scale MLLM\nfinetuning to enhance MLLM's spatial understanding ability. In this paper, we\npresent a data-efficient approach. We propose a LLM agent system with strong\nand advanced spatial reasoning ability, which can be used to solve the\nchallenging spatial question answering task in complex indoor warehouse\nscenarios. Our system integrates multiple tools that allow the LLM agent to\nconduct spatial reasoning and API tools interaction to answer the given\ncomplicated spatial question. Extensive evaluations on the 2025 AI City\nChallenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that\nour system achieves high accuracy and efficiency in tasks such as object\nretrieval, counting, and distance estimation. The code is available at:\nhttps://github.com/hsiangwei0903/SpatialAgent", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7LLM\u4ee3\u7406\u7cfb\u7edf\u589e\u5f3a\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u590d\u6742\u5ba4\u5185\u4ed3\u5e93\u573a\u666f\u4e2d\u7684\u7a7a\u95f4\u95ee\u7b54\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u7406\u89e3\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u63d0\u5347\u80fd\u529b\u3002", "method": "\u96c6\u6210\u591a\u79cd\u5de5\u5177\u7684LLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u7a7a\u95f4\u63a8\u7406\u548cAPI\u5de5\u5177\u4ea4\u4e92\u5b8c\u6210\u4efb\u52a1\u3002", "result": "\u57282025 AI City Challenge\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u5177\u6709\u4f18\u8d8a\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "keywords": "\u7a7a\u95f4\u7406\u89e3,\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b,LLM\u4ee3\u7406\u7cfb\u7edf,\u7a7a\u95f4\u63a8\u7406,AI City Challenge"}}
{"id": "2507.10786", "pdf": "https://arxiv.org/pdf/2507.10786", "abs": "https://arxiv.org/abs/2507.10786", "authors": ["Henry Bell", "Jabari Kwesi", "Hiba Laabadli", "Pardis Emami-Naeini"], "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots", "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.ET", "cs.HC"], "comment": null, "summary": "Equipped with artificial intelligence (AI) and advanced sensing capabilities,\nsocial robots are gaining interest among consumers in the United States. These\nrobots seem like a natural evolution of traditional smart home devices.\nHowever, their extensive data collection capabilities, anthropomorphic\nfeatures, and capacity to interact with their environment make social robots a\nmore significant security and privacy threat. Increased risks include data\nlinkage, unauthorized data sharing, and the physical safety of users and their\nhomes. It is critical to investigate U.S. users' security and privacy needs and\nconcerns to guide the design of social robots while these devices are still in\nthe early stages of commercialization in the U.S. market. Through 19\nsemi-structured interviews, we identified significant security and privacy\nconcerns, highlighting the need for transparency, usability, and robust privacy\ncontrols to support adoption. For educational applications, participants\nworried most about misinformation, and in medical use cases, they worried about\nthe reliability of these devices. Participants were also concerned with the\ndata inference that social robots could enable. We found that participants\nexpect tangible privacy controls, indicators of data collection, and\ncontext-appropriate functionality.", "AI": {"tldr": "\u7f8e\u56fd\u7528\u6237\u5bf9\u793e\u4ea4\u673a\u5668\u4eba\u7684\u5b89\u5168\u548c\u9690\u79c1\u98ce\u9669\u8868\u793a\u62c5\u5fe7\uff0c\u5f3a\u8c03\u9700\u8981\u900f\u660e\u6027\u3001\u6613\u7528\u6027\u548c\u5f3a\u5927\u7684\u9690\u79c1\u63a7\u5236\u3002", "motivation": "\u793e\u4ea4\u673a\u5668\u4eba\u56e0\u5176AI\u548c\u5148\u8fdb\u4f20\u611f\u80fd\u529b\u5728\u7f8e\u56fd\u5e02\u573a\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u6570\u636e\u6536\u96c6\u548c\u4ea4\u4e92\u80fd\u529b\u5e26\u6765\u4e86\u663e\u8457\u7684\u5b89\u5168\u4e0e\u9690\u79c1\u5a01\u80c1\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u7528\u6237\u9700\u6c42\uff0c\u6307\u5bfc\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc719\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u8bc6\u522b\u7528\u6237\u7684\u4e3b\u8981\u5b89\u5168\u548c\u9690\u79c1\u5173\u5207\u3002", "result": "\u7528\u6237\u6700\u5173\u6ce8\u6570\u636e\u900f\u660e\u5ea6\u3001\u8bef\u4fe1\u606f\u548c\u8bbe\u5907\u53ef\u9760\u6027\uff0c\u671f\u671b\u6709\u660e\u786e\u7684\u9690\u79c1\u63a7\u5236\u548c\u6570\u636e\u6536\u96c6\u6307\u793a\u3002", "conclusion": "\u793e\u4ea4\u673a\u5668\u4eba\u5728\u5546\u4e1a\u5316\u65e9\u671f\u9636\u6bb5\u9700\u6ce8\u91cd\u7528\u6237\u9690\u79c1\u548c\u5b89\u5168\u9700\u6c42\uff0c\u8bbe\u8ba1\u900f\u660e\u4e14\u6613\u7528\u7684\u9690\u79c1\u529f\u80fd\u3002", "keywords": "\u793e\u4ea4\u673a\u5668\u4eba, \u9690\u79c1, \u5b89\u5168, AI, \u7528\u6237\u9700\u6c42"}}
{"id": "2507.10812", "pdf": "https://arxiv.org/pdf/2507.10812", "abs": "https://arxiv.org/abs/2507.10812", "authors": ["Chuxuan Zhang", "Yasaman Etesam", "Angelica Lim"], "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI", "categories": ["cs.HC", "cs.AI"], "comment": "5 pages, 3 figures", "summary": "We propose an approach to test embodied AI agents for interaction awareness\nand believability, particularly in scenarios where humans push them to their\nlimits. Turing introduced the Imitation Game as a way to explore the question:\n\"Can machines think?\" The Total Turing Test later expanded this concept beyond\npurely verbal communication, incorporating perceptual and physical interaction.\nBuilding on this, we propose a new guiding question: \"Can machines react?\" and\nintroduce the React to This (RTT) test for nonverbal behaviors, presenting\nresults from an initial experiment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d4b\u8bd5\u5177\u8eabAI\u4ee3\u7406\u4ea4\u4e92\u610f\u8bc6\u548c\u53ef\u4fe1\u5ea6\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u4eba\u7c7b\u5c06\u5176\u63a8\u5411\u6781\u9650\u7684\u573a\u666f\u3002\u63d0\u51fa\u4e86\"\u673a\u5668\u80fd\u53cd\u5e94\u5417\uff1f\"\u7684\u65b0\u95ee\u9898\uff0c\u5e76\u4ecb\u7ecd\u4e86\"React to This\"\uff08RTT\uff09\u6d4b\u8bd5\u3002", "motivation": "\u63a2\u7d22AI\u4ee3\u7406\u5728\u4eba\u7c7b\u6781\u9650\u6d4b\u8bd5\u4e0b\u7684\u4ea4\u4e92\u610f\u8bc6\u548c\u53ef\u4fe1\u5ea6\uff0c\u6269\u5c55\u4e86\u56fe\u7075\u6d4b\u8bd5\u7684\u8303\u7574\u3002", "method": "\u8bbe\u8ba1\u4e86RTT\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u975e\u8bed\u8a00\u884c\u4e3a\uff0c\u5e76\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u9a8c\u3002", "result": "\u5c55\u793a\u4e86RTT\u6d4b\u8bd5\u5728\u975e\u8bed\u8a00\u884c\u4e3a\u4e2d\u7684\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "RTT\u6d4b\u8bd5\u4e3a\u8bc4\u4f30AI\u4ee3\u7406\u7684\u53cd\u5e94\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "keywords": "\u5177\u8eabAI, \u4ea4\u4e92\u610f\u8bc6, \u53ef\u4fe1\u5ea6, RTT\u6d4b\u8bd5, \u975e\u8bed\u8a00\u884c\u4e3a"}}
{"id": "2507.10634", "pdf": "https://arxiv.org/pdf/2507.10634", "abs": "https://arxiv.org/abs/2507.10634", "authors": ["Thomas Feys", "Liesbet Van der Perre", "Fran\u00e7ois Rottenberg"], "title": "Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "stat.ML"], "comment": null, "summary": "Massive MIMO systems are moving toward increased numbers of radio frequency\nchains, higher carrier frequencies and larger bandwidths. As such,\ndigital-to-analog converters (DACs) are becoming a bottleneck in terms of\nhardware complexity and power consumption. In this work, non-linear precoding\nfor coarsely quantized downlink massive MIMO is studied. Given the NP-hard\nnature of this problem, a graph neural network (GNN) is proposed that directly\noutputs the precoded quantized vector based on the channel matrix and the\nintended transmit symbols. The model is trained in a self-supervised manner, by\ndirectly maximizing the achievable rate. To overcome the non-differentiability\nof the objective function, introduced due to the non-differentiable DAC\nfunctions, a straight-through Gumbel-softmax estimation of the gradient is\nproposed. The proposed method achieves a significant increase in achievable sum\nrate under coarse quantization. For instance, in the single-user case, the\nproposed method can achieve the same sum rate as maximum ratio transmission\n(MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the\nDAC's power consumption by a factor 4-7 and 3 for baseband and RF DACs\nrespectively. This, however, comes at the cost of increased digital signal\nprocessing power consumption. When accounting for this, the reduction in\noverall power consumption holds for a system bandwidth up to 3.5 MHz for\nbaseband DACs, while the RF DACs can maintain a power reduction of 2.9 for\nhigher bandwidths. Notably, indirect effects, which further reduce the power\nconsumption, such as a reduced fronthaul consumption and reduction in other\ncomponents, are not considered in this analysis.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u9488\u5bf9\u7c97\u91cf\u5316\u4e0b\u884c\u94fe\u8def\u5927\u89c4\u6a21MIMO\u7684\u975e\u7ebf\u6027\u9884\u7f16\u7801\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u5b9e\u73b0\u7684\u603b\u548c\u901f\u7387\uff0c\u5e76\u964d\u4f4e\u4e86DAC\u7684\u529f\u8017\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u5c04\u9891\u94fe\u6570\u91cf\u3001\u8f7d\u6ce2\u9891\u7387\u548c\u5e26\u5bbd\u589e\u52a0\uff0c\u6570\u5b57\u6a21\u62df\u8f6c\u6362\u5668\uff08DAC\uff09\u5728\u786c\u4ef6\u590d\u6742\u6027\u548c\u529f\u8017\u65b9\u9762\u7684\u74f6\u9888\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u9884\u7f16\u7801\u65b9\u6cd5\u4ee5\u51cf\u5c11DAC\u7684\u8d1f\u62c5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u76f4\u63a5\u6839\u636e\u4fe1\u9053\u77e9\u9635\u548c\u4f20\u8f93\u7b26\u53f7\u8f93\u51fa\u9884\u7f16\u7801\u91cf\u5316\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u6700\u5927\u5316\u53ef\u5b9e\u73b0\u901f\u7387\u3002\u4e3a\u89e3\u51b3\u4e0d\u53ef\u5fae\u5206\u7684DAC\u51fd\u6570\u5bfc\u81f4\u7684\u68af\u5ea6\u8ba1\u7b97\u95ee\u9898\uff0c\u91c7\u7528\u4e86\u76f4\u901aGumbel-softmax\u68af\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u5728\u7c97\u91cf\u5316\u6761\u4ef6\u4e0b\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u5b9e\u73b0\u7684\u603b\u548c\u901f\u7387\u3002\u4f8b\u5982\uff0c\u5728\u5355\u7528\u6237\u60c5\u51b5\u4e0b\uff0c\u4f7f\u75281\u4f4dDAC\u5373\u53ef\u8fbe\u5230\u4e0e3\u4f4dDAC\u7684MRT\u76f8\u540c\u7684\u901f\u7387\uff0c\u4ece\u800c\u5c06DAC\u529f\u8017\u964d\u4f4e4-7\u500d\uff08\u57fa\u5e26DAC\uff09\u548c3\u500d\uff08\u5c04\u9891DAC\uff09\u3002\u4f46\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u7684\u529f\u8017\u6709\u6240\u589e\u52a0\u3002\u603b\u4f53\u529f\u8017\u964d\u4f4e\u5728\u57fa\u5e26DAC\u4e0b\u9002\u7528\u4e8e3.5 MHz\u7cfb\u7edf\u5e26\u5bbd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7c97\u91cf\u5316\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u663e\u8457\u964d\u4f4e\u4e86DAC\u529f\u8017\uff0c\u5c24\u5176\u5728\u4f4e\u5e26\u5bbd\u4e0b\u6548\u679c\u663e\u8457\uff0c\u4f46\u9700\u6743\u8861\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u529f\u8017\u7684\u589e\u52a0\u3002", "keywords": "\u5927\u89c4\u6a21MIMO, \u975e\u7ebf\u6027\u9884\u7f16\u7801, \u56fe\u795e\u7ecf\u7f51\u7edc, DAC\u529f\u8017, \u81ea\u76d1\u7763\u5b66\u4e60"}}
{"id": "2507.10635", "pdf": "https://arxiv.org/pdf/2507.10635", "abs": "https://arxiv.org/abs/2507.10635", "authors": ["Nicola Assolini", "Luca Marzari", "Isabella Mastroeni", "Alessandra di Pierro"], "title": "Formal Verification of Variational Quantum Circuits", "categories": ["quant-ph", "cs.LG", "cs.PL"], "comment": "Assolini and Marzari contributed equally to the paper", "summary": "Variational quantum circuits (VQCs) are a central component of many quantum\nmachine learning algorithms, offering a hybrid quantum-classical framework\nthat, under certain aspects, can be considered similar to classical deep neural\nnetworks. A shared aspect is, for instance, their vulnerability to adversarial\ninputs, small perturbations that can lead to incorrect predictions. While\nformal verification techniques have been extensively developed for classical\nmodels, no comparable framework exists for certifying the robustness of VQCs.\nHere, we present the first in-depth theoretical and practical study of the\nformal verification problem for VQCs. Inspired by abstract interpretation\nmethods used in deep learning, we analyze the applicability and limitations of\ninterval-based reachability techniques in the quantum setting. We show that\nquantum-specific aspects, such as state normalization, introduce inter-variable\ndependencies that challenge existing approaches. We investigate these issues by\nintroducing a novel semantic framework based on abstract interpretation, where\nthe verification problem for VQCs can be formally defined, and its complexity\nanalyzed. Finally, we demonstrate our approach on standard verification\nbenchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQCs\uff09\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u501f\u9274\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u62bd\u8c61\u89e3\u91ca\u6280\u672f\uff0c\u5206\u6790\u4e86\u91cf\u5b50\u7279\u5b9a\u56e0\u7d20\u5bf9\u9a8c\u8bc1\u7684\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6807\u51c6\u9a8c\u8bc1\u57fa\u51c6\u4e0a\u7684\u5e94\u7528\u3002", "motivation": "\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQCs\uff09\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u9c81\u68d2\u6027\u9a8c\u8bc1\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6846\u67b6\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u57fa\u4e8e\u62bd\u8c61\u89e3\u91ca\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8bed\u4e49\u6846\u67b6\uff0c\u5206\u6790\u4e86\u533a\u95f4\u53ef\u8fbe\u6027\u6280\u672f\u5728\u91cf\u5b50\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u9650\u5236\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u91cf\u5b50\u7279\u6709\u7684\u72b6\u6001\u5f52\u4e00\u5316\u5f15\u5165\u4e86\u53d8\u91cf\u95f4\u7684\u4f9d\u8d56\u6027\uff0c\u6311\u6218\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9a8c\u8bc1\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u4e3aVQCs\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5176\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\u3002", "keywords": "\u53d8\u5206\u91cf\u5b50\u7535\u8def,\u5f62\u5f0f\u5316\u9a8c\u8bc1,\u62bd\u8c61\u89e3\u91ca,\u91cf\u5b50\u673a\u5668\u5b66\u4e60,\u9c81\u68d2\u6027"}}
{"id": "2507.10822", "pdf": "https://arxiv.org/pdf/2507.10822", "abs": "https://arxiv.org/abs/2507.10822", "authors": ["Omar Elsisi", "Glaucia Melo"], "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Conversational agents, such as chatbots and virtual assistants, have become\nessential in software development, boosting productivity, collaboration, and\nautomating various tasks. This paper examines the role of adaptive AI-powered\nconversational agents in software development, highlighting their ability to\noffer dynamic, context-aware assistance to developers. Unlike traditional\nrule-based systems, adaptive AI agents use machine learning and natural\nlanguage processing to learn from interactions and improve over time, providing\nmore personalized and responsive help. We look at how these tools have evolved\nfrom simple query-based systems to advanced AI-driven solutions like GitHub\nCopilot and Microsoft Teams bots. We also explore the challenges of integrating\nadaptive AI into software development processes. The study aims to assess the\nbenefits and limitations of these systems, address concerns like data privacy\nand ethical issues, and offer insights into their future use in the field.\nUltimately, adaptive AI chatbots have great potential to revolutionize software\ndevelopment by delivering real-time, customized support and enhancing the\nefficiency of development cycles.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u81ea\u9002\u5e94AI\u9a71\u52a8\u7684\u5bf9\u8bdd\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4f5c\u7528\uff0c\u5f3a\u8c03\u5176\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u63d0\u4f9b\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8f85\u52a9\u80fd\u529b\uff0c\u5e76\u5206\u6790\u4e86\u5176\u4ece\u7b80\u5355\u67e5\u8be2\u7cfb\u7edf\u5230\u9ad8\u7ea7AI\u89e3\u51b3\u65b9\u6848\u7684\u6f14\u53d8\u3001\u96c6\u6210\u6311\u6218\u3001\u4f18\u52bf\u4e0e\u9650\u5236\uff0c\u4ee5\u53ca\u5bf9\u672a\u6765\u7684\u5c55\u671b\u3002", "motivation": "\u968f\u7740\u804a\u5929\u673a\u5668\u4eba\u548c\u865a\u62df\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u666e\u53ca\uff0c\u7814\u7a76\u81ea\u9002\u5e94AI\u4ee3\u7406\u5982\u4f55\u63d0\u5347\u751f\u4ea7\u529b\u3001\u534f\u4f5c\u80fd\u529b\u53ca\u4efb\u52a1\u81ea\u52a8\u5316\u6210\u4e3a\u91cd\u8981\u8bfe\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4ece\u4f20\u7edf\u89c4\u5219\u7cfb\u7edf\u5230\u73b0\u4ee3AI\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u7684\u6f14\u53d8\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u8bc4\u4f30\u81ea\u9002\u5e94AI\u4ee3\u7406\u7684\u6548\u7387\u548c\u6311\u6218\u3002", "result": "\u81ea\u9002\u5e94AI\u4ee3\u7406\u80fd\u591f\u63d0\u4f9b\u4e2a\u6027\u5316\u548c\u5b9e\u65f6\u652f\u6301\uff0c\u663e\u8457\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u4e5f\u9762\u4e34\u6570\u636e\u9690\u79c1\u548c\u4f26\u7406\u95ee\u9898\u7b49\u6311\u6218\u3002", "conclusion": "\u81ea\u9002\u5e94AI\u804a\u5929\u673a\u5668\u4eba\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u514b\u670d\u6280\u672f\u548c\u793e\u4f1a\u5c42\u9762\u7684\u969c\u788d\u4ee5\u5b9e\u73b0\u5176\u9769\u547d\u6027\u5f71\u54cd\u3002", "keywords": "\u81ea\u9002\u5e94AI\u3001\u5bf9\u8bdd\u4ee3\u7406\u3001\u8f6f\u4ef6\u5f00\u53d1\u3001\u673a\u5668\u5b66\u4e60\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406"}}
{"id": "2507.10640", "pdf": "https://arxiv.org/pdf/2507.10640", "abs": "https://arxiv.org/abs/2507.10640", "authors": ["Labiba Farah", "Mohammad Ridwan Kabir", "Shohel Ahmed", "MD Mohaymen Ul Anam", "Md. Sakibul Islam"], "title": "SENSOR: An ML-Enhanced Online Annotation Tool to Uncover Privacy Concerns from User Reviews in Social-Media Applications", "categories": ["cs.SE", "cs.LG", "cs.SI", "D.2.2"], "comment": "26 pages, 9 figures, 5 tables", "summary": "The widespread use of social media applications has raised significant\nprivacy concerns, often highlighted in user reviews. These reviews also provide\ndevelopers with valuable insights into improving apps by addressing issues and\nintroducing better features. However, the sheer volume and nuanced nature of\nreviews make manual identification and prioritization of privacy-related\nconcerns challenging for developers. Previous studies have developed software\nutilities to automatically classify user reviews as privacy-relevant,\nprivacy-irrelevant, bug reports, feature requests, etc., using machine\nlearning. Notably, there is a lack of focus on classifying reviews specifically\nas privacy-related feature requests, privacy-related bug reports, or\nprivacy-irrelevant. This paper introduces SENtinel SORt (SENSOR), an automated\nonline annotation tool designed to help developers annotate and classify user\nreviews into these categories. For automating the annotation of such reviews,\nthis paper introduces the annotation model, GRACE (GRU-based Attention with\nCBOW Embedding), using Gated Recurrent Units (GRU) with Continuous Bag of Words\n(CBOW) and Attention mechanism. Approximately 16000 user reviews from seven\npopular social media apps on Google Play Store, including Instagram, Facebook,\nWhatsApp, Snapchat, X (formerly Twitter), Facebook Lite, and Line were\nanalyzed. Two annotators manually labelled the reviews, achieving a Cohen's\nKappa value of 0.87, ensuring a labeled dataset with high inter-rater agreement\nfor training machine learning models. Among the models tested, GRACE\ndemonstrated the best performance (macro F1-score: 0.9434, macro ROC-AUC:\n0.9934, and accuracy: 95.10%) despite class imbalance. SENSOR demonstrates\nsignificant potential to assist developers with extracting and addressing\nprivacy-related feature requests or bug reports from user reviews, enhancing\nuser privacy and trust.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SENSOR\u5de5\u5177\u548cGRACE\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u52a8\u5206\u7c7b\u793e\u4ea4\u5a92\u4f53\u5e94\u7528\u7684\u7528\u6237\u8bc4\u8bba\uff0c\u7279\u522b\u662f\u9690\u79c1\u76f8\u5173\u7684\u529f\u80fd\u8bf7\u6c42\u548c\u9519\u8bef\u62a5\u544a\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u5e94\u7528\u7684\u7528\u6237\u8bc4\u8bba\u5305\u542b\u5927\u91cf\u9690\u79c1\u76f8\u5173\u53cd\u9988\uff0c\u4f46\u624b\u52a8\u5206\u7c7b\u56f0\u96be\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u5de5\u5177\u6765\u5e2e\u52a9\u5f00\u53d1\u8005\u8bc6\u522b\u548c\u4f18\u5148\u5904\u7406\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86GRACE\u6a21\u578b\uff08\u57fa\u4e8eGRU\u3001CBOW\u548c\u6ce8\u610f\u529b\u673a\u5236\uff09\u548cSENSOR\u81ea\u52a8\u5316\u6ce8\u91ca\u5de5\u5177\uff0c\u5206\u6790\u4e8616000\u6761\u7528\u6237\u8bc4\u8bba\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u9a8c\u8bc1\u6570\u636e\u3002", "result": "GRACE\u6a21\u578b\u5728\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f73\uff08\u5b8fF1\u5206\u6570\uff1a0.9434\uff0c\u5b8fROC-AUC\uff1a0.9934\uff0c\u51c6\u786e\u7387\uff1a95.10%\uff09\uff0cSENSOR\u5de5\u5177\u663e\u793a\u51fa\u663e\u8457\u7684\u5b9e\u7528\u6f5c\u529b\u3002", "conclusion": "SENSOR\u548cGRACE\u80fd\u6709\u6548\u5e2e\u52a9\u5f00\u53d1\u8005\u4ece\u7528\u6237\u8bc4\u8bba\u4e2d\u63d0\u53d6\u9690\u79c1\u76f8\u5173\u95ee\u9898\uff0c\u589e\u5f3a\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u548c\u4fe1\u4efb\u3002", "keywords": "\u9690\u79c1\u4fdd\u62a4, \u7528\u6237\u8bc4\u8bba\u5206\u7c7b, \u673a\u5668\u5b66\u4e60, GRU, SENSOR, GRACE"}}
{"id": "2507.10846", "pdf": "https://arxiv.org/pdf/2507.10846", "abs": "https://arxiv.org/abs/2507.10846", "authors": ["Casey Wall", "Longwei Wang", "Rodrigue Rizk", "KC Santosh"], "title": "Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "15 pages, 10 figures, 7 tables. Submitted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence", "summary": "Interpreting the decision-making process of Convolutional Neural Networks\n(CNNs) is critical for deploying models in high-stakes domains.\nGradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method\nfor visual explanations, yet it typically focuses on the final convolutional\nlayer or na\\\"ively averages across layers, strategies that can obscure\nimportant semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a\nnovel, human-tunable extension of Grad-CAM that generates robust and coherent\nsaliency maps by aggregating information across all convolutional layers. To\nmitigate the influence of noisy or extreme attribution values, Winsor-CAM\napplies Winsorization, a percentile-based outlier attenuation technique. A\nuser-controllable threshold allows for semantic-level tuning, enabling flexible\nexploration of model behavior across representational hierarchies. Evaluations\non standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the\nPASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable\nheatmaps and achieves superior performance in localization metrics, including\nintersection-over-union and center-of-mass alignment, when compared to Grad-CAM\nand uniform layer-averaging baselines. Winsor-CAM advances the goal of\ntrustworthy AI by offering interpretable, multi-layer insights with\nhuman-in-the-loop control.", "AI": {"tldr": "Winsor-CAM \u662f\u4e00\u79cd\u57fa\u4e8e Grad-CAM \u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u5377\u79ef\u5c42\u805a\u5408\u4fe1\u606f\u548c Winsorization \u6280\u672f\u751f\u6210\u66f4\u9c81\u68d2\u548c\u8fde\u8d2f\u7684\u663e\u8457\u6027\u56fe\u3002", "motivation": "\u4e3a CNN \u63d0\u4f9b\u66f4\u900f\u660e\u7684\u51b3\u7b56\u89e3\u91ca\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u514b\u670d Grad-CAM \u5728\u591a\u5c42\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa Winsor-CAM\uff0c\u5229\u7528 Winsorization \u6280\u672f\u6291\u5236\u6781\u7aef\u503c\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u53ef\u8c03\u9608\u503c\u5b9e\u73b0\u8bed\u4e49\u7ea7\u63a7\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6807\u51c6\u67b6\u6784\uff08\u5982 ResNet50\uff09\u548c PASCAL VOC 2012 \u6570\u636e\u96c6\u4e0a\uff0cWinsor-CAM \u5728\u70ed\u56fe\u53ef\u89e3\u91ca\u6027\u548c\u5b9a\u4f4d\u6307\u6807\u4e0a\u4f18\u4e8e Grad-CAM\u3002", "conclusion": "Winsor-CAM \u901a\u8fc7\u591a\u5c42\u7ea7\u89e3\u91ca\u548c\u4eba\u5de5\u53ef\u63a7\u6027\uff0c\u63d0\u5347\u4e86 AI \u7684\u53ef\u4fe1\u5ea6\u3002", "keywords": "CNN \u89e3\u91ca\u6027, Grad-CAM, Winsor-CAM, \u663e\u8457\u6027\u56fe, \u591a\u5c42\u7ea7\u805a\u5408, \u53ef\u4fe1 AI"}}
{"id": "2507.10701", "pdf": "https://arxiv.org/pdf/2507.10701", "abs": "https://arxiv.org/abs/2507.10701", "authors": ["Owen Futter", "Nicola Muca Cirone", "Blanka Horvath"], "title": "Kernel Learning for Mean-Variance Trading Strategies", "categories": ["q-fin.TR", "cs.LG", "q-fin.MF", "q-fin.PM"], "comment": "49 pages", "summary": "In this article, we develop a kernel-based framework for constructing\ndynamic, pathdependent trading strategies under a mean-variance optimisation\ncriterion. Building on the theoretical results of (Muca Cirone and Salvi,\n2025), we parameterise trading strategies as functions in a reproducing kernel\nHilbert space (RKHS), enabling a flexible and non-Markovian approach to optimal\nportfolio problems. We compare this with the signature-based framework of\n(Futter, Horvath, Wiese, 2023) and demonstrate that both significantly\noutperform classical Markovian methods when the asset dynamics or predictive\nsignals exhibit temporal dependencies for both synthetic and market-data\nexamples. Using kernels in this context provides significant modelling\nflexibility, as the choice of feature embedding can range from randomised\nsignatures to the final layers of neural network architectures. Crucially, our\nframework retains closed-form solutions and provides an alternative to\ngradient-based optimisation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6838\u7684\u52a8\u6001\u8def\u5f84\u4f9d\u8d56\u4ea4\u6613\u7b56\u7565\u6846\u67b6\uff0c\u901a\u8fc7\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u53c2\u6570\u5316\u7b56\u7565\uff0c\u5728\u5747\u503c-\u65b9\u5dee\u4f18\u5316\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u8d44\u4ea7\u52a8\u6001\u6216\u9884\u6d4b\u4fe1\u53f7\u5b58\u5728\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u7075\u6d3b\u4e14\u975e\u9a6c\u5c14\u53ef\u592b\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u6295\u8d44\u7ec4\u5408\u3002", "method": "\u5229\u7528\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff08RKHS\uff09\u53c2\u6570\u5316\u4ea4\u6613\u7b56\u7565\uff0c\u5e76\u4e0e\u57fa\u4e8e\u7b7e\u540d\u7684\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u6838\u65b9\u6cd5\u4e0e\u7b7e\u540d\u65b9\u6cd5\u5747\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9a6c\u5c14\u53ef\u592b\u65b9\u6cd5\uff0c\u4e14\u5728\u5408\u6210\u6570\u636e\u548c\u5e02\u573a\u6570\u636e\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u901a\u8fc7\u6838\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5efa\u6a21\u7075\u6d3b\u6027\uff0c\u4fdd\u7559\u4e86\u95ed\u5f0f\u89e3\uff0c\u5e76\u6210\u4e3a\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "keywords": "\u6838\u65b9\u6cd5, \u4ea4\u6613\u7b56\u7565, \u5747\u503c-\u65b9\u5dee\u4f18\u5316, RKHS, \u975e\u9a6c\u5c14\u53ef\u592b\u65b9\u6cd5"}}
{"id": "2507.10854", "pdf": "https://arxiv.org/pdf/2507.10854", "abs": "https://arxiv.org/abs/2507.10854", "authors": ["Thomas Dalton", "Hemanth Gowda", "Girish Rao", "Sachin Pargi", "Alireza Hadj Khodabakhshi", "Joseph Rombs", "Stephan Jou", "Manish Marwah"], "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Phishing remains a pervasive and growing threat, inflicting heavy economic\nand reputational damage. While machine learning has been effective in real-time\ndetection of phishing attacks, progress is hindered by lack of large,\nhigh-quality datasets and benchmarks. In addition to poor-quality due to\nchallenges in data collection, existing datasets suffer from leakage and\nunrealistic base rates, leading to overly optimistic performance results. In\nthis paper, we introduce PhreshPhish, a large-scale, high-quality dataset of\nphishing websites that addresses these limitations. Compared to existing public\ndatasets, PhreshPhish is substantially larger and provides significantly higher\nquality, as measured by the estimated rate of invalid or mislabeled data\npoints. Additionally, we propose a comprehensive suite of benchmark datasets\nspecifically designed for realistic model evaluation by minimizing leakage,\nincreasing task difficulty, enhancing dataset diversity, and adjustment of base\nrates more likely to be seen in the real world. We train and evaluate multiple\nsolution approaches to provide baseline performance on the benchmark sets. We\nbelieve the availability of this dataset and benchmarks will enable realistic,\nstandardized model comparison and foster further advances in phishing\ndetection. The datasets and benchmarks are available on Hugging Face\n(https://huggingface.co/datasets/phreshphish/phreshphish).", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86PhreshPhish\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u9493\u9c7c\u7f51\u7ad9\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u66f4\u771f\u5b9e\u7684\u6a21\u578b\u8bc4\u4f30\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u65e5\u76ca\u4e25\u91cd\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u8d28\u91cf\u5dee\u3001\u57fa\u51c6\u4e0d\u771f\u5b9e\uff0c\u5bfc\u81f4\u6a21\u578b\u8bc4\u4f30\u7ed3\u679c\u8fc7\u4e8e\u4e50\u89c2\uff0c\u6025\u9700\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u7814\u7a76\u8005\u6784\u5efa\u4e86PhreshPhish\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u51cf\u5c11\u6cc4\u6f0f\u3001\u589e\u52a0\u4efb\u52a1\u96be\u5ea6\u3001\u589e\u5f3a\u6570\u636e\u96c6\u591a\u6837\u6027\u548c\u8c03\u6574\u57fa\u7840\u7387\uff0c\u8bbe\u8ba1\u4e86\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "PhreshPhish\u6570\u636e\u96c6\u6bd4\u73b0\u6709\u516c\u5171\u6570\u636e\u96c6\u66f4\u5927\u3001\u8d28\u91cf\u66f4\u9ad8\uff0c\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e3a\u9493\u9c7c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "conclusion": "PhreshPhish\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u5c06\u63a8\u52a8\u9493\u9c7c\u68c0\u6d4b\u9886\u57df\u7684\u6807\u51c6\u5316\u6a21\u578b\u6bd4\u8f83\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "keywords": "\u9493\u9c7c\u68c0\u6d4b\u3001\u6570\u636e\u96c6\u3001\u673a\u5668\u5b66\u4e60\u3001\u57fa\u51c6\u6d4b\u8bd5\u3001PhreshPhish"}}
{"id": "2507.10710", "pdf": "https://arxiv.org/pdf/2507.10710", "abs": "https://arxiv.org/abs/2507.10710", "authors": ["Haoyu Chen", "Anna Little", "Akin Narayan"], "title": "Robust Multi-Manifold Clustering via Simplex Paths", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This article introduces a novel, geometric approach for multi-manifold\nclustering (MMC), i.e. for clustering a collection of potentially intersecting,\nd-dimensional manifolds into the individual manifold components. We first\ncompute a locality graph on d-simplices, using the dihedral angle in between\nadjacent simplices as the graph weights, and then compute infinity path\ndistances in this simplex graph. This procedure gives a metric on simplices\nwhich we refer to as the largest angle path distance (LAPD). We analyze the\nproperties of LAPD under random sampling, and prove that with an appropriate\ndenoising procedure, this metric separates the manifold components with high\nprobability. We validate the proposed methodology with extensive numerical\nexperiments on both synthetic and real-world data sets. These experiments\ndemonstrate that the method is robust to noise, curvature, and small\nintersection angle, and generally out-performs other MMC algorithms. In\naddition, we provide a highly scalable implementation of the proposed\nalgorithm, which leverages approximation schemes for infinity path distance to\nachieve quasi-linear computational complexity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u51e0\u4f55\u65b9\u6cd5\uff0c\u7528\u4e8e\u591a\u6d41\u5f62\u805a\u7c7b\uff08MMC\uff09\uff0c\u901a\u8fc7\u8ba1\u7b97d-\u5355\u7eaf\u5f62\u4e0a\u7684\u5c40\u90e8\u56fe\u548c\u5927\u89d2\u5ea6\u8def\u5f84\u8ddd\u79bb\uff08LAPD\uff09\uff0c\u6210\u529f\u5206\u79bb\u6d41\u5f62\u6210\u5206\u3002", "motivation": "\u591a\u6d41\u5f62\u805a\u7c7b\u65e8\u5728\u5c06\u6f5c\u5728\u76f8\u4ea4\u7684d\u7ef4\u6d41\u5f62\u5206\u79bb\u4e3a\u72ec\u7acb\u7684\u6d41\u5f62\u6210\u5206\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u566a\u58f0\u3001\u66f2\u7387\u548c\u5c0f\u7684\u76f8\u4ea4\u89d2\u4e0d\u591f\u9c81\u68d2\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u9996\u5148\u5728d-\u5355\u7eaf\u5f62\u4e0a\u6784\u5efa\u5c40\u90e8\u56fe\uff0c\u4f7f\u7528\u76f8\u90bb\u5355\u7eaf\u5f62\u4e4b\u95f4\u7684\u4e8c\u9762\u89d2\u4f5c\u4e3a\u6743\u91cd\uff0c\u7136\u540e\u8ba1\u7b97\u65e0\u9650\u8def\u5f84\u8ddd\u79bb\uff08LAPD\uff09\uff0c\u5e76\u901a\u8fc7\u53bb\u566a\u65b9\u6cd5\u5206\u79bb\u6d41\u5f62\u6210\u5206\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5bf9\u566a\u58f0\u3001\u66f2\u7387\u548c\u5c0f\u76f8\u4ea4\u89d2\u5177\u6709\u9c81\u68d2\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u5176\u4ed6MMC\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u8fd1\u4f3c\u65b9\u6848\u5b9e\u73b0\u4e86\u51c6\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684LAPD\u65b9\u6cd5\u5728\u591a\u6d41\u5f62\u805a\u7c7b\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u4e14\u5177\u6709\u9ad8\u6548\u7684\u53ef\u6269\u5c55\u6027\u3002", "keywords": "\u591a\u6d41\u5f62\u805a\u7c7b,\u51e0\u4f55\u65b9\u6cd5,LAPD,\u65e0\u9650\u8def\u5f84\u8ddd\u79bb,\u53bb\u566a"}}
{"id": "2507.10864", "pdf": "https://arxiv.org/pdf/2507.10864", "abs": "https://arxiv.org/abs/2507.10864", "authors": ["Saadat Behzadi", "Danial Sharifrazi", "Bita Mesbahzadeh", "Javad Hassannataj Joloudarid", "Roohallah Alizadehsani"], "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Objectives: Timely and accurate detection of colorectal polyps plays a\ncrucial role in diagnosing and preventing colorectal cancer, a major cause of\nmortality worldwide. This study introduces a new, lightweight, and efficient\nframework for polyp detection that combines the Local Outlier Factor (LOF)\nalgorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier\nremoval techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly\navailable datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.\nSince these datasets originally lacked bounding box annotations, we converted\ntheir segmentation masks into suitable detection labels. To enhance the\nrobustness and generalizability of our model, we apply 5-fold cross-validation\nand remove anomalous samples using the LOF method configured with 30 neighbors\nand a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a\nfast and resource-efficient object detection architecture optimized for\nreal-time applications. We train the model using a combination of modern\naugmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance,\nachieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5\nof 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,\nour model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited\nfor real-time colonoscopy support in clinical settings. Overall, the study\nunderscores how crucial data preprocessing and model efficiency are when\ndesigning effective AI systems for medical imaging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LOF\u7b97\u6cd5\u548cYOLO-v11n\u6a21\u578b\u7684\u8f7b\u91cf\u7ea7\u7ed3\u80a0\u606f\u8089\u68c0\u6d4b\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u7ed3\u80a0\u606f\u8089\u7684\u53ca\u65f6\u51c6\u786e\u68c0\u6d4b\u5bf9\u9884\u9632\u7ed3\u76f4\u80a0\u764c\u81f3\u5173\u91cd\u8981\u3002\u8be5\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u4e14\u9002\u7528\u4e8e\u5b9e\u65f6\u4e34\u5e8a\u5e94\u7528\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u591a\u6570\u636e\u96c6\uff08CVC-ColonDB\u7b49\uff09\uff0c\u901a\u8fc7LOF\u7b97\u6cd5\u53bb\u9664\u566a\u58f0\u6570\u636e\uff0c\u7ed3\u5408YOLO-v11n\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4f7f\u7528\u4e865\u6298\u4ea4\u53c9\u9a8c\u8bc1\u548c\u6570\u636e\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u6a21\u578b\u5728\u7cbe\u5ea6\uff0895.83%\uff09\u3001\u53ec\u56de\u7387\uff0891.85%\uff09\u3001F1\u5206\u6570\uff0893.48%\uff09\u3001mAP@0.5\uff0896.48%\uff09\u548cmAP@0.5:0.95\uff0877.75%\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709YOLO\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u4e34\u5e8a\u5b9e\u65f6\u7ed3\u80a0\u955c\u68c0\u67e5\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u6a21\u578b\u6548\u7387\u5728\u533b\u5b66\u5f71\u50cfAI\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027\u3002", "keywords": "\u7ed3\u80a0\u606f\u8089\u68c0\u6d4b, LOF\u7b97\u6cd5, YOLO-v11n, \u6df1\u5ea6\u5b66\u4e60, \u533b\u5b66\u5f71\u50cf"}}
{"id": "2507.10715", "pdf": "https://arxiv.org/pdf/2507.10715", "abs": "https://arxiv.org/abs/2507.10715", "authors": ["Chandler Jones", "Mark Bandstra", "Stefan Faaland", "Yue Shi Lai", "Nico Abgrall", "Scott Suchyta", "Reynold Cooper"], "title": "Real-time, Adaptive Radiological Anomaly Detection and Isotope Identification Using Non-negative Matrix Factorization", "categories": ["physics.app-ph", "cs.LG"], "comment": "11 pages, 8 figures", "summary": "Spectroscopic anomaly detection and isotope identification algorithms are\nintegral components in nuclear nonproliferation applications such as search\noperations. The task is especially challenging in the case of mobile detector\nsystems due to the fact that the observed gamma-ray background changes more\nthan for a static detector system, and a pretrained background model can easily\nfind itself out of domain. The result is that algorithms may exceed their\nintended false alarm rate, or sacrifice detection sensitivity in order to\nmaintain the desired false alarm rate. Non-negative matrix factorization (NMF)\nhas been shown to be a powerful tool for spectral anomaly detection and\nidentification, but, like many similar algorithms that rely on data-driven\nbackground models, in its conventional implementation it is unable to update in\nreal time to account for environmental changes that affect the background\nspectroscopic signature. We have developed a novel NMF-based algorithm that\nperiodically updates its background model to accommodate changing environmental\nconditions. The Adaptive NMF algorithm involves fewer assumptions about its\nenvironment, making it more generalizable than existing NMF-based methods while\nmaintaining or exceeding detection performance on simulated and real-world\ndatasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff08NMF\uff09\u7684\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u79fb\u52a8\u63a2\u6d4b\u5668\u7cfb\u7edf\u4e2d\u5904\u7406\u80cc\u666f\u5149\u8c31\u53d8\u5316\u7684\u6838\u4e0d\u6269\u6563\u5e94\u7528\u3002", "motivation": "\u79fb\u52a8\u63a2\u6d4b\u5668\u7cfb\u7edf\u4e2d\u7684\u80cc\u666f\u4f3d\u9a6c\u5c04\u7ebf\u53d8\u5316\u5bfc\u81f4\u4f20\u7edf\u7b97\u6cd5\u96be\u4ee5\u7ef4\u6301\u5047\u8b66\u62a5\u7387\u6216\u68c0\u6d4b\u7075\u654f\u5ea6\uff0c\u9700\u5f00\u53d1\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u7b97\u6cd5\u3002", "method": "\u901a\u8fc7\u5b9a\u671f\u66f4\u65b0\u80cc\u666f\u6a21\u578b\u7684NMF\u7b97\u6cd5\uff08Adaptive NMF\uff09\uff0c\u51cf\u5c11\u5bf9\u73af\u5883\u5047\u8bbe\u7684\u4f9d\u8d56\u3002", "result": "\u8be5\u7b97\u6cd5\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u6216\u8d85\u8d8a\u73b0\u6709NMF\u65b9\u6cd5\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "Adaptive NMF\u7b97\u6cd5\u66f4\u901a\u7528\u4e14\u9002\u7528\u4e8e\u52a8\u6001\u73af\u5883\uff0c\u63d0\u9ad8\u4e86\u6838\u4e0d\u6269\u6563\u5e94\u7528\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "keywords": "\u975e\u8d1f\u77e9\u9635\u5206\u89e3, \u6838\u4e0d\u6269\u6563, \u81ea\u9002\u5e94\u7b97\u6cd5, \u4f3d\u9a6c\u5c04\u7ebf\u80cc\u666f, \u5f02\u5e38\u68c0\u6d4b"}}
{"id": "2507.10726", "pdf": "https://arxiv.org/pdf/2507.10726", "abs": "https://arxiv.org/abs/2507.10726", "authors": ["Yuki Iwamoto", "Kaoru Tsunoda", "Ken Kaneiwa"], "title": "Extracting Document Relations from Search Corpus by Marginalizing over User Queries", "categories": ["cs.IR", "cs.LG"], "comment": "9 pages, 6 figures", "summary": "Understanding relationships between documents in large-scale corpora is\nessential for knowledge discovery and information organization. However,\nexisting approaches rely heavily on manual annotation or predefined\nrelationship taxonomies. We propose EDR-MQ (Extracting Document Relations by\nMarginalizing over User Queries), a novel framework that discovers document\nrelationships through query marginalization. EDR-MQ is based on the insight\nthat strongly related documents often co-occur in results across diverse user\nqueries, enabling us to estimate joint probabilities between document pairs by\nmarginalizing over a collection of queries. To enable this query\nmarginalization approach, we develop Multiply Conditioned Retrieval-Augmented\nGeneration (MC-RAG), which employs conditional retrieval where subsequent\ndocument retrievals depend on previously retrieved content. By observing\nco-occurrence patterns across diverse queries, EDR-MQ estimates joint\nprobabilities between document pairs without requiring labeled training data or\npredefined taxonomies. Experimental results show that our query marginalization\napproach successfully identifies meaningful document relationships, revealing\ntopical clusters, evidence chains, and cross-domain connections that are not\napparent through traditional similarity-based methods. Our query-driven\nframework offers a practical approach to document organization that adapts to\ndifferent user perspectives and information needs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEDR-MQ\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u67e5\u8be2\u8fb9\u7f18\u5316\u53d1\u73b0\u6587\u6863\u5173\u7cfb\uff0c\u65e0\u9700\u624b\u52a8\u6807\u6ce8\u6216\u9884\u5b9a\u4e49\u5206\u7c7b\u6cd5\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e2d\u7406\u89e3\u6587\u6863\u5173\u7cfb\u5bf9\u4e8e\u77e5\u8bc6\u53d1\u73b0\u548c\u4fe1\u606f\u7ec4\u7ec7\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u9884\u5b9a\u4e49\u5206\u7c7b\u6cd5\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u5229\u7528EDR-MQ\u6846\u67b6\uff0c\u901a\u8fc7\u67e5\u8be2\u8fb9\u7f18\u5316\u4f30\u8ba1\u6587\u6863\u5bf9\u7684\u8054\u5408\u6982\u7387\uff0c\u5e76\u7ed3\u5408MC-RAG\u8fdb\u884c\u6761\u4ef6\u68c0\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u8bc6\u522b\u4e86\u6709\u610f\u4e49\u7684\u6587\u6863\u5173\u7cfb\uff0c\u5305\u62ec\u4e3b\u9898\u96c6\u7fa4\u3001\u8bc1\u636e\u94fe\u548c\u8de8\u9886\u57df\u8fde\u63a5\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u6587\u6863\u7ec4\u7ec7\u65b9\u6cd5\uff0c\u9002\u5e94\u4e0d\u540c\u7528\u6237\u89c6\u89d2\u548c\u4fe1\u606f\u9700\u6c42\u3002", "keywords": "\u6587\u6863\u5173\u7cfb, \u67e5\u8be2\u8fb9\u7f18\u5316, \u6761\u4ef6\u68c0\u7d22, \u65e0\u76d1\u7763\u5b66\u4e60"}}
{"id": "2507.10893", "pdf": "https://arxiv.org/pdf/2507.10893", "abs": "https://arxiv.org/abs/2507.10893", "authors": ["Minjong Cheon", "Eunhan Goo", "Su-Hyeon Shin", "Muhammad Ahmed", "Hyungjun Kim"], "title": "Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.ao-ph"], "comment": "26pages, 9 Figures", "summary": "Recently, AI-based weather forecast models have achieved impressive advances.\nThese models have reached accuracy levels comparable to traditional NWP\nsystems, marking a significant milestone in data-driven weather prediction.\nHowever, they mostly leverage Transformer-based architectures, which often\nleads to high training complexity and resource demands due to the massive\nparameter sizes. In this study, we introduce a modernized CNN-based model for\nglobal weather forecasting that delivers competitive accuracy while\nsignificantly reducing computational requirements. To present a systematic\nmodernization roadmap, we highlight key architectural enhancements across\nmultiple design scales from an earlier CNN-based approach. KAI-a incorporates a\nscale-invariant architecture and InceptionNeXt-based blocks within a\ngeophysically-aware design, tailored to the structure of Earth system data.\nTrained on the ERA5 daily dataset with 67 atmospheric variables, the model\ncontains about 7 million parameters and completes training in just 12 hours on\na single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the\nperformance of state-of-the-art models in medium-range weather forecasting,\nwhile offering a significantly lightweight design. Furthermore, case studies on\nthe 2018 European heatwave and the East Asian summer monsoon demonstrate\nKAI-a's robust skill in capturing extreme events, reinforcing its practical\nutility.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8eCNN\u7684\u5168\u7403\u5929\u6c14\u9884\u62a5\u6a21\u578bKAI-a\uff0c\u901a\u8fc7\u73b0\u4ee3\u5316\u8bbe\u8ba1\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524dAI\u5929\u6c14\u9884\u62a5\u6a21\u578b\u591a\u57fa\u4e8eTransformer\u67b6\u6784\uff0c\u8ba1\u7b97\u590d\u6742\u4e14\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u73b0\u4ee3\u5316\u7684CNN\u67b6\u6784\uff0c\u7ed3\u5408\u5c3a\u5ea6\u4e0d\u53d8\u8bbe\u8ba1\u548cInceptionNeXt\u6a21\u5757\uff0c\u8bad\u7ec3\u4e8eERA5\u6570\u636e\u96c6\u3002", "result": "KAI-a\u5728\u4e2d\u7b49\u8303\u56f4\u5929\u6c14\u9884\u62a5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\u5e45\u964d\u4f4e\uff0c\u5e76\u80fd\u6709\u6548\u6355\u6349\u6781\u7aef\u4e8b\u4ef6\u3002", "conclusion": "KAI-a\u4e3a\u6570\u636e\u9a71\u52a8\u5929\u6c14\u9884\u62a5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "AI\u5929\u6c14\u9884\u62a5, CNN, InceptionNeXt, \u8ba1\u7b97\u6548\u7387, \u6781\u7aef\u5929\u6c14"}}
{"id": "2507.10795", "pdf": "https://arxiv.org/pdf/2507.10795", "abs": "https://arxiv.org/abs/2507.10795", "authors": ["\u0141ukasz Krai\u0144ski", "Micha\u0142 Czuba", "Piotr Br\u00f3dka", "Pawe\u0142 Pra\u0142at", "Bogumi\u0142 Kami\u0144ski", "Fran\u00e7ois Th\u00e9berge"], "title": "Multilayer Artificial Benchmark for Community Detection (mABCD)", "categories": ["cs.SI", "cs.LG"], "comment": "28 pages, 15 figures, 7 tables", "summary": "The Artificial Benchmark for Community Detection (ABCD) model is a random\ngraph model with community structure and power-law distribution for both\ndegrees and community sizes. The model generates graphs similar to the\nwell-known LFR model but it is faster, more interpretable, and can be\ninvestigated analytically. In this paper, we use the underlying ingredients of\nthe ABCD model and introduce its variant for multilayer networks, mABCD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u5c42\u7f51\u7edc\u53d8\u4f53mABCD\uff0c\u57fa\u4e8eABCD\u6a21\u578b\u7684\u5feb\u901f\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u5206\u6790\u7684\u968f\u673a\u56fe\u6a21\u578b\u3002", "motivation": "\u6269\u5c55ABCD\u6a21\u578b\u4ee5\u652f\u6301\u591a\u5c42\u7f51\u7edc\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u7f51\u7edc\u5206\u6790\u5de5\u5177\u3002", "method": "\u57fa\u4e8eABCD\u6a21\u578b\u7684\u5e95\u5c42\u673a\u5236\uff0c\u8bbe\u8ba1\u591a\u5c42\u7f51\u7edc\u53d8\u4f53mABCD\u3002", "result": "mABCD\u6a21\u578b\u80fd\u591f\u751f\u6210\u7c7b\u4f3c\u4e8eLFR\u6a21\u578b\u4f46\u66f4\u9ad8\u6548\u7684\u7f51\u7edc\u7ed3\u6784\u3002", "conclusion": "mABCD\u4e3a\u591a\u5c42\u7f51\u7edc\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5feb\u901f\u4e14\u53ef\u5206\u6790\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u968f\u673a\u56fe\u6a21\u578b\uff0c\u591a\u5c42\u7f51\u7edc\uff0c\u793e\u533a\u68c0\u6d4b\uff0cABCD\u6a21\u578b"}}
{"id": "2507.10895", "pdf": "https://arxiv.org/pdf/2507.10895", "abs": "https://arxiv.org/abs/2507.10895", "authors": ["Xiaocong Zeng", "Craig Michoski", "Yan Pang", "Dongyang Kuang"], "title": "Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.SP"], "comment": null, "summary": "In this work, we address the often-overlooked issue of Timescale Dependent\nLabel Inconsistency (TsDLI) in training neural network models for EEG-based\nhuman emotion recognition. To mitigate TsDLI and enhance model generalization\nand explainability, we propose two novel regularization strategies: Local\nVariation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods\nincorporate classical mathematical principles--specifically, functions of\nbounded variation and commute-time distances--within a graph theoretic\nframework. Complementing our regularizers, we introduce a suite of new\nevaluation metrics that better capture the alignment between temporally local\npredictions and their associated global emotion labels. We validate our\napproach through comprehensive experiments on two widely used EEG emotion\ndatasets, DREAMER and DEAP, across a range of neural architectures including\nLSTM and transformer-based models. Performance is assessed using five distinct\nmetrics encompassing both quantitative accuracy and qualitative consistency.\nResults consistently show that our proposed methods outperform state-of-the-art\nbaselines, delivering superior aggregate performance and offering a principled\ntrade-off between interpretability and predictive power under label\ninconsistency. Notably, LVL achieves the best aggregate rank across all\nbenchmarked backbones and metrics, while LGCL frequently ranks the second,\nhighlighting the effectiveness of our framework.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u6b63\u5219\u5316\u7b56\u7565\uff08LVL\u548cLGCL\uff09\u89e3\u51b3EEG\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u65f6\u95f4\u5c3a\u5ea6\u4f9d\u8d56\u6807\u7b7e\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3EEG\u60c5\u611f\u8bc6\u522b\u4e2d\u65f6\u95f4\u5c3a\u5ea6\u4f9d\u8d56\u6807\u7b7e\u4e0d\u4e00\u81f4\uff08TsDLI\uff09\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u5c40\u90e8\u53d8\u5316\u635f\u5931\uff08LVL\uff09\u548c\u5c40\u90e8-\u5168\u5c40\u4e00\u81f4\u6027\u635f\u5931\uff08LGCL\uff09\uff0c\u7ed3\u5408\u6709\u754c\u53d8\u51fd\u6570\u548c\u4ea4\u6362\u65f6\u95f4\u8ddd\u79bb\u7684\u6570\u5b66\u539f\u7406\u3002", "result": "\u5728DREAMER\u548cDEAP\u6570\u636e\u96c6\u4e0a\uff0cLVL\u548cLGCL\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0cLVL\u7efc\u5408\u6392\u540d\u6700\u4f73\u3002", "conclusion": "LVL\u548cLGCL\u80fd\u6709\u6548\u89e3\u51b3TsDLI\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u5e73\u8861\u3002", "keywords": "EEG\u60c5\u611f\u8bc6\u522b, TsDLI, \u6b63\u5219\u5316\u7b56\u7565, LVL, LGCL"}}
{"id": "2507.10835", "pdf": "https://arxiv.org/pdf/2507.10835", "abs": "https://arxiv.org/abs/2507.10835", "authors": ["Victor Armegioiu", "Juan Carrasquilla", "Siddhartha Mishra", "Johannes M\u00fcller", "Jannes Nys", "Marius Zeinhofer", "Hang Zhang"], "title": "Functional Neural Wavefunction Optimization", "categories": ["cond-mat.str-el", "cs.LG", "math.OC", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "We propose a framework for the design and analysis of optimization algorithms\nin variational quantum Monte Carlo, drawing on geometric insights into the\ncorresponding function space. The framework translates infinite-dimensional\noptimization dynamics into tractable parameter-space algorithms through a\nGalerkin projection onto the tangent space of the variational ansatz. This\nperspective unifies existing methods such as stochastic reconfiguration and\nRayleigh-Gauss-Newton, provides connections to classic function-space\nalgorithms, and motivates the derivation of novel algorithms with geometrically\nprincipled hyperparameter choices. We validate our framework with numerical\nexperiments demonstrating its practical relevance through the accurate\nestimation of ground-state energies for several prototypical models in\ncondensed matter physics modeled with neural network wavefunctions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u51e0\u4f55\u89c6\u89d2\u7684\u53d8\u5206\u91cf\u5b50\u8499\u7279\u5361\u7f57\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u4e0e\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7Galerkin\u6295\u5f71\u5c06\u65e0\u9650\u7ef4\u4f18\u5316\u52a8\u6001\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u7684\u53c2\u6570\u7a7a\u95f4\u7b97\u6cd5\uff0c\u7edf\u4e00\u4e86\u73b0\u6709\u65b9\u6cd5\u5e76\u63a8\u5bfc\u51fa\u65b0\u7b97\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u6a21\u578b\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u53d8\u5206\u91cf\u5b50\u8499\u7279\u5361\u7f57\u4e2d\u7684\u4f18\u5316\u7b97\u6cd5\u63d0\u4f9b\u7edf\u4e00\u7684\u51e0\u4f55\u5206\u6790\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u7b97\u6cd5\u8bbe\u8ba1\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7Galerkin\u6295\u5f71\u5c06\u65e0\u9650\u7ef4\u4f18\u5316\u52a8\u6001\u8f6c\u5316\u4e3a\u53c2\u6570\u7a7a\u95f4\u7b97\u6cd5\uff0c\u7ed3\u5408\u53d8\u5206ansatz\u7684\u5207\u7a7a\u95f4\uff0c\u7edf\u4e00\u73b0\u6709\u65b9\u6cd5\u5982\u968f\u673a\u91cd\u6784\u548cRayleigh-Gauss-Newton\uff0c\u5e76\u63a8\u5bfc\u65b0\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u51c6\u786e\u4f30\u8ba1\u5178\u578b\u51dd\u805a\u6001\u7269\u7406\u6a21\u578b\u4e2d\u7684\u57fa\u6001\u80fd\u91cf\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u51e0\u4f55\u6846\u67b6\u4e0d\u4ec5\u7edf\u4e00\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u4e3a\u4f18\u5316\u7b97\u6cd5\u7684\u8bbe\u8ba1\u4e0e\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "keywords": "\u53d8\u5206\u91cf\u5b50\u8499\u7279\u5361\u7f57, \u4f18\u5316\u7b97\u6cd5, Galerkin\u6295\u5f71, \u51e0\u4f55\u6846\u67b6, \u57fa\u6001\u80fd\u91cf"}}
{"id": "2507.10898", "pdf": "https://arxiv.org/pdf/2507.10898", "abs": "https://arxiv.org/abs/2507.10898", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Noha El Kachach"], "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "6 pages, 4 figures, accepted for publication in IEEE 26th\n  International Conference on Information Reuse and Integration (IRI 2025)", "summary": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions.", "AI": {"tldr": "MalCodeAI \u662f\u4e00\u79cd\u8bed\u8a00\u65e0\u5173\u3001\u591a\u9636\u6bb5 AI \u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u81ea\u4e3b\u4ee3\u7801\u5b89\u5168\u5206\u6790\u548c\u4fee\u590d\uff0c\u7ed3\u5408\u4ee3\u7801\u5206\u89e3\u548c\u8bed\u4e49\u63a8\u7406\uff0c\u901a\u8fc7 LoRA \u4f18\u5316\uff0c\u652f\u6301 14 \u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u5e76\u53d6\u5f97\u4e86\u4f4e\u9a8c\u8bc1\u635f\u5931\u548c\u9ad8\u5f00\u53d1\u8005\u8bc4\u4ef7\u3002", "motivation": "\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u7684\u5c40\u9650\u6027\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u7f51\u7edc\u5a01\u80c1\uff0c\u4ee5\u4fdd\u969c\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b89\u5168\u3002", "method": "\u4f7f\u7528 Qwen2.5-Coder-3B-Instruct \u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u5206\u89e3\u548c\u8bed\u4e49\u63a8\u7406\uff0c\u901a\u8fc7 LoRA \u4f18\u5316\u5e76\u5728 MLX \u6846\u67b6\u4e2d\u5b9e\u73b0\uff0c\u5206\u4e3a\u529f\u80fd\u5206\u89e3\u548c\u6f0f\u6d1e\u68c0\u6d4b\u4fee\u590d\u4e24\u9636\u6bb5\u3002", "result": "\u7b2c\u4e00\u9636\u6bb5\u9a8c\u8bc1\u635f\u5931\u4e3a 0.397\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4e3a 0.199\uff1b\u5f00\u53d1\u8005\u8bc4\u4ef7\u4e2d\u5b9e\u7528\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8f93\u51fa\u53ef\u8bfb\u6027\u5f97\u5206\u5747\u8f83\u9ad8\u3002", "conclusion": "MalCodeAI \u5b9e\u73b0\u4e86\u667a\u80fd\u3001\u53ef\u89e3\u91ca\u4e14\u4ee5\u5f00\u53d1\u8005\u4e3a\u4e2d\u5fc3\u7684\u8f6f\u4ef6\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "AI \u5b89\u5168\u5206\u6790, LoRA, \u4ee3\u7801\u4fee\u590d, \u6f0f\u6d1e\u68c0\u6d4b, \u591a\u8bed\u8a00\u652f\u6301"}}
{"id": "2507.10850", "pdf": "https://arxiv.org/pdf/2507.10850", "abs": "https://arxiv.org/abs/2507.10850", "authors": ["Matteo Bagagli", "Francesco Grigoli", "Davide Bacciu"], "title": "HEIMDALL: a grapH-based sEIsMic Detector And Locator for microseismicity", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "In this work, we present a new deep-learning model for microseismicity\nmonitoring that utilizes continuous spatiotemporal relationships between\nseismic station recordings, forming an end-to-end pipeline for seismic catalog\ncreation. It employs graph theory and state-of-the-art graph neural network\narchitectures to perform phase picking, association, and event location\nsimultaneously over rolling windows, making it suitable for both playback and\nnear-real-time monitoring. As part of the global strategy to reduce carbon\nemissions within the broader context of a green-energy transition, there has\nbeen growing interest in exploiting enhanced geothermal systems. Tested in the\ncomplex geothermal area of Iceland's Hengill region using open-access data from\na temporary experiment, our model was trained and validated using both manually\nrevised and automatic seismic catalogs. Results showed a significant increase\nin event detection compared to previously published automatic systems and\nreference catalogs, including a $4 M_w$ seismic sequence in December 2018 and a\nsingle-day sequence in February 2019. Our method reduces false events,\nminimizes manual oversight, and decreases the need for extensive tuning of\npipelines or transfer learning of deep-learning models. Overall, it validates a\nrobust monitoring tool for geothermal seismic regions, complementing existing\nsystems and enhancing operational risk mitigation during geothermal energy\nexploitation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5730\u9707\u76d1\u6d4b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u8fdb\u884c\u76f8\u4f4d\u62fe\u53d6\u3001\u5173\u8054\u548c\u4e8b\u4ef6\u5b9a\u4f4d\uff0c\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u7387\u5e76\u51cf\u5c11\u8bef\u62a5\u3002", "motivation": "\u5728\u7eff\u8272\u80fd\u6e90\u8f6c\u578b\u80cc\u666f\u4e0b\uff0c\u589e\u5f3a\u578b\u5730\u70ed\u7cfb\u7edf\u7684\u5f00\u53d1\u9700\u6c42\u589e\u957f\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5730\u9707\u76d1\u6d4b\u5de5\u5177\u4ee5\u51cf\u5c11\u98ce\u9669\u3002", "method": "\u5229\u7528\u56fe\u8bba\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u6784\u5efa\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u7ed3\u5408\u624b\u52a8\u548c\u81ea\u52a8\u5730\u9707\u76ee\u5f55\u8fdb\u884c\u8bad\u7ec3\u548c\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u68c0\u6d4b\u7387\u663e\u8457\u63d0\u5347\uff0c\u51cf\u5c11\u4e86\u8bef\u62a5\u548c\u4eba\u5de5\u5e72\u9884\u9700\u6c42\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u4e0e\u56de\u653e\u76d1\u6d4b\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u5730\u70ed\u5730\u9707\u533a\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u76d1\u6d4b\u5de5\u5177\uff0c\u8865\u5145\u73b0\u6709\u7cfb\u7edf\u5e76\u964d\u4f4e\u8fd0\u8425\u98ce\u9669\u3002", "keywords": "\u6df1\u5ea6\u5b66\u4e60, \u56fe\u795e\u7ecf\u7f51\u7edc, \u5730\u70ed\u7cfb\u7edf, \u5730\u9707\u76d1\u6d4b, \u78b3\u51cf\u6392"}}
{"id": "2507.10933", "pdf": "https://arxiv.org/pdf/2507.10933", "abs": "https://arxiv.org/abs/2507.10933", "authors": ["Orhan Erdem", "Ragavi Pobbathi Ashok"], "title": "Artificial Finance: How AI Thinks About Money", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "comment": null, "summary": "In this paper, we explore how large language models (LLMs) approach financial\ndecision-making by systematically comparing their responses to those of human\nparticipants across the globe. We posed a set of commonly used financial\ndecision-making questions to seven leading LLMs, including five models from the\nGPT series(GPT-4o, GPT-4.5, o1, o3-mini), Gemini 2.0 Flash, and DeepSeek R1. We\nthen compared their outputs to human responses drawn from a dataset covering 53\nnations. Our analysis reveals three main results. First, LLMs generally exhibit\na risk-neutral decision-making pattern, favoring choices aligned with expected\nvalue calculations when faced with lottery-type questions. Second, when\nevaluating trade-offs between present and future, LLMs occasionally produce\nresponses that appear inconsistent with normative reasoning. Third, when we\nexamine cross-national similarities, we find that the LLMs' aggregate responses\nmost closely resemble those of participants from Tanzania. These findings\ncontribute to the understanding of how LLMs emulate human-like decision\nbehaviors and highlight potential cultural and training influences embedded\nwithin their outputs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6bd4\u8f83\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u5168\u7403\u4eba\u7c7b\u53c2\u4e0e\u8005\u5728\u8d22\u52a1\u51b3\u7b56\u95ee\u9898\u4e0a\u7684\u56de\u7b54\uff0c\u63ed\u793a\u4e86LLMs\u5728\u98ce\u9669\u504f\u597d\u3001\u65f6\u95f4\u504f\u597d\u548c\u8de8\u6587\u5316\u76f8\u4f3c\u6027\u65b9\u9762\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u8d22\u52a1\u51b3\u7b56\u4e2d\u5982\u4f55\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u5e76\u63ed\u793a\u6f5c\u5728\u7684\u6587\u5316\u548c\u8bad\u7ec3\u5bf9\u5176\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "method": "\u5411\u4e03\u79cd\u9886\u5148\u7684LLMs\uff08\u5305\u62ecGPT\u7cfb\u5217\u6a21\u578b\u3001Gemini 2.0 Flash\u548cDeepSeek R1\uff09\u63d0\u51fa\u8d22\u52a1\u51b3\u7b56\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u56de\u7b54\u4e0e\u6765\u81ea53\u4e2a\u56fd\u5bb6\u7684\u4eba\u7c7b\u6570\u636e\u96c6\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "1. LLMs\u503e\u5411\u4e8e\u98ce\u9669\u4e2d\u6027\u51b3\u7b56\uff1b2. \u5728\u65f6\u95f4\u504f\u597d\u4e0a\u5076\u5c14\u8868\u73b0\u51fa\u4e0e\u89c4\u8303\u6027\u63a8\u7406\u4e0d\u4e00\u81f4\u7684\u884c\u4e3a\uff1b3. LLMs\u7684\u96c6\u4f53\u56de\u7b54\u4e0e\u5766\u6851\u5c3c\u4e9a\u53c2\u4e0e\u8005\u7684\u56de\u7b54\u6700\u4e3a\u76f8\u4f3c\u3002", "conclusion": "LLMs\u5728\u8d22\u52a1\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u72ec\u7279\u7684\u6a21\u5f0f\uff0c\u5176\u884c\u4e3a\u53d7\u6587\u5316\u548c\u8bad\u7ec3\u6570\u636e\u5f71\u54cd\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u8d22\u52a1\u51b3\u7b56, \u98ce\u9669\u504f\u597d, \u8de8\u6587\u5316\u6bd4\u8f83"}}
{"id": "2507.10877", "pdf": "https://arxiv.org/pdf/2507.10877", "abs": "https://arxiv.org/abs/2507.10877", "authors": ["Yuchen Zhu", "Jihong Chen", "Yitong Li", "Xiaomin Fang", "Xianbin Ye", "Jingzhou He", "Xujun Zhang", "Jingxuan Ge", "Chao Shen", "Xiaonan Zhang", "Tingjun Hou", "Chang-Yu Hsieh"], "title": "BioScore: A Foundational Scoring Function For Diverse Biomolecular Complexes", "categories": ["physics.chem-ph", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Structural assessment of biomolecular complexes is vital for translating\nmolecular models into functional insights, shaping our understanding of biology\nand aiding drug discovery. However, current structure-based scoring functions\noften lack generalizability across diverse biomolecular systems. We present\nBioScore, a foundational scoring function that addresses key challenges -- data\nsparsity, cross-system representation, and task compatibility -- through a\ndual-scale geometric graph learning framework with tailored modules for\nstructure assessment and affinity prediction. BioScore supports a wide range of\ntasks, including affinity prediction, conformation ranking, and structure-based\nvirtual screening. Evaluated on 16 benchmarks spanning proteins, nucleic acids,\nsmall molecules, and carbohydrates, BioScore consistently outperforms or\nmatches 70 traditional and deep learning methods. Our newly proposed PPI\nBenchmark further enables comprehensive evaluation of protein-protein complex\nscoring. BioScore demonstrates broad applicability: (1) pretraining on\nmixed-structure data boosts protein-protein affinity prediction by up to 40%\nand antigen-antibody binding correlation by over 90%; (2) cross-system\ngeneralizability enables zero- and few-shot prediction with up to 71%\ncorrelation gain; and (3) its unified representation captures chemically\nchallenging systems such as cyclic peptides, improving affinity prediction by\nover 60%. BioScore establishes a robust and generalizable framework for\nstructural assessment across complex biomolecular landscapes.", "AI": {"tldr": "BioScore\u662f\u4e00\u79cd\u901a\u7528\u7684\u751f\u7269\u5206\u5b50\u7ed3\u6784\u8bc4\u5206\u51fd\u6570\uff0c\u901a\u8fc7\u53cc\u5c3a\u5ea6\u51e0\u4f55\u56fe\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u6570\u636e\u7a00\u758f\u6027\u548c\u8de8\u7cfb\u7edf\u8868\u793a\u7b49\u6311\u6218\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u751f\u7269\u5206\u5b50\u7ed3\u6784\u8bc4\u5206\u51fd\u6570\u7684\u6cdb\u5316\u6027\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0d\u540c\u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "BioScore\u91c7\u7528\u53cc\u5c3a\u5ea6\u51e0\u4f55\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u7ed3\u5408\u4e13\u95e8\u6a21\u5757\u7528\u4e8e\u7ed3\u6784\u8bc4\u4f30\u548c\u4eb2\u548c\u529b\u9884\u6d4b\u3002", "result": "BioScore\u572816\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u652f\u6301\u591a\u79cd\u4efb\u52a1\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u4eb2\u548c\u529b\u9884\u6d4b\u548c\u6297\u539f-\u6297\u4f53\u7ed3\u5408\u76f8\u5173\u6027\u3002", "conclusion": "BioScore\u4e3a\u590d\u6742\u751f\u7269\u5206\u5b50\u7ed3\u6784\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "BioScore, \u7ed3\u6784\u8bc4\u4f30, \u51e0\u4f55\u56fe\u5b66\u4e60, \u751f\u7269\u5206\u5b50, \u4eb2\u548c\u529b\u9884\u6d4b"}}
{"id": "2507.10951", "pdf": "https://arxiv.org/pdf/2507.10951", "abs": "https://arxiv.org/abs/2507.10951", "authors": ["Siyu Yu", "Zihan Qin", "Tingshan Liu", "Beiya Xu", "R. Jacob Vogelstein", "Jason Brown", "Joshua T. Vogelstein"], "title": "Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "comment": "Accepted to AGI 2025", "summary": "The complete connectome of the Drosophila larva brain offers a unique\nopportunity to investigate whether biologically evolved circuits can support\nartificial intelligence. We convert this wiring diagram into a Biological\nProcessing Unit (BPU), a fixed recurrent network derived directly from synaptic\nconnectivity. Despite its modest size 3,000 neurons and 65,000 weights between\nthem), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,\nsurpassing size-matched MLPs. Scaling the BPU via structured connectome\nexpansions further improves CIFAR-10 performance, while modality-specific\nablations reveal the uneven contributions of different sensory subsystems. On\nthe ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000\ngames achieves 60% move accuracy, nearly 10x better than any size transformer.\nMoreover, CNN-BPU models with ~2M parameters outperform parameter-matched\nTransformers, and with a depth-6 minimax search at inference, reach 91.7%\naccuracy, exceeding even a 9M-parameter Transformer baseline. These results\ndemonstrate the potential of biofidelic neural architectures to support complex\ncognitive tasks and motivate scaling to larger and more intelligent connectomes\nin future work.", "AI": {"tldr": "\u5229\u7528\u679c\u8747\u5e7c\u866b\u5927\u8111\u7684\u5b8c\u6574\u8fde\u63a5\u7ec4\u6784\u5efa\u7684\u751f\u7269\u5904\u7406\u5355\u5143\uff08BPU\uff09\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u4e86\u751f\u7269\u542f\u53d1\u795e\u7ecf\u7f51\u7edc\u5728\u590d\u6742\u8ba4\u77e5\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u63a2\u7d22\u751f\u7269\u8fdb\u5316\u7684\u795e\u7ecf\u56de\u8def\u662f\u5426\u652f\u6301\u4eba\u5de5\u667a\u80fd\uff0c\u5e76\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "method": "\u5c06\u679c\u8747\u5e7c\u866b\u5927\u8111\u7684\u8fde\u63a5\u7ec4\u8f6c\u6362\u4e3a\u56fa\u5b9a\u5faa\u73af\u7f51\u7edc\uff08BPU\uff09\uff0c\u5e76\u901a\u8fc7\u6269\u5c55\u548c\u7279\u5b9a\u6a21\u6001\u6d88\u878d\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "BPU\u5728MNIST\u4e0a\u8fbe\u523098%\u51c6\u786e\u7387\uff0cCIFAR-10\u4e0a58%\uff0c\u4f18\u4e8e\u89c4\u6a21\u5339\u914d\u7684\u591a\u5c42\u611f\u77e5\u673a\uff1b\u5728ChessBench\u548cCNN-BPU\u4e2d\u4e5f\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u751f\u7269\u542f\u53d1\u7684\u795e\u7ecf\u67b6\u6784\u6709\u671b\u652f\u6301\u590d\u6742\u8ba4\u77e5\u4efb\u52a1\uff0c\u672a\u6765\u53ef\u6269\u5c55\u81f3\u66f4\u5927\u89c4\u6a21\u7684\u8fde\u63a5\u7ec4\u3002", "keywords": "\u8fde\u63a5\u7ec4, BPU, \u751f\u7269\u542f\u53d1, \u795e\u7ecf\u7f51\u7edc, \u6027\u80fd\u6bd4\u8f83"}}
{"id": "2507.10977", "pdf": "https://arxiv.org/pdf/2507.10977", "abs": "https://arxiv.org/abs/2507.10977", "authors": ["Quan Bi Pay", "Vishnu Monn Baskaran", "Junn Yong Loo", "KokSheik Wong", "Simon See"], "title": "Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "Human-object interaction (HOI) detection is essential for accurately\nlocalizing and characterizing interactions between humans and objects,\nproviding a comprehensive understanding of complex visual scenes across various\ndomains. However, existing HOI detectors often struggle to deliver reliable\npredictions efficiently, relying on resource-intensive training methods and\ninefficient architectures. To address these challenges, we conceptualize a\nwavelet attention-like backbone and a novel ray-based encoder architecture\ntailored for HOI detection. Our wavelet backbone addresses the limitations of\nexpressing middle-order interactions by aggregating discriminative features\nfrom the low- and high-order interactions extracted from diverse convolutional\nfilters. Concurrently, the ray-based encoder facilitates multi-scale attention\nby optimizing the focus of the decoder on relevant regions of interest and\nmitigating computational overhead. As a result of harnessing the attenuated\nintensity of learnable ray origins, our decoder aligns query embeddings with\nemphasized regions of interest for accurate predictions. Experimental results\non benchmark datasets, including ImageNet and HICO-DET, showcase the potential\nof our proposed architecture. The code is publicly available at\n[https://github.com/henry-pay/RayEncoder].", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u6ce2\u6ce8\u610f\u529b\u4f3c\u9aa8\u5e72\u548c\u5c04\u7ebf\u7f16\u7801\u5668\u67b6\u6784\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u4eba\u673a\u4ea4\u4e92\u68c0\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u673a\u4ea4\u4e92\u68c0\u6d4b\u65b9\u6cd5\u5728\u6548\u7387\u548c\u53ef\u9760\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u8d44\u6e90\u5bc6\u96c6\u7684\u8bad\u7ec3\u65b9\u6cd5\u548c\u4f4e\u6548\u7684\u67b6\u6784\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u5c0f\u6ce2\u6ce8\u610f\u529b\u4f3c\u9aa8\u5e72\u548c\u5c04\u7ebf\u7f16\u7801\u5668\u67b6\u6784\uff0c\u805a\u5408\u4f4e\u9636\u548c\u9ad8\u9636\u4ea4\u4e92\u7279\u5f81\uff0c\u4f18\u5316\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b\u3002", "result": "\u5728ImageNet\u548cHICO-DET\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u7684\u6f5c\u529b\u3002", "conclusion": "\u65b0\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86\u4eba\u673a\u4ea4\u4e92\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "keywords": "\u4eba\u673a\u4ea4\u4e92\u68c0\u6d4b,\u5c0f\u6ce2\u6ce8\u610f\u529b,\u5c04\u7ebf\u7f16\u7801\u5668,\u591a\u5c3a\u5ea6\u6ce8\u610f\u529b"}}
{"id": "2507.10985", "pdf": "https://arxiv.org/pdf/2507.10985", "abs": "https://arxiv.org/abs/2507.10985", "authors": ["Andrew Valdivia", "Yueming Zhang", "Hailu Xu", "Amir Ghasemkhani", "Xin Qin"], "title": "Pronunciation Deviation Analysis Through Voice Cloning and Acoustic Comparison", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This paper presents a novel approach for detecting mispronunciations by\nanalyzing deviations between a user's original speech and their voice-cloned\ncounterpart with corrected pronunciation. We hypothesize that regions with\nmaximal acoustic deviation between the original and cloned utterances indicate\npotential mispronunciations. Our method leverages recent advances in voice\ncloning to generate a synthetic version of the user's voice with proper\npronunciation, then performs frame-by-frame comparisons to identify problematic\nsegments. Experimental results demonstrate the effectiveness of this approach\nin pinpointing specific pronunciation errors without requiring predefined\nphonetic rules or extensive training data for each target language.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u5206\u6790\u7528\u6237\u539f\u59cb\u8bed\u97f3\u4e0e\u7ecf\u8fc7\u53d1\u97f3\u6821\u6b63\u7684\u8bed\u97f3\u514b\u9686\u7248\u672c\u4e4b\u95f4\u7684\u504f\u5dee\u6765\u68c0\u6d4b\u53d1\u97f3\u9519\u8bef\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u5bf9\u6bd4\u539f\u59cb\u8bed\u97f3\u548c\u514b\u9686\u8bed\u97f3\u7684\u58f0\u5b66\u5dee\u5f02\uff0c\u6709\u6548\u8bc6\u522b\u53d1\u97f3\u9519\u8bef\uff0c\u800c\u65e0\u9700\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u8bed\u97f3\u89c4\u5219\u6216\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u5229\u7528\u8bed\u97f3\u514b\u9686\u6280\u672f\u751f\u6210\u53d1\u97f3\u6b63\u786e\u7684\u7528\u6237\u8bed\u97f3\u5408\u6210\u7248\u672c\uff0c\u5e76\u8fdb\u884c\u9010\u5e27\u6bd4\u8f83\uff0c\u4ee5\u8bc6\u522b\u53d1\u97f3\u9519\u8bef\u7684\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u51c6\u786e\u5b9a\u4f4d\u7279\u5b9a\u53d1\u97f3\u9519\u8bef\uff0c\u65e0\u9700\u9488\u5bf9\u6bcf\u79cd\u76ee\u6807\u8bed\u8a00\u8fdb\u884c\u5927\u91cf\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u9884\u5b9a\u4e49\u89c4\u5219\u6216\u5927\u89c4\u6a21\u6570\u636e\u7684\u65b0\u9014\u5f84\u3002", "keywords": "\u8bed\u97f3\u514b\u9686,\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b,\u58f0\u5b66\u5206\u6790,\u9010\u5e27\u6bd4\u8f83"}}
{"id": "2507.10913", "pdf": "https://arxiv.org/pdf/2507.10913", "abs": "https://arxiv.org/abs/2507.10913", "authors": ["Shuangyao Huang", "Haibo Zhang", "Zhiyi Huang"], "title": "A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge", "categories": ["cs.MA", "cs.LG", "cs.RO"], "comment": "Under review at AAAI 2026", "summary": "This paper presents a multi-agent reinforcement learning (MARL) framework for\ncooperative collision avoidance of UAV swarms leveraging domain\nknowledge-driven reward. The reward is derived from knowledge in the domain of\nimage processing, approximating contours on a two-dimensional field. By\nmodeling obstacles as maxima on the field, collisions are inherently avoided as\ncontours never go through peaks or intersect. Additionally, counters are smooth\nand energy-efficient. Our framework enables training with large swarm sizes as\nthe agent interaction is minimized and the need for complex credit assignment\nschemes or observation sharing mechanisms in state-of-the-art MARL approaches\nare eliminated. Moreover, UAVs obtain the ability to adapt to complex\nenvironments where contours may be non-viable or non-existent through intensive\ntraining. Extensive experiments are conducted to evaluate the performances of\nour framework against state-of-the-art MARL algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u4eba\u673a\u7fa4\u7684\u534f\u540c\u907f\u78b0\u3002", "motivation": "\u89e3\u51b3\u65e0\u4eba\u673a\u7fa4\u5728\u590d\u6742\u73af\u5883\u4e2d\u534f\u540c\u907f\u78b0\u7684\u95ee\u9898\uff0c\u5229\u7528\u56fe\u50cf\u5904\u7406\u9886\u57df\u7684\u77e5\u8bc6\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u3002", "method": "\u5c06\u969c\u788d\u7269\u5efa\u6a21\u4e3a\u4e8c\u7ef4\u573a\u4e2d\u7684\u6781\u5927\u503c\u70b9\uff0c\u901a\u8fc7\u8fd1\u4f3c\u8f6e\u5ed3\u5b9e\u73b0\u907f\u78b0\uff1b\u51cf\u5c11\u667a\u80fd\u4f53\u4ea4\u4e92\uff0c\u7b80\u5316\u4fe1\u7528\u5206\u914d\u548c\u89c2\u6d4b\u5171\u4eab\u673a\u5236\u3002", "result": "\u6846\u67b6\u5728\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u7fa4\u4e2d\u8868\u73b0\u9ad8\u6548\uff0c\u80fd\u591f\u9002\u5e94\u590d\u6742\u73af\u5883\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u9a71\u52a8\u7684\u5956\u52b1\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7fa4\u7684\u534f\u540c\u907f\u78b0\u80fd\u529b\u3002", "keywords": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60, \u65e0\u4eba\u673a\u7fa4, \u534f\u540c\u907f\u78b0, \u9886\u57df\u77e5\u8bc6, \u56fe\u50cf\u5904\u7406"}}
{"id": "2507.10934", "pdf": "https://arxiv.org/pdf/2507.10934", "abs": "https://arxiv.org/abs/2507.10934", "authors": ["Xinyuan Liu", "Jiahui Chen", "Bocheng Hu", "Yu Sun", "Xinyang Chen", "Shaoxu Song"], "title": "Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Data quality remains an important challenge in data-driven systems, as errors\nin tabular data can severely compromise downstream analytics and machine\nlearning performance. Although numerous error detection algorithms have been\nproposed, the lack of diverse, real-world error datasets limits comprehensive\nevaluation. Manual error annotation is both time-consuming and inconsistent,\nmotivating the exploration of synthetic error generation as an alternative. In\nthis work, we introduce TableEG, a framework that leverages large language\nmodels (LLMs) to generate authentic errors. By employing a table fine-tuning\nstrategy and a triplet representation $(I, T, O)$ to model error generation,\ndetection, and correction tasks, TableEG captures the complex dependencies\ninherent in two-dimensional tables. Trained on 12 real-world datasets spanning\n10 diverse domains, TableEG ensures that the synthesized errors faithfully\nreflect authentic error distributions. Experimental results indicate that\nerrors generated by TableEG exhibit superior pattern and distribution\nsimilarity compared to both rule-based methods and LLM-generated errors without\nfine-tuning. Furthermore, performance metrics on TableEG-generated errors\nclosely align with those on real-world errors across nearly all datasets and\ndetection algorithms, particularly for machine learning based detection\ntechniques. Overall, TableEG not only bridges the gap between synthetic and\nreal-world errors but also establishes a robust benchmark for subsequent error\ndetection and correction tasks.", "AI": {"tldr": "TableEG\u662f\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u771f\u5b9e\u9519\u8bef\u7684\u6846\u67b6\uff0c\u586b\u8865\u4e86\u5408\u6210\u9519\u8bef\u4e0e\u771f\u5b9e\u9519\u8bef\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u4f9b\u4e86\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u7684\u57fa\u51c6\u3002", "motivation": "\u6570\u636e\u8d28\u91cf\u662f\u6570\u636e\u9a71\u52a8\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u591a\u6837\u5316\u7684\u771f\u5b9e\u9519\u8bef\u6570\u636e\u96c6\uff0c\u624b\u52a8\u6807\u6ce8\u8017\u65f6\u4e14\u4e0d\u4e00\u81f4\u3002", "method": "TableEG\u901a\u8fc7\u8868\u683c\u5fae\u8c03\u7b56\u7565\u548c\u4e09\u5143\u7ec4\u8868\u793a\uff08I, T, O\uff09\u6a21\u62df\u9519\u8bef\u751f\u6210\u3001\u68c0\u6d4b\u548c\u7ea0\u6b63\u4efb\u52a1\uff0c\u6355\u6349\u8868\u683c\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "TableEG\u751f\u6210\u7684\u9519\u8bef\u5728\u6a21\u5f0f\u548c\u5206\u5e03\u4e0a\u66f4\u63a5\u8fd1\u771f\u5b9e\u9519\u8bef\uff0c\u4e14\u6027\u80fd\u6307\u6807\u4e0e\u771f\u5b9e\u9519\u8bef\u6570\u636e\u96c6\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "TableEG\u4e0d\u4ec5\u5408\u6210\u771f\u5b9e\u7684\u9519\u8bef\uff0c\u8fd8\u4e3a\u540e\u7eed\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u57fa\u51c6\u3002", "keywords": "\u6570\u636e\u8d28\u91cf, \u9519\u8bef\u68c0\u6d4b, \u5927\u8bed\u8a00\u6a21\u578b, \u8868\u683c\u6570\u636e, \u5408\u6210\u9519\u8bef"}}
{"id": "2507.10956", "pdf": "https://arxiv.org/pdf/2507.10956", "abs": "https://arxiv.org/abs/2507.10956", "authors": ["Zhaoyu Xing", "Yang Wan", "Juan Wen", "Wei Zhong"], "title": "GOLFS: Feature Selection via Combining Both Global and Local Information for High Dimensional Clustering", "categories": ["stat.ML", "cs.LG", "62-08", "G.3"], "comment": null, "summary": "It is important to identify the discriminative features for high dimensional\nclustering. However, due to the lack of cluster labels, the regularization\nmethods developed for supervised feature selection can not be directly applied.\nTo learn the pseudo labels and select the discriminative features\nsimultaneously, we propose a new unsupervised feature selection method, named\nGlObal and Local information combined Feature Selection (GOLFS), for high\ndimensional clustering problems. The GOLFS algorithm combines both local\ngeometric structure via manifold learning and global correlation structure of\nsamples via regularized self-representation to select the discriminative\nfeatures. The combination improves the accuracy of both feature selection and\nclustering by exploiting more comprehensive information. In addition, an\niterative algorithm is proposed to solve the optimization problem and the\nconvergency is proved. Simulations and two real data applications demonstrate\nthe excellent finite-sample performance of GOLFS on both feature selection and\nclustering.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGOLFS\u7684\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\uff0c\u7528\u4e8e\u9ad8\u7ef4\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7279\u5f81\u9009\u62e9\u548c\u805a\u7c7b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u9ad8\u7ef4\u805a\u7c7b\u4e2d\u8bc6\u522b\u5224\u522b\u6027\u7279\u5f81\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u805a\u7c7b\u6807\u7b7e\uff0c\u5df2\u6709\u76d1\u7763\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u3002", "method": "\u63d0\u51faGOLFS\u7b97\u6cd5\uff0c\u7ed3\u5408\u6d41\u5f62\u5b66\u4e60\u7684\u5c40\u90e8\u51e0\u4f55\u7ed3\u6784\u548c\u6b63\u5219\u5316\u81ea\u8868\u793a\u7684\u5168\u5c40\u76f8\u5173\u7ed3\u6784\uff0c\u901a\u8fc7\u8fed\u4ee3\u7b97\u6cd5\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u548c\u771f\u5b9e\u6570\u636e\u5e94\u7528\u8868\u660eGOLFS\u5728\u7279\u5f81\u9009\u62e9\u548c\u805a\u7c7b\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "GOLFS\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u4e0e\u5168\u5c40\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7279\u5f81\u9009\u62e9\u548c\u805a\u7c7b\u7684\u51c6\u786e\u6027\u3002", "keywords": "\u9ad8\u7ef4\u805a\u7c7b,\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9,\u6d41\u5f62\u5b66\u4e60,\u6b63\u5219\u5316\u81ea\u8868\u793a"}}
{"id": "2507.11106", "pdf": "https://arxiv.org/pdf/2507.11106", "abs": "https://arxiv.org/abs/2507.11106", "authors": ["V\u00edctor Blanco", "Inmaculada Espejo", "Ra\u00fal P\u00e1ez", "Antonio M. Rodr\u00edguez-Ch\u00eda"], "title": "A Mathematical Optimization Approach to Multisphere Support Vector Data Description", "categories": ["math.OC", "cs.LG"], "comment": "18 pages, 5 figures, 3 tables", "summary": "We present a novel mathematical optimization framework for outlier detection\nin multimodal datasets, extending Support Vector Data Description approaches.\nWe provide a primal formulation, in the shape of a Mixed Integer Second Order\nCone model, that constructs Euclidean hyperspheres to identify anomalous\nobservations. Building on this, we develop a dual model that enables the\napplication of the kernel trick, thus allowing for the detection of outliers\nwithin complex, non-linear data structures. An extensive computational study\ndemonstrates the effectiveness of our exact method, showing clear advantages\nover existing heuristic techniques in terms of accuracy and robustness.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b66\u4f18\u5316\u7684\u65b0\u578b\u591a\u6a21\u6001\u6570\u636e\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u652f\u6301\u5411\u91cf\u6570\u636e\u63cf\u8ff0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u6574\u6570\u4e8c\u9636\u9525\u6a21\u578b\u548c\u6838\u6280\u5de7\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u9488\u5bf9\u591a\u6a21\u6001\u6570\u636e\u4e2d\u5f02\u5e38\u68c0\u6d4b\u7684\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u7cbe\u786e\u7684\u9c81\u68d2\u65b9\u6cd5\u4ee5\u8d85\u8d8a\u73b0\u6709\u542f\u53d1\u5f0f\u6280\u672f\u3002", "method": "\u91c7\u7528\u6df7\u5408\u6574\u6570\u4e8c\u9636\u9525\u6a21\u578b\u6784\u5efa\u6b27\u51e0\u91cc\u5f97\u8d85\u7403\u4f53\uff0c\u5e76\u901a\u8fc7\u5bf9\u5076\u6a21\u578b\u5f15\u5165\u6838\u6280\u5de7\u5904\u7406\u975e\u7ebf\u6027\u6570\u636e\u7ed3\u6784\u3002", "result": "\u8ba1\u7b97\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u4f18\u5316\u6846\u67b6\u5728\u591a\u6a21\u6001\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u6570\u636e\u7ed3\u6784\u3002", "keywords": "\u5f02\u5e38\u68c0\u6d4b, \u6570\u5b66\u4f18\u5316, \u591a\u6a21\u6001\u6570\u636e, \u6838\u6280\u5de7, \u6df7\u5408\u6574\u6570\u4e8c\u9636\u9525\u6a21\u578b"}}
{"id": "2507.10999", "pdf": "https://arxiv.org/pdf/2507.10999", "abs": "https://arxiv.org/abs/2507.10999", "authors": ["Quan Bi Pay", "Vishnu Monn Baskaran", "Junn Yong Loo", "KokSheik Wong", "Simon See"], "title": "SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "The resurgence of convolutional neural networks (CNNs) in visual recognition\ntasks, exemplified by ConvNeXt, has demonstrated their capability to rival\ntransformer-based architectures through advanced training methodologies and\nViT-inspired design principles. However, both CNNs and transformers exhibit a\nsimplicity bias, favoring straightforward features over complex structural\nrepresentations. Furthermore, modern CNNs often integrate MLP-like blocks akin\nto those in transformers, but these blocks suffer from significant information\nredundancies, necessitating high expansion ratios to sustain competitive\nperformance. To address these limitations, we propose SpaRTAN, a lightweight\narchitectural design that enhances spatial and channel-wise information\nprocessing. SpaRTAN employs kernels with varying receptive fields, controlled\nby kernel size and dilation factor, to capture discriminative multi-order\nspatial features effectively. A wave-based channel aggregation module further\nmodulates and reinforces pixel interactions, mitigating channel-wise\nredundancies. Combining the two modules, the proposed network can efficiently\ngather and dynamically contextualize discriminative features. Experimental\nresults in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable\nparameter efficiency while maintaining competitive performance. In particular,\non the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M\nparameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver\nstrong performance through an efficient design. On the COCO benchmark, it\nachieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M\nparameters. The code is publicly available at\n[https://github.com/henry-pay/SpaRTAN].", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SpaRTAN\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u67b6\u6784\u8bbe\u8ba1\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u7a7a\u95f4\u7279\u5f81\u548c\u901a\u9053\u805a\u5408\u6a21\u5757\uff0c\u89e3\u51b3\u4e86CNN\u548cTransformer\u7684\u4fe1\u606f\u5197\u4f59\u95ee\u9898\uff0c\u5728ImageNet\u548cCOCO\u4e0a\u8868\u73b0\u4f18\u5f02\u4e14\u53c2\u6570\u9ad8\u6548\u3002", "motivation": "\u73b0\u4ee3CNN\u548cTransformer\u867d\u7136\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u4ecd\u5b58\u5728\u7b80\u5355\u6027\u504f\u597d\u548c\u4fe1\u606f\u5197\u4f59\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u6548\u7387\u548c\u8868\u73b0\u3002", "method": "SpaRTAN\u7ed3\u5408\u4e86\u591a\u5c3a\u5ea6\u7a7a\u95f4\u6838\u548c\u6ce2\u72b6\u901a\u9053\u805a\u5408\u6a21\u5757\uff0c\u52a8\u6001\u6355\u6349\u548c\u589e\u5f3a\u7279\u5f81\uff0c\u51cf\u5c11\u5197\u4f59\u3002", "result": "\u5728ImageNet-1k\u4e0a\u8fbe\u523077.7%\u51c6\u786e\u7387\uff08\u4ec53.8M\u53c2\u6570\uff09\uff0cCOCO\u4e0a50.0% AP\uff0821.5M\u53c2\u6570\uff09\uff0c\u5747\u8d85\u8fc7\u57fa\u51c6\u3002", "conclusion": "SpaRTAN\u901a\u8fc7\u9ad8\u6548\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u4f4e\u53c2\u6570\u91cf\uff0c\u89e3\u51b3\u4e86\u5197\u4f59\u95ee\u9898\u3002", "keywords": "CNN, Transformer, \u8f7b\u91cf\u7ea7\u67b6\u6784, \u4fe1\u606f\u5197\u4f59, \u7a7a\u95f4\u7279\u5f81, \u901a\u9053\u805a\u5408"}}
{"id": "2507.11015", "pdf": "https://arxiv.org/pdf/2507.11015", "abs": "https://arxiv.org/abs/2507.11015", "authors": ["Zeyi Hou", "Zeqiang Wei", "Ruixin Yan", "Ning Lang", "Xiuzhuang Zhou"], "title": "Semantically Informed Salient Regions Guided Radiology Report Generation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in automated radiology report generation from chest X-rays\nusing deep learning algorithms have the potential to significantly reduce the\narduous workload of radiologists. However, due to the inherent massive data\nbias in radiology images, where abnormalities are typically subtle and sparsely\ndistributed, existing methods often produce fluent yet medically inaccurate\nreports, limiting their applicability in clinical practice. To address this\nissue effectively, we propose a Semantically Informed Salient Regions-guided\n(SISRNet) report generation method. Specifically, our approach explicitly\nidentifies salient regions with medically critical characteristics using\nfine-grained cross-modal semantics. Then, SISRNet systematically focuses on\nthese high-information regions during both image modeling and report\ngeneration, effectively capturing subtle abnormal findings, mitigating the\nnegative impact of data bias, and ultimately generating clinically accurate\nreports. Compared to its peers, SISRNet demonstrates superior performance on\nwidely used IU-Xray and MIMIC-CXR datasets.", "AI": {"tldr": "SISRNet\u901a\u8fc7\u8bc6\u522b\u533b\u5b66\u5173\u952e\u7279\u5f81\u7684\u663e\u8457\u533a\u57df\uff0c\u751f\u6210\u66f4\u51c6\u786e\u7684\u653e\u5c04\u5b66\u62a5\u544a\uff0c\u51cf\u5c11\u6570\u636e\u504f\u5dee\u7684\u5f71\u54cd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u5728\u81ea\u52a8\u751f\u6210\u653e\u5c04\u5b66\u62a5\u544a\u4e2d\u5b58\u5728\u533b\u5b66\u4e0d\u51c6\u786e\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8e\u6570\u636e\u504f\u5dee\u548c\u5f02\u5e38\u533a\u57df\u7684\u7a00\u758f\u6027\u3002", "method": "\u63d0\u51faSISRNet\u65b9\u6cd5\uff0c\u5229\u7528\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u8bed\u4e49\u8bc6\u522b\u663e\u8457\u533a\u57df\uff0c\u5e76\u5728\u56fe\u50cf\u5efa\u6a21\u548c\u62a5\u544a\u751f\u6210\u4e2d\u805a\u7126\u8fd9\u4e9b\u533a\u57df\u3002", "result": "SISRNet\u5728IU-Xray\u548cMIMIC-CXR\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SISRNet\u80fd\u6709\u6548\u51cf\u5c11\u6570\u636e\u504f\u5dee\uff0c\u751f\u6210\u4e34\u5e8a\u51c6\u786e\u7684\u653e\u5c04\u5b66\u62a5\u544a\u3002", "keywords": "\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210,\u6df1\u5ea6\u5b66\u4e60,SISRNet,\u6570\u636e\u504f\u5dee,\u8de8\u6a21\u6001\u8bed\u4e49"}}
{"id": "2507.11129", "pdf": "https://arxiv.org/pdf/2507.11129", "abs": "https://arxiv.org/abs/2507.11129", "authors": ["Zhifeng Gu", "Bing Wang"], "title": "MMOne: Representing Multiple Modalities in One Scene", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted to ICCV 2025", "summary": "Humans perceive the world through multimodal cues to understand and interact\nwith the environment. Learning a scene representation for multiple modalities\nenhances comprehension of the physical world. However, modality conflicts,\narising from inherent distinctions among different modalities, present two\ncritical challenges: property disparity and granularity disparity. To address\nthese challenges, we propose a general framework, MMOne, to represent multiple\nmodalities in one scene, which can be readily extended to additional\nmodalities. Specifically, a modality modeling module with a novel modality\nindicator is proposed to capture the unique properties of each modality.\nAdditionally, we design a multimodal decomposition mechanism to separate\nmulti-modal Gaussians into single-modal Gaussians based on modality\ndifferences. We address the essential distinctions among modalities by\ndisentangling multimodal information into shared and modality-specific\ncomponents, resulting in a more compact and efficient multimodal scene\nrepresentation. Extensive experiments demonstrate that our method consistently\nenhances the representation capability for each modality and is scalable to\nadditional modalities. The code is available at\nhttps://github.com/Neal2020GitHub/MMOne.", "AI": {"tldr": "MMOne\u6846\u67b6\u901a\u8fc7\u6a21\u6001\u5efa\u6a21\u6a21\u5757\u548c\u591a\u6a21\u6001\u5206\u89e3\u673a\u5236\u89e3\u51b3\u6a21\u6001\u51b2\u7a81\uff0c\u63d0\u5347\u591a\u6a21\u6001\u573a\u666f\u8868\u793a\u80fd\u529b\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u56e0\u6a21\u6001\u95f4\u7684\u5c5e\u6027\u5dee\u5f02\u548c\u7c92\u5ea6\u5dee\u5f02\u800c\u9762\u4e34\u6311\u6218\uff0c\u9700\u7edf\u4e00\u8868\u793a\u65b9\u6cd5\u4ee5\u589e\u5f3a\u5bf9\u7269\u7406\u4e16\u754c\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51faMMOne\u6846\u67b6\uff0c\u5f15\u5165\u6a21\u6001\u6307\u793a\u5668\u6355\u6349\u6a21\u6001\u7279\u6027\uff0c\u901a\u8fc7\u5206\u89e3\u673a\u5236\u5206\u79bb\u591a\u6a21\u6001\u9ad8\u65af\u4e3a\u5355\u6a21\u6001\u9ad8\u65af\uff0c\u89e3\u8026\u5171\u4eab\u548c\u7279\u5b9a\u6a21\u6001\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u5404\u6a21\u6001\u8868\u793a\u80fd\u529b\uff0c\u5e76\u80fd\u6269\u5c55\u81f3\u66f4\u591a\u6a21\u6001\u3002", "conclusion": "MMOne\u901a\u8fc7\u89e3\u8026\u5171\u4eab\u548c\u7279\u5b9a\u6a21\u6001\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u7d27\u51d1\u9ad8\u6548\u7684\u591a\u6a21\u6001\u573a\u666f\u8868\u793a\u3002", "keywords": "\u591a\u6a21\u6001\u5b66\u4e60,\u573a\u666f\u8868\u793a,\u6a21\u6001\u51b2\u7a81,MMOne"}}
{"id": "2507.11136", "pdf": "https://arxiv.org/pdf/2507.11136", "abs": "https://arxiv.org/abs/2507.11136", "authors": ["Afra Kilic", "Kim Batselier"], "title": "Interpretable Bayesian Tensor Network Kernel Machines with Automatic Rank and Feature Selection", "categories": ["stat.ML", "cs.LG"], "comment": "39 pages, 5 figures, 4 tables. Submitted to Journal of Machine\n  Learning Research. The code is available at:\n  https://github.com/afrakilic/BTN-Kernel-Machines. arXiv admin note: text\n  overlap with arXiv:1401.6497 by other authors", "summary": "Tensor Network (TN) Kernel Machines speed up model learning by representing\nparameters as low-rank TNs, reducing computation and memory use. However, most\nTN-based Kernel methods are deterministic and ignore parameter uncertainty.\nFurther, they require manual tuning of model complexity hyperparameters like\ntensor rank and feature dimensions, often through trial-and-error or\ncomputationally costly methods like cross-validation. We propose Bayesian\nTensor Network Kernel Machines, a fully probabilistic framework that uses\nsparsity-inducing hierarchical priors on TN factors to automatically infer\nmodel complexity. This enables automatic inference of tensor rank and feature\ndimensions, while also identifying the most relevant features for prediction,\nthereby enhancing model interpretability. All the model parameters and\nhyperparameters are treated as latent variables with corresponding priors.\nGiven the Bayesian approach and latent variable dependencies, we apply a\nmean-field variational inference to approximate their posteriors. We show that\napplying a mean-field approximation to TN factors yields a Bayesian ALS\nalgorithm with the same computational complexity as its deterministic\ncounterpart, enabling uncertainty quantification at no extra computational\ncost. Experiments on synthetic and real-world datasets demonstrate the superior\nperformance of our model in prediction accuracy, uncertainty quantification,\ninterpretability, and scalability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d1d\u53f6\u65af\u5f20\u91cf\u7f51\u7edc\u6838\u673a\u5668\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u8bf1\u5bfc\u5206\u5c42\u5148\u9a8c\u81ea\u52a8\u63a8\u65ad\u6a21\u578b\u590d\u6742\u6027\uff0c\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3001\u4e0d\u786e\u5b9a\u5ea6\u91cf\u5316\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5927\u591a\u6570\u5f20\u91cf\u7f51\u7edc\u6838\u65b9\u6cd5\u662f\u786e\u5b9a\u6027\u7684\uff0c\u5ffd\u7565\u4e86\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u4e14\u9700\u8981\u624b\u52a8\u8c03\u6574\u6a21\u578b\u590d\u6742\u6027\u8d85\u53c2\u6570\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u6982\u7387\u6846\u67b6\uff0c\u5229\u7528\u5206\u5c42\u5148\u9a8c\u81ea\u52a8\u63a8\u65ad\u5f20\u91cf\u79e9\u548c\u7279\u5f81\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u53d8\u5206\u63a8\u65ad\u8fd1\u4f3c\u540e\u9a8c\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9884\u6d4b\u7cbe\u5ea6\u3001\u4e0d\u786e\u5b9a\u5ea6\u91cf\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8d1d\u53f6\u65af\u5f20\u91cf\u7f51\u7edc\u6838\u673a\u5668\u5728\u81ea\u52a8\u63a8\u65ad\u6a21\u578b\u590d\u6742\u6027\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "keywords": "\u8d1d\u53f6\u65af\u5b66\u4e60, \u5f20\u91cf\u7f51\u7edc, \u6838\u673a\u5668, \u53d8\u5206\u63a8\u65ad"}}
{"id": "2507.11137", "pdf": "https://arxiv.org/pdf/2507.11137", "abs": "https://arxiv.org/abs/2507.11137", "authors": ["Yuan Yao", "Jin Song", "Jian Jin"], "title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "As valuable digital assets, deep neural networks necessitate robust ownership\nprotection, positioning neural network watermarking (NNW) as a promising\nsolution. Among various NNW approaches, weight-based methods are favored for\ntheir simplicity and practicality; however, they remain vulnerable to forging\nand overwriting attacks. To address those challenges, we propose NeuralMark, a\nrobust method built around a hashed watermark filter. Specifically, we utilize\na hash function to generate an irreversible binary watermark from a secret key,\nwhich is then used as a filter to select the model parameters for embedding.\nThis design cleverly intertwines the embedding parameters with the hashed\nwatermark, providing a robust defense against both forging and overwriting\nattacks. An average pooling is also incorporated to resist fine-tuning and\npruning attacks. Furthermore, it can be seamlessly integrated into various\nneural network architectures, ensuring broad applicability. Theoretically, we\nanalyze its security boundary. Empirically, we verify its effectiveness and\nrobustness across 13 distinct Convolutional and Transformer architectures,\ncovering five image classification tasks and one text generation task. The\nsource codes are available at https://github.com/AIResearch-Group/NeuralMark.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u54c8\u5e0c\u6c34\u5370\u6ee4\u6ce2\u5668\u7684\u795e\u7ecf\u7f51\u7edc\u6c34\u5370\u65b9\u6cd5NeuralMark\uff0c\u7528\u4e8e\u4fdd\u62a4\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u7248\u6743\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u54c8\u5e0c\u51fd\u6570\u751f\u6210\u4e0d\u53ef\u9006\u7684\u4e8c\u8fdb\u5236\u6c34\u5370\uff0c\u5e76\u9009\u62e9\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u5d4c\u5165\uff0c\u6709\u6548\u62b5\u5fa1\u4f2a\u9020\u548c\u8986\u5199\u653b\u51fb\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6709\u4ef7\u503c\u7684\u6570\u5b57\u8d44\u4ea7\uff0c\u9700\u8981\u5f3a\u5065\u7684\u6240\u6709\u6743\u4fdd\u62a4\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u6c34\u5370\u65b9\u6cd5\u867d\u7136\u7b80\u5355\u5b9e\u7528\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u4f2a\u9020\u548c\u8986\u5199\u653b\u51fb\u3002", "method": "\u63d0\u51faNeuralMark\uff0c\u5229\u7528\u54c8\u5e0c\u51fd\u6570\u4ece\u5bc6\u94a5\u751f\u6210\u4e0d\u53ef\u9006\u7684\u4e8c\u8fdb\u5236\u6c34\u5370\uff0c\u5e76\u5c06\u6c34\u5370\u4f5c\u4e3a\u6ee4\u6ce2\u5668\u9009\u62e9\u5d4c\u5165\u53c2\u6570\u3002\u7ed3\u5408\u5e73\u5747\u6c60\u5316\u4ee5\u62b5\u6297\u5fae\u8c03\u548c\u526a\u679d\u653b\u51fb\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u7f51\u7edc\u67b6\u6784\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e86\u5b89\u5168\u6027\u8fb9\u754c\uff0c\u5e76\u901a\u8fc713\u79cd\u5377\u79ef\u548cTransformer\u67b6\u6784\u57285\u4e2a\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u548c1\u4e2a\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "NeuralMark\u80fd\u591f\u6709\u6548\u9632\u5fa1\u591a\u79cd\u653b\u51fb\uff0c\u5e76\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u7248\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u795e\u7ecf\u7f51\u7edc\u6c34\u5370, \u7248\u6743\u4fdd\u62a4, \u54c8\u5e0c\u51fd\u6570, \u9c81\u68d2\u6027, \u6a21\u578b\u5b89\u5168"}}
{"id": "2507.11143", "pdf": "https://arxiv.org/pdf/2507.11143", "abs": "https://arxiv.org/abs/2507.11143", "authors": ["Lam Pham", "Cam Le", "Hieu Tang", "Khang Truong", "Truong Nguyen", "Jasmin Lampert", "Alexander Schindler", "Martin Boyer", "Son Phan"], "title": "RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": null, "summary": "In recent years, landslide disasters have reported frequently due to the\nextreme weather events of droughts, floods , storms, or the consequence of\nhuman activities such as deforestation, excessive exploitation of natural\nresources. However, automatically observing landslide is challenging due to the\nextremely large observing area and the rugged topography such as mountain or\nhighland. This motivates us to propose an end-to-end deep-learning-based model\nwhich explores the remote sensing images for automatically observing landslide\nevents. By considering remote sensing images as the input data, we can obtain\nfree resource, observe large and rough terrains by time. To explore the remote\nsensing images, we proposed a novel neural network architecture which is for\ntwo tasks of landslide detection and landslide segmentation. We evaluated our\nproposed model on three different benchmark datasets of LandSlide4Sense, Bijie,\nand Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,\n93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU\nscores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,\nNepal datasets. These experimental results prove potential to integrate our\nproposed model into real-life landslide observation systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790\u9065\u611f\u56fe\u50cf\u81ea\u52a8\u89c2\u6d4b\u6ed1\u5761\u4e8b\u4ef6\uff0c\u89e3\u51b3\u4e86\u56e0\u5730\u5f62\u590d\u6742\u548c\u5927\u9762\u79ef\u89c2\u6d4b\u56f0\u96be\u7684\u95ee\u9898\u3002", "motivation": "\u6ed1\u5761\u707e\u5bb3\u9891\u7e41\u53d1\u751f\uff0c\u4f20\u7edf\u89c2\u6d4b\u65b9\u6cd5\u56e0\u5730\u5f62\u590d\u6742\u548c\u5927\u9762\u79ef\u89c2\u6d4b\u96be\u5ea6\u9ad8\u800c\u53d7\u9650\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u9065\u611f\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\u6570\u636e\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8e\u6ed1\u5761\u68c0\u6d4b\u548c\u5206\u5272\u4efb\u52a1\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u68c0\u6d4b\u4efb\u52a1\u7684F1\u5206\u6570\u5206\u522b\u4e3a98.23\u548c93.83\uff0c\u5206\u5272\u4efb\u52a1\u7684mIoU\u5206\u6570\u4e3a63.74\u548c76.88\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u6a21\u578b\u5728\u5b9e\u65f6\u6ed1\u5761\u89c2\u6d4b\u7cfb\u7edf\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002", "keywords": "\u6ed1\u5761\u89c2\u6d4b,\u6df1\u5ea6\u5b66\u4e60,\u9065\u611f\u56fe\u50cf,\u6ed1\u5761\u68c0\u6d4b,\u6ed1\u5761\u5206\u5272"}}
{"id": "2507.11061", "pdf": "https://arxiv.org/pdf/2507.11061", "abs": "https://arxiv.org/abs/2507.11061", "authors": ["Hayeon Kim", "Ji Ha Jang", "Se Young Chun"], "title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advances in 3D neural representations and instance-level editing\nmodels have enabled the efficient creation of high-quality 3D content. However,\nachieving precise local 3D edits remains challenging, especially for Gaussian\nSplatting, due to inconsistent multi-view 2D part segmentations and inherently\nambiguous nature of Score Distillation Sampling (SDS) loss. To address these\nlimitations, we propose RoMaP, a novel local 3D Gaussian editing framework that\nenables precise and drastic part-level modifications. First, we introduce a\nrobust 3D mask generation module with our 3D-Geometry Aware Label Prediction\n(3D-GALP), which uses spherical harmonics (SH) coefficients to model\nview-dependent label variations and soft-label property, yielding accurate and\nconsistent part segmentations across viewpoints. Second, we propose a\nregularized SDS loss that combines the standard SDS loss with additional\nregularizers. In particular, an L1 anchor loss is introduced via our Scheduled\nLatent Mixing and Part (SLaMP) editing method, which generates high-quality\npart-edited 2D images and confines modifications only to the target region\nwhile preserving contextual coherence. Additional regularizers, such as\nGaussian prior removal, further improve flexibility by allowing changes beyond\nthe existing context, and robust 3D masking prevents unintended edits.\nExperimental results demonstrate that our RoMaP achieves state-of-the-art local\n3D editing on both reconstructed and generated Gaussian scenes and objects\nqualitatively and quantitatively, making it possible for more robust and\nflexible part-level 3D Gaussian editing.", "AI": {"tldr": "RoMaP\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5c40\u90e83D\u9ad8\u65af\u7f16\u8f91\u6846\u67b6\uff0c\u7ed3\u54083D-GALP\u548cSLaMP\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u4e14\u9ad8\u7075\u6d3b\u6027\u7684\u90e8\u5206\u7ea7\u522b\u7f16\u8f91\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u89c6\u56fe2D\u90e8\u5206\u5206\u5272\u548cSDS\u635f\u5931\u7684\u56fa\u6709\u6a21\u7cca\u6027\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u963b\u788d\u4e86\u7cbe\u786e\u7684\u5c40\u90e83D\u7f16\u8f91\u3002", "method": "\u63d0\u51fa\u4e863D-GALP\u6a21\u5757\u751f\u6210\u7a33\u5065\u76843D\u63a9\u7801\uff0c\u5e76\u4f7f\u7528SLaMP\u65b9\u6cd5\u7ed3\u5408\u6b63\u5219\u5316SDS\u635f\u5931\u4f18\u5316\u7f16\u8f91\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRoMaP\u5728\u91cd\u5efa\u548c\u751f\u6210\u7684\u9ad8\u65af\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5c40\u90e83D\u7f16\u8f91\u6548\u679c\u3002", "conclusion": "RoMaP\u4e3a3D\u9ad8\u65af\u7f16\u8f91\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u90e8\u5206\u7ea7\u522b\u7f16\u8f91\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "keywords": "3D\u7f16\u8f91,\u9ad8\u65af\u55b7\u6d82,\u5c40\u90e8\u7f16\u8f91,SDS\u635f\u5931,3D-GALP,SLaMP"}}
{"id": "2507.11161", "pdf": "https://arxiv.org/pdf/2507.11161", "abs": "https://arxiv.org/abs/2507.11161", "authors": ["Jun Chen", "Hong Chen", "Yonghua Yu", "Yiming Ying"], "title": "How does Labeling Error Impact Contrastive Learning? A Perspective from Data Dimensionality Reduction", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted by ICML2025 as a poster", "summary": "In recent years, contrastive learning has achieved state-of-the-art\nperformance in the territory of self-supervised representation learning. Many\nprevious works have attempted to provide the theoretical understanding\nunderlying the success of contrastive learning. Almost all of them rely on a\ndefault assumption, i.e., the label consistency assumption, which may not hold\nin practice (the probability of failure is called labeling error) due to the\nstrength and randomness of common augmentation strategies, such as random\nresized crop (RRC). This paper investigates the theoretical impact of labeling\nerror on the downstream classification performance of contrastive learning. We\nfirst reveal several significant negative impacts of labeling error on\ndownstream classification risk. To mitigate these impacts, data dimensionality\nreduction method (e.g., singular value decomposition, SVD) is applied on\noriginal data to reduce false positive samples, and establish both theoretical\nand empirical evaluations. Moreover, it is also found that SVD acts as a\ndouble-edged sword, which may lead to the deterioration of downstream\nclassification accuracy due to the reduced connectivity of the augmentation\ngraph. Based on the above observations, we give the augmentation suggestion\nthat we should use some moderate embedding dimension (such as $512, 1024$ in\nour experiments), data inflation, weak augmentation, and SVD to ensure large\ngraph connectivity and small labeling error to improve model performance.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5bf9\u6bd4\u5b66\u4e60\u4e2d\u6807\u7b7e\u9519\u8bef\u5bf9\u4e0b\u6e38\u5206\u7c7b\u6027\u80fd\u7684\u7406\u8bba\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u6570\u636e\u964d\u7ef4\u7b49\u65b9\u6cd5\u51cf\u5c11\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u5bf9\u6bd4\u5b66\u4e60\u5728\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u7406\u8bba\u7406\u89e3\u4f9d\u8d56\u4e8e\u6807\u7b7e\u4e00\u81f4\u6027\u5047\u8bbe\uff0c\u8fd9\u4e00\u5047\u8bbe\u5728\u5b9e\u9645\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u6807\u7b7e\u9519\u8bef\u5bf9\u4e0b\u6e38\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6570\u636e\u964d\u7ef4\u65b9\u6cd5\uff08\u5982SVD\uff09\u51cf\u5c11\u8bef\u62a5\u6837\u672c\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc4\u4f30\u5176\u6548\u679c\u3002\u540c\u65f6\u63a2\u8ba8\u4e86SVD\u7684\u53cc\u5203\u5251\u6027\u8d28\u3002", "result": "SVD\u53ef\u4ee5\u51cf\u5c11\u6807\u7b7e\u9519\u8bef\uff0c\u4f46\u53ef\u80fd\u56e0\u964d\u4f4e\u589e\u5f3a\u56fe\u7684\u8fde\u901a\u6027\u800c\u5f71\u54cd\u5206\u7c7b\u51c6\u786e\u6027\u3002\u5efa\u8bae\u4f7f\u7528\u9002\u5ea6\u5d4c\u5165\u7ef4\u5ea6\u3001\u6570\u636e\u81a8\u80c0\u548c\u5f31\u589e\u5f3a\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u901a\u8fc7\u5e73\u8861\u6570\u636e\u964d\u7ef4\u548c\u589e\u5f3a\u7b56\u7565\u6765\u4f18\u5316\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u7684\u5efa\u8bae\u3002", "keywords": "\u5bf9\u6bd4\u5b66\u4e60, \u6807\u7b7e\u9519\u8bef, \u6570\u636e\u964d\u7ef4, SVD, \u4e0b\u6e38\u5206\u7c7b"}}
{"id": "2507.11064", "pdf": "https://arxiv.org/pdf/2507.11064", "abs": "https://arxiv.org/abs/2507.11064", "authors": ["Sehyun Ryu", "Hyun Jong Yang"], "title": "Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems", "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "comment": null, "summary": "Reducing feedback overhead in beyond 5G networks is a critical challenge, as\nthe growing number of antennas in modern massive MIMO systems substantially\nincreases the channel state information (CSI) feedback demand in frequency\ndivision duplex (FDD) systems. To address this, extensive research has focused\non CSI compression and prediction, with neural network-based approaches gaining\nmomentum and being considered for integration into the 3GPP 5G-Advanced\nstandards. While deep learning has been effectively applied to CSI-limited\nbeamforming and handover optimization, reference signal allocation under such\nconstraints remains surprisingly underexplored. To fill this gap, we introduce\nthe concept of channel prediction-based reference signal allocation (CPRS),\nwhich jointly optimizes channel prediction and DM-RS allocation to improve data\nthroughput without requiring CSI feedback. We further propose a\nstandards-compliant ViViT/CNN-based architecture that implements CPRS by\ntreating evolving CSI matrices as sequential image-like data, enabling\nefficient and adaptive transmission in dynamic environments. Simulation results\nusing ray-tracing channel data generated in NVIDIA Sionna validate the proposed\nmethod, showing up to 36.60% throughput improvement over benchmark strategies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u9053\u9884\u6d4b\u7684\u53c2\u8003\u4fe1\u53f7\u5206\u914d\uff08CPRS\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u4fe1\u9053\u9884\u6d4b\u548cDM-RS\u5206\u914d\u6765\u63d0\u9ad8\u6570\u636e\u541e\u5410\u91cf\uff0c\u65e0\u9700CSI\u53cd\u9988\uff0c\u4eff\u771f\u7ed3\u679c\u663e\u793a\u541e\u5410\u91cf\u63d0\u5347\u8fbe36.60%\u3002", "motivation": "\u8d855G\u7f51\u7edc\u4e2d\uff0c\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u5929\u7ebf\u6570\u91cf\u589e\u52a0\u5bfc\u81f4CSI\u53cd\u9988\u9700\u6c42\u6fc0\u589e\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8CSI\u538b\u7f29\u548c\u9884\u6d4b\uff0c\u4f46\u5728\u53c2\u8003\u4fe1\u53f7\u5206\u914d\u65b9\u9762\u7684\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51faCPRS\u6982\u5ff5\uff0c\u91c7\u7528ViViT/CNN\u67b6\u6784\uff0c\u5c06CSI\u77e9\u9635\u89c6\u4e3a\u5e8f\u5217\u56fe\u50cf\u6570\u636e\uff0c\u5b9e\u73b0\u9ad8\u6548\u81ea\u9002\u5e94\u4f20\u8f93\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0cCPRS\u65b9\u6cd5\u5728\u541e\u5410\u91cf\u4e0a\u6bd4\u57fa\u51c6\u7b56\u7565\u63d0\u9ad836.60%\u3002", "conclusion": "CPRS\u4e3a\u8d855G\u7f51\u7edc\u4e2d\u7684\u53c2\u8003\u4fe1\u53f7\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u4f20\u8f93\u6548\u7387\u3002", "keywords": "\u5927\u89c4\u6a21MIMO, CSI\u53cd\u9988, \u53c2\u8003\u4fe1\u53f7\u5206\u914d, \u6df1\u5ea6\u5b66\u4e60, 5G-Advanced"}}
{"id": "2507.11168", "pdf": "https://arxiv.org/pdf/2507.11168", "abs": "https://arxiv.org/abs/2507.11168", "authors": ["Gabriele Formis", "Amanda Ericson", "Stefan Forsstrom", "Kyi Thar", "Gianluca Cena", "Stefano Scanzio"], "title": "Improving Wi-Fi Network Performance Prediction with Deep Learning Models", "categories": ["cs.NI", "cs.AI", "cs.LG", "eess.SP"], "comment": "preprint accepted, 8 pages, 2025", "summary": "The increasing need for robustness, reliability, and determinism in wireless\nnetworks for industrial and mission-critical applications is the driver for the\ngrowth of new innovative methods. The study presented in this work makes use of\nmachine learning techniques to predict channel quality in a Wi-Fi network in\nterms of the frame delivery ratio. Predictions can be used proactively to\nadjust communication parameters at runtime and optimize network operations for\nindustrial applications. Methods including convolutional neural networks and\nlong short-term memory were analyzed on datasets acquired from a real Wi-Fi\nsetup across multiple channels. The models were compared in terms of prediction\naccuracy and computational complexity. Results show that the frame delivery\nratio can be reliably predicted, and convolutional neural networks, although\nslightly less effective than other models, are more efficient in terms of CPU\nusage and memory consumption. This enhances the model's usability on embedded\nand industrial systems.", "AI": {"tldr": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u9884\u6d4bWi-Fi\u7f51\u7edc\u7684\u4fe1\u9053\u8d28\u91cf\uff0c\u901a\u8fc7\u8c03\u6574\u901a\u4fe1\u53c2\u6570\u4f18\u5316\u5de5\u4e1a\u5e94\u7528\u7f51\u7edc\u6027\u80fd\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u6d88\u8017\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5de5\u4e1a\u53ca\u5173\u952e\u4efb\u52a1\u5e94\u7528\u5bf9\u65e0\u7ebf\u7f51\u7edc\u7684\u9c81\u68d2\u6027\u3001\u53ef\u9760\u6027\u548c\u786e\u5b9a\u6027\u9700\u6c42\u589e\u52a0\uff0c\u9a71\u52a8\u4e86\u65b0\u65b9\u6cd5\u7684\u521b\u65b0\u3002", "method": "\u5206\u6790\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u5728\u771f\u5b9eWi-Fi\u591a\u4fe1\u9053\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u6bd4\u8f83\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5e27\u4f20\u9012\u6bd4\u53ef\u88ab\u53ef\u9760\u9884\u6d4b\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u6d88\u8017\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66f4\u9002\u5408\u5d4c\u5165\u5f0f\u53ca\u5de5\u4e1a\u7cfb\u7edf\u5e94\u7528\uff0c\u56e0\u5176\u9ad8\u6548\u6027\u3002", "keywords": "\u673a\u5668\u5b66\u4e60, Wi-Fi, \u4fe1\u9053\u8d28\u91cf\u9884\u6d4b, \u5377\u79ef\u795e\u7ecf\u7f51\u7edc, \u5de5\u4e1a\u5e94\u7528"}}
{"id": "2507.11191", "pdf": "https://arxiv.org/pdf/2507.11191", "abs": "https://arxiv.org/abs/2507.11191", "authors": ["Eider Garate-Perez", "Kerman L\u00f3pez de Calle-Etxabe", "Susana Ferreiro"], "title": "Data-Driven Differential Evolution in Tire Industry Extrusion: Leveraging Surrogate Models", "categories": ["cs.CE", "cs.LG", "J.6; I.2; H.4"], "comment": "22 pages, 15 figures", "summary": "The optimization of industrial processes remains a critical challenge,\nparticularly when no mathematical formulation of objective functions or\nconstraints is available. This study addresses this issue by proposing a\nsurrogate-based, data-driven methodology for optimizing complex real-world\nmanufacturing systems using only historical process data. Machine learning\nmodels are employed to approximate system behavior and construct surrogate\nmodels, which are integrated into a tailored metaheuristic approach:\nData-Driven Differential Evolution with Multi-Level Penalty Functions and\nSurrogate Models, an adapted version of Differential Evolution suited to the\ncharacteristics of the studied process. The methodology is applied to an\nextrusion process in the tire manufacturing industry, with the goal of\noptimizing initialization parameters to reduce waste and production time.\nResults show that the surrogate-based optimization approach outperforms\nhistorical best configurations, achieving a 65\\% reduction in initialization\nand setup time, while also significantly minimizing material waste. These\nfindings highlight the potential of combining data-driven modeling and\nmetaheuristic optimization for industrial processes where explicit formulations\nare unavailable.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u590d\u6742\u5de5\u4e1a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6784\u5efa\u4ee3\u7406\u6a21\u578b\u5e76\u7ed3\u5408\u6539\u8fdb\u7684\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8f6e\u80ce\u5236\u9020\u8fc7\u7a0b\u4e2d\u7684\u521d\u59cb\u5316\u65f6\u95f4\u548c\u6750\u6599\u6d6a\u8d39\u3002", "motivation": "\u5de5\u4e1a\u8fc7\u7a0b\u4f18\u5316\u4e2d\u7ecf\u5e38\u7f3a\u4e4f\u76ee\u6807\u51fd\u6570\u6216\u7ea6\u675f\u7684\u6570\u5b66\u8868\u8fbe\uff0c\u8fd9\u6210\u4e3a\u4e86\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6784\u5efa\u4ee3\u7406\u6a21\u578b\uff0c\u5e76\u96c6\u6210\u5230\u6539\u8fdb\u7684\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\uff08Data-Driven Differential Evolution with Multi-Level Penalty Functions and Surrogate Models\uff09\u4e2d\uff0c\u5e94\u7528\u4e8e\u8f6e\u80ce\u5236\u9020\u4e1a\u7684\u6324\u51fa\u8fc7\u7a0b\u3002", "result": "\u4e0e\u5386\u53f2\u6700\u4f73\u914d\u7f6e\u76f8\u6bd4\uff0c\u521d\u59cb\u5316\u65f6\u95f4\u51cf\u5c11\u4e8665%\uff0c\u6750\u6599\u6d6a\u8d39\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u4e0e\u5143\u542f\u53d1\u5f0f\u4f18\u5316\u7ed3\u5408\u5728\u7f3a\u4e4f\u663e\u5f0f\u6570\u5b66\u8868\u8fbe\u7684\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u529b\u3002", "keywords": "\u5de5\u4e1a\u4f18\u5316, \u4ee3\u7406\u6a21\u578b, \u6570\u636e\u9a71\u52a8, \u5dee\u5206\u8fdb\u5316\u7b97\u6cd5, \u8f6e\u80ce\u5236\u9020"}}
{"id": "2507.11075", "pdf": "https://arxiv.org/pdf/2507.11075", "abs": "https://arxiv.org/abs/2507.11075", "authors": ["Chang Peng", "Yifei Zhou", "Huifeng Xi", "Shiqing Huang", "Chuangye Chen", "Jianming Yang", "Bao Yang", "Zhenyu Jiang"], "title": "Joint angle model based learning to refine kinematic human pose estimation", "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.3"], "comment": null, "summary": "Marker-free human pose estimation (HPE) has found increasing applications in\nvarious fields. Current HPE suffers from occasional errors in keypoint\nrecognition and random fluctuation in keypoint trajectories when analyzing\nkinematic human poses. The performance of existing deep learning-based models\nfor HPE refinement is considerably limited by inaccurate training datasets in\nwhich the keypoints are manually annotated. This paper proposed a novel method\nto overcome the difficulty through joint angle-based modeling. The key\ntechniques include: (i) A joint angle-based model of human pose, which is\nrobust to describe kinematic human poses; (ii) Approximating temporal variation\nof joint angles through high order Fourier series to get reliable \"ground\ntruth\"; (iii) A bidirectional recurrent network is designed as a\npost-processing module to refine the estimation of well-established HRNet.\nTrained with the high-quality dataset constructed using our method, the network\ndemonstrates outstanding performance to correct wrongly recognized joints and\nsmooth their spatiotemporal trajectories. Tests show that joint angle-based\nrefinement (JAR) outperforms the state-of-the-art HPE refinement network in\nchallenging cases like figure skating and breaking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5173\u8282\u89d2\u5efa\u6a21\u7684\u65b0\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u65e0\u6807\u8bb0\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\uff08HPE\uff09\u4e2d\u5173\u952e\u70b9\u8bc6\u522b\u548c\u8f68\u8ff9\u5e73\u6ed1\u7684\u8bef\u5dee\u95ee\u9898\u3002", "motivation": "\u5f53\u524dHPE\u5728\u5206\u6790\u8fd0\u52a8\u4eba\u4f53\u59ff\u6001\u65f6\u5b58\u5728\u5173\u952e\u70b9\u8bc6\u522b\u9519\u8bef\u548c\u8f68\u8ff9\u968f\u673a\u6ce2\u52a8\u7684\u95ee\u9898\uff0c\u800c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd\u53d7\u9650\u4e8e\u4e0d\u51c6\u786e\u7684\u6807\u6ce8\u6570\u636e\u96c6\u3002", "method": "1. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5173\u8282\u89d2\u7684\u4eba\u4f53\u59ff\u6001\u6a21\u578b\uff1b2. \u901a\u8fc7\u9ad8\u9636\u5085\u91cc\u53f6\u7ea7\u6570\u8fd1\u4f3c\u5173\u8282\u89d2\u7684\u65f6\u5e8f\u53d8\u5316\u4ee5\u83b7\u53d6\u53ef\u9760'\u771f\u503c'\uff1b3. \u8bbe\u8ba1\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u4f5c\u4e3aHRNet\u7684\u540e\u5904\u7406\u6a21\u5757\u4ee5\u4f18\u5316\u4f30\u8ba1\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u5173\u8282\u89d2\u7684\u6539\u8fdb\u65b9\u6cd5\uff08JAR\uff09\u5728\u82b1\u6837\u6ed1\u51b0\u548c\u9739\u96f3\u821e\u7b49\u6311\u6218\u6027\u6848\u4f8b\u4e2d\u4f18\u4e8e\u73b0\u6709HPE\u6539\u8fdb\u7f51\u7edc\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u7ea0\u6b63\u9519\u8bef\u8bc6\u522b\u7684\u5173\u8282\u5e76\u5e73\u6ed1\u5176\u65f6\u7a7a\u8f68\u8ff9\uff0c\u663e\u8457\u63d0\u5347\u4e86HPE\u7684\u6027\u80fd\u3002", "keywords": "\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1, \u5173\u8282\u89d2\u5efa\u6a21, \u5085\u91cc\u53f6\u7ea7\u6570, \u53cc\u5411\u5faa\u73af\u7f51\u7edc, \u59ff\u6001\u4f18\u5316"}}
{"id": "2507.11192", "pdf": "https://arxiv.org/pdf/2507.11192", "abs": "https://arxiv.org/abs/2507.11192", "authors": ["Bo Liang", "He Wang"], "title": "Recent Advances in Simulation-based Inference for Gravitational Wave Data Analysis", "categories": ["gr-qc", "astro-ph.HE", "astro-ph.IM", "cs.LG", "stat.ML"], "comment": "30 pages, 6 figures, 1 table. Published version accepted by\n  Astronomical Techniques and Instruments (ATI)", "summary": "The detection of gravitational waves by the LIGO-Virgo-KAGRA collaboration\nhas ushered in a new era of observational astronomy, emphasizing the need for\nrapid and detailed parameter estimation and population-level analyses.\nTraditional Bayesian inference methods, particularly Markov chain Monte Carlo,\nface significant computational challenges when dealing with the\nhigh-dimensional parameter spaces and complex noise characteristics inherent in\ngravitational wave data. This review examines the emerging role of\nsimulation-based inference methods in gravitational wave astronomy, with a\nfocus on approaches that leverage machine-learning techniques such as\nnormalizing flows and neural posterior estimation. We provide a comprehensive\noverview of the theoretical foundations underlying various simulation-based\ninference methods, including neural posterior estimation, neural ratio\nestimation, neural likelihood estimation, flow matching, and consistency\nmodels. We explore the applications of these methods across diverse\ngravitational wave data processing scenarios, from single-source parameter\nestimation and overlapping signal analysis to testing general relativity and\nconducting population studies. Although these techniques demonstrate speed\nimprovements over traditional methods in controlled studies, their\nmodel-dependent nature and sensitivity to prior assumptions are barriers to\ntheir widespread adoption. Their accuracy, which is similar to that of\nconventional methods, requires further validation across broader parameter\nspaces and noise conditions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u6a21\u62df\u7684\u63a8\u65ad\u65b9\u6cd5\u5728\u5f15\u529b\u6ce2\u5929\u6587\u5b66\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u53c2\u6570\u4f30\u8ba1\u548c\u7fa4\u4f53\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u53ca\u5176\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u9488\u5bf9\u4f20\u7edf\u8d1d\u53f6\u65af\u63a8\u65ad\u65b9\u6cd5\u5728\u5904\u7406\u5f15\u529b\u6ce2\u6570\u636e\u65f6\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u590d\u6742\u6027\uff0c\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u6a21\u62df\u63a8\u65ad\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5982\u5f52\u4e00\u5316\u6d41\u548c\u795e\u7ecf\u540e\u9a8c\u4f30\u8ba1\uff0c\u4ee5\u53ca\u591a\u79cd\u6a21\u62df\u63a8\u65ad\u65b9\u6cd5\uff08\u5982\u795e\u7ecf\u6bd4\u7387\u4f30\u8ba1\u548c\u4e00\u81f4\u6027\u6a21\u578b\uff09\u3002", "result": "\u8fd9\u4e9b\u65b9\u6cd5\u5728\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5176\u51c6\u786e\u6027\u548c\u5bf9\u5148\u9a8c\u5047\u8bbe\u7684\u4f9d\u8d56\u6027\u4ecd\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002", "conclusion": "\u57fa\u4e8e\u6a21\u62df\u7684\u63a8\u65ad\u65b9\u6cd5\u867d\u5177\u6f5c\u529b\uff0c\u4f46\u9700\u66f4\u5e7f\u6cdb\u7684\u9a8c\u8bc1\u548c\u6539\u8fdb\u4ee5\u63a8\u52a8\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "keywords": "\u5f15\u529b\u6ce2, \u6a21\u62df\u63a8\u65ad, \u673a\u5668\u5b66\u4e60, \u53c2\u6570\u4f30\u8ba1, \u7fa4\u4f53\u7814\u7a76"}}
{"id": "2507.11081", "pdf": "https://arxiv.org/pdf/2507.11081", "abs": "https://arxiv.org/abs/2507.11081", "authors": ["Chang Peng", "Bao Yang", "Meiqi Li", "Ge Zhang", "Hui Sun", "Zhenyu Jiang"], "title": "Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification", "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.2"], "comment": null, "summary": "Ground penetrating radar (GPR) has become a rapid and non-destructive\nsolution for road subsurface distress (RSD) detection. However, RSD recognition\nfrom GPR images is labor-intensive and heavily relies on inspectors' expertise.\nDeep learning offers the possibility for automatic RSD recognition, but its\ncurrent performance is limited by two factors: Scarcity of high-quality dataset\nfor network training and insufficient capability of network to distinguish RSD.\nIn this study, a rigorously validated 3D GPR dataset containing 2134 samples of\ndiverse types was constructed through field scanning. Based on the finding that\nthe YOLO model trained with one of the three scans of GPR images exhibits\nvarying sensitivity to specific type of RSD, we proposed a novel\ncross-verification strategy with outstanding accuracy in RSD recognition,\nachieving recall over 98.6% in field tests. The approach, integrated into an\nonline RSD detection system, can reduce the labor of inspection by around 90%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPR\u56fe\u50cf\u7684\u81ea\u52a8\u9053\u8def\u5730\u4e0b\u75c5\u5bb3\uff08RSD\uff09\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u548c\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u51c6\u786e\u7387\u548c\u6548\u7387\u3002", "motivation": "GPR\u56fe\u50cf\u7528\u4e8eRSD\u68c0\u6d4b\u65f6\u4f9d\u8d56\u4e13\u5bb6\u7ecf\u9a8c\u4e14\u5de5\u4f5c\u91cf\u5927\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u6027\u80fd\u53d7\u9650\u4e8e\u6570\u636e\u8d28\u91cf\u548c\u7f51\u7edc\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b2134\u4e2a\u6837\u672c\u76843D GPR\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8eYOLO\u6a21\u578b\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u65b9\u6cd5\u5728\u5b9e\u5730\u6d4b\u8bd5\u4e2d\u53ec\u56de\u7387\u8d85\u8fc798.6%\uff0c\u68c0\u6d4b\u7cfb\u7edf\u53ef\u51cf\u5c11\u7ea690%\u7684\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86RSD\u81ea\u52a8\u8bc6\u522b\u7684\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "keywords": "GPR, RSD, \u6df1\u5ea6\u5b66\u4e60, YOLO, \u4ea4\u53c9\u9a8c\u8bc1"}}
{"id": "2507.11202", "pdf": "https://arxiv.org/pdf/2507.11202", "abs": "https://arxiv.org/abs/2507.11202", "authors": ["Xinkui Zhao", "Jinsong Shu", "Yangyang Wu", "Guanjie Cheng", "Zihe Liu", "Naibo Wang", "Shuiguang Deng", "Zhongle Xie", "Jianwei Yin"], "title": "A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal Emotion Recognition (MER) often encounters incomplete\nmultimodality in practical applications due to sensor failures or privacy\nprotection requirements. While existing methods attempt to address various\nincomplete multimodal scenarios by balancing the training of each modality\ncombination through additional gradients, these approaches face a critical\nlimitation: training gradients from different modality combinations conflict\nwith each other, ultimately degrading the performance of the final prediction\nmodel. In this paper, we propose a unimodal decoupled dynamic low-rank\nadaptation method based on modality combinations, named MCULoRA, which is a\nnovel framework for the parameter-efficient training of incomplete multimodal\nlearning models. MCULoRA consists of two key modules, modality combination\naware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The\nMCLA module effectively decouples the shared information from the distinct\ncharacteristics of individual modality combinations. The DPFT module adjusts\nthe training ratio of modality combinations based on the separability of each\nmodality's representation space, optimizing the learning efficiency across\ndifferent modality combinations. Our extensive experimental evaluation in\nmultiple benchmark datasets demonstrates that MCULoRA substantially outperforms\nprevious incomplete multimodal learning approaches in downstream task accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMCULoRA\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u6a21\u6001\u7ec4\u5408\u7684\u5171\u4eab\u4fe1\u606f\u548c\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u6bd4\u4f8b\uff0c\u6709\u6548\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u4e2d\u6a21\u6001\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u5e38\u56e0\u4f20\u611f\u5668\u6545\u969c\u6216\u9690\u79c1\u4fdd\u62a4\u5bfc\u81f4\u6a21\u6001\u4e0d\u5b8c\u6574\uff0c\u73b0\u6709\u65b9\u6cd5\u56e0\u4e0d\u540c\u6a21\u6001\u7ec4\u5408\u7684\u8bad\u7ec3\u68af\u5ea6\u51b2\u7a81\u800c\u6027\u80fd\u4e0b\u964d\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u7684\u65b0\u65b9\u6cd5\u3002", "method": "MCULoRA\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a\u6a21\u6001\u7ec4\u5408\u611f\u77e5\u7684\u4f4e\u79e9\u9002\u5e94\uff08MCLA\uff09\u89e3\u8026\u5171\u4eab\u4fe1\u606f\uff0c\u52a8\u6001\u53c2\u6570\u5fae\u8c03\uff08DPFT\uff09\u57fa\u4e8e\u6a21\u6001\u8868\u793a\u7a7a\u95f4\u7684\u53ef\u5206\u6027\u8c03\u6574\u8bad\u7ec3\u6bd4\u4f8b\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMCULoRA\u663e\u8457\u4f18\u4e8e\u6b64\u524d\u7684\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "MCULoRA\u901a\u8fc7\u89e3\u8026\u548c\u52a8\u6001\u8c03\u6574\u7b56\u7565\uff0c\u4e3a\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u8bad\u7ec3\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\u3002", "keywords": "\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u3001\u4e0d\u5b8c\u6574\u6a21\u6001\u3001\u4f4e\u79e9\u9002\u5e94\u3001\u52a8\u6001\u5fae\u8c03\u3001\u4efb\u52a1\u51c6\u786e\u7387"}}
{"id": "2507.11096", "pdf": "https://arxiv.org/pdf/2507.11096", "abs": "https://arxiv.org/abs/2507.11096", "authors": ["Vassilis Sioros", "Alexandros Potamianos", "Giorgos Paraskevopoulos"], "title": "EditGen: Harnessing Cross-Attention Control for Instruction-Based Auto-Regressive Audio Editing", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "In this study, we investigate leveraging cross-attention control for\nefficient audio editing within auto-regressive models. Inspired by image\nediting methodologies, we develop a Prompt-to-Prompt-like approach that guides\nedits through cross and self-attention mechanisms. Integrating a\ndiffusion-based strategy, influenced by Auffusion, we extend the model's\nfunctionality to support refinement edits, establishing a baseline for\nprompt-guided audio editing. Additionally, we introduce an alternative approach\nby incorporating MUSICGEN, a pre-trained frozen auto-regressive model, and\npropose three editing mechanisms, based on Replacement, Reweighting, and\nRefinement of the attention scores. We employ commonly-used music-specific\nevaluation metrics and a human study, to gauge time-varying controllability,\nadherence to global text cues, and overall audio realism. The automatic and\nhuman evaluations indicate that the proposed combination of prompt-to-prompt\nguidance with autoregressive generation models significantly outperforms the\ndiffusion-based baseline in terms of melody, dynamics, and tempo of the\ngenerated audio. Our code is available at https://github.com/billsioros/EditGen", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u63a7\u5236\u5b9e\u73b0\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u9ad8\u6548\u97f3\u9891\u7f16\u8f91\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7Prompt-to-Prompt\u7c7b\u4f3c\u65b9\u6cd5\u6307\u5bfc\u7f16\u8f91\uff0c\u7ed3\u5408\u6269\u6563\u7b56\u7565\u548cMUSICGEN\u6a21\u578b\uff0c\u63d0\u51fa\u4e09\u79cd\u7f16\u8f91\u673a\u5236\uff0c\u5e76\u5728\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u53d7\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5c06\u7c7b\u4f3cPrompt-to-Prompt\u7684\u6ce8\u610f\u529b\u673a\u5236\u5e94\u7528\u4e8e\u97f3\u9891\u7f16\u8f91\uff0c\u4ee5\u63d0\u5347\u81ea\u56de\u5f52\u6a21\u578b\u7684\u7f16\u8f91\u80fd\u529b\u548c\u751f\u6210\u8d28\u91cf\u3002", "method": "\u7ed3\u5408\u6269\u6563\u7b56\u7565\uff08\u57fa\u4e8eAuffusion\uff09\u548cMUSICGEN\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6570\u66ff\u6362\u3001\u91cd\u52a0\u6743\u548c\u7ec6\u5316\u7684\u4e09\u79cd\u7f16\u8f91\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u7684\u7ec4\u5408\u5728\u65cb\u5f8b\u3001\u52a8\u6001\u548c\u8282\u62cd\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6269\u6563\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u548c\u81ea\u56de\u5f52\u6a21\u578b\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u97f3\u9891\u7f16\u8f91\uff0c\u4e3a\u57fa\u4e8e\u63d0\u793a\u7684\u97f3\u9891\u7f16\u8f91\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002", "keywords": "\u97f3\u9891\u7f16\u8f91, \u81ea\u56de\u5f52\u6a21\u578b, \u4ea4\u53c9\u6ce8\u610f\u529b, Prompt-to-Prompt, \u6269\u6563\u6a21\u578b"}}
{"id": "2507.11236", "pdf": "https://arxiv.org/pdf/2507.11236", "abs": "https://arxiv.org/abs/2507.11236", "authors": ["Yuchen He", "Zhehan Lei", "Jianan Shao", "Chihao Zhang"], "title": "Improved sampling algorithms and Poincar\u00e9 inequalities for non-log-concave distributions", "categories": ["cs.DS", "cs.LG", "math.PR", "stat.ML"], "comment": null, "summary": "We study the problem of sampling from a distribution $\\mu$ with density\n$\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with\nquery access to $V$ and $\\nabla V$. We start with the following standard\nassumptions:\n  (1) The potential function $V$ is $L$-smooth.\n  (2) The second moment $\\mathbf{E}_{X\\sim \\mu}[\\|X\\|^2]\\leq M$.\n  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling\nfrom such distributions is at least\n$\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired\naccuracy in total variation distance, and the Poincar\\'e constant can be\narbitrarily large.\n  Meanwhile, another common assumption in the study of diffusion based samplers\n(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23))\nstrengthens the smoothness condition (1) to the following:\n  (1*) The potential function of *every* distribution along the\nOrnstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\n  We show that under the assumptions (1*) and (2), the query complexity of\nsampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot\n\\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial\nin $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and\n$M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query\ncomplexity developed by Huang et al. (COLT'24). Our results imply that the\nseemly moderate strengthening of the smoothness condition (1) to (1*) can lead\nto an exponential gap in the query complexity of sampling algorithms.\n  Moreover, we show that together with the assumption (1*) and the stronger\nmoment assumption that $\\|X\\|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the\nPoincar\\'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an\napplication of our technique, we obtain improved estimate of the Poincar\\'e\nconstant for mixture of Gaussians with the same covariance.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4ece\u7279\u5b9a\u5206\u5e03\u4e2d\u91c7\u6837\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u5f3a\u5316\u5e73\u6ed1\u6027\u6761\u4ef6\uff081*\uff09\u548c\u4e8c\u9636\u77e9\u5047\u8bbe\uff082\uff09\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u590d\u6742\u5ea6\uff0c\u8bc1\u660e\u4e86\u6761\u4ef6\uff081*\uff09\u5bf9\u91c7\u6837\u7b97\u6cd5\u590d\u6742\u5ea6\u7684\u91cd\u8981\u5f71\u54cd\u3002\u5e94\u7528\u8fd8\u5305\u62ec\u6539\u8fdb\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684Poincar\u00e9\u5e38\u6570\u4f30\u8ba1\u3002", "motivation": "\u7814\u7a76\u4ece\u5206\u5e03$\\mu$\u4e2d\u91c7\u6837\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u63a2\u7d22\u4e0d\u540c\u5e73\u6ed1\u6027\u6761\u4ef6\u5bf9\u590d\u6742\u5ea6\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u5f3a\u5316\u6761\u4ef6\u4e0b\u7684\u6539\u8fdb\u6548\u679c\u3002", "method": "\u5728\u5e73\u6ed1\u6027\u6761\u4ef6\uff081*\uff09\u548c\u4e8c\u9636\u77e9\u5047\u8bbe\uff082\uff09\u4e0b\uff0c\u5206\u6790\u91c7\u6837\u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u5e76\u4e0e\u73b0\u6709\u7ed3\u679c\u5bf9\u6bd4\u3002", "result": "\u5728\u5f3a\u5316\u5e73\u6ed1\u6027\u6761\u4ef6\u4e0b\uff0c\u67e5\u8be2\u590d\u6742\u5ea6\u53ef\u964d\u4e3a\u591a\u9879\u5f0f\u7ea7\u522b\uff0c\u4e14Poincar\u00e9\u5e38\u6570\u4f30\u8ba1\u5f97\u5230\u6539\u8fdb\u3002", "conclusion": "\u5f3a\u5316\u5e73\u6ed1\u6027\u6761\u4ef6\uff081*\uff09\u80fd\u663e\u8457\u964d\u4f4e\u91c7\u6837\u590d\u6742\u5ea6\uff0c\u5bf9\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u5e94\u7528\u4e5f\u6709\u91cd\u8981\u610f\u4e49\u3002", "keywords": "\u91c7\u6837\u590d\u6742\u5ea6,\u5e73\u6ed1\u6027\u6761\u4ef6,Poincar\u00e9\u5e38\u6570,Ornstein-Uhlenbeck\u8fc7\u7a0b,\u9ad8\u65af\u6df7\u5408\u6a21\u578b"}}
{"id": "2507.11152", "pdf": "https://arxiv.org/pdf/2507.11152", "abs": "https://arxiv.org/abs/2507.11152", "authors": ["Duoyou Chen", "Yunqing Chen", "Can Zhang", "Zhou Wang", "Cheng Chen", "Ruoxiu Xiao"], "title": "Latent Space Consistency for Sparse-View CT Reconstruction", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "ACMMM2025 Accepted", "summary": "Computed Tomography (CT) is a widely utilized imaging modality in clinical\nsettings. Using densely acquired rotational X-ray arrays, CT can capture 3D\nspatial features. However, it is confronted with challenged such as significant\ntime consumption and high radiation exposure. CT reconstruction methods based\non sparse-view X-ray images have garnered substantial attention from\nresearchers as they present a means to mitigate costs and risks. In recent\nyears, diffusion models, particularly the Latent Diffusion Model (LDM), have\ndemonstrated promising potential in the domain of 3D CT reconstruction.\nNonetheless, due to the substantial differences between the 2D latent\nrepresentation of X-ray modalities and the 3D latent representation of CT\nmodalities, the vanilla LDM is incapable of achieving effective alignment\nwithin the latent space. To address this issue, we propose the Consistent\nLatent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature\ncontrastive learning to efficiently extract latent 3D information from 2D X-ray\nimages and achieve latent space alignment between modalities. Experimental\nresults indicate that CLS-DM outperforms classical and state-of-the-art\ngenerative models in terms of standard voxel-level metrics (PSNR, SSIM) on the\nLIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing\nthe effectiveness and economic viability of sparse X-ray reconstructed CT but\ncan also be generalized to other cross-modal transformation tasks, such as\ntext-to-image synthesis. We have made our code publicly available at\nhttps://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research\nand applications in other domains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCLS-DM\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u7279\u5f81\u5bf9\u6bd4\u5b66\u4e60\uff0c\u89e3\u51b32D X\u5c04\u7ebf\u4e0e3D CT\u6a21\u6001\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u5347\u7a00\u758f\u89c6\u56feCT\u91cd\u5efa\u6548\u679c\u3002", "motivation": "\u4f20\u7edfCT\u6210\u50cf\u5b58\u5728\u8017\u65f6\u548c\u9ad8\u8f90\u5c04\u95ee\u9898\uff0c\u7a00\u758f\u89c6\u56feCT\u91cd\u5efa\u53ef\u964d\u4f4e\u6210\u672c\u4e0e\u98ce\u9669\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u4e0a\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684CLS-DM\uff0c\u5f15\u5165\u8de8\u6a21\u6001\u7279\u5f81\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ece2D X\u5c04\u7ebf\u56fe\u50cf\u4e2d\u63d0\u53d6\u6f5c\u57283D\u4fe1\u606f\u5e76\u5b9e\u73b0\u6a21\u6001\u95f4\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u3002", "result": "\u5728LIDC-IDRI\u548cCTSpine1K\u6570\u636e\u96c6\u4e0a\uff0cCLS-DM\u5728PSNR\u548cSSIM\u7b49\u4f53\u7d20\u7ea7\u6307\u6807\u4e0a\u4f18\u4e8e\u7ecf\u5178\u53ca\u6700\u65b0\u751f\u6210\u6a21\u578b\u3002", "conclusion": "CLS-DM\u63d0\u5347\u4e86\u7a00\u758f\u89c6\u56feCT\u91cd\u5efa\u7684\u6548\u679c\u4e0e\u7ecf\u6d4e\u6027\uff0c\u5e76\u53ef\u6cdb\u5316\u81f3\u5176\u4ed6\u8de8\u6a21\u6001\u8f6c\u6362\u4efb\u52a1\u3002", "keywords": "CT\u91cd\u5efa, \u6269\u6563\u6a21\u578b, \u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50, \u8de8\u6a21\u6001\u5b66\u4e60, \u7a00\u758f\u89c6\u56feX\u5c04\u7ebf"}}
{"id": "2507.11247", "pdf": "https://arxiv.org/pdf/2507.11247", "abs": "https://arxiv.org/abs/2507.11247", "authors": ["Veronika Shilova", "Emmanuel Malherbe", "Giovanni Palma", "Laurent Risser", "Jean-Michel Loubes"], "title": "Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Within a legal framework, fairness in datasets and models is typically\nassessed by dividing observations into predefined groups and then computing\nfairness measures (e.g., Disparate Impact or Equality of Odds with respect to\ngender). However, when sensitive attributes such as skin color are continuous,\ndividing into default groups may overlook or obscure the discrimination\nexperienced by certain minority subpopulations. To address this limitation, we\npropose a fairness-based grouping approach for continuous (possibly\nmultidimensional) sensitive attributes. By grouping data according to observed\nlevels of discrimination, our method identifies the partition that maximizes a\nnovel criterion based on inter-group variance in discrimination, thereby\nisolating the most critical subgroups.\n  We validate the proposed approach using multiple synthetic datasets and\ndemonstrate its robustness under changing population distributions - revealing\nhow discrimination is manifested within the space of sensitive attributes.\nFurthermore, we examine a specialized setting of monotonic fairness for the\ncase of skin color. Our empirical results on both CelebA and FFHQ, leveraging\nthe skin tone as predicted by an industrial proprietary algorithm, show that\nthe proposed segmentation uncovers more nuanced patterns of discrimination than\npreviously reported, and that these findings remain stable across datasets for\na given model. Finally, we leverage our grouping model for debiasing purpose,\naiming at predicting fair scores with group-by-group post-processing. The\nresults demonstrate that our approach improves fairness while having minimal\nimpact on accuracy, thus confirming our partition method and opening the door\nfor industrial deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u516c\u5e73\u6027\u7684\u8fde\u7eed\u654f\u611f\u5c5e\u6027\u5206\u7ec4\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u5316\u7ec4\u95f4\u6b67\u89c6\u5dee\u5f02\u7684\u65b0\u6807\u51c6\uff0c\u8bc6\u522b\u5173\u952e\u5b50\u7fa4\u4f53\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\u5c06\u6570\u636e\u5212\u5206\u4e3a\u9884\u5b9a\u4e49\u7ec4\u522b\uff0c\u65e0\u6cd5\u6355\u6349\u8fde\u7eed\u654f\u611f\u5c5e\u6027\uff08\u5982\u80a4\u8272\uff09\u7684\u7ec6\u5fae\u6b67\u89c6\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7075\u6d3b\u7684\u5206\u7ec4\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6b67\u89c6\u6c34\u5e73\u7684\u5206\u7ec4\u7b56\u7565\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6807\u51c6\uff08\u7ec4\u95f4\u6b67\u89c6\u5dee\u5f02\u6700\u5927\u5316\uff09\uff0c\u4ee5\u8bc6\u522b\u5173\u952e\u5b50\u7fa4\u4f53\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u6570\u636e\u96c6\uff08CelebA\u3001FFHQ\uff09\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u654f\u611f\u5c5e\u6027\u7a7a\u95f4\u4e2d\u7684\u6b67\u89c6\u6a21\u5f0f\uff0c\u5e76\u5728\u53bb\u504f\u5904\u7406\u4e2d\u63d0\u5347\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u8fde\u7eed\u654f\u611f\u5c5e\u6027\u573a\u666f\u4e0b\u4f18\u4e8e\u4f20\u7edf\u5206\u7ec4\u65b9\u5f0f\uff0c\u4e3a\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u3002", "keywords": "\u516c\u5e73\u6027\u3001\u8fde\u7eed\u654f\u611f\u5c5e\u6027\u3001\u5206\u7ec4\u65b9\u6cd5\u3001\u80a4\u8272\u6b67\u89c6\u3001\u53bb\u504f\u5904\u7406"}}
{"id": "2507.11153", "pdf": "https://arxiv.org/pdf/2507.11153", "abs": "https://arxiv.org/abs/2507.11153", "authors": ["Hongfei Ye", "Bin Chen", "Wenxi Liu", "Yu Zhang", "Zhao Li", "Dandan Ni", "Hongyang Chen"], "title": "Assessing Color Vision Test in Large Vision-language Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the widespread adoption of large vision-language models, the capacity\nfor color vision in these models is crucial. However, the color vision\nabilities of large visual-language models have not yet been thoroughly\nexplored. To address this gap, we define a color vision testing task for large\nvision-language models and construct a dataset \\footnote{Anonymous Github\nShowing some of the data\nhttps://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers\nmultiple categories of test questions and tasks of varying difficulty levels.\nFurthermore, we analyze the types of errors made by large vision-language\nmodels and propose fine-tuning strategies to enhance their performance in color\nvision tests.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8272\u5f69\u89c6\u89c9\u80fd\u529b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u7684\u9519\u8bef\u7c7b\u578b\u53ca\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u8272\u5f69\u89c6\u89c9\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5b9a\u4e49\u8272\u5f69\u89c6\u89c9\u6d4b\u8bd5\u4efb\u52a1\uff0c\u6784\u5efa\u591a\u7c7b\u522b\u3001\u591a\u96be\u5ea6\u7ea7\u522b\u7684\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u5e76\u5206\u6790\u6a21\u578b\u9519\u8bef\u7c7b\u578b\uff0c\u63d0\u51fa\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8272\u5f69\u89c6\u89c9\u6d4b\u8bd5\u4e2d\u5b58\u5728\u7279\u5b9a\u9519\u8bef\u6a21\u5f0f\uff0c\u901a\u8fc7\u5fae\u8c03\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8bba\u6587\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u8272\u5f69\u89c6\u89c9\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u548c\u5de5\u5177\u3002", "keywords": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b, \u8272\u5f69\u89c6\u89c9, \u6d4b\u8bd5\u6570\u636e\u96c6, \u5fae\u8c03\u7b56\u7565"}}
{"id": "2507.11366", "pdf": "https://arxiv.org/pdf/2507.11366", "abs": "https://arxiv.org/abs/2507.11366", "authors": ["Taemin Kim", "James P. Bailey"], "title": "A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent", "categories": ["cs.GT", "cs.LG", "90C47, 91A05, 91A26, 68Q32"], "comment": null, "summary": "We study online optimization methods for zero-sum games, a fundamental\nproblem in adversarial learning in machine learning, economics, and many other\ndomains. Traditional methods approximate Nash equilibria (NE) using either\nregret-based methods (time-average convergence) or contraction-map-based\nmethods (last-iterate convergence). We propose a new method based on\nHamiltonian dynamics in physics and prove that it can characterize the set of\nNE in a finite (linear) number of iterations of alternating gradient descent in\nthe unbounded setting, modulo degeneracy, a first in online optimization.\nUnlike standard methods for computing NE, our proposed approach can be\nparallelized and works with arbitrary learning rates, both firsts in\nalgorithmic game theory. Experimentally, we support our results by showing our\napproach drastically outperforms standard methods.", "AI": {"tldr": "\u7814\u7a76\u96f6\u548c\u535a\u5f08\u7684\u5728\u7ebf\u4f18\u5316\u65b9\u6cd5\uff0c\u63d0\u51fa\u57fa\u4e8e\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u65b0\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u80fd\u5728\u7ebf\u6027\u8fed\u4ee3\u6b21\u6570\u5185\u627e\u5230\u7eb3\u4ec0\u5747\u8861\uff0c\u4e14\u652f\u6301\u5e76\u884c\u5316\u4e0e\u4efb\u610f\u5b66\u4e60\u7387\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u96f6\u548c\u535a\u5f08\u4e2d\u8981\u4e48\u57fa\u4e8e\u9057\u61be\uff08\u65f6\u95f4\u5e73\u5747\u6536\u655b\uff09\uff0c\u8981\u4e48\u57fa\u4e8e\u6536\u7f29\u6620\u5c04\uff08\u6700\u540e\u4e00\u6b21\u8fed\u4ee3\u6536\u655b\uff09\uff0c\u9700\u8981\u6539\u8fdb\u6548\u7387\u4e0e\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d\uff0c\u8bc1\u660e\u5176\u80fd\u5728\u65e0\u754c\u8bbe\u5b9a\u4e0b\u7ebf\u6027\u8fed\u4ee3\u6b21\u6570\u5185\u627e\u5230\u7eb3\u4ec0\u5747\u8861\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u652f\u6301\u5e76\u884c\u5316\u548c\u4efb\u610f\u5b66\u4e60\u7387\u3002", "conclusion": "\u57fa\u4e8e\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\u5728\u96f6\u548c\u535a\u5f08\u4e2d\u9ad8\u6548\u4e14\u7075\u6d3b\uff0c\u662f\u7b97\u6cd5\u535a\u5f08\u8bba\u4e2d\u7684\u9996\u6b21\u7a81\u7834\u3002", "keywords": "\u96f6\u548c\u535a\u5f08\uff1b\u5728\u7ebf\u4f18\u5316\uff1b\u7eb3\u4ec0\u5747\u8861\uff1b\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\uff1b\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d"}}
{"id": "2507.11381", "pdf": "https://arxiv.org/pdf/2507.11381", "abs": "https://arxiv.org/abs/2507.11381", "authors": ["Rom Gutman", "Shimon Sheiba", "Omer Noy Klien", "Naama Dekel Bird", "Amit Gruber", "Doron Aronson", "Oren Caspi", "Uri Shalit"], "title": "From Observational Data to Clinical Recommendations: A Causal Framework for Estimating Patient-level Treatment Effects and Learning Policies", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "We propose a framework for building patient-specific treatment recommendation\nmodels, building on the large recent literature on learning patient-level\ncausal models and inspired by the target trial paradigm of Hernan and Robins.\nWe focus on safety and validity, including the crucial issue of causal\nidentification when using observational data. We do not provide a specific\nmodel, but rather a way to integrate existing methods and know-how into a\npractical pipeline. We further provide a real world use-case of treatment\noptimization for patients with heart failure who develop acute kidney injury\nduring hospitalization. The results suggest our pipeline can improve patient\noutcomes over the current treatment regime.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u9488\u5bf9\u60a3\u8005\u4e2a\u4f53\u5316\u6cbb\u7597\u63a8\u8350\u7684\u6846\u67b6\uff0c\u5f3a\u8c03\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u5e76\u6574\u5408\u73b0\u6709\u65b9\u6cd5\u5230\u5b9e\u9645\u6d41\u7a0b\u4e2d\u3002", "motivation": "\u53d7Hernan\u548cRobins\u7684\u76ee\u6807\u8bd5\u9a8c\u8303\u5f0f\u542f\u53d1\uff0c\u89e3\u51b3\u89c2\u5bdf\u6027\u6570\u636e\u4e2d\u7684\u56e0\u679c\u8bc6\u522b\u95ee\u9898\uff0c\u65e8\u5728\u63d0\u5347\u60a3\u8005\u6cbb\u7597\u6548\u679c\u3002", "method": "\u6574\u5408\u73b0\u6709\u60a3\u8005\u7ea7\u56e0\u679c\u6a21\u578b\u65b9\u6cd5\uff0c\u6784\u5efa\u5b9e\u9645\u63a8\u8350\u6d41\u7a0b\uff0c\u4e0d\u63d0\u51fa\u65b0\u6a21\u578b\u3002", "result": "\u5728\u5fc3\u529b\u8870\u7aed\u5408\u5e76\u6025\u6027\u80be\u635f\u4f24\u60a3\u8005\u7684\u6cbb\u7597\u4f18\u5316\u6848\u4f8b\u4e2d\uff0c\u6d41\u7a0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6cbb\u7597\u65b9\u6848\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u6709\u6548\u6574\u5408\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u5347\u60a3\u8005\u6cbb\u7597\u6548\u679c\u3002", "keywords": "\u4e2a\u4f53\u5316\u6cbb\u7597,\u56e0\u679c\u6a21\u578b,\u89c2\u5bdf\u6027\u6570\u636e,\u6cbb\u7597\u4f18\u5316"}}
{"id": "2507.11385", "pdf": "https://arxiv.org/pdf/2507.11385", "abs": "https://arxiv.org/abs/2507.11385", "authors": ["George D. Pasparakis", "Ioannis A. Kougioumtzoglou", "Michael D. Shields"], "title": "Joint space-time wind field data extrapolation and uncertainty quantification using nonparametric Bayesian dictionary learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A methodology is developed, based on nonparametric Bayesian dictionary\nlearning, for joint space-time wind field data extrapolation and estimation of\nrelated statistics by relying on limited/incomplete measurements. Specifically,\nutilizing sparse/incomplete measured data, a time-dependent optimization\nproblem is formulated for determining the expansion coefficients of an\nassociated low-dimensional representation of the stochastic wind field.\nCompared to an alternative, standard, compressive sampling treatment of the\nproblem, the developed methodology exhibits the following advantages. First,\nthe Bayesian formulation enables also the quantification of the uncertainty in\nthe estimates. Second, the requirement in standard CS-based applications for an\na priori selection of the expansion basis is circumvented. Instead, this is\ndone herein in an adaptive manner based on the acquired data. Overall, the\nmethodology exhibits enhanced extrapolation accuracy, even in cases of\nhigh-dimensional data of arbitrary form, and of relatively large extrapolation\ndistances. Thus, it can be used, potentially, in a wide range of wind\nengineering applications where various constraints dictate the use of a limited\nnumber of sensors. The efficacy of the methodology is demonstrated by\nconsidering two case studies. The first relates to the extrapolation of\nsimulated wind velocity records consistent with a prescribed joint\nwavenumber-frequency power spectral density in a three-dimensional domain (2D\nand time). The second pertains to the extrapolation of four-dimensional (3D and\ntime) boundary layer wind tunnel experimental data that exhibit significant\nspatial variability and non-Gaussian characteristics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u975e\u53c2\u6570\u8d1d\u53f6\u65af\u5b57\u5178\u5b66\u4e60\u7684\u8054\u5408\u65f6\u7a7a\u98ce\u573a\u6570\u636e\u5916\u63a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u6709\u9650/\u4e0d\u5b8c\u6574\u6d4b\u91cf\u6570\u636e\u4f30\u8ba1\u76f8\u5173\u7edf\u8ba1\u91cf\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f/\u4e0d\u5b8c\u6574\u6d4b\u91cf\u6570\u636e\uff0c\u89e3\u51b3\u98ce\u573a\u6570\u636e\u5916\u63a8\u548c\u7edf\u8ba1\u91cf\u4f30\u8ba1\u95ee\u9898\uff0c\u5f25\u8865\u4f20\u7edf\u538b\u7f29\u611f\u77e5\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u57fa\u4e8e\u975e\u53c2\u6570\u8d1d\u53f6\u65af\u5b57\u5178\u5b66\u4e60\uff0c\u81ea\u9002\u5e94\u786e\u5b9a\u4f4e\u7ef4\u8868\u793a\u7cfb\u6570\uff0c\u5e76\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u9884\u5148\u9009\u62e9\u57fa\u51fd\u6570\u7684\u95ee\u9898\u3002", "result": "\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u5916\u63a8\u7cbe\u5ea6\uff0c\u5e76\u80fd\u5904\u7406\u9ad8\u7ef4\u548c\u975e\u9ad8\u65af\u6570\u636e\uff0c\u9002\u7528\u4e8e\u4f20\u611f\u5668\u6570\u91cf\u6709\u9650\u7684\u573a\u666f\u3002\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u57fa\u9009\u62e9\u548c\u4e0d\u5b8c\u6574\u6d4b\u91cf\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u98ce\u573a\u6570\u636e\u5916\u63a8\u7684\u51c6\u786e\u6027\u548c\u9002\u7528\u6027\u3002", "keywords": "\u975e\u53c2\u6570\u8d1d\u53f6\u65af,\u5b57\u5178\u5b66\u4e60,\u98ce\u573a\u6570\u636e\u5916\u63a8,\u538b\u7f29\u611f\u77e5"}}
{"id": "2507.11387", "pdf": "https://arxiv.org/pdf/2507.11387", "abs": "https://arxiv.org/abs/2507.11387", "authors": ["Gennaro Auricchio", "Giovanni Brigati", "Paolo Giudici", "Giuseppe Toscani"], "title": "From Kinetic Theory to AI: a Rediscovery of High-Dimensional Divergences and Their Properties", "categories": ["math-ph", "cs.AI", "cs.LG", "cs.MA", "math.MP", "35B40, 35L60, 35K55, 35Q70, 35Q91, 35Q92"], "comment": null, "summary": "Selecting an appropriate divergence measure is a critical aspect of machine\nlearning, as it directly impacts model performance. Among the most widely used,\nwe find the Kullback-Leibler (KL) divergence, originally introduced in kinetic\ntheory as a measure of relative entropy between probability distributions. Just\nas in machine learning, the ability to quantify the proximity of probability\ndistributions plays a central role in kinetic theory. In this paper, we present\na comparative review of divergence measures rooted in kinetic theory,\nhighlighting their theoretical foundations and exploring their potential\napplications in machine learning and artificial intelligence.", "AI": {"tldr": "\u6bd4\u8f83\u673a\u5668\u5b66\u4e60\u4e0e\u52a8\u529b\u5b66\u7406\u8bba\u4e2d\u7684\u6563\u5ea6\u5ea6\u91cf\uff0c\u63a2\u8ba8\u5176\u7406\u8bba\u57fa\u7840\u53ca\u5176\u5728AI\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u9009\u62e9\u5408\u9002\u7684\u6563\u5ea6\u5ea6\u91cf\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u9700\u501f\u9274\u52a8\u529b\u5b66\u7406\u8bba\u4e2d\u7684\u76f8\u5173\u65b9\u6cd5\u3002", "method": "\u5bf9\u52a8\u529b\u5b66\u7406\u8bba\u4e2d\u7684\u6563\u5ea6\u5ea6\u91cf\u8fdb\u884c\u4e86\u6bd4\u8f83\u6027\u7efc\u8ff0\u3002", "result": "\u603b\u7ed3\u4e86\u4e0d\u540c\u6563\u5ea6\u5ea6\u91cf\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u5728\u673a\u5668\u5b66\u4e60\u548cAI\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002", "conclusion": "\u52a8\u529b\u5b66\u7406\u8bba\u4e2d\u7684\u6563\u5ea6\u5ea6\u91cf\u53ef\u4e3a\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u65b0\u7684\u5de5\u5177\u548c\u89c6\u89d2\u3002", "keywords": "Kullback-Leibler\u6563\u5ea6, \u673a\u5668\u5b66\u4e60, \u52a8\u529b\u5b66\u7406\u8bba, \u6563\u5ea6\u5ea6\u91cf, \u4eba\u5de5\u667a\u80fd"}}
{"id": "2507.11401", "pdf": "https://arxiv.org/pdf/2507.11401", "abs": "https://arxiv.org/abs/2507.11401", "authors": ["Mehri Mehrnia", "Mohammed S. M. Elbaz"], "title": "Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI", "categories": ["quant-ph", "cs.CV", "cs.ET", "cs.LG"], "comment": "Accepted for publication at IEEE International Conference on Quantum\n  Computing and Engineering (QCE) 2025", "summary": "Efficient entanglement strategies are essential for advancing variational\nquantum circuits (VQCs) for quantum machine learning (QML). However, most\ncurrent approaches use fixed entanglement topologies that are not adaptive to\ntask requirements, limiting potential gains over classical models. We introduce\na novel stochastic entanglement configuration method that systematically\ngenerates diverse entanglement topologies to identify a subspace of\nconstructive entanglement configurations, defined as entanglement topologies\nthat boost hybrid model performance (e.g., classification accuracy) beyond\nclassical baselines. Each configuration is encoded as a stochastic binary\nmatrix, denoting directed entanglement between qubits. This enables scalable\nexploration of the hyperspace of candidate entanglement topologies using\nentanglement density and per-qubit constraints as key metrics. We define\nunconstrained and constrained sampling modes, controlling entanglement per\nqubit. Using our method, 400 stochastic configurations were generated and\nevaluated in a hybrid QML for cardiac MRI disease classification. We identified\n64 (16%) novel constructive entanglement configurations that consistently\noutperformed the classical baseline. Ensemble aggregation of top-performing\nconfigurations achieved ~0.92 classification accuracy, exceeding the classical\nmodel (~0.87) by over 5%. Compared to four conventional topologies (ring,\nnearest neighbor, no entanglement, fully entangled), none surpassed the\nclassical baseline (maximum accuracy ~0.82), while our configurations delivered\nup to ~20% higher accuracy. Thus, highlighting the robustness and\ngeneralizability of the identified constructive entanglements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u968f\u673a\u7ea0\u7f20\u914d\u7f6e\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u53d8\u5206\u91cf\u5b50\u7535\u8def\u7684\u6027\u80fd\uff0c\u5728\u5fc3\u810fMRI\u75be\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u56fa\u5b9a\u7ea0\u7f20\u62d3\u6251\u65b9\u6cd5\u4e0d\u9002\u5e94\u4efb\u52a1\u9700\u6c42\uff0c\u9650\u5236\u4e86\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6f5c\u529b\u3002", "method": "\u91c7\u7528\u968f\u673a\u4e8c\u8fdb\u5236\u77e9\u9635\u7f16\u7801\u7ea0\u7f20\u62d3\u6251\uff0c\u901a\u8fc7\u7ea0\u7f20\u5bc6\u5ea6\u548c\u91cf\u5b50\u4f4d\u7ea6\u675f\u8fdb\u884c\u53ef\u6269\u5c55\u63a2\u7d22\u3002", "result": "\u751f\u621064\u79cd\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\u7684\u7ea0\u7f20\u914d\u7f6e\uff0c\u96c6\u6210\u540e\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53475%\u3002", "conclusion": "\u968f\u673a\u7ea0\u7f20\u914d\u7f6e\u65b9\u6cd5\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "keywords": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff0c\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff0c\u7ea0\u7f20\u62d3\u6251\uff0c\u968f\u673a\u914d\u7f6e\uff0c\u5206\u7c7b\u51c6\u786e\u7387"}}
{"id": "2507.11210", "pdf": "https://arxiv.org/pdf/2507.11210", "abs": "https://arxiv.org/abs/2507.11210", "authors": ["Rushia Harada", "Yuken Kimura", "Keito Inoshita"], "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Well-being in family settings involves subtle psychological dynamics that\nconventional metrics often overlook. In particular, unconscious parental\nexpectations, termed ideal parent bias, can suppress children's emotional\nexpression and autonomy. This suppression, referred to as suppressed emotion,\noften stems from well-meaning but value-driven communication, which is\ndifficult to detect or address from outside the family. Focusing on these\nlatent dynamics, this study explores Large Language Model (LLM)-based support\nfor psychologically safe family communication. We constructed a Japanese\nparent-child dialogue corpus of 30 scenarios, each annotated with metadata on\nideal parent bias and suppressed emotion. Based on this corpus, we developed a\nRole-Playing LLM-based multi-agent dialogue support framework that analyzes\ndialogue and generates feedback. Specialized agents detect suppressed emotion,\ndescribe implicit ideal parent bias in parental speech, and infer contextual\nattributes such as the child's age and background. A meta-agent compiles these\noutputs into a structured report, which is then passed to five selected expert\nagents. These agents collaboratively generate empathetic and actionable\nfeedback through a structured four-step discussion process. Experiments show\nthat the system can detect categories of suppressed emotion with moderate\naccuracy and produce feedback rated highly in empathy and practicality.\nMoreover, simulated follow-up dialogues incorporating this feedback exhibited\nsigns of improved emotional expression and mutual understanding, suggesting the\nframework's potential in supporting positive transformation in family\ninteractions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86LLM\u6280\u672f\u5728\u5bb6\u5ead\u5fc3\u7406\u5b89\u5168\u6c9f\u901a\u4e2d\u7684\u5e94\u7528\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5bf9\u8bdd\u652f\u6301\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u538b\u6291\u60c5\u7eea\u548c\u7406\u60f3\u7236\u6bcd\u504f\u89c1\uff0c\u5e76\u63d0\u4f9b\u5b9e\u7528\u53cd\u9988\u3002", "motivation": "\u4f20\u7edf\u6307\u6807\u5e38\u5ffd\u89c6\u5bb6\u5ead\u4e2d\u7684\u5fae\u5999\u5fc3\u7406\u52a8\u6001\uff0c\u5c24\u5176\u662f\u7406\u60f3\u7236\u6bcd\u504f\u89c1\u5bf9\u513f\u7ae5\u60c5\u7eea\u8868\u8fbe\u548c\u81ea\u4e3b\u6027\u7684\u538b\u5236\u3002", "method": "\u6784\u5efa\u4e8630\u4e2a\u65e5\u8bed\u4eb2\u5b50\u5bf9\u8bdd\u573a\u666f\u7684\u8bed\u6599\u5e93\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8eLLM\u7684\u89d2\u8272\u626e\u6f14\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u68c0\u6d4b\u538b\u6291\u60c5\u7eea\u548c\u504f\u89c1\uff0c\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\u548c\u53cd\u9988\u3002", "result": "\u7cfb\u7edf\u80fd\u9002\u5ea6\u51c6\u786e\u5730\u68c0\u6d4b\u538b\u6291\u60c5\u7eea\uff0c\u751f\u6210\u7684\u53cd\u9988\u5728\u540c\u7406\u5fc3\u548c\u5b9e\u7528\u6027\u4e0a\u83b7\u5f97\u9ad8\u8bc4\u4ef7\uff0c\u6a21\u62df\u540e\u7eed\u5bf9\u8bdd\u663e\u793a\u60c5\u7eea\u8868\u8fbe\u548c\u76f8\u4e92\u7406\u89e3\u7684\u6539\u5584\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u652f\u6301\u5bb6\u5ead\u4e92\u52a8\u79ef\u6781\u8f6c\u53d8\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002", "keywords": "LLM, \u5bb6\u5ead\u6c9f\u901a, \u538b\u6291\u60c5\u7eea, \u7406\u60f3\u7236\u6bcd\u504f\u89c1, \u591a\u667a\u80fd\u4f53\u7cfb\u7edf"}}
{"id": "2507.11419", "pdf": "https://arxiv.org/pdf/2507.11419", "abs": "https://arxiv.org/abs/2507.11419", "authors": ["Anna Lunghi", "Matteo Castiglioni", "Alberto Marchesi"], "title": "Better Regret Rates in Bilateral Trade via Sublinear Budget Violation", "categories": ["cs.GT", "cs.LG"], "comment": null, "summary": "Bilateral trade is a central problem in algorithmic economics, and recent\nwork has explored how to design trading mechanisms using no-regret learning\nalgorithms. However, no-regret learning is impossible when budget balance has\nto be enforced at each time step. Bernasconi et al. [Ber+24] show how this\nimpossibility can be circumvented by relaxing the budget balance constraint to\nhold only globally over all time steps. In particular, they design an algorithm\nachieving regret of the order of $\\tilde O(T^{3/4})$ and provide a lower bound\nof $\\Omega(T^{5/7})$.\n  In this work, we interpolate between these two extremes by studying how the\noptimal regret rate varies with the allowed violation of the global budget\nbalance constraint. Specifically, we design an algorithm that, by violating the\nconstraint by at most $T^{\\beta}$ for any given $\\beta \\in [\\frac{3}{4},\n\\frac{6}{7}]$, attains regret $\\tilde O(T^{1 - \\beta/3})$. We complement this\nresult with a matching lower bound, thus fully characterizing the trade-off\nbetween regret and budget violation. Our results show that both the $\\tilde\nO(T^{3/4})$ upper bound in the global budget balance case and the\n$\\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation\nobtained by Bernasconi et al. [Ber+24] are tight.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53cc\u8fb9\u8d38\u6613\u4e2d\u9884\u7b97\u5e73\u8861\u7ea6\u675f\u7684\u677e\u5f1b\u4e0e\u5b66\u4e60\u7b97\u6cd5\u9057\u61be\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b97\u6cd5\uff0c\u901a\u8fc7\u5141\u8bb8\u9884\u7b97\u8fdd\u53cd\uff0c\u5b9e\u73b0\u4e86\u9057\u61be\u4e0e\u8fdd\u53cd\u7a0b\u5ea6\u7684\u6700\u4f18\u6743\u8861", "motivation": "\u89e3\u51b3\u53cc\u8fb9\u8d38\u6613\u4e2d\u9884\u7b97\u5e73\u8861\u7ea6\u675f\u4e0e\u5b66\u4e60\u7b97\u6cd5\u9057\u61be\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b97\u6cd5\uff0c\u5141\u8bb8\u9884\u7b97\u5e73\u8861\u7ea6\u675f\u7684\u8fdd\u53cd\u7a0b\u5ea6\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u53d8\u5316\uff0c\u8fdb\u800c\u4f18\u5316\u9057\u61be\u7387", "result": "\u7b97\u6cd5\u5728\u9884\u7b97\u8fdd\u53cd\u7a0b\u5ea6\u4e3aT^\u03b2\u65f6\uff0c\u9057\u61be\u7387\u4e3aO(T^(1-\u03b2/3))\uff0c\u5e76\u7ed9\u51fa\u4e86\u5339\u914d\u7684\u4e0b\u754c", "conclusion": "\u6587\u7ae0\u786e\u5b9a\u4e86\u9884\u7b97\u8fdd\u53cd\u4e0e\u9057\u61be\u7684\u6700\u4f18\u6743\u8861\u5173\u7cfb\uff0c\u8bc1\u660e\u4e86Bernasconi\u7b49\u4eba\u7684\u4e0a\u4e0b\u754c\u7ed3\u679c\u7684\u7d27\u6027", "keywords": "\u53cc\u8fb9\u8d38\u6613, \u9884\u7b97\u5e73\u8861, \u5b66\u4e60\u7b97\u6cd5, \u9057\u61be, \u6743\u8861"}}
{"id": "2507.11267", "pdf": "https://arxiv.org/pdf/2507.11267", "abs": "https://arxiv.org/abs/2507.11267", "authors": ["Aon Safdar", "Usman Akram", "Waseem Anwar", "Basit Malik", "Mian Ibad Ali"], "title": "YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery", "categories": ["cs.CV", "cs.AI"], "comment": "Published in 25th Irish Machine Vision and Image Processing Conf.,\n  Galway, Ireland, Aug 30-Sep 1 2023 Also available at\n  https://doi.org/10.5281/zenodo.8264062", "summary": "Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared\n(TI) imagery in the defense and surveillance domain is a challenging computer\nvision (CV) task in comparison to the commercial autonomous vehicle perception\ndomain. Limited datasets, peculiar domain-specific and TI modality-specific\nchallenges, i.e., limited hardware, scale invariance issues due to greater\ndistances, deliberate occlusion by tactical vehicles, lower sensor resolution\nand resultant lack of structural information in targets, effects of weather,\ntemperature, and time of day variations, and varying target to clutter ratios\nall result in increased intra-class variability and higher inter-class\nsimilarity, making accurate real-time ATR a challenging CV task. Resultantly,\ncontemporary state-of-the-art (SOTA) deep learning architectures underperform\nin the ATR domain. We propose a modified anchor-based single-stage detector,\ncalled YOLOatr, based on a modified YOLOv5s, with optimal modifications to the\ndetection heads, feature fusion in the neck, and a custom augmentation profile.\nWe evaluate the performance of our proposed model on a comprehensive DSIAC MWIR\ndataset for real-time ATR over both correlated and decorrelated testing\nprotocols. The results demonstrate that our proposed model achieves\nstate-of-the-art ATR performance of up to 99.6%.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5355\u9636\u6bb5\u68c0\u6d4b\u5668YOLOatr\uff0c\u7528\u4e8e\u70ed\u7ea2\u5916\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\u548c\u8bc6\u522b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u5728\u56fd\u9632\u548c\u76d1\u63a7\u9886\u57df\u7684\u7f3a\u9677\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe99.6%\u7684\u8bc6\u522b\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u70ed\u7ea2\u5916\u56fe\u50cf\u5728\u56fd\u9632\u548c\u76d1\u63a7\u9886\u57df\u7684\u72ec\u7279\u6311\u6218\uff08\u5982\u786c\u4ef6\u9650\u5236\u3001\u5929\u6c14\u5f71\u54cd\u7b49\uff09\uff0c\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728\u8fd9\u4e00\u9886\u57df\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eYOLOv5s\u6539\u8fdb\u7684YOLOatr\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u5316\u68c0\u6d4b\u5934\u3001\u7279\u5f81\u878d\u5408\u548c\u81ea\u5b9a\u4e49\u6570\u636e\u589e\u5f3a\uff0c\u63d0\u5347\u4e86\u76ee\u6807\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "result": "\u5728DSIAC MWIR\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cYOLOatr\u5728\u76f8\u5173\u548c\u975e\u76f8\u5173\u6d4b\u8bd5\u534f\u8bae\u4e0b\u5747\u8fbe\u5230\u4e8699.6%\u7684\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "YOLOatr\u89e3\u51b3\u4e86\u70ed\u7ea2\u5916\u56fe\u50cf\u4e2d\u7684\u76ee\u6807\u8bc6\u522b\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u9ad8\u6027\u80fd\u68c0\u6d4b\uff0c\u4e3a\u56fd\u9632\u548c\u76d1\u63a7\u9886\u57df\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u76ee\u6807\u68c0\u6d4b,\u70ed\u7ea2\u5916\u56fe\u50cf,YOLOatr,\u6df1\u5ea6\u5b66\u4e60,\u56fd\u9632\u76d1\u63a7"}}
{"id": "2507.11430", "pdf": "https://arxiv.org/pdf/2507.11430", "abs": "https://arxiv.org/abs/2507.11430", "authors": ["Arnab Mukherjee", "Raju Halder", "Joydeep Chandra"], "title": "FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning", "categories": ["cs.DC", "cs.LG"], "comment": null, "summary": "Federated Learning (FL) has undergone significant development since its\ninception in 2016, advancing from basic algorithms to complex methodologies\ntailored to address diverse challenges and use cases. However, research and\nbenchmarking of novel FL techniques against a plethora of established\nstate-of-the-art solutions remain challenging. To streamline this process, we\nintroduce FLsim, a comprehensive FL simulation framework designed to meet the\ndiverse requirements of FL workflows in the literature. FLsim is characterized\nby its modularity, scalability, resource efficiency, and controlled\nreproducibility of experimental outcomes. Its easy to use interface allows\nusers to specify customized FL requirements through job configuration, which\nsupports: (a) customized data distributions, ranging from non-independent and\nidentically distributed (non-iid) data to independent and identically\ndistributed (iid) data, (b) selection of local learning algorithms according to\nuser preferences, with complete agnosticism to ML libraries, (c) choice of\nnetwork topology illustrating communication patterns among nodes, (d)\ndefinition of model aggregation and consensus algorithms, and (e) pluggable\nblockchain support for enhanced robustness. Through a series of experimental\nevaluations, we demonstrate the effectiveness and versatility of FLsim in\nsimulating a diverse range of state-of-the-art FL experiments. We envisage that\nFLsim would mark a significant advancement in FL simulation frameworks,\noffering unprecedented flexibility and functionality for researchers and\npractitioners alike.", "AI": {"tldr": "FLsim\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u4eff\u771f\u6846\u67b6\uff0c\u65e8\u5728\u7b80\u5316\u8054\u90a6\u5b66\u4e60\u6280\u672f\u7684\u5b9e\u9a8c\u4e0e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5177\u6709\u9ad8\u5ea6\u7075\u6d3b\u6027\u548c\u5b9a\u5236\u5316\u529f\u80fd\u3002", "motivation": "\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u7814\u7a76\u4e2d\u5b9e\u9a8c\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u7684\u6311\u6218\uff0cFLsim\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u4e14\u7075\u6d3b\u7684\u4eff\u771f\u6846\u67b6\uff0c\u652f\u6301\u591a\u6837\u5316\u9700\u6c42\u7684\u8054\u90a6\u5b66\u4e60\u5de5\u4f5c\u6d41\u3002", "method": "FLsim\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u7528\u6237\u81ea\u5b9a\u4e49\u6570\u636e\u5206\u5e03\u3001\u5b66\u4e60\u7b97\u6cd5\u3001\u7f51\u7edc\u62d3\u6251\u3001\u6a21\u578b\u805a\u5408\u53ca\u533a\u5757\u94fe\u652f\u6301\uff0c\u786e\u4fdd\u5b9e\u9a8c\u7684\u53ef\u63a7\u590d\u73b0\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eFLsim\u80fd\u6709\u6548\u6a21\u62df\u591a\u79cd\u5148\u8fdb\u8054\u90a6\u5b66\u4e60\u5b9e\u9a8c\uff0c\u5c55\u793a\u5176\u9ad8\u6548\u6027\u548c\u591a\u529f\u80fd\u6027\u3002", "conclusion": "FLsim\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u7075\u6d3b\u6027\u548c\u529f\u80fd\u6027\uff0c\u6807\u5fd7\u7740\u8054\u90a6\u5b66\u4e60\u4eff\u771f\u6846\u67b6\u7684\u91cd\u8981\u8fdb\u5c55\u3002", "keywords": "\u8054\u90a6\u5b66\u4e60, \u4eff\u771f\u6846\u67b6, \u6a21\u5757\u5316\u8bbe\u8ba1, \u8d44\u6e90\u6548\u7387, \u5b9a\u5236\u5316"}}
{"id": "2507.11441", "pdf": "https://arxiv.org/pdf/2507.11441", "abs": "https://arxiv.org/abs/2507.11441", "authors": ["Kaif Shaikh", "Antoni Kowalczuk", "Franziska Boenisch", "Adam Dziedzic"], "title": "Implementing Adaptations for Vision AutoRegressive Model", "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.4.8; I.2.10"], "comment": "Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025", "summary": "Vision AutoRegressive model (VAR) was recently introduced as an alternative\nto Diffusion Models (DMs) in image generation domain. In this work we focus on\nits adaptations, which aim to fine-tune pre-trained models to perform specific\ndownstream tasks, like medical data generation. While for DMs there exist many\ntechniques, adaptations for VAR remain underexplored. Similarly, differentially\nprivate (DP) adaptations-ones that aim to preserve privacy of the adaptation\ndata-have been extensively studied for DMs, while VAR lacks such solutions. In\nour work, we implement and benchmark many strategies for VAR, and compare them\nto state-of-the-art DM adaptation strategies. We observe that VAR outperforms\nDMs for non-DP adaptations, however, the performance of DP suffers, which\nnecessitates further research in private adaptations for VAR. Code is available\nat https://github.com/sprintml/finetuning_var_dp.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Vision AutoRegressive model\uff08VAR\uff09\u5728\u56fe\u50cf\u751f\u6210\u9886\u57df\u7684\u9002\u5e94\u6027\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u533b\u5b66\u6570\u636e\u751f\u6210\u7684\u4e0b\u6e38\u4efb\u52a1\u3002\u540c\u65f6\u6bd4\u8f83\u4e86VAR\u548cDiffusion Models\uff08DMs\uff09\u7684\u79c1\u4eba\u9002\u5e94\u6027\uff0c\u53d1\u73b0VAR\u5728\u975e\u79c1\u4eba\u9002\u5e94\u6027\u4e0a\u8868\u73b0\u4f18\u4e8eDMs\uff0c\u4f46\u5728\u79c1\u4eba\u9002\u5e94\u6027\u4e0a\u4ecd\u9700\u6539\u8fdb\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22VAR\u6a21\u578b\u7684\u9002\u5e94\u6027\uff0c\u5c24\u5176\u662f\u5728\u533b\u5b66\u6570\u636e\u751f\u6210\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u7684\u8868\u73b0\uff0c\u586b\u8865VAR\u5728\u79c1\u4eba\u9002\u5e94\u6027\u4e0a\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5b9e\u73b0\u548c\u6d4b\u8bd5\u591a\u79cdVAR\u9002\u5e94\u6027\u7b56\u7565\uff0c\u5e76\u4e0eDM\u7684\u9002\u5e94\u6027\u7b56\u7565\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cVAR\u5728\u975e\u79c1\u4eba\u9002\u5e94\u6027\u4efb\u52a1\u4e0a\u4f18\u4e8eDMs\uff0c\u4f46\u5728\u79c1\u4eba\u9002\u5e94\u6027\u4e0a\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "conclusion": "VAR\u5728\u975e\u79c1\u4eba\u9002\u5e94\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728Differential Privacy\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002", "keywords": "VAR\uff1bDMs\uff1b\u56fe\u50cf\u751f\u6210\uff1b\u533b\u5b66\u6570\u636e\uff1b\u5dee\u5206\u9690\u79c1"}}
{"id": "2507.11325", "pdf": "https://arxiv.org/pdf/2507.11325", "abs": "https://arxiv.org/abs/2507.11325", "authors": ["Arefin Ittesafun Abian", "Ripon Kumar Debnath", "Md. Abdur Rahman", "Mohaimenul Azam Khan Raiaan", "Md Rafiqul Islam", "Asif Karim", "Reem E. Mohamed", "Sami Azam"], "title": "HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 figures. Will be submitted to IEEE Transactions on Radiation and\n  Plasma Medical Sciences", "summary": "Accurate liver and tumor segmentation on abdominal CT images is critical for\nreliable diagnosis and treatment planning, but remains challenging due to\ncomplex anatomical structures, variability in tumor appearance, and limited\nannotated data. To address these issues, we introduce Hyperbolic-convolutions\nAdaptive-temporal-attention with Neural-representation and Synaptic-plasticity\nNetwork (HANS-Net), a novel segmentation framework that synergistically\ncombines hyperbolic convolutions for hierarchical geometric representation, a\nwavelet-inspired decomposition module for multi-scale texture learning, a\nbiologically motivated synaptic plasticity mechanism for adaptive feature\nenhancement, and an implicit neural representation branch to model fine-grained\nand continuous anatomical boundaries. Additionally, we incorporate\nuncertainty-aware Monte Carlo dropout to quantify prediction confidence and\nlightweight temporal attention to improve inter-slice consistency without\nsacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate\nthat HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an\naverage symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap\nerror (VOE) of 11.91%. Furthermore, cross-dataset validation on the\n3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of\n1.525 mm, and VOE of 19.71%, indicating strong generalization across different\ndatasets. These results confirm the effectiveness and robustness of HANS-Net in\nproviding anatomically consistent, accurate, and confident liver and tumor\nsegmentation.", "AI": {"tldr": "HANS-Net\u662f\u4e00\u79cd\u65b0\u578b\u809d\u810f\u548c\u80bf\u7624\u5206\u5272\u6846\u67b6\uff0c\u7ed3\u5408\u53cc\u66f2\u5377\u79ef\u3001\u591a\u5c3a\u5ea6\u7eb9\u7406\u5b66\u4e60\u3001\u7a81\u89e6\u53ef\u5851\u6027\u673a\u5236\u548c\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u5206\u5272\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u7531\u4e8e\u809d\u810f\u548c\u80bf\u7624\u7684\u590d\u6742\u89e3\u5256\u7ed3\u6784\u3001\u5916\u89c2\u591a\u53d8\u6027\u548c\u6807\u6ce8\u6570\u636e\u6709\u9650\uff0c\u51c6\u786e\u5206\u5272\u5728CT\u56fe\u50cf\u4e2d\u5177\u6709\u6311\u6218\u6027\u3002", "method": "HANS-Net\u7ed3\u5408\u53cc\u66f2\u5377\u79ef\u3001\u5c0f\u6ce2\u5206\u89e3\u6a21\u5757\u3001\u7a81\u89e6\u53ef\u5851\u6027\u673a\u5236\u548c\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff0c\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u65f6\u95f4\u6ce8\u610f\u529b\u6a21\u5757\u3002", "result": "\u5728LiTS\u548c3D-IRCADb-01\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u523093.26%\u548c87.45%\u7684Dice\u5206\u6570\uff0c\u8868\u73b0\u4f18\u5f02\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u3002", "conclusion": "HANS-Net\u80fd\u591f\u63d0\u4f9b\u4e00\u81f4\u3001\u51c6\u786e\u4e14\u53ef\u9760\u7684\u809d\u810f\u548c\u80bf\u7624\u5206\u5272\uff0c\u5177\u6709\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "keywords": "\u809d\u810f\u5206\u5272,\u80bf\u7624\u5206\u5272,HANS-Net,CT\u56fe\u50cf,\u6df1\u5ea6\u5b66\u4e60"}}
{"id": "2507.11329", "pdf": "https://arxiv.org/pdf/2507.11329", "abs": "https://arxiv.org/abs/2507.11329", "authors": ["Hagar Shmuely", "Michal Rivlin", "Or Perlman"], "title": "Quantitative multi-metabolite imaging of Parkinson's disease using AI boosted molecular MRI", "categories": ["physics.med-ph", "cs.AI"], "comment": "This project was funded by the European Union (ERC, BabyMagnet,\n  project no. 101115639). Views and opinions expressed are, however, those of\n  the authors only and do not necessarily reflect those of the European Union\n  or the European Research Council. Neither the European Union nor the granting\n  authority can be held responsible for them", "summary": "Traditional approaches for molecular imaging of Parkinson's disease (PD) in\nvivo require radioactive isotopes, lengthy scan times, or deliver only low\nspatial resolution. Recent advances in saturation transfer-based PD magnetic\nresonance imaging (MRI) have provided biochemical insights, although the image\ncontrast is semi-quantitative and nonspecific. Here, we combined a rapid\nmolecular MRI acquisition paradigm with deep learning based reconstruction for\nmulti-metabolite quantification of glutamate, mobile proteins, semisolid, and\nmobile macromolecules in an acute MPTP\n(1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine) mouse model. The quantitative\nparameter maps are in general agreement with the histology and MR spectroscopy,\nand demonstrate that semisolid magnetization transfer (MT), amide, and\naliphatic relayed nuclear Overhauser effect (rNOE) proton volume fractions may\nserve as PD biomarkers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5feb\u901f\u5206\u5b50MRI\u91c7\u96c6\u4e0e\u6df1\u5ea6\u5b66\u4e60\u91cd\u5efa\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b9a\u91cf\u5206\u6790PD\u6a21\u578b\u4e2d\u7684\u591a\u79cd\u4ee3\u8c22\u7269\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3aPD\u751f\u7269\u6807\u5fd7\u7269\u7684\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edfPD\u5206\u5b50\u6210\u50cf\u65b9\u6cd5\u4f9d\u8d56\u653e\u5c04\u6027\u540c\u4f4d\u7d20\u3001\u626b\u63cf\u65f6\u95f4\u957f\u6216\u5206\u8fa8\u7387\u4f4e\uff0c\u800c\u65b0\u578bMRI\u6280\u672f\u867d\u80fd\u63d0\u4f9b\u751f\u5316\u4fe1\u606f\uff0c\u4f46\u5bf9\u6bd4\u5ea6\u534a\u5b9a\u91cf\u4e14\u975e\u7279\u5f02\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u3001\u5b9a\u91cf\u7684\u6210\u50cf\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u5feb\u901f\u5206\u5b50MRI\u91c7\u96c6\u4e0e\u6df1\u5ea6\u5b66\u4e60\u91cd\u5efa\u6280\u672f\uff0c\u5b9a\u91cf\u5206\u6790\u6025\u6027MPTP\u5c0f\u9f20\u6a21\u578b\u4e2d\u7684\u8c37\u6c28\u9178\u3001\u53ef\u79fb\u52a8\u86cb\u767d\u3001\u534a\u56fa\u4f53\u53ca\u53ef\u79fb\u52a8\u5927\u5206\u5b50\u3002", "result": "\u5b9a\u91cf\u53c2\u6570\u56fe\u4e0e\u7ec4\u7ec7\u5b66\u548cMR\u5149\u8c31\u5b66\u7ed3\u679c\u4e00\u81f4\uff0c\u8868\u660e\u534a\u56fa\u4f53\u78c1\u5316\u8f6c\u79fb\u3001\u9170\u80fa\u53ca\u8102\u80aa\u94fe\u63a5\u529b\u6838\u6b27\u6c83\u8c6a\u65af\u6548\u5e94\u8d28\u5b50\u4f53\u79ef\u5206\u6570\u53ef\u4f5c\u4e3aPD\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aPD\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5b9a\u91cf\u7684\u5206\u5b50\u6210\u50cf\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u9a8c\u8bc1\u4e86\u65b0\u578b\u751f\u7269\u6807\u5fd7\u7269\u7684\u6f5c\u529b\u3002", "keywords": "Parkinson disease, molecular MRI, deep learning, multi-metabolite quantification, biomarkers"}}
{"id": "2507.11506", "pdf": "https://arxiv.org/pdf/2507.11506", "abs": "https://arxiv.org/abs/2507.11506", "authors": ["Yiqi Liu", "Yuqi Xue", "Noelle Crawford", "Jilong Xue", "Jian Huang"], "title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques", "categories": ["cs.AR", "cs.DC", "cs.LG"], "comment": "This paper is accepted at the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO'25)", "summary": "To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development.", "AI": {"tldr": "Elk\u662f\u4e00\u4e2aDL\u7f16\u8bd1\u5668\u6846\u67b6\uff0c\u65e8\u5728\u6700\u5927\u5316ICCA\u82af\u7247\u7684\u6548\u7387\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8ba1\u7b97\u3001\u901a\u4fe1\u548cI/O\u6027\u80fd\u56e0\u7d20\uff0c\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3ICCA\u82af\u7247\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u56e0\u8ba1\u7b97\u3001\u901a\u4fe1\u548cI/O\u4e4b\u95f4\u7684\u6743\u8861\u800c\u96be\u4ee5\u9ad8\u6548\u5229\u7528\u7684\u95ee\u9898\u3002", "method": "Elk\u901a\u8fc7\u53ef\u914d\u7f6e\u53c2\u6570\u6784\u5efa\u6027\u80fd\u56e0\u7d20\u7684\u5168\u5c40\u6743\u8861\u7a7a\u95f4\uff0c\u91c7\u7528\u65b0\u7684\u5f52\u7eb3\u64cd\u4f5c\u8c03\u5ea6\u7b56\u7565\u548c\u6210\u672c\u611f\u77e5\u7684\u7247\u4e0a\u5185\u5b58\u5206\u914d\u7b97\u6cd5\uff0c\u751f\u6210\u5168\u5c40\u4f18\u5316\u7684\u6267\u884c\u8ba1\u5212\u3002", "result": "\u5728IPU-POD4\u82af\u7247\u4e0a\uff0cElk\u5b9e\u73b0\u4e86\u7406\u60f3\u6027\u80fd\u768494%\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728ICCA\u82af\u7247\u67b6\u6784\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "Elk\u6709\u6548\u4f18\u5316\u4e86ICCA\u82af\u7247\u7684\u6548\u7387\uff0c\u4e3a\u652f\u6301\u5927\u89c4\u6a21DL\u6a21\u578b\u548c\u65b0\u578bICCA\u82af\u7247\u5f00\u53d1\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002", "keywords": "\u6df1\u5ea6\u5b66\u4e60\uff0cAI\u82af\u7247\uff0c\u7f16\u8bd1\u5668\uff0c\u6027\u80fd\u4f18\u5316\uff0cICCA"}}
{"id": "2507.11522", "pdf": "https://arxiv.org/pdf/2507.11522", "abs": "https://arxiv.org/abs/2507.11522", "authors": ["Tariq Mehmood", "Hamza Ahmad", "Muhammad Haroon Shakeel", "Murtaza Taj"], "title": "CATVis: Context-Aware Thought Visualization", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MICCAI 2025. This is the submitted version prior to peer\n  review. The final Version of Record will appear in the MICCAI 2025\n  proceedings (Springer LNCS)", "summary": "EEG-based brain-computer interfaces (BCIs) have shown promise in various\napplications, such as motor imagery and cognitive state monitoring. However,\ndecoding visual representations from EEG signals remains a significant\nchallenge due to their complex and noisy nature. We thus propose a novel\n5-stage framework for decoding visual representations from EEG signals: (1) an\nEEG encoder for concept classification, (2) cross-modal alignment of EEG and\ntext embeddings in CLIP feature space, (3) caption refinement via re-ranking,\n(4) weighted interpolation of concept and caption embeddings for richer\nsemantics, and (5) image generation using a pre-trained Stable Diffusion model.\nWe enable context-aware EEG-to-image generation through cross-modal alignment\nand re-ranking. Experimental results demonstrate that our method generates\nhigh-quality images aligned with visual stimuli, outperforming SOTA approaches\nby 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and\nreducing Fr\\'echet Inception Distance by 36.61%, indicating superior semantic\nalignment and image quality.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a5\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u4eceEEG\u4fe1\u53f7\u89e3\u7801\u89c6\u89c9\u8868\u5f81\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u91cd\u6392\u540d\u63d0\u5347\u56fe\u50cf\u751f\u6210\u8d28\u91cf\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "EEG\u4fe1\u53f7\u89e3\u7801\u89c6\u89c9\u8868\u5f81\u7684\u590d\u6742\u6027\u548c\u566a\u58f0\u95ee\u9898\u662f\u4e00\u4e2a\u91cd\u8981\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u5347\u89e3\u7801\u7cbe\u5ea6\u548c\u56fe\u50cf\u751f\u6210\u8d28\u91cf\u3002", "method": "\u57fa\u4e8e5\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ecEEG\u7f16\u7801\u5668\u5206\u7c7b\u3001\u8de8\u6a21\u6001\u5bf9\u9f50\u3001\u6807\u9898\u91cd\u6392\u540d\u3001\u52a0\u6743\u63d2\u503c\u548c\u56fe\u50cf\u751f\u6210\uff0c\u7ed3\u5408Stable Diffusion\u6a21\u578b\u3002", "result": "\u751f\u6210\u7684\u56fe\u50cf\u8d28\u91cf\u9ad8\uff0c\u4e0e\u89c6\u89c9\u523a\u6fc0\u5bf9\u9f50\uff0c\u5206\u7c7b\u548c\u751f\u6210\u51c6\u786e\u7387\u5206\u522b\u63d0\u534713.43%\u548c15.21%\uff0cFID\u964d\u4f4e36.61%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u91cd\u6392\u540d\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684EEG\u5230\u56fe\u50cf\u751f\u6210\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "keywords": "EEG, \u8111\u673a\u63a5\u53e3, \u89c6\u89c9\u8868\u5f81, \u8de8\u6a21\u6001\u5bf9\u9f50, \u56fe\u50cf\u751f\u6210"}}
{"id": "2507.11331", "pdf": "https://arxiv.org/pdf/2507.11331", "abs": "https://arxiv.org/abs/2507.11331", "authors": ["Jiawei Lin", "Guokai Chen", "Yuanlong Li", "Thomas Bourgeat"], "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "categories": ["cs.AR", "cs.AI"], "comment": null, "summary": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u8109\u52a8\u9635\u5217\u67b6\u6784FSA\uff0c\u901a\u8fc7SystolicAttention\u8c03\u5ea6\u7b97\u6cd5\uff0c\u4f7fFlashAttention\u5b8c\u5168\u5728\u5355\u4e2a\u8109\u52a8\u9635\u5217\u4e2d\u8fd0\u884c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5229\u7528\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8109\u52a8\u9635\u5217\u7684\u52a0\u901f\u5668\u5728\u6267\u884cFlashAttention\u65f6\u9762\u4e34\u4f4e\u5229\u7528\u7387\u95ee\u9898\uff0c\u4e3b\u8981\u7531\u4e8e\u9891\u7e41\u7684\u6570\u636e\u4ea4\u6362\u548c\u975e\u77e9\u9635\u8fd0\u7b97\u7684\u4e0d\u9002\u914d\u3002", "method": "\u63d0\u51faFSA\u67b6\u6784\u548cSystolicAttention\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5c06FlashAttention\u64cd\u4f5c\u6620\u5c04\u5230\u8109\u52a8\u9635\u5217\u4e0a\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u5143\u7d20\u7ea7\u91cd\u53e0\u3002", "result": "FSA\u5728\u6ce8\u610f\u529bFLOPs/s\u5229\u7528\u7387\u4e0a\u5206\u522b\u6bd4AWS NeuronCore-v2\u548cGoogle TPUv5e\u9ad8\u51fa1.77\u500d\u548c4.83\u500d\uff0c\u9762\u79ef\u5f00\u9500\u4ec5\u7ea610%\u3002", "conclusion": "FSA\u901a\u8fc7\u4f18\u5316\u8109\u52a8\u9635\u5217\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86FlashAttention\u7684\u6267\u884c\u6548\u7387\uff0c\u4e3aTransformer\u6a21\u578b\u7684\u9ad8\u6548\u52a0\u901f\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002", "keywords": "Transformer, FlashAttention, \u8109\u52a8\u9635\u5217, \u8c03\u5ea6\u7b97\u6cd5, \u6027\u80fd\u4f18\u5316"}}
{"id": "2507.11535", "pdf": "https://arxiv.org/pdf/2507.11535", "abs": "https://arxiv.org/abs/2507.11535", "authors": ["Andrey Bryutkin", "Matthew E. Levine", "I\u00f1igo Urteaga", "Youssef Marzouk"], "title": "Canonical Bayesian Linear System Identification", "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY", "stat.CO"], "comment": "46 pages, 9 figures", "summary": "Standard Bayesian approaches for linear time-invariant (LTI) system\nidentification are hindered by parameter non-identifiability; the resulting\ncomplex, multi-modal posteriors make inference inefficient and impractical. We\nsolve this problem by embedding canonical forms of LTI systems within the\nBayesian framework. We rigorously establish that inference in these minimal\nparameterizations fully captures all invariant system dynamics (e.g., transfer\nfunctions, eigenvalues, predictive distributions of system outputs) while\nresolving identifiability. This approach unlocks the use of meaningful,\nstructure-aware priors (e.g., enforcing stability via eigenvalues) and ensures\nconditions for a Bernstein--von Mises theorem -- a link between Bayesian and\nfrequentist large-sample asymptotics that is broken in standard forms.\nExtensive simulations with modern MCMC methods highlight advantages over\nstandard parameterizations: canonical forms achieve higher computational\nefficiency, generate interpretable and well-behaved posteriors, and provide\nrobust uncertainty estimates, particularly from limited data.", "AI": {"tldr": "\u6458\u8981\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5d4c\u5165\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7684\u89c4\u8303\u5f62\u5f0f\u6765\u89e3\u51b3\u8d1d\u53f6\u65af\u6846\u67b6\u4e2d\u53c2\u6570\u975e\u53ef\u8bc6\u522b\u6027\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u63a8\u65ad\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728LTI\u7cfb\u7edf\u8fa8\u8bc6\u4e2d\u56e0\u53c2\u6570\u975e\u53ef\u8bc6\u522b\u6027\u5bfc\u81f4\u540e\u9a8c\u5206\u5e03\u590d\u6742\u4e14\u591a\u5cf0\uff0c\u4f7f\u5f97\u63a8\u65ad\u4f4e\u6548\u4e14\u4e0d\u5b9e\u7528\u3002", "method": "\u5c06LTI\u7cfb\u7edf\u7684\u89c4\u8303\u5f62\u5f0f\u5d4c\u5165\u5230\u8d1d\u53f6\u65af\u6846\u67b6\u4e2d\uff0c\u786e\u4fdd\u63a8\u65ad\u80fd\u591f\u5b8c\u5168\u6355\u83b7\u6240\u6709\u4e0d\u53d8\u7cfb\u7edf\u52a8\u6001\uff0c\u540c\u65f6\u89e3\u51b3\u53ef\u8bc6\u522b\u6027\u95ee\u9898\u3002", "result": "\u89c4\u8303\u5f62\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u751f\u6210\u4e86\u53ef\u89e3\u91ca\u4e14\u884c\u4e3a\u826f\u597d\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u5728\u6570\u636e\u6709\u9650\u65f6\u63d0\u4f9b\u7a33\u5065\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aLTI\u7cfb\u7edf\u8fa8\u8bc6\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u8d1d\u53f6\u65af\u63a8\u65ad\u65b9\u6848\uff0c\u4e14\u652f\u6301\u6709\u610f\u4e49\u7684\u7ed3\u6784\u5316\u5148\u9a8c\u3002", "keywords": "\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf,\u8d1d\u53f6\u65af\u63a8\u65ad,\u89c4\u8303\u5f62\u5f0f,\u53c2\u6570\u975e\u53ef\u8bc6\u522b\u6027,\u540e\u9a8c\u5206\u5e03"}}
{"id": "2507.11345", "pdf": "https://arxiv.org/pdf/2507.11345", "abs": "https://arxiv.org/abs/2507.11345", "authors": ["Oscar Lima", "Marc Vinci", "Sunandita Patra", "Sebastian Stock", "Joachim Hertzberg", "Martin Atzmueller", "Malik Ghallab", "Dana Nau", "Paolo Traverso"], "title": "Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted in ECMR 2025 conference", "summary": "Robotic task execution faces challenges due to the inconsistency between\nsymbolic planner models and the rich control structures actually running on the\nrobot. In this paper, we present the first physical deployment of an integrated\nactor-planner system that shares hierarchical operational models for both\nacting and planning, interleaving the Reactive Acting Engine (RAE) with an\nanytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile\nmanipulator in a real-world deployment for an object collection task. Our\nexperiments demonstrate robust task execution under action failures and sensor\nnoise, and provide empirical insights into the interleaved acting-and-planning\ndecision making process.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u884c\u52a8-\u89c4\u5212\u7cfb\u7edf\uff08RAE+UPOM\uff09\uff0c\u901a\u8fc7\u5171\u4eab\u5c42\u7ea7\u64cd\u4f5c\u6a21\u578b\u89e3\u51b3\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u4e2d\u7b26\u53f7\u89c4\u5212\u4e0e\u5b9e\u9645\u63a7\u5236\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5e76\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u3002", "motivation": "\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u4e2d\u7b26\u53f7\u89c4\u5212\u6a21\u578b\u4e0e\u5b9e\u9645\u63a7\u5236\u7ed3\u6784\u7684\u4e0d\u4e00\u81f4\u5bfc\u81f4\u6267\u884c\u56f0\u96be\uff0c\u4e9f\u9700\u4e00\u79cd\u96c6\u6210\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408Reactive Acting Engine\uff08RAE\uff09\u4e0eanytime UCT-like Monte Carlo\u89c4\u5212\u5668\uff08UPOM\uff09\uff0c\u5171\u4eab\u5c42\u7ea7\u64cd\u4f5c\u6a21\u578b\uff0c\u5b9e\u73b0\u884c\u52a8\u4e0e\u89c4\u5212\u7684\u4ea4\u9519\u8fdb\u884c\u3002", "result": "\u5728\u771f\u5b9e\u79fb\u52a8\u673a\u68b0\u81c2\u7684\u7269\u4f53\u6536\u96c6\u4efb\u52a1\u4e2d\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u52a8\u4f5c\u5931\u8d25\u548c\u4f20\u611f\u5668\u566a\u58f0\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u51b3\u7b56\u6d41\u7a0b\u7684\u5b9e\u8bc1\u5206\u6790\u3002", "conclusion": "RAE+UPOM\u7cfb\u7edf\u901a\u8fc7\u96c6\u6210\u884c\u52a8\u4e0e\u89c4\u5212\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4e3a\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "keywords": "\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u3001\u7b26\u53f7\u89c4\u5212\u3001\u96c6\u6210\u884c\u52a8-\u89c4\u5212\u3001RAE\u3001UPOM"}}
{"id": "2507.11539", "pdf": "https://arxiv.org/pdf/2507.11539", "abs": "https://arxiv.org/abs/2507.11539", "authors": ["Dong Zhuo", "Wenzhao Zheng", "Jiahe Guo", "Yuqi Wu", "Jie Zhou", "Jiwen Lu"], "title": "Streaming 4D Visual Geometry Transformer", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Code is available at: https://github.com/wzzheng/StreamVGGT", "summary": "Perceiving and reconstructing 4D spatial-temporal geometry from videos is a\nfundamental yet challenging computer vision task. To facilitate interactive and\nreal-time applications, we propose a streaming 4D visual geometry transformer\nthat shares a similar philosophy with autoregressive large language models. We\nexplore a simple and efficient design and employ a causal transformer\narchitecture to process the input sequence in an online manner. We use temporal\ncausal attention and cache the historical keys and values as implicit memory to\nenable efficient streaming long-term 4D reconstruction. This design can handle\nreal-time 4D reconstruction by incrementally integrating historical information\nwhile maintaining high-quality spatial consistency. For efficient training, we\npropose to distill knowledge from the dense bidirectional visual geometry\ngrounded transformer (VGGT) to our causal model. For inference, our model\nsupports the migration of optimized efficient attention operator (e.g.,\nFlashAttention) from the field of large language models. Extensive experiments\non various 4D geometry perception benchmarks demonstrate that our model\nincreases the inference speed in online scenarios while maintaining competitive\nperformance, paving the way for scalable and interactive 4D vision systems.\nCode is available at: https://github.com/wzzheng/StreamVGGT.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u5f0f4D\u89c6\u89c9\u51e0\u4f55\u53d8\u6362\u5668\uff0c\u7528\u4e8e\u5b9e\u65f6\u611f\u77e5\u548c\u91cd\u5efa\u89c6\u9891\u4e2d\u76844D\u65f6\u7a7a\u51e0\u4f55\uff0c\u7ed3\u5408\u56e0\u679c\u53d8\u6362\u5668\u67b6\u6784\u548c\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u5b9e\u65f6\u5904\u7406\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u89c6\u9891\u4e2d4D\u65f6\u7a7a\u51e0\u4f55\u611f\u77e5\u4e0e\u91cd\u5efa\u7684\u5b9e\u65f6\u6027\u548c\u4ea4\u4e92\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u56e0\u679c\u53d8\u6362\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u65f6\u5e8f\u56e0\u679c\u6ce8\u610f\u529b\u5e76\u7f13\u5b58\u5386\u53f2\u952e\u503c\u4f5c\u4e3a\u9690\u5f0f\u8bb0\u5fc6\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4ece\u53cc\u5411\u89c6\u89c9\u51e0\u4f55\u53d8\u6362\u5668\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a4D\u51e0\u4f55\u611f\u77e5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u5728\u5728\u7ebf\u573a\u666f\u4e2d\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u6269\u5c55\u548c\u4ea4\u4e92\u5f0f\u76844D\u89c6\u89c9\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002", "keywords": "4D\u51e0\u4f55,\u6d41\u5f0f\u5904\u7406,\u56e0\u679c\u53d8\u6362\u5668,\u89c6\u9891\u91cd\u5efa,\u5b9e\u65f6\u63a8\u7406"}}
{"id": "2507.11372", "pdf": "https://arxiv.org/pdf/2507.11372", "abs": "https://arxiv.org/abs/2507.11372", "authors": ["Pierrick Leroy", "Antonio Mastropietro", "Marco Nurisso", "Francesco Vaccarino"], "title": "Attributes Shape the Embedding Space of Face Recognition Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Face Recognition (FR) tasks have made significant progress with the advent of\nDeep Neural Networks, particularly through margin-based triplet losses that\nembed facial images into high-dimensional feature spaces. During training,\nthese contrastive losses focus exclusively on identity information as labels.\nHowever, we observe a multiscale geometric structure emerging in the embedding\nspace, influenced by interpretable facial (e.g., hair color) and image\nattributes (e.g., contrast). We propose a geometric approach to describe the\ndependence or invariance of FR models to these attributes and introduce a\nphysics-inspired alignment metric. We evaluate the proposed metric on\ncontrolled, simplified models and widely used FR models fine-tuned with\nsynthetic data for targeted attribute augmentation. Our findings reveal that\nthe models exhibit varying degrees of invariance across different attributes,\nproviding insight into their strengths and weaknesses and enabling deeper\ninterpretability. Code available here:\nhttps://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u51e0\u4f55\u65b9\u6cd5\u5206\u6790\u4eba\u8138\u8bc6\u522b\u6a21\u578b\u5bf9\u4e0d\u540c\u5c5e\u6027\u7684\u4f9d\u8d56\u6027\u6216\u4e0d\u53d8\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u7269\u7406\u542f\u53d1\u7684\u5bf9\u9f50\u5ea6\u91cf\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u63ed\u793a\u6df1\u5ea6\u5b66\u4e60\u4eba\u8138\u8bc6\u522b\u6a21\u578b\u4e2d\u5d4c\u5165\u7a7a\u95f4\u7684\u591a\u5c3a\u5ea6\u51e0\u4f55\u7ed3\u6784\uff0c\u63a2\u8ba8\u6a21\u578b\u5bf9\u53ef\u89e3\u91ca\u9762\u90e8\u548c\u56fe\u50cf\u5c5e\u6027\u7684\u4f9d\u8d56\u6027\u6216\u4e0d\u53d8\u6027\u3002", "method": "\u63d0\u51fa\u51e0\u4f55\u65b9\u6cd5\u6765\u63cf\u8ff0\u6a21\u578b\u7684\u5c5e\u6027\u4f9d\u8d56\u6027\uff0c\u5f15\u5165\u7269\u7406\u542f\u53d1\u7684\u5bf9\u9f50\u5ea6\u91cf\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u589e\u5f3a\u7684FR\u6a21\u578b\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u5c5e\u6027\u4e0a\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u4e0d\u53d8\u6027\uff0c\u63ed\u793a\u4e86\u5176\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u6a21\u578b\u66f4\u6df1\u5c42\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u5176\u884c\u4e3a\u548c\u4f18\u5316\u65b9\u5411\u3002", "keywords": "\u4eba\u8138\u8bc6\u522b, \u51e0\u4f55\u7ed3\u6784, \u5c5e\u6027\u4f9d\u8d56\u6027, \u5bf9\u9f50\u5ea6\u91cf, \u53ef\u89e3\u91ca\u6027"}}
{"id": "2507.11415", "pdf": "https://arxiv.org/pdf/2507.11415", "abs": "https://arxiv.org/abs/2507.11415", "authors": ["Hongbo Ye", "Fenghe Tang", "Peiang Zhao", "Zhen Huang", "Dexin Zhao", "Minghao Bian", "S. Kevin Zhou"], "title": "U-RWKV: Lightweight medical image segmentation with direction-adaptive RWKV", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "Accepted by MICCAI2025", "summary": "Achieving equity in healthcare accessibility requires lightweight yet\nhigh-performance solutions for medical image segmentation, particularly in\nresource-limited settings. Existing methods like U-Net and its variants often\nsuffer from limited global Effective Receptive Fields (ERFs), hindering their\nability to capture long-range dependencies. To address this, we propose U-RWKV,\na novel framework leveraging the Recurrent Weighted Key-Value(RWKV)\narchitecture, which achieves efficient long-range modeling at O(N)\ncomputational cost. The framework introduces two key innovations: the\nDirection-Adaptive RWKV Module(DARM) and the Stage-Adaptive\nSqueeze-and-Excitation Module(SASE). DARM employs Dual-RWKV and QuadScan\nmechanisms to aggregate contextual cues across images, mitigating directional\nbias while preserving global context and maintaining high computational\nefficiency. SASE dynamically adapts its architecture to different feature\nextraction stages, balancing high-resolution detail preservation and semantic\nrelationship capture. Experiments demonstrate that U-RWKV achieves\nstate-of-the-art segmentation performance with high computational efficiency,\noffering a practical solution for democratizing advanced medical imaging\ntechnologies in resource-constrained environments. The code is available at\nhttps://github.com/hbyecoding/U-RWKV.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86U-RWKV\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u957f\u8ddd\u79bb\u5efa\u6a21\u7684\u533b\u5b66\u56fe\u50cf\u5206\u5272\uff0c\u7ed3\u5408DARM\u548cSASE\u6a21\u5757\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709U-Net\u53ca\u5176\u53d8\u4f53\u56e0\u5168\u5c40\u6709\u6548\u611f\u53d7\u91ce\u6709\u9650\u5bfc\u81f4\u7684\u957f\u8ddd\u79bb\u4f9d\u8d56\u6355\u6349\u4e0d\u8db3\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u73af\u5883\u63d0\u4f9b\u5b9e\u7528\u65b9\u6848\u3002", "method": "\u5f15\u5165\u57fa\u4e8eRWKV\u67b6\u6784\u7684U-RWKV\u6846\u67b6\uff0c\u5305\u542bDARM\uff08\u65b9\u5411\u81ea\u9002\u5e94RWKV\u6a21\u5757\uff09\u548cSASE\uff08\u9636\u6bb5\u81ea\u9002\u5e94\u6324\u538b\u6fc0\u52b1\u6a21\u5757\uff09\u4ee5\u4f18\u5316\u7279\u5f81\u63d0\u53d6\u3002", "result": "U-RWNV\u5728\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u56fe\u50cf\u5206\u5272\u6027\u80fd\u3002", "conclusion": "U-RWKV\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u9ad8\u6548\u7684\u533b\u5b66\u56fe\u50cf\u5206\u5272\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u533b\u5b66\u56fe\u50cf\u5206\u5272\u3001U-RWKV\u3001RWKV\u67b6\u6784\u3001\u957f\u8ddd\u79bb\u5efa\u6a21\u3001\u8d44\u6e90\u53d7\u9650\u73af\u5883"}}
{"id": "2507.11443", "pdf": "https://arxiv.org/pdf/2507.11443", "abs": "https://arxiv.org/abs/2507.11443", "authors": ["Haoran Wang", "Hanyu Pei", "Yang Lyu", "Kai Zhang", "Li Li", "Feng-Lei Fan"], "title": "COLI: A Hierarchical Efficient Compressor for Large Images", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The escalating adoption of high-resolution, large-field-of-view imagery\namplifies the need for efficient compression methodologies. Conventional\ntechniques frequently fail to preserve critical image details, while\ndata-driven approaches exhibit limited generalizability. Implicit Neural\nRepresentations (INRs) present a promising alternative by learning continuous\nmappings from spatial coordinates to pixel intensities for individual images,\nthereby storing network weights rather than raw pixels and avoiding the\ngeneralization problem. However, INR-based compression of large images faces\nchallenges including slow compression speed and suboptimal compression ratios.\nTo address these limitations, we introduce COLI (Compressor for Large Images),\na novel framework leveraging Neural Representations for Videos (NeRV). First,\nrecognizing that INR-based compression constitutes a training process, we\naccelerate its convergence through a pretraining-finetuning paradigm,\nmixed-precision training, and reformulation of the sequential loss into a\nparallelizable objective. Second, capitalizing on INRs' transformation of image\nstorage constraints into weight storage, we implement Hyper-Compression, a\nnovel post-training technique to substantially enhance compression ratios while\nmaintaining minimal output distortion. Evaluations across two medical imaging\ndatasets demonstrate that COLI consistently achieves competitive or superior\nPSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while\naccelerating NeRV training by up to 4 times.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCOLI\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u56fe\u50cf\u538b\u7f29\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u5408\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u548c\u89c6\u9891\u795e\u7ecf\u8868\u793a\uff08NeRV\uff09\uff0cCOLI\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u901f\u5ea6\u548c\u538b\u7f29\u6bd4\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u9ad8\u5206\u8fa8\u7387\u3001\u5927\u89c6\u91ce\u56fe\u50cf\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f20\u7edf\u538b\u7f29\u65b9\u6cd5\u65e0\u6cd5\u4fdd\u7559\u5173\u952e\u7ec6\u8282\uff0c\u800c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u4f46\u5728\u5927\u56fe\u50cf\u538b\u7f29\u4e2d\u4ecd\u9762\u4e34\u901f\u5ea6\u548c\u538b\u7f29\u6bd4\u95ee\u9898\u3002", "method": "COLI\u6846\u67b6\u7ed3\u5408\u4e86NeRV\uff0c\u91c7\u7528\u9884\u8bad\u7ec3-\u5fae\u8c03\u6a21\u5f0f\u3001\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u5e76\u884c\u5316\u76ee\u6807\u52a0\u901f\u6536\u655b\u3002\u540c\u65f6\uff0c\u63d0\u51faHyper-Compression\u6280\u672f\u63d0\u5347\u538b\u7f29\u6bd4\u3002", "result": "\u5728\u4e24\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\uff0cCOLI\u5728PSNR\u548cSSIM\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6bd4\u7279\u6bcf\u50cf\u7d20\uff08bpp\uff09\uff0c\u5e76\u52a0\u901fNeRV\u8bad\u7ec3\u8fbe4\u500d\u3002", "conclusion": "COLI\u4e3a\u5927\u89c4\u6a21\u56fe\u50cf\u538b\u7f29\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u901f\u5ea6\u548c\u538b\u7f29\u6bd4\u4f18\u52bf\u3002", "keywords": "\u56fe\u50cf\u538b\u7f29,\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09,\u89c6\u9891\u795e\u7ecf\u8868\u793a\uff08NeRV\uff09,Hyper-Compression,\u533b\u5b66\u5f71\u50cf"}}
{"id": "2507.11488", "pdf": "https://arxiv.org/pdf/2507.11488", "abs": "https://arxiv.org/abs/2507.11488", "authors": ["Pakizar Shamoi", "Nuray Toganas", "Muragul Muratbekova", "Elnara Kadyrgali", "Adilet Yerkin", "Ayan Igali", "Malika Ziyada", "Ayana Adilova", "Aron Karatayev", "Yerdauit Torekhan"], "title": "COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation", "categories": ["cs.CV", "cs.AI"], "comment": "submitted to IEEE for consideration", "summary": "Colors are omnipresent in today's world and play a vital role in how humans\nperceive and interact with their surroundings. However, it is challenging for\ncomputers to imitate human color perception. This paper introduces the Human\nPerception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based\nRepresentation and Interpretation), designed to bridge the gap between\ncomputational color representations and human visual perception. The proposed\nmodel uses fuzzy sets and logic to create a framework for color categorization.\nUsing a three-phase experimental approach, the study first identifies\ndistinguishable color stimuli for hue, saturation, and intensity through\npreliminary experiments, followed by a large-scale human categorization survey\ninvolving more than 1000 human subjects. The resulting data are used to extract\nfuzzy partitions and generate membership functions that reflect real-world\nperceptual uncertainty. The model incorporates a mechanism for adaptation that\nallows refinement based on feedback and contextual changes. Comparative\nevaluations demonstrate the model's alignment with human perception compared to\ntraditional color models, such as RGB, HSV, and LAB. To the best of our\nknowledge, no previous research has documented the construction of a model for\ncolor attribute specification based on a sample of this size or a comparable\nsample of the human population (n = 2496). Our findings are significant for\nfields such as design, artificial intelligence, marketing, and human-computer\ninteraction, where perceptually relevant color representation is critical.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u4eba\u7c7b\u611f\u77e5\u7684\u6a21\u7cca\u8272\u5f69\u6a21\u578bCOLIBRI\uff0c\u901a\u8fc7\u6a21\u7cca\u96c6\u548c\u903b\u8f91\u6a21\u62df\u4eba\u7c7b\u8272\u5f69\u611f\u77e5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u8272\u5f69\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u8ba1\u7b97\u673a\u96be\u4ee5\u6a21\u62df\u4eba\u7c7b\u8272\u5f69\u611f\u77e5\u7684\u95ee\u9898\uff0c\u586b\u8865\u8ba1\u7b97\u8272\u5f69\u8868\u793a\u4e0e\u4eba\u7c7b\u89c6\u89c9\u611f\u77e5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5305\u62ec\u521d\u6b65\u5b9e\u9a8c\u3001\u5927\u89c4\u6a21\u4eba\u7c7b\u5206\u7c7b\u8c03\u67e5\uff0c\u751f\u6210\u6a21\u7cca\u5206\u533a\u548c\u6210\u5458\u51fd\u6570\u3002", "result": "\u6a21\u578b\u5728\u4eba\u7c7b\u611f\u77e5\u5bf9\u9f50\u4e0a\u4f18\u4e8e\u4f20\u7edf\u8272\u5f69\u6a21\u578b\uff08\u5982RGB\u3001HSV\u3001LAB\uff09\uff0c\u9002\u7528\u4e8e\u8bbe\u8ba1\u3001AI\u7b49\u9886\u57df\u3002", "conclusion": "COLIBRI\u6a21\u578b\u6210\u529f\u6a21\u62df\u4eba\u7c7b\u8272\u5f69\u611f\u77e5\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002", "keywords": "\u8272\u5f69\u6a21\u578b, \u6a21\u7cca\u903b\u8f91, \u4eba\u7c7b\u611f\u77e5, COLIBRI, \u5b9e\u9a8c\u9a8c\u8bc1"}}
{"id": "2507.11513", "pdf": "https://arxiv.org/pdf/2507.11513", "abs": "https://arxiv.org/abs/2507.11513", "authors": ["Serge Gratton", "Alena Kopani\u010d\u00e1kov\u00e1", "Philippe Toint"], "title": "Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization", "categories": ["math.OC", "cs.AI", "cs.NA", "math.NA", "49K20, 65M55, 65Y20, 68Q25, 68T05, 90C26, 90C30", "F.2.1; G.1.8; I.2.5"], "comment": "33 pages", "summary": "Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are\npresented that handle bound constraints, inexact gradients and use second-order\ninformation when available.The first is a multi-level method exploiting a\nhierarchical description of the problem and the second is a\ndomain-decomposition method covering the standard addditive Schwarz\ndecompositions. Both are generalizations of the first-order AdaGrad algorithm\nfor unconstrained optimization. Because these algorithms share a common\ntheoretical framework, a single convergence/complexity theory is provided which\ncovers them both. Its main result is that, with high probability, both methods\nneed at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to\ncompute an $\\epsilon$-approximate first-order critical point of the\nbound-constrained problem. Extensive numerical experiments are discussed on\napplications ranging from PDE-based problems to deep neural network training,\nillustrating their remarkable computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cdOFNO\u566a\u58f0\u5bb9\u5fcd\u7b97\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u8fb9\u754c\u7ea6\u675f\u548c\u8fd1\u4f3c\u68af\u5ea6\uff0c\u5e76\u5728\u53ef\u7528\u65f6\u5229\u7528\u4e8c\u9636\u4fe1\u606f\u3002\u7b2c\u4e00\u79cd\u662f\u591a\u7ea7\u65b9\u6cd5\uff0c\u5229\u7528\u95ee\u9898\u7684\u5206\u5c42\u63cf\u8ff0\uff0c\u7b2c\u4e8c\u79cd\u662f\u57df\u5206\u89e3\u65b9\u6cd5\uff0c\u6db5\u76d6\u6807\u51c6\u52a0\u6cd5Schwarz\u5206\u89e3\u3002\u8fd9\u4e24\u79cd\u7b97\u6cd5\u662f\u4e00\u9636AdaGrad\u65e0\u7ea6\u675f\u4f18\u5316\u7b97\u6cd5\u7684\u63a8\u5e7f\u3002\u7531\u4e8e\u5176\u5171\u4eab\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6536\u655b/\u590d\u6742\u5ea6\u7406\u8bba\uff0c\u8868\u660e\u9ad8\u6982\u7387\u4e0b\u6700\u591a\u9700\u8981$O(\\epsilon^{-2})$\u6b21\u8fed\u4ee3\u548c\u566a\u58f0\u68af\u5ea6\u8bc4\u4f30\u6765\u8ba1\u7b97\u8fb9\u754c\u7ea6\u675f\u95ee\u9898\u7684\u8fd1\u4f3c\u4e00\u9636\u4e34\u754c\u70b9\u3002\u6570\u503c\u5b9e\u9a8c\u5c55\u793a\u4e86\u5176\u5728PDE\u95ee\u9898\u5230\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u9ad8\u6548\u6027\u3002", "motivation": "\u9488\u5bf9\u8fb9\u754c\u7ea6\u675f\u3001\u8fd1\u4f3c\u68af\u5ea6\u548c\u4e8c\u9636\u4fe1\u606f\u7684\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u63d0\u51fa\u65b0\u7684\u566a\u58f0\u5bb9\u5fcd\u7b97\u6cd5\u4ee5\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8eOFNO\u6846\u67b6\u7684\u7b97\u6cd5\uff1a\u591a\u7ea7\u65b9\u6cd5\u548c\u57df\u5206\u89e3\u65b9\u6cd5\uff0c\u5747\u4e3a\u4e00\u9636AdaGrad\u7b97\u6cd5\u7684\u63a8\u5e7f\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u7b97\u6cd5\u9ad8\u6982\u7387\u4e0b\u6700\u591a\u9700\u8981$O(\\epsilon^{-2})$\u6b21\u8fed\u4ee3\u548c\u566a\u58f0\u68af\u5ea6\u8bc4\u4f30\uff0c\u5b9e\u9645\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u3002", "conclusion": "\u4e24\u79cd\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u8868\u73b0\u51fa\u9ad8\u6548\uff0c\u9002\u7528\u4e8e\u4ecePDE\u5230\u6df1\u5ea6\u5b66\u4e60\u7684\u5e7f\u6cdb\u95ee\u9898\u3002", "keywords": "OFNO, \u566a\u58f0\u5bb9\u5fcd, \u8fb9\u754c\u7ea6\u675f, \u4e8c\u9636\u4f18\u5316, \u57df\u5206\u89e3, \u591a\u7ea7\u65b9\u6cd5"}}
