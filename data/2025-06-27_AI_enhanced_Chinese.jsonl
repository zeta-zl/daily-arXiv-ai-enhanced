{"id": "2506.20747", "pdf": "https://arxiv.org/pdf/2506.20747", "abs": "https://arxiv.org/abs/2506.20747", "authors": ["Chen Shen", "Sajjadur Rahman", "Estevam Hruschka"], "title": "Towards Probabilistic Question Answering Over Tabular Data", "categories": ["cs.CL", "68T50, 68T37", "I.2.7"], "comment": null, "summary": "Current approaches for question answering (QA) over tabular data, such as\nNL2SQL systems, perform well for factual questions where answers are directly\nretrieved from tables. However, they fall short on probabilistic questions\nrequiring reasoning under uncertainty. In this paper, we introduce a new\nbenchmark LUCARIO and a framework for probabilistic QA over large tabular data.\nOur method induces Bayesian Networks from tables, translates natural language\nqueries into probabilistic queries, and uses large language models (LLMs) to\ngenerate final answers. Empirical results demonstrate significant improvements\nover baselines, highlighting the benefits of hybrid symbolic-neural reasoning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20793", "pdf": "https://arxiv.org/pdf/2506.20793", "abs": "https://arxiv.org/abs/2506.20793", "authors": ["Victor Ojewale", "Inioluwa Deborah Raji", "Suresh Venkatasubramanian"], "title": "Multi-lingual Functional Evaluation for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Multi-lingual competence in large language models is often evaluated via\nstatic data benchmarks such as Belebele, M-MMLU and M-GSM. However, these\nevaluations often fail to provide an adequate understanding of the practical\nperformance and robustness of models across multi-lingual settings. In\nresponse, we create multi-lingual functional benchmarks -- Cross-Lingual Grade\nSchool Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following\nEval (CL-IFEval)-- by translating existing functional benchmark templates from\nEnglish to five additional languages that span the range of resources available\nfor NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that\nsome static multi-lingual benchmarks capture functional performance much more\nclosely than others (i.e. across models, there is a 24%, 17% and 18% decrease\nin performance between M-GSM and CL-GSM Symbolic in English, French and Spanish\nrespectively; similarly there's a 15 - 24% performance drop across languages\nbetween Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between\nM-MMLU and CL-IFEval). Similarly, we find that model robustness across\nlanguages varies significantly, with certain languages (eg. Arabic, English)\nbeing the most consistently well performing across evaluation iterations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u8bed\u8a00\u529f\u80fd\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff08CL-GSM Symbolic\u548cCL-IFEval\uff09\uff0c\u901a\u8fc7\u7ffb\u8bd1\u73b0\u6709\u82f1\u8bed\u57fa\u51c6\u6d4b\u8bd5\u6a21\u677f\u5230\u591a\u8bed\u8a00\uff08\u6cd5\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u5370\u5730\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u7ea6\u9c81\u5df4\u8bed\uff09\uff0c\u63ed\u793a\u4e86\u9759\u6001\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u5728\u5b9e\u9645\u6027\u80fd\u8bc4\u4f30\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u9759\u6001\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982Belebele\u3001M-MMLU\u548cM-GSM\uff09\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u521b\u5efa\u4e86\u529f\u80fd\u6027\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5c06\u73b0\u6709\u7684\u82f1\u8bed\u529f\u80fd\u57fa\u51c6\u6d4b\u8bd5\u6a21\u677f\u7ffb\u8bd1\u6210\u4e94\u79cd\u5176\u4ed6\u8bed\u8a00\uff08\u6cd5\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u5370\u5730\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u7ea6\u9c81\u5df4\u8bed\uff09\uff0c\u521b\u5efa\u4e86CL-GSM Symbolic\u548cCL-IFEval\u4e24\u4e2a\u65b0\u7684\u591a\u8bed\u8a00\u529f\u80fd\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u67d0\u4e9b\u9759\u6001\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982M-GSM\u548cBelebele\uff09\u4e0e\u529f\u80fd\u6027\u6027\u80fd\u8bc4\u4f30\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u8f83\u5927\uff08\u4e0b\u964d15%-24%\uff09\uff0c\u800cM-MMLU\u4e0eCL-IFEval\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u8f83\u5c0f\uff080.5%-3%\uff09\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u9c81\u68d2\u6027\u5dee\u5f02\u663e\u8457\uff0c\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u8868\u73b0\u6700\u7a33\u5b9a\u3002", "conclusion": "\u529f\u80fd\u6027\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u80fd\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u6a21\u578b\u7684\u5b9e\u9645\u6027\u80fd\uff0c\u800c\u9759\u6001\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u63a9\u76d6\u6027\u80fd\u5dee\u8ddd\u3002\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u9c81\u68d2\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "keywords": "\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u3001\u529f\u80fd\u6027\u8bc4\u4f30\u3001\u5927\u8bed\u8a00\u6a21\u578b\u3001\u8de8\u8bed\u8a00\u8868\u73b0\u3001\u9c81\u68d2\u6027"}}
{"id": "2506.20803", "pdf": "https://arxiv.org/pdf/2506.20803", "abs": "https://arxiv.org/abs/2506.20803", "authors": ["Chenglei Si", "Tatsunori Hashimoto", "Diyi Yang"], "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "comment": "main paper is 14 pages", "summary": "Large Language Models (LLMs) have shown promise in accelerating the\nscientific research pipeline. A key capability for this process is the ability\nto generate novel research ideas, and prior studies have found settings in\nwhich LLM-generated research ideas were judged as more novel than human-expert\nideas. However, a good idea should not simply appear to be novel, it should\nalso result in better research after being executed. To test whether\nAI-generated ideas lead to better research outcomes, we conduct an execution\nstudy by recruiting 43 expert researchers to execute randomly-assigned ideas,\neither written by experts or generated by an LLM. Each expert spent over 100\nhours implementing the idea and wrote a 4-page short paper to document the\nexperiments. All the executed projects are then reviewed blindly by expert NLP\nresearchers. Comparing the review scores of the same ideas before and after\nexecution, the scores of the LLM-generated ideas decrease significantly more\nthan expert-written ideas on all evaluation metrics (novelty, excitement,\neffectiveness, and overall; p < 0.05), closing the gap between LLM and human\nideas observed at the ideation stage. When comparing the aggregated review\nscores from the execution study, we even observe that for many metrics there is\na flip in rankings where human ideas score higher than LLM ideas. This\nideation-execution gap highlights the limitations of current LLMs in generating\ntruly effective research ideas and the challenge of evaluating research ideas\nin the absence of execution outcomes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20821", "pdf": "https://arxiv.org/pdf/2506.20821", "abs": "https://arxiv.org/abs/2506.20821", "authors": ["Chinmay Gondhalekar", "Urjitkumar Patel", "Fang-Chun Yeh"], "title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering", "categories": ["cs.CL", "cs.AI", "cs.CE", "68T50, 68T07 (Primary) 68P20, 91G15, 91G70, 68U10 (Secondary)", "I.2.7; I.2.10; H.3.3; H.2.8; I.5.4; J.1"], "comment": "Preprint Copy", "summary": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span\nhundreds of pages and combine diverse modalities, including dense narrative\ntext, structured tables, and complex figures. Answering questions over such\ncontent often requires joint reasoning across modalities, which strains\ntraditional large language models (LLMs) and retrieval-augmented generation\n(RAG) pipelines due to token limitations, layout loss, and fragmented\ncross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation\nframework purpose-built for financial QA. MultiFinRAG first performs multimodal\nextraction by grouping table and figure images into batches and sending them to\na lightweight, quantized open-source multimodal LLM, which produces both\nstructured JSON outputs and concise textual summaries. These outputs, along\nwith narrative text, are embedded and indexed with modality-aware similarity\nthresholds for precise retrieval. A tiered fallback strategy then dynamically\nescalates from text-only to text+table+image contexts when necessary, enabling\ncross-modal reasoning while reducing irrelevant context. Despite running on\ncommodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy\nthan ChatGPT-4o (free-tier) on complex financial QA tasks involving text,\ntables, images, and combined multimodal reasoning.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20702", "pdf": "https://arxiv.org/pdf/2506.20702", "abs": "https://arxiv.org/abs/2506.20702", "authors": ["Yoshua Bengio", "Tegan Maharaj", "Luke Ong", "Stuart Russell", "Dawn Song", "Max Tegmark", "Lan Xue", "Ya-Qin Zhang", "Stephen Casper", "Wan Sie Lee", "S\u00f6ren Mindermann", "Vanessa Wilfred", "Vidhisha Balachandran", "Fazl Barez", "Michael Belinsky", "Imane Bello", "Malo Bourgon", "Mark Brakel", "Sim\u00e9on Campos", "Duncan Cass-Beggs", "Jiahao Chen", "Rumman Chowdhury", "Kuan Chua Seah", "Jeff Clune", "Juntao Dai", "Agnes Delaborde", "Nouha Dziri", "Francisco Eiras", "Joshua Engels", "Jinyu Fan", "Adam Gleave", "Noah Goodman", "Fynn Heide", "Dan Hendrycks", "Cyrus Hodes", "Bryan Low Kian Hsiang", "Minlie Huang", "Sami Jawhar", "Wang Jingyu", "Adam Tauman Kalai", "Meindert Kamphuis", "Mohan Kankanhalli", "Subhash Kantamneni", "Mathias Bonde Kirk", "Thomas Kwa", "Jeffrey Ladish", "Kwok-Yan Lam", "Wan Lee Sie", "Taewhi Lee", "Xiaojian Li", "Jiajun Liu", "Chaochao Lu", "Yifan Mai", "Richard Mallah", "Julian Michael", "Nick Mo\u00ebs", "Simon M\u00f6ller", "Kihyuk Nam", "Kwan Yee Ng", "Mark Nitzberg", "Besmira Nushi", "Se\u00e1n O h\u00c9igeartaigh", "Alejandro Ortega", "Pierre Peign\u00e9", "James Petrie", "Benjamin Prud'Homme", "Reihaneh Rabbany", "Nayat Sanchez-Pi", "Sarah Schwettmann", "Buck Shlegeris", "Saad Siddiqui", "Aradhana Sinha", "Mart\u00edn Soto", "Cheston Tan", "Dong Ting", "Robert Trager", "Brian Tse", "Anthony Tung K. H.", "Vanessa Wilfred", "John Willes", "Denise Wong", "Wei Xu", "Rongwu Xu", "Yi Zeng", "HongJiang Zhang", "Djordje \u017dikeli\u0107"], "title": "The Singapore Consensus on Global AI Safety Research Priorities", "categories": ["cs.AI", "cs.CY"], "comment": "Final report from the \"2025 Singapore Conference on AI (SCAI)\" held\n  April 26: https://www.scai.gov.sg/2025/scai2025-report", "summary": "Rapidly improving AI capabilities and autonomy hold significant promise of\ntransformation, but are also driving vigorous debate on how to ensure that AI\nis safe, i.e., trustworthy, reliable, and secure. Building a trusted ecosystem\nis therefore essential -- it helps people embrace AI with confidence and gives\nmaximal space for innovation while avoiding backlash.\n  The \"2025 Singapore Conference on AI (SCAI): International Scientific\nExchange on AI Safety\" aimed to support research in this space by bringing\ntogether AI scientists across geographies to identify and synthesise research\npriorities in AI safety. This resulting report builds on the International AI\nSafety Report chaired by Yoshua Bengio and backed by 33 governments. By\nadopting a defence-in-depth model, this report organises AI safety research\ndomains into three types: challenges with creating trustworthy AI systems\n(Development), challenges with evaluating their risks (Assessment), and\nchallenges with monitoring and intervening after deployment (Control).", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86AI\u5b89\u5168\u6027\u7814\u7a76\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df1\u5ea6\u9632\u5fa1\u6a21\u578b\u7684\u4e09\u5927\u7814\u7a76\u9886\u57df\u3002", "motivation": "\u968f\u7740AI\u80fd\u529b\u7684\u5feb\u901f\u63d0\u5347\u548c\u81ea\u4e3b\u6027\u7684\u589e\u5f3a\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u3001\u53ef\u4fe1\u8d56\u3001\u53ef\u9760\u548c\u5b89\u5168\u7684\u5fc5\u8981\u6027\u5f15\u53d1\u4e86\u5e7f\u6cdb\u8ba8\u8bba\u3002\u6784\u5efa\u53ef\u4fe1\u751f\u6001\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u5e2e\u52a9\u4eba\u4eec\u81ea\u4fe1\u5730\u63a5\u53d7AI\u5e76\u6700\u5927\u9650\u5ea6\u5730\u4fc3\u8fdb\u521b\u65b0\u3002", "method": "\u901a\u8fc72025\u5e74\u65b0\u52a0\u5761AI\u5b89\u5168\u56fd\u9645\u79d1\u5b66\u4ea4\u6d41\u4f1a\u8bae\uff0c\u6c47\u96c6\u5168\u7403AI\u79d1\u5b66\u5bb6\uff0c\u8bc6\u522b\u5e76\u7efc\u5408AI\u5b89\u5168\u7814\u7a76\u7684\u4f18\u5148\u4e8b\u9879\u3002\u62a5\u544a\u57fa\u4e8e33\u4e2a\u653f\u5e9c\u652f\u6301\u7684\u56fd\u9645AI\u5b89\u5168\u62a5\u544a\uff0c\u91c7\u7528\u6df1\u5ea6\u9632\u5fa1\u6a21\u578b\uff0c\u5c06AI\u5b89\u5168\u7814\u7a76\u5206\u4e3a\u5f00\u53d1\u3001\u8bc4\u4f30\u548c\u63a7\u5236\u4e09\u5927\u9886\u57df\u3002", "result": "\u62a5\u544a\u63d0\u51fa\u4e86\u4e09\u5927AI\u5b89\u5168\u7814\u7a76\u9886\u57df\uff1a\u5f00\u53d1\uff08\u521b\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u7684\u6311\u6218\uff09\u3001\u8bc4\u4f30\uff08\u8bc4\u4f30\u98ce\u9669\u7684\u6311\u6218\uff09\u548c\u63a7\u5236\uff08\u90e8\u7f72\u540e\u76d1\u63a7\u548c\u5e72\u9884\u7684\u6311\u6218\uff09\u3002", "conclusion": "\u6784\u5efa\u53ef\u4fe1\u7684AI\u751f\u6001\u7cfb\u7edf\u9700\u8981\u4ece\u5f00\u53d1\u3001\u8bc4\u4f30\u548c\u63a7\u5236\u4e09\u4e2a\u65b9\u9762\u5165\u624b\uff0c\u4ee5\u786e\u4fddAI\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4fc3\u8fdb\u521b\u65b0\u3002", "keywords": "AI\u5b89\u5168\uff0c\u53ef\u4fe1\u751f\u6001\u7cfb\u7edf\uff0c\u6df1\u5ea6\u9632\u5fa1\u6a21\u578b\uff0c\u5f00\u53d1\uff0c\u8bc4\u4f30\uff0c\u63a7\u5236"}}
{"id": "2506.20685", "pdf": "https://arxiv.org/pdf/2506.20685", "abs": "https://arxiv.org/abs/2506.20685", "authors": ["Sajid Hussain", "Muhammad Sohail", "Nauman Ali Khan", "Naima Iltaf", "Ihtesham ul Islam"], "title": "Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated Learning (FL) has emerged as a transformative paradigm for\ndistributed machine learning while preserving data privacy. However, existing\napproaches predominantly focus on model heterogeneity and aggregation\ntechniques, largely overlooking the fundamental impact of dataset size\ncharacteristics on federated training dynamics. This paper introduces\nSize-Based Adaptive Federated Learning (SAFL), a novel progressive training\nframework that systematically organizes federated learning based on dataset\nsize characteristics across heterogeneous multi-modal data. Our comprehensive\nexperimental evaluation across 13 diverse datasets spanning 7 modalities\n(vision, text, time series, audio, sensor, medical vision, and multimodal)\nreveals critical insights: 1) an optimal dataset size range of 1000-1500\nsamples for federated learning effectiveness; 2) a clear modality performance\nhierarchy with structured data (time series, sensor) significantly\noutperforming unstructured data (text, multimodal); and 3) systematic\nperformance degradation for large datasets exceeding 2000 samples. SAFL\nachieves an average accuracy of 87.68% across all datasets, with structured\ndata modalities reaching 99%+ accuracy. The framework demonstrates superior\ncommunication efficiency, reducing total data transfer to 7.38 GB across 558\ncommunications while maintaining high performance. Our real-time monitoring\nframework provides unprecedented insights into system resource utilization,\nnetwork efficiency, and training dynamics. This work fills critical gaps in\nunderstanding how data characteristics should drive federated learning\nstrategies, providing both theoretical insights and practical guidance for\nreal-world FL deployments in neural network and learning systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u96c6\u5927\u5c0f\u7279\u6027\u7684\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\u6846\u67b6SAFL\uff0c\u63ed\u793a\u4e86\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u6001\u5bf9\u8054\u90a6\u5b66\u4e60\u6548\u679c\u7684\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u6a21\u6001\u6570\u636e\u4e0a\u7684\u9ad8\u6548\u6027\u548c\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u5f02\u8d28\u6027\u548c\u805a\u5408\u6280\u672f\uff0c\u800c\u5ffd\u89c6\u4e86\u6570\u636e\u96c6\u5927\u5c0f\u7279\u6027\u5bf9\u8bad\u7ec3\u52a8\u6001\u7684\u6839\u672c\u5f71\u54cd\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51faSize-Based Adaptive Federated Learning (SAFL)\u6846\u67b6\uff0c\u6839\u636e\u6570\u636e\u96c6\u5927\u5c0f\u7279\u6027\u7cfb\u7edf\u7ec4\u7ec7\u8054\u90a6\u5b66\u4e60\uff0c\u5e76\u901a\u8fc713\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u6570\u636e\u96c6\u5927\u5c0f\u57281000-1500\u6837\u672c\u65f6\u6548\u679c\u6700\u4f73\uff0c\u7ed3\u6784\u5316\u6570\u636e\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u975e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4e14\u5927\u6570\u636e\u96c6\u6027\u80fd\u4e0b\u964d\u3002SAFL\u5e73\u5747\u51c6\u786e\u7387\u8fbe87.68%\uff0c\u901a\u4fe1\u6548\u7387\u9ad8\u3002", "conclusion": "SAFL\u4e3a\u8054\u90a6\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u586b\u8865\u4e86\u6570\u636e\u7279\u6027\u9a71\u52a8\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u7684\u7814\u7a76\u7a7a\u767d\u3002", "keywords": "\u8054\u90a6\u5b66\u4e60, \u6570\u636e\u96c6\u5927\u5c0f, \u591a\u6a21\u6001\u6570\u636e, \u901a\u4fe1\u6548\u7387, SAFL"}}
{"id": "2506.20822", "pdf": "https://arxiv.org/pdf/2506.20822", "abs": "https://arxiv.org/abs/2506.20822", "authors": ["Quintin Myers", "Yanjun Gao"], "title": "Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes", "categories": ["cs.CL", "cs.AI"], "comment": "Under review", "summary": "Large language models (LLMs) are increasingly proposed for detecting and\nresponding to violent content online, yet their ability to reason about morally\nambiguous, real-world scenarios remains underexamined. We present the first\nstudy to evaluate LLMs using a validated social science instrument designed to\nmeasure human response to everyday conflict, namely the Violent Behavior\nVignette Questionnaire (VBVQ). To assess potential bias, we introduce\npersona-based prompting that varies race, age, and geographic identity within\nthe United States. Six LLMs developed across different geopolitical and\norganizational contexts are evaluated under a unified zero-shot setting. Our\nstudy reveals two key findings: (1) LLMs surface-level text generation often\ndiverges from their internal preference for violent responses; (2) their\nviolent tendencies vary across demographics, frequently contradicting\nestablished findings in criminology, social science, and psychology.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u548c\u5904\u7406\u66b4\u529b\u5185\u5bb9\u65f6\u5bf9\u9053\u5fb7\u6a21\u7cca\u573a\u666f\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u8868\u9762\u751f\u6210\u4e0e\u5185\u90e8\u66b4\u529b\u503e\u5411\u5b58\u5728\u5dee\u5f02\uff0c\u5e76\u5b58\u5728\u8de8\u4eba\u53e3\u7edf\u8ba1\u5b66\u7684\u504f\u89c1\u3002", "motivation": "LLMs\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u68c0\u6d4b\u548c\u5e94\u5bf9\u5728\u7ebf\u66b4\u529b\u5185\u5bb9\uff0c\u4f46\u5176\u5728\u73b0\u5b9e\u9053\u5fb7\u6a21\u7cca\u573a\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u9a8c\u8bc1\u7684\u793e\u4f1a\u79d1\u5b66\u5de5\u5177\uff08VBVQ\uff09\u548c\u57fa\u4e8e\u8eab\u4efd\u7684\u63d0\u793a\uff08\u5982\u79cd\u65cf\u3001\u5e74\u9f84\u3001\u5730\u7406\uff09\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u516d\u4e2aLLMs\u3002", "result": "LLMs\u7684\u8868\u5c42\u6587\u672c\u751f\u6210\u4e0e\u5185\u90e8\u66b4\u529b\u503e\u5411\u4e0d\u4e00\u81f4\uff0c\u4e14\u5176\u66b4\u529b\u503e\u5411\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b66\u4e2d\u5b58\u5728\u504f\u89c1\uff0c\u4e0e\u793e\u4f1a\u79d1\u5b66\u7684\u53d1\u73b0\u76f8\u77db\u76fe\u3002", "conclusion": "LLMs\u5728\u66b4\u529b\u5185\u5bb9\u5904\u7406\u4e2d\u5b58\u5728\u6f5c\u5728\u504f\u89c1\u548c\u63a8\u7406\u7f3a\u9677\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u548c\u8bc4\u4f30\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b,\u66b4\u529b\u5185\u5bb9,\u9053\u5fb7\u6a21\u7cca,\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u89c1"}}
{"id": "2506.20737", "pdf": "https://arxiv.org/pdf/2506.20737", "abs": "https://arxiv.org/abs/2506.20737", "authors": ["Gurusha Juneja", "Alon Albalak", "Wenyue Hua", "William Yang Wang"], "title": "MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The proliferation of LLM-based agents has led to increasing deployment of\ninter-agent collaboration for tasks like scheduling, negotiation, resource\nallocation etc. In such systems, privacy is critical, as agents often access\nproprietary tools and domain-specific databases requiring strict\nconfidentiality. This paper examines whether LLM-based agents demonstrate an\nunderstanding of contextual privacy. And, if instructed, do these systems\npreserve inference time user privacy in non-adversarial multi-turn\nconversation. Existing benchmarks to evaluate contextual privacy in LLM-agents\nprimarily assess single-turn, low-complexity tasks where private information\ncan be easily excluded. We first present a benchmark - MAGPIE comprising 158\nreal-life high-stakes scenarios across 15 domains. These scenarios are designed\nsuch that complete exclusion of private data impedes task completion yet\nunrestricted information sharing could lead to substantial losses. We then\nevaluate the current state-of-the-art LLMs on (a) their understanding of\ncontextually private data and (b) their ability to collaborate without\nviolating user privacy. Empirical experiments demonstrate that current models,\nincluding GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual\nprivacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the\ntime. In multi-turn conversations, these models disclose private information in\n59.9\\% and 50.5\\% of cases even under explicit privacy instructions.\nFurthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios.\nThese results underscore that current models are not aligned towards both\ncontextual privacy preservation and collaborative task-solving.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u4ee3\u7406\u5728\u4e0a\u4e0b\u6587\u9690\u79c1\u7406\u89e3\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u5904\u7406\u9ad8\u590d\u6742\u5ea6\u4efb\u52a1\u65f6\u9690\u79c1\u4fdd\u62a4\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740LLM\u4ee3\u7406\u5728\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9690\u79c1\u4fdd\u62a4\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u5728\u6d89\u53ca\u4e13\u6709\u5de5\u5177\u548c\u6570\u636e\u5e93\u7684\u573a\u666f\u4e2d\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86MAGPIE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b158\u4e2a\u9ad8\u98ce\u9669\u573a\u666f\uff0c\u8bc4\u4f30LLM\u4ee3\u7406\u5728\u4e0a\u4e0b\u6587\u9690\u79c1\u7406\u89e3\u548c\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5305\u62ecGPT-4o\u548cClaude-2.7-Sonnet\u5728\u5185\u7684\u6a21\u578b\u5bf9\u9690\u79c1\u6570\u636e\u7684\u5206\u7c7b\u9519\u8bef\u7387\u8f83\u9ad8\uff0c\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4ecd\u4f1a\u6cc4\u9732\u9690\u79c1\u4fe1\u606f\u3002", "conclusion": "\u5f53\u524dLLM\u4ee3\u7406\u5728\u4e0a\u4e0b\u6587\u9690\u79c1\u4fdd\u62a4\u548c\u534f\u4f5c\u4efb\u52a1\u5b8c\u6210\u65b9\u9762\u5c1a\u4e0d\u5b8c\u5584\u3002", "keywords": "LLM\u4ee3\u7406, \u9690\u79c1\u4fdd\u62a4, MAGPIE\u57fa\u51c6, \u591a\u8f6e\u5bf9\u8bdd, \u534f\u4f5c\u4efb\u52a1"}}
{"id": "2506.20693", "pdf": "https://arxiv.org/pdf/2506.20693", "abs": "https://arxiv.org/abs/2506.20693", "authors": ["Ugo Lomoio", "Tommaso Mazza", "Pierangelo Veltri", "Pietro Hiram Guzzi"], "title": "E-ABIN: an Explainable module for Anomaly detection in BIological Networks", "categories": ["cs.LG"], "comment": null, "summary": "The increasing availability of large-scale omics data calls for robust\nanalytical frameworks capable of handling complex gene expression datasets\nwhile offering interpretable results. Recent advances in artificial\nintelligence have enabled the identification of aberrant molecular patterns\ndistinguishing disease states from healthy controls. Coupled with improvements\nin model interpretability, these tools now support the identification of genes\npotentially driving disease phenotypes. However, current approaches to gene\nanomaly detection often remain limited to single datasets and lack accessible\ngraphical interfaces. Here, we introduce E-ABIN, a general-purpose, explainable\nframework for Anomaly detection in Biological Networks. E-ABIN combines\nclassical machine learning and graph-based deep learning techniques within a\nunified, user-friendly platform, enabling the detection and interpretation of\nanomalies from gene expression or methylation-derived networks. By integrating\nalgorithms such as Support Vector Machines, Random Forests, Graph Autoencoders\n(GAEs), and Graph Adversarial Attributed Networks (GAANs), E-ABIN ensures a\nhigh predictive accuracy while maintaining interpretability. We demonstrate the\nutility of E-ABIN through case studies of bladder cancer and coeliac disease,\nwhere it effectively uncovers biologically relevant anomalies and offers\ninsights into disease mechanisms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20876", "pdf": "https://arxiv.org/pdf/2506.20876", "abs": "https://arxiv.org/abs/2506.20876", "authors": ["Sebastian Joseph", "Lily Chen", "Barry Wei", "Michael Mackert", "Iain J. Marshall", "Paul Pu Liang", "Ramez Kouzy", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine", "categories": ["cs.CL"], "comment": null, "summary": "Technological progress has led to concrete advancements in tasks that were\nregarded as challenging, such as automatic fact-checking. Interest in adopting\nthese systems for public health and medicine has grown due to the high-stakes\nnature of medical decisions and challenges in critically appraising a vast and\ndiverse medical literature. Evidence-based medicine connects to every\nindividual, and yet the nature of it is highly technical, rendering the medical\nliteracy of majority users inadequate to sufficiently navigate the domain. Such\nproblems with medical communication ripens the ground for end-to-end\nfact-checking agents: check a claim against current medical literature and\nreturn with an evidence-backed verdict. And yet, such systems remain largely\nunused. To understand this, we present the first study examining how clinical\nexperts verify real claims from social media by synthesizing medical evidence.\nIn searching for this upper-bound, we reveal fundamental challenges in\nend-to-end fact-checking when applied to medicine: Difficulties connecting\nclaims in the wild to scientific evidence in the form of clinical trials;\nambiguities in underspecified claims mixed with mismatched intentions; and\ninherently subjective veracity labels. We argue that fact-checking should be\napproached and evaluated as an interactive communication problem, rather than\nan end-to-end process.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u533b\u7597\u9886\u57df\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u6311\u6218\uff0c\u6307\u51fa\u5f53\u524d\u7cfb\u7edf\u672a\u666e\u53ca\u7684\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u5e94\u5c06\u4e8b\u5b9e\u6838\u67e5\u89c6\u4e3a\u4ea4\u4e92\u5f0f\u6c9f\u901a\u95ee\u9898\u800c\u975e\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "motivation": "\u533b\u7597\u51b3\u7b56\u7684\u9ad8\u98ce\u9669\u6027\u548c\u533b\u5b66\u6587\u732e\u7684\u590d\u6742\u6027\u5bfc\u81f4\u5bf9\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u9700\u6c42\u589e\u957f\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u4ecd\u672a\u5e7f\u6cdb\u5e94\u7528\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5176\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u4e34\u5e8a\u4e13\u5bb6\u5982\u4f55\u9a8c\u8bc1\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u533b\u7597\u58f0\u660e\u5e76\u7efc\u5408\u533b\u5b66\u8bc1\u636e\uff0c\u63ed\u793a\u533b\u7597\u4e8b\u5b9e\u6838\u67e5\u7684\u96be\u70b9\u3002", "result": "\u53d1\u73b0\u533b\u7597\u4e8b\u5b9e\u6838\u67e5\u9762\u4e34\u7684\u6311\u6218\u5305\u62ec\uff1a\u65e0\u6cd5\u5c06\u5b9e\u9645\u58f0\u660e\u4e0e\u4e34\u5e8a\u8bd5\u9a8c\u8bc1\u636e\u5173\u8054\u3001\u58f0\u660e\u6a21\u7cca\u6027\u53ca\u610f\u56fe\u4e0d\u5339\u914d\u3001\u4e3b\u89c2\u771f\u5b9e\u6027\u6807\u7b7e\u95ee\u9898\u3002", "conclusion": "\u4e8b\u5b9e\u6838\u67e5\u5e94\u88ab\u89c6\u4e3a\u4ea4\u4e92\u5f0f\u6c9f\u901a\u95ee\u9898\uff0c\u800c\u975e\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "keywords": "\u533b\u7597\u4e8b\u5b9e\u6838\u67e5\u3001\u81ea\u52a8\u5316\u7cfb\u7edf\u3001\u8bc1\u636e\u533b\u5b66\u3001\u4ea4\u4e92\u6c9f\u901a"}}
{"id": "2506.20815", "pdf": "https://arxiv.org/pdf/2506.20815", "abs": "https://arxiv.org/abs/2506.20815", "authors": ["Xinye Tang", "Haijun Zhai", "Chaitanya Belwal", "Vineeth Thayanithi", "Philip Baumann", "Yogesh K Roy"], "title": "Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications", "categories": ["cs.AI"], "comment": null, "summary": "LLM-powered applications are highly susceptible to the quality of user\nprompts, and crafting high-quality prompts can often be challenging especially\nfor domain-specific applications. This paper presents a novel dynamic\ncontext-aware prompt recommendation system for domain-specific AI applications.\nOur solution combines contextual query analysis, retrieval-augmented knowledge\ngrounding, hierarchical skill organization, and adaptive skill ranking to\ngenerate relevant and actionable prompt suggestions.\n  The system leverages behavioral telemetry and a two-stage hierarchical\nreasoning process to dynamically select and rank relevant skills, and\nsynthesizes prompts using both predefined and adaptive templates enhanced with\nfew-shot learning. Experiments on real-world datasets demonstrate that our\napproach achieves high usefulness and relevance, as validated by both automated\nand expert evaluations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9886\u57df\u7279\u5b9aAI\u5e94\u7528\u7684\u52a8\u6001\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u63a8\u8350\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u4e0a\u4e0b\u6587\u67e5\u8be2\u5206\u6790\u548c\u81ea\u9002\u5e94\u6280\u80fd\u6392\u540d\u7b49\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63d0\u793a\u7684\u5b9e\u7528\u6027\u548c\u76f8\u5173\u6027\u3002", "motivation": "\u7531\u4e8eLLM\u9a71\u52a8\u7684\u5e94\u7528\u5bf9\u7528\u6237\u63d0\u793a\u8d28\u91cf\u9ad8\u5ea6\u654f\u611f\uff0c\u800c\u9ad8\u8d28\u91cf\u63d0\u793a\u7684\u751f\u6210\u5728\u9886\u57df\u7279\u5b9a\u5e94\u7528\u4e2d\u5c24\u4e3a\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u52a8\u6001\u4e14\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63d0\u793a\u63a8\u8350\u7cfb\u7edf\u3002", "method": "\u7cfb\u7edf\u7ed3\u5408\u4e86\u4e0a\u4e0b\u6587\u67e5\u8be2\u5206\u6790\u3001\u68c0\u7d22\u589e\u5f3a\u77e5\u8bc6\u57fa\u7840\u3001\u5206\u5c42\u6280\u80fd\u7ec4\u7ec7\u548c\u81ea\u9002\u5e94\u6280\u80fd\u6392\u540d\uff0c\u901a\u8fc7\u884c\u4e3a\u9065\u6d4b\u548c\u4e24\u9636\u6bb5\u5206\u5c42\u63a8\u7406\u52a8\u6001\u751f\u6210\u63d0\u793a\u5efa\u8bae\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7cfb\u7edf\u751f\u6210\u7684\u63d0\u793a\u5177\u6709\u9ad8\u5ea6\u7684\u5b9e\u7528\u6027\u548c\u76f8\u5173\u6027\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u548c\u4e13\u5bb6\u8bc4\u4f30\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u9886\u57df\u7279\u5b9a\u5e94\u7528\u4e2d\u9ad8\u8d28\u91cf\u63d0\u793a\u751f\u6210\u7684\u6311\u6218\uff0c\u4e3aLLM\u5e94\u7528\u63d0\u4f9b\u4e86\u52a8\u6001\u4e14\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u63a8\u8350\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "LLM, \u63d0\u793a\u63a8\u8350, \u4e0a\u4e0b\u6587\u611f\u77e5, \u9886\u57df\u7279\u5b9a\u5e94\u7528, \u81ea\u9002\u5e94\u6280\u80fd\u6392\u540d"}}
{"id": "2506.20699", "pdf": "https://arxiv.org/pdf/2506.20699", "abs": "https://arxiv.org/abs/2506.20699", "authors": ["Xin Li"], "title": "On Context-Content Uncertainty Principle", "categories": ["cs.LG"], "comment": null, "summary": "The Context-Content Uncertainty Principle (CCUP) proposes that inference\nunder uncertainty is governed by an entropy asymmetry between context and\ncontent: high-entropy contexts must be interpreted through alignment with\nlow-entropy, structured content. In this paper, we develop a layered\ncomputational framework that derives operational principles from this\nfoundational asymmetry. At the base level, CCUP formalizes inference as\ndirectional entropy minimization, establishing a variational gradient that\nfavors content-first structuring. Building upon this, we identify four\nhierarchical layers of operational principles: (\\textbf{L1}) \\emph{Core\nInference Constraints}, including structure-before-specificity, asymmetric\ninference flow, cycle-consistent bootstrapping, and conditional compression,\nall shown to be mutually reducible; (\\textbf{L2}) \\emph{Resource Allocation\nPrinciples}, such as precision-weighted attention, asymmetric learning rates,\nand attractor-based memory encoding; (\\textbf{L3}) \\emph{Temporal Bootstrapping\nDynamics}, which organize learning over time via structure-guided curricula;\nand (\\textbf{L4}) \\emph{Spatial Hierarchical Composition}, which integrates\nthese mechanisms into self-organizing cycles of memory, inference, and\nplanning. We present formal equivalence theorems, a dependency lattice among\nprinciples, and computational simulations demonstrating the efficiency gains of\nCCUP-aligned inference. This work provides a unified theoretical foundation for\nunderstanding how brains and machines minimize uncertainty through recursive\nstructure-specificity alignment. The brain is not just an inference machine. It\nis a cycle-consistent entropy gradient resolver, aligning structure and\nspecificity via path-dependent, content-seeded simulation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20917", "pdf": "https://arxiv.org/pdf/2506.20917", "abs": "https://arxiv.org/abs/2506.20917", "authors": ["Zhengyan Shi"], "title": "Optimising Language Models for Downstream Tasks: A Post-Training Perspective", "categories": ["cs.CL", "cs.AI"], "comment": "PhD Thesis", "summary": "Language models (LMs) have demonstrated remarkable capabilities in NLP, yet\nadapting them efficiently and robustly to specific tasks remains challenging.\nAs their scale and complexity grow, fine-tuning LMs on labelled data often\nunderutilizes available unlabelled data, leads to overfitting on small\ntask-specific sets, and imposes significant computational costs. These\nlimitations hamper their application to the open-ended landscape of real-world\nlanguage tasks.\n  This thesis proposes a series of methods to better adapt LMs to downstream\napplications. First, we explore strategies for extracting task-relevant\nknowledge from unlabelled data, introducing a novel continued pre-training\ntechnique that outperforms state-of-the-art semi-supervised approaches. Next,\nwe present a parameter-efficient fine-tuning method that substantially reduces\nmemory and compute costs while maintaining competitive performance. We also\nintroduce improved supervised fine-tuning methods that enable LMs to better\nfollow instructions, especially when labelled data is scarce, enhancing their\nperformance across a range of NLP tasks, including open-ended generation.\nFinally, we develop new evaluation methods and benchmarks, such as multi-hop\nspatial reasoning tasks, to assess LM capabilities and adaptation more\ncomprehensively.\n  Through extensive empirical studies across diverse NLP tasks, our results\ndemonstrate that these approaches substantially improve LM robustness,\nefficiency, and generalization, making them more adaptable to a broad range of\napplications. These advances mark a significant step towards more robust and\nefficient LMs, bringing us closer to the goal of artificial general\nintelligence.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20949", "pdf": "https://arxiv.org/pdf/2506.20949", "abs": "https://arxiv.org/abs/2506.20949", "authors": ["Chenkai Sun", "Denghui Zhang", "ChengXiang Zhai", "Heng Ji"], "title": "Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Given the growing influence of language model-based agents on high-stakes\nsocietal decisions, from public policy to healthcare, ensuring their beneficial\nimpact requires understanding the far-reaching implications of their\nsuggestions. We propose a proof-of-concept framework that projects how\nmodel-generated advice could propagate through societal systems on a\nmacroscopic scale over time, enabling more robust alignment. To assess the\nlong-term safety awareness of language models, we also introduce a dataset of\n100 indirect harm scenarios, testing models' ability to foresee adverse,\nnon-obvious outcomes from seemingly harmless user prompts. Our approach\nachieves not only over 20% improvement on the new dataset but also an average\nwin rate exceeding 70% against strong baselines on existing safety benchmarks\n(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer\nagents.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20701", "pdf": "https://arxiv.org/pdf/2506.20701", "abs": "https://arxiv.org/abs/2506.20701", "authors": ["Vineet Jain", "Kusha Sareen", "Mohammad Pedramfar", "Siamak Ravanbakhsh"], "title": "Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Adapting a pretrained diffusion model to new objectives at inference time\nremains an open problem in generative modeling. Existing steering methods\nsuffer from inaccurate value estimation, especially at high noise levels, which\nbiases guidance. Moreover, information from past runs is not reused to improve\nsample quality, resulting in inefficient use of compute. Inspired by the\nsuccess of Monte Carlo Tree Search, we address these limitations by casting\ninference-time alignment as a search problem that reuses past computations. We\nintroduce a tree-based approach that samples from the reward-aligned target\ndensity by propagating terminal rewards back through the diffusion chain and\niteratively refining value estimates with each additional generation. Our\nproposed method, Diffusion Tree Sampling (DTS), produces asymptotically exact\nsamples from the target distribution in the limit of infinite rollouts, and its\ngreedy variant, Diffusion Tree Search (DTS$^\\star$), performs a global search\nfor high reward samples. On MNIST and CIFAR-10 class-conditional generation,\nDTS matches the FID of the best-performing baseline with up to $10\\times$ less\ncompute. In text-to-image generation and language completion tasks, DTS$^\\star$\neffectively searches for high reward samples that match best-of-N with up to\n$5\\times$ less compute. By reusing information from previous generations, we\nget an anytime algorithm that turns additional compute into steadily better\nsamples, providing a scalable approach for inference-time alignment of\ndiffusion models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20920", "pdf": "https://arxiv.org/pdf/2506.20920", "abs": "https://arxiv.org/abs/2506.20920", "authors": ["Guilherme Penedo", "Hynek Kydl\u00ed\u010dek", "Vinko Sabol\u010dec", "Bettina Messmer", "Negar Foroutan", "Amir Hossein Kargaran", "Colin Raffel", "Martin Jaggi", "Leandro Von Werra", "Thomas Wolf"], "title": "FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language", "categories": ["cs.CL"], "comment": null, "summary": "Pre-training state-of-the-art large language models (LLMs) requires vast\namounts of clean and diverse text data. While the open development of large\nhigh-quality English pre-training datasets has seen substantial recent\nprogress, training performant multilingual LLMs remains a challenge, in large\npart due to the inherent difficulty of tailoring filtering and deduplication\npipelines to a large number of languages. In this work, we introduce a new\npre-training dataset curation pipeline based on FineWeb that can be\nautomatically adapted to support any language. We extensively ablate our\npipeline design choices on a set of nine diverse languages, guided by a set of\nmeaningful and informative evaluation tasks that were chosen through a novel\nselection process based on measurable criteria. Ultimately, we show that our\npipeline can be used to create non-English corpora that produce more performant\nmodels than prior datasets. We additionally introduce a straightforward and\nprincipled approach to rebalance datasets that takes into consideration both\nduplication count and quality, providing an additional performance uplift.\nFinally, we scale our pipeline to over 1000 languages using almost 100 Common\nCrawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)\nmultilingual dataset which we release along with our pipeline, training, and\nevaluation codebases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u6570\u636e\u96c6FineWeb2\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7684\u6570\u636e\u7ba1\u9053\u652f\u6301\u591a\u79cd\u8bed\u8a00\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5f15\u5165\u4e86\u57fa\u4e8e\u91cd\u590d\u8ba1\u6570\u548c\u8d28\u91cf\u7684\u6570\u636e\u91cd\u65b0\u5e73\u8861\u65b9\u6cd5\u3002", "motivation": "\u9884\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u7684\u591a\u8bed\u8a00\u6570\u636e\uff0c\u4f46\u76ee\u524d\u591a\u8bed\u8a00\u6570\u636e\u7684\u8fc7\u6ee4\u548c\u53bb\u91cd\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8eFineWeb\u7684\u81ea\u52a8\u5316\u6570\u636e\u7ba1\u9053\uff0c\u652f\u6301\u591a\u79cd\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u4f18\u5316\u8bbe\u8ba1\u9009\u62e9\uff1b\u5f15\u5165\u4e86\u6570\u636e\u91cd\u65b0\u5e73\u8861\u65b9\u6cd5\u3002", "result": "FineWeb2\u6570\u636e\u96c6\uff0820TB\uff0c50\u4ebf\u6587\u6863\uff09\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u6570\u636e\u7ba1\u9053\u548c\u6570\u636e\u96c6\u4e3a\u591a\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u516c\u5f00\u4e86\u76f8\u5173\u4ee3\u7801\u3002", "keywords": "\u591a\u8bed\u8a00\u9884\u8bad\u7ec3,\u6570\u636e\u7ba1\u9053,FineWeb2,\u8bed\u8a00\u6a21\u578b"}}
{"id": "2506.21215", "pdf": "https://arxiv.org/pdf/2506.21215", "abs": "https://arxiv.org/abs/2506.21215", "authors": ["Haoang Chi", "He Li", "Wenjing Yang", "Feng Liu", "Long Lan", "Xiaoguang Ren", "Tongliang Liu", "Bo Han"], "title": "Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "24 pages, accepted at NeurIPS 2024", "summary": "Causal reasoning capability is critical in advancing large language models\n(LLMs) toward strong artificial intelligence. While versatile LLMs appear to\nhave demonstrated capabilities in understanding contextual causality and\nproviding responses that obey the laws of causality, it remains unclear whether\nthey perform genuine causal reasoning akin to humans. However, current evidence\nindicates the contrary. Specifically, LLMs are only capable of performing\nshallow (level-1) causal reasoning, primarily attributed to the causal\nknowledge embedded in their parameters, but they lack the capacity for genuine\nhuman-like (level-2) causal reasoning. To support this hypothesis,\nmethodologically, we delve into the autoregression mechanism of\ntransformer-based LLMs, revealing that it is not inherently causal.\nEmpirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,\nwhose corpora are fresh and nearly unseen for the studied LLMs. The LLMs\nexhibit a significant performance drop on CausalProbe-2024 compared to earlier\nbenchmarks, indicating the fact that they primarily engage in level-1 causal\nreasoning. To bridge the gap towards level-2 causal reasoning, we draw\ninspiration from the fact that human reasoning is usually facilitated by\ngeneral knowledge and intended goals. We propose G^2-Reasoner, a method that\nincorporates general knowledge and goal-oriented prompts into LLMs' causal\nreasoning processes. Experiments demonstrate that G^2-Reasoner significantly\nenhances LLMs' causal reasoning capability, particularly in fresh and\ncounterfactual contexts. This work sheds light on a new path for LLMs to\nadvance towards genuine causal reasoning, going beyond level-1 and making\nstrides towards level-2.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u771f\u5b9e\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u4ec5\u80fd\u8fdb\u884c\u6d45\u5c42\uff08level-1\uff09\u63a8\u7406\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u6c34\u5e73\uff08level-2\uff09\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u65b0\u65b9\u6cd5G\u00b2-Reasoner\uff0c\u7ed3\u5408\u901a\u7528\u77e5\u8bc6\u548c\u76ee\u6807\u5bfc\u5411\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u7814\u7a76LLMs\u662f\u5426\u5177\u5907\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\uff0c\u63ed\u793a\u5176\u5c40\u9650\u6027\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u5206\u6790transformer LLMs\u7684\u81ea\u56de\u5f52\u673a\u5236\uff0c\u63d0\u51faCausalProbe-2024\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f00\u53d1G\u00b2-Reasoner\u65b9\u6cd5\uff0c\u7ed3\u5408\u901a\u7528\u77e5\u8bc6\u548c\u76ee\u6807\u5bfc\u5411\u63d0\u793a\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u4ec5\u80fd\u8fdb\u884clevel-1\u56e0\u679c\u63a8\u7406\uff0c\u800cG\u00b2-Reasoner\u663e\u8457\u63d0\u5347\u4e86\u5176\u5728\u65b0\u9c9c\u548c\u53cd\u4e8b\u5b9e\u4e0a\u4e0b\u6587\u4e2d\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "G\u00b2-Reasoner\u4e3aLLMs\u5b9e\u73b0level-2\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u63ed\u793a\u4e86\u8d85\u8d8a\u6d45\u5c42\u63a8\u7406\u7684\u53ef\u80fd\u6027\u3002", "keywords": "\u56e0\u679c\u63a8\u7406,\u5927\u8bed\u8a00\u6a21\u578b,G\u00b2-Reasoner,CausalProbe-2024"}}
{"id": "2506.20705", "pdf": "https://arxiv.org/pdf/2506.20705", "abs": "https://arxiv.org/abs/2506.20705", "authors": ["Kin Kwan Leung", "Rasa Hosseinzadeh", "Gabriel Loaiza-Ganem"], "title": "On Convolutions, Intrinsic Dimension, and Diffusion Models", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "The manifold hypothesis asserts that data of interest in high-dimensional\nambient spaces, such as image data, lies on unknown low-dimensional\nsubmanifolds. Diffusion models (DMs) -- which operate by convolving data with\nprogressively larger amounts of Gaussian noise and then learning to revert this\nprocess -- have risen to prominence as the most performant generative models,\nand are known to be able to learn distributions with low-dimensional support.\nFor a given datum in one of these submanifolds, we should thus intuitively\nexpect DMs to have implicitly learned its corresponding local intrinsic\ndimension (LID), i.e. the dimension of the submanifold it belongs to. Kamkari\net al. (2024b) recently showed that this is indeed the case by linking this LID\nto the rate of change of the log marginal densities of the DM with respect to\nthe amount of added noise, resulting in an LID estimator known as FLIPD. LID\nestimators such as FLIPD have a plethora of uses, among others they quantify\nthe complexity of a given datum, and can be used to detect outliers,\nadversarial examples and AI-generated text. FLIPD achieves state-of-the-art\nperformance at LID estimation, yet its theoretical underpinnings are incomplete\nsince Kamkari et al. (2024b) only proved its correctness under the highly\nunrealistic assumption of affine submanifolds. In this work we bridge this gap\nby formally proving the correctness of FLIPD under realistic assumptions.\nAdditionally, we show that an analogous result holds when Gaussian convolutions\nare replaced with uniform ones, and discuss the relevance of this result.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20923", "pdf": "https://arxiv.org/pdf/2506.20923", "abs": "https://arxiv.org/abs/2506.20923", "authors": ["Xinping Zhao", "Xinshuo Hu", "Zifei Shan", "Shouzheng Huang", "Yao Zhou", "Zetian Sun", "Zhenyu Liu", "Dongfang Li", "Xinyuan Wei", "Qian Chen", "Youcheng Pan", "Yang Xiang", "Meishan Zhang", "Haofen Wang", "Jun Yu", "Baotian Hu", "Min Zhang"], "title": "KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model", "categories": ["cs.CL"], "comment": "Technical Report; 26 pages 12 tables 1 figure. arXiv admin note:\n  substantial text overlap with arXiv:2501.01028", "summary": "In this paper, we propose KaLM-Embedding-V2, a versatile and compact\nembedding model, which achieves impressive performance in general-purpose text\nembedding tasks by leveraging superior training techniques and data. Our key\ninnovations include: (1) To better align the architecture with representation\nlearning, we remove the causal attention mask and adopt a fully bidirectional\ntransformer with simple yet effective mean-pooling to produce fixed-length\nembeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on\nlarge-scale weakly supervised open-source corpora; (ii) fine-tuning on\nhigh-quality retrieval and non-retrieval datasets; and (iii) model-soup\nparameter averaging for robust generalization. Besides, we introduce a\nfocal-style reweighting mechanism that concentrates learning on difficult\nsamples and an online hard-negative mixing strategy to continuously enrich hard\nnegatives without expensive offline mining; (3) We collect over 20 categories\nof data for pre-training and 100 categories of data for fine-tuning, to boost\nboth the performance and generalization of the embedding model. Extensive\nevaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English\nshow that our model significantly outperforms others of comparable size, and\ncompetes with 3x, 14x, 18x, and 26x larger embedding models, setting a new\nstandard for a versatile and compact embedding model with less than 1B\nparameters.", "AI": {"tldr": "\u63d0\u51faKaLM-Embedding-V2\uff0c\u4e00\u79cd\u591a\u529f\u80fd\u4e14\u7d27\u51d1\u7684\u5d4c\u5165\u6a21\u578b\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u8bad\u7ec3\u6280\u672f\u548c\u6570\u636e\u5728\u901a\u7528\u6587\u672c\u5d4c\u5165\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5d4c\u5165\u6a21\u578b\u5728\u6027\u80fd\u548c\u901a\u7528\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u548c\u6570\u636e\u7b56\u7565\u3002", "method": "1. \u91c7\u7528\u53cc\u5411Transformer\u548c\u5747\u503c\u6c60\u5316\u751f\u6210\u56fa\u5b9a\u957f\u5ea6\u5d4c\u5165\uff1b2. \u591a\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1b3. \u5f15\u5165\u7126\u70b9\u5f0f\u91cd\u52a0\u6743\u548c\u5728\u7ebf\u96be\u8d1f\u6837\u672c\u6df7\u5408\u7b56\u7565\u3002", "result": "\u5728MTEB\u4e2d\u663e\u8457\u4f18\u4e8e\u540c\u7c7b\u6a21\u578b\uff0c\u751a\u81f3\u4e0e\u5927\u6a21\u578b\u7ade\u4e89\u3002", "conclusion": "KaLM-Embedding-V2\u4e3a\u7d27\u51d1\u578b\u5d4c\u5165\u6a21\u578b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002", "keywords": "\u6587\u672c\u5d4c\u5165, Transformer, \u591a\u9636\u6bb5\u8bad\u7ec3, MTEB"}}
{"id": "2506.21230", "pdf": "https://arxiv.org/pdf/2506.21230", "abs": "https://arxiv.org/abs/2506.21230", "authors": ["Junhao Shi", "Zhaoye Fei", "Siyin Wang", "Qipeng Guo", "Jingjing Gong", "Xipeng QIu"], "title": "World-aware Planning Narratives Enhance Large Vision-Language Model Planner", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Large Vision-Language Models (LVLMs) show promise for embodied planning tasks\nbut struggle with complex scenarios involving unfamiliar environments and\nmulti-step goals. Current approaches rely on environment-agnostic imitation\nlearning that disconnects instructions from environmental contexts, causing\nmodels to struggle with context-sensitive instructions and rely on\nsupplementary cues rather than visual reasoning during long-horizon\ninteractions. In this work, we propose World-Aware Planning Narrative\nEnhancement (WAP), a framework that infuses LVLMs with comprehensive\nenvironmental understanding through four cognitive capabilities (visual\nappearance modeling, spatial reasoning, functional abstraction, and syntactic\ngrounding) while developing and evaluating models using only raw visual\nobservations through curriculum learning. Evaluations on the EB-ALFRED\nbenchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a\n60.7 absolute improvement in task success rates, particularly in commonsense\nreasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced\nopen-source models outperform proprietary systems like GPT-4o and\nClaude-3.5-Sonnet by a large margin.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWAP\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u79cd\u8ba4\u77e5\u80fd\u529b\u63d0\u5347\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u73af\u5883\u611f\u77e5\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u573a\u666f\u548c\u957f\u65f6\u7a0b\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u5176\u7f3a\u4e4f\u5bf9\u73af\u5883\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86World-Aware Planning Narrative Enhancement (WAP)\u6846\u67b6\uff0c\u901a\u8fc7\u56db\u79cd\u8ba4\u77e5\u80fd\u529b\uff08\u89c6\u89c9\u5916\u89c2\u5efa\u6a21\u3001\u7a7a\u95f4\u63a8\u7406\u3001\u529f\u80fd\u62bd\u8c61\u548c\u8bed\u6cd5\u57fa\u7840\uff09\u548c\u73af\u5883\u611f\u77e5\u7684\u8bfe\u7a0b\u5b66\u4e60\uff0c\u63d0\u5347\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728EB-ALFRED\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4efb\u52a1\u6210\u529f\u7387\u5927\u5e45\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u5e38\u8bc6\u63a8\u7406\u548c\u957f\u65f6\u7a0b\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "WAP\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u73af\u5883\u611f\u77e5\u80fd\u529b\uff0c\u5176\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u4e13\u6709\u7cfb\u7edf\u3002", "keywords": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b, \u73af\u5883\u611f\u77e5, \u8bfe\u7a0b\u5b66\u4e60, \u8ba4\u77e5\u80fd\u529b, EB-ALFRED\u57fa\u51c6"}}
{"id": "2506.20729", "pdf": "https://arxiv.org/pdf/2506.20729", "abs": "https://arxiv.org/abs/2506.20729", "authors": ["Zhiqi Gao", "Tianyi Li", "Yurii Kvasiuk", "Sai Chaitanya Tadepalli", "Maja Rudolph", "Daniel J. H. Chung", "Frederic Sala", "Moritz M\u00fcnchmeyer"], "title": "Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset", "categories": ["cs.LG", "astro-ph.CO", "cs.AI", "hep-ph", "hep-th"], "comment": "23 pages, 6 figures", "summary": "Large language models (LLMs) have shown strong capabilities in complex\nreasoning, and test-time scaling techniques can enhance their performance with\ncomparably low cost. Many of these methods have been developed and evaluated on\nmathematical reasoning benchmarks such as AIME. This paper investigates whether\nthe lessons learned from these benchmarks generalize to the domain of advanced\ntheoretical physics. We evaluate a range of common test-time scaling methods on\nthe TPBench physics dataset and compare their effectiveness with results on\nAIME. To better leverage the structure of physics problems, we develop a novel,\nsymbolic weak-verifier framework to improve parallel scaling results. Our\nempirical results demonstrate that this method significantly outperforms\nexisting test-time scaling approaches on TPBench. We also evaluate our method\non AIME, confirming its effectiveness in solving advanced mathematical\nproblems. Our findings highlight the power of step-wise symbolic verification\nfor tackling complex scientific problems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9ad8\u7ea7\u7406\u8bba\u7269\u7406\u9886\u57df\u7684\u8868\u73b0\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u7b26\u53f7\u5f31\u9a8c\u8bc1\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728TPBench\u7269\u7406\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8\u4ece\u6570\u5b66\u63a8\u7406\u57fa\u51c6\uff08\u5982AIME\uff09\u4e2d\u5b66\u5230\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u662f\u5426\u80fd\u63a8\u5e7f\u5230\u9ad8\u7ea7\u7406\u8bba\u7269\u7406\u9886\u57df\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u7b26\u53f7\u5f31\u9a8c\u8bc1\u6846\u67b6\uff0c\u5229\u7528\u7269\u7406\u95ee\u9898\u7684\u7ed3\u6784\u63d0\u5347\u5e76\u884c\u6269\u5c55\u6548\u679c\u3002", "result": "\u65b0\u65b9\u6cd5\u5728TPBench\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\uff0c\u5e76\u5728AIME\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5206\u6b65\u7b26\u53f7\u9a8c\u8bc1\u662f\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u95ee\u9898\u7684\u6709\u6548\u5de5\u5177\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u7406\u8bba\u7269\u7406, \u6d4b\u8bd5\u65f6\u6269\u5c55, \u7b26\u53f7\u9a8c\u8bc1"}}
{"id": "2506.20989", "pdf": "https://arxiv.org/pdf/2506.20989", "abs": "https://arxiv.org/abs/2506.20989", "authors": ["Eric Zhang", "Leshem Choshen", "Jacob Andreas"], "title": "Can Gradient Descent Simulate Prompting?", "categories": ["cs.CL", "cs.LG"], "comment": "14 pages, 2 figures", "summary": "There are two primary ways of incorporating new information into a language\nmodel (LM): changing its prompt or changing its parameters, e.g. via\nfine-tuning. Parameter updates incur no long-term storage cost for model\nchanges. However, for many model updates, prompting is significantly more\neffective: prompted models can generalize robustly from single examples and\ndraw logical inferences that do not occur under standard fine-tuning. Can\nmodels be modified so that fine-tuning does emulate prompting? This paper\ndescribes a method for meta-training LMs such that gradient updates emulate the\neffects of conditioning on new information. Our approach uses tools from\ngradient-based meta-learning but uses an LM's own prompted predictions as\ntargets, eliminating the need for ground-truth labels. Subsequent gradient\ndescent training recovers some (and occasionally all) of prompted model\nperformance -- showing improvement on the ``reversal curse'' tasks, and\nanswering questions about text passages after a single gradient update. These\nresults suggest that, with appropriate initialization, gradient descent can be\nsurprisingly expressive. Our results suggest new avenues for long-context\nmodeling and offer insight into the generalization capabilities of\ngradient-based learning.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u4ee5\u6a21\u62df\u63d0\u793a\u6548\u679c\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u521d\u59cb\u5316\u4e0b\uff0c\u68af\u5ea6\u4e0b\u964d\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u4f7f\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u63d0\u793a\u7684\u6548\u679c\uff0c\u4ee5\u7ed3\u5408\u63d0\u793a\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u548c\u53c2\u6570\u66f4\u65b0\u7684\u4f4e\u6210\u672c\u4f18\u52bf\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u63d0\u793a\u9884\u6d4b\u4f5c\u4e3a\u76ee\u6807\uff0c\u65e0\u9700\u771f\u5b9e\u6807\u7b7e\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u6a21\u62df\u63d0\u793a\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u68af\u5ea6\u4e0b\u964d\u80fd\u90e8\u5206\u6216\u5b8c\u5168\u6062\u590d\u63d0\u793a\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u201c\u53cd\u8f6c\u8bc5\u5492\u201d\u4efb\u52a1\u548c\u6587\u672c\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\u68af\u5ea6\u4e0b\u964d\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u5177\u6709\u5f3a\u5927\u8868\u8fbe\u80fd\u529b\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u68af\u5ea6\u5b66\u4e60\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "keywords": "\u8bed\u8a00\u6a21\u578b, \u68af\u5ea6\u4e0b\u964d, \u5143\u5b66\u4e60, \u63d0\u793a, \u6cdb\u5316"}}
{"id": "2506.21310", "pdf": "https://arxiv.org/pdf/2506.21310", "abs": "https://arxiv.org/abs/2506.21310", "authors": ["Pauline Speckmann", "Mario Nadj", "Christian Janiesch"], "title": "IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems", "categories": ["cs.AI", "cs.SE", "K.6.3 Software Management"], "comment": "9 pages, 2 figures, accepted to DESRIST 2025 Prototype Track", "summary": "Although several post-hoc methods for explainable AI have been developed,\nmost are static and neglect the user perspective, limiting their effectiveness\nfor the target audience. In response, we developed the interactive explainable\nintelligent system called IXAII that offers explanations from four explainable\nAI methods: LIME, SHAP, Anchors, and DiCE. Our prototype provides tailored\nviews for five user groups and gives users agency over the explanations'\ncontent and their format. We evaluated IXAII through interviews with experts\nand lay users. Our results indicate that IXAII, which provides different\nexplanations with multiple visualization options, is perceived as helpful to\nincrease transparency. By bridging the gaps between explainable AI methods,\ninteractivity, and practical implementation, we provide a novel perspective on\nAI explanation practices and human-AI interaction.", "AI": {"tldr": "IXAII\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7684\u53ef\u89e3\u91caAI\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u591a\u79cd\u89e3\u91ca\u65b9\u6cd5\uff08LIME\u3001SHAP\u3001Anchors\u3001DiCE\uff09\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u63d0\u4f9b\u5b9a\u5236\u5316\u89c6\u56fe\u548c\u89e3\u91ca\u5185\u5bb9\u3002", "motivation": "\u73b0\u6709\u7684AI\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u591a\u4e3a\u9759\u6001\u4e14\u5ffd\u89c6\u4e86\u7528\u6237\u89c6\u89d2\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u6548\u679c\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86IXAII\u4ee5\u63d0\u5347\u900f\u660e\u5ea6\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u7cfb\u7edfIXAII\uff0c\u6574\u5408\u4e86LIME\u3001SHAP\u3001Anchors\u548cDiCE\u56db\u79cd\u89e3\u91ca\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5b9a\u5236\u5316\u89c6\u56fe\u548c\u7528\u6237\u53ef\u63a7\u7684\u89e3\u91ca\u683c\u5f0f\u3002", "result": "\u901a\u8fc7\u4e13\u5bb6\u548c\u666e\u901a\u7528\u6237\u7684\u8bbf\u8c08\u8bc4\u4f30\uff0cIXAII\u56e0\u5176\u591a\u6837\u5316\u7684\u89e3\u91ca\u548c\u53ef\u89c6\u5316\u9009\u9879\u88ab\u8ba4\u4e3a\u6709\u52a9\u4e8e\u589e\u5f3a\u900f\u660e\u5ea6\u3002", "conclusion": "IXAII\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u89e3\u91ca\u65b9\u6cd5\u548c\u4ea4\u4e92\u6027\uff0c\u4e3aAI\u89e3\u91ca\u5b9e\u8df5\u548c\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "keywords": "\u53ef\u89e3\u91caAI, \u4ea4\u4e92\u5f0f\u7cfb\u7edf, \u7528\u6237\u89c6\u89d2, \u900f\u660e\u5ea6, LIME, SHAP"}}
{"id": "2506.20743", "pdf": "https://arxiv.org/pdf/2506.20743", "abs": "https://arxiv.org/abs/2506.20743", "authors": ["Minh-Hao Van", "Prateek Verma", "Chen Zhao", "Xintao Wu"], "title": "A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Foundation models (FMs) are catalyzing a transformative shift in materials\nscience (MatSci) by enabling scalable, general-purpose, and multimodal AI\nsystems for scientific discovery. Unlike traditional machine learning models,\nwhich are typically narrow in scope and require task-specific engineering, FMs\noffer cross-domain generalization and exhibit emergent capabilities. Their\nversatility is especially well-suited to materials science, where research\nchallenges span diverse data types and scales. This survey provides a\ncomprehensive overview of foundation models, agentic systems, datasets, and\ncomputational tools supporting this growing field. We introduce a task-driven\ntaxonomy encompassing six broad application areas: data extraction,\ninterpretation and Q\\&A; atomistic simulation; property prediction; materials\nstructure, design and discovery; process planning, discovery, and optimization;\nand multiscale modeling. We discuss recent advances in both unimodal and\nmultimodal FMs, as well as emerging large language model (LLM) agents.\nFurthermore, we review standardized datasets, open-source tools, and autonomous\nexperimental platforms that collectively fuel the development and integration\nof FMs into research workflows. We assess the early successes of foundation\nmodels and identify persistent limitations, including challenges in\ngeneralizability, interpretability, data imbalance, safety concerns, and\nlimited multimodal fusion. Finally, we articulate future research directions\ncentered on scalable pretraining, continual learning, data governance, and\ntrustworthiness.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u7840\u6a21\u578b\uff08FM\uff09\u5728\u6750\u6599\u79d1\u5b66\uff08MatSci\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u6db5\u76d6\u4e86\u5176\u4f18\u52bf\u3001\u5e94\u7528\u9886\u57df\u53ca\u6311\u6218\u3002", "motivation": "\u6750\u6599\u79d1\u5b66\u7814\u7a76\u9762\u4e34\u591a\u6837\u5316\u7684\u6570\u636e\u7c7b\u578b\u548c\u5c3a\u5ea6\u6311\u6218\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u96be\u4ee5\u80dc\u4efb\u3002FM\u56e0\u5176\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u548c\u591a\u6a21\u6001\u7279\u6027\uff0c\u4e3a\u6750\u6599\u79d1\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4efb\u52a1\u9a71\u52a8\u7684\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u6570\u636e\u63d0\u53d6\u3001\u539f\u5b50\u6a21\u62df\u3001\u6027\u8d28\u9884\u6d4b\u7b49\u516d\u5927\u5e94\u7528\u9886\u57df\uff0c\u5e76\u7efc\u8ff0\u4e86\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001FM\u3001LLM\u4ee3\u7406\u4ee5\u53ca\u76f8\u5173\u5de5\u5177\u548c\u5e73\u53f0\u3002", "result": "FM\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u5df2\u53d6\u5f97\u521d\u6b65\u6210\u529f\uff0c\u4f46\u4ecd\u9762\u4e34\u6cdb\u5316\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6570\u636e\u4e0d\u5e73\u8861\u7b49\u5c40\u9650\u6027\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6269\u5c55\u9884\u8bad\u7ec3\u3001\u6301\u7eed\u5b66\u4e60\u3001\u6570\u636e\u6cbb\u7406\u548c\u53ef\u4fe1\u5ea6\u63d0\u5347\u3002", "keywords": "\u57fa\u7840\u6a21\u578b\uff1b\u6750\u6599\u79d1\u5b66\uff1b\u591a\u6a21\u6001AI\uff1b\u6570\u636e\u6cbb\u7406\uff1b\u6301\u7eed\u5b66\u4e60"}}
{"id": "2506.20993", "pdf": "https://arxiv.org/pdf/2506.20993", "abs": "https://arxiv.org/abs/2506.20993", "authors": ["Adithya Chittem", "Aishna Shrivastava", "Sai Tarun Pendela", "Jagat Sesh Challa", "Dhruv Kumar"], "title": "SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Under review", "summary": "Large language models (LLMs) have gained significant traction across a wide\nrange of fields in recent years. There is also a growing expectation for them\nto display human-like personalities during interactions. To meet this\nexpectation, numerous studies have proposed methods for modelling LLM\npersonalities through psychometric evaluations. However, most existing models\nface two major limitations: they rely on the Big Five (OCEAN) framework, which\nonly provides coarse personality dimensions, and they lack mechanisms for\ncontrolling trait intensity. In this paper, we address this gap by extending\nthe Machine Personality Inventory (MPI), which originally used the Big Five\nmodel, to incorporate the 16 Personality Factor (16PF) model, allowing\nexpressive control over sixteen distinct traits. We also developed a structured\nframework known as Specific Attribute Control (SAC) for evaluating and\ndynamically inducing trait intensity in LLMs. Our method introduces\nadjective-based semantic anchoring to guide trait intensity expression and\nleverages behavioural questions across five intensity factors:\n\\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and\n\\textit{Willingness}. Through experimentation, we find that modelling intensity\nas a continuous spectrum yields substantially more consistent and controllable\npersonality expression compared to binary trait toggling. Moreover, we observe\nthat changes in target trait intensity systematically influence closely related\ntraits in psychologically coherent directions, suggesting that LLMs internalize\nmulti-dimensional personality structures rather than treating traits in\nisolation. Our work opens new pathways for controlled and nuanced human-machine\ninteractions in domains such as healthcare, education, and interviewing\nprocesses, bringing us one step closer to truly human-like social machines.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684LLM\u4e2a\u6027\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c5516PF\u6a21\u578b\u548c\u5f15\u5165SAC\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5bf916\u79cd\u7279\u8d28\u7684\u8868\u8fbe\u5f3a\u5ea6\u63a7\u5236\u3002", "motivation": "\u73b0\u6709LLM\u4e2a\u6027\u6a21\u578b\u53d7\u9650\u4e8eBig Five\u6846\u67b6\u7684\u7c97\u7c92\u5ea6\u548c\u7f3a\u4e4f\u5f3a\u5ea6\u63a7\u5236\u673a\u5236\u3002", "method": "\u6269\u5c55MPI\u81f316PF\u6a21\u578b\uff0c\u5f00\u53d1SAC\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5bb9\u8bcd\u951a\u5b9a\u548c\u4e94\u7ef4\u5f3a\u5ea6\u56e0\u7d20\u52a8\u6001\u63a7\u5236\u7279\u8d28\u5f3a\u5ea6\u3002", "result": "\u8fde\u7eed\u5f3a\u5ea6\u8c31\u6bd4\u4e8c\u5143\u5207\u6362\u66f4\u4e00\u81f4\u53ef\u63a7\uff0c\u7279\u8d28\u5f3a\u5ea6\u53d8\u5316\u5bf9\u76f8\u5173\u7279\u8d28\u6709\u7cfb\u7edf\u6027\u5f71\u54cd\u3002", "conclusion": "\u65b9\u6cd5\u4e3a\u533b\u7597\u3001\u6559\u80b2\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u7684\u4eba\u673a\u4ea4\u4e92\u9014\u5f84\u3002", "keywords": "LLM, 16PF, SAC, personality modelling, human-like interaction"}}
{"id": "2506.21329", "pdf": "https://arxiv.org/pdf/2506.21329", "abs": "https://arxiv.org/abs/2506.21329", "authors": ["Karthik Duraisamy"], "title": "Active Inference AI Systems for Scientific Discovery", "categories": ["cs.AI", "physics.soc-ph", "68", "I.2"], "comment": null, "summary": "The rapid evolution of artificial intelligence has led to expectations of\ntransformative scientific discovery, yet current systems remain fundamentally\nlimited by their operational architectures, brittle reasoning mechanisms, and\ntheir separation from experimental reality. Building on earlier work, we\ncontend that progress in AI-driven science now depends on closing three\nfundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap\n-- rather than on model size/data/test time compute. Scientific reasoning\ndemands internal representations that support simulation of actions and\nresponse, causal structures that distinguish correlation from mechanism, and\ncontinuous calibration. We define active inference AI systems for scientific\ndiscovery as those that (i) maintain long-lived research memories grounded in\ncausal self-supervised foundation models, (ii) symbolic or neuro-symbolic\nplanners equipped with Bayesian guardrails, (iii) grow persistent knowledge\ngraphs where thinking generates novel conceptual nodes, reasoning establishes\ncausal edges, and real-world interaction prunes false connections while\nstrengthening verified pathways, and (iv) refine their internal representations\nthrough closed-loop interaction with both high-fidelity simulators and\nautomated laboratories - an operational loop where mental simulation guides\naction and empirical surprise reshapes understanding. In essence, we outline an\narchitecture where discovery arises from the interplay between internal models\nthat enable counterfactual reasoning and external validation that grounds\nhypotheses in reality. It is also argued that the inherent ambiguity in\nfeedback from simulations and experiments, and underlying uncertainties makes\nhuman judgment indispensable, not as a temporary scaffold but as a permanent\narchitectural component.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u9a71\u52a8\u79d1\u5b66\u53d1\u5c55\u6240\u9700\u89e3\u51b3\u7684\u4e09\u5927\u6838\u5fc3\u95ee\u9898\uff1a\u62bd\u8c61\u3001\u63a8\u7406\u4e0e\u73b0\u5b9e\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684AI\u7cfb\u7edf\u67b6\u6784\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u5b58\u5728\u64cd\u4f5c\u67b6\u6784\u3001\u8106\u5f31\u7684\u63a8\u7406\u673a\u5236\u53ca\u4e0e\u5b9e\u9a8c\u73b0\u5b9e\u7684\u5206\u79bb\u95ee\u9898\uff0c\u963b\u788d\u4e86\u5176\u98a0\u8986\u6027\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e3b\u52a8\u63a8\u7406AI\u7cfb\u7edf\uff0c\u7ed3\u5408\u56e0\u679c\u81ea\u76d1\u7763\u57fa\u7840\u6a21\u578b\u3001\u8d1d\u53f6\u65af\u89c4\u5212\u5668\u3001\u6301\u4e45\u77e5\u8bc6\u56fe\u8c31\u53ca\u95ed\u73af\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u5185\u90e8\u6a21\u578b\u4e0e\u5916\u90e8\u9a8c\u8bc1\u7684\u4ea4\u4e92\u5b9e\u73b0\u79d1\u5b66\u53d1\u73b0\uff0c\u5e76\u5f3a\u8c03\u4e86\u4eba\u7c7b\u5224\u65ad\u5728\u5176\u4e2d\u7684\u6301\u4e45\u91cd\u8981\u6027\u3002", "conclusion": "\u672a\u6765AI\u9a71\u52a8\u79d1\u5b66\u4f9d\u8d56\u4e8e\u586b\u8865\u4e09\u5927\u6838\u5fc3\u5dee\u8ddd\uff0c\u5e76\u6784\u5efa\u7ed3\u5408\u5185\u90e8\u63a8\u7406\u4e0e\u5916\u90e8\u9a8c\u8bc1\u7684\u4f53\u7cfb\uff0c\u540c\u65f6\u4eba\u7c7b\u89d2\u8272\u4e0d\u53ef\u6216\u7f3a\u3002", "keywords": "AI\u9a71\u52a8\u79d1\u5b66, \u4e3b\u52a8\u63a8\u7406, \u56e0\u679c\u6a21\u578b, \u77e5\u8bc6\u56fe\u8c31, \u5b9e\u9a8c\u95ed\u73af"}}
{"id": "2506.20746", "pdf": "https://arxiv.org/pdf/2506.20746", "abs": "https://arxiv.org/abs/2506.20746", "authors": ["Todd Nief", "David Reber", "Sean Richardson", "Ari Holtzman"], "title": "Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers", "categories": ["cs.LG"], "comment": null, "summary": "When an LLM learns a relation during finetuning (e.g., new movie releases,\ncorporate mergers, etc.), where does this information go? Is it extracted when\nthe model processes an entity, recalled just-in-time before a prediction, or\nare there multiple separate heuristics? Existing localization approaches (e.g.\nactivation patching) are ill-suited for this analysis because they tend to\nreplace parts of the residual stream, potentially deleting information. To fill\nthis gap, we propose dynamic weight-grafting between fine-tuned and pre-trained\nlanguage models to show that fine-tuned language models both (1) extract\nrelation information learned during finetuning while processing entities and\n(2) ``recall\" this information in later layers while generating predictions. In\nsome cases, models need both of these pathways to correctly generate finetuned\ninformation while, in other cases, a single ``enrichment\" or ``recall\" pathway\nalone is sufficient. We examine the necessity and sufficiency of these\ninformation pathways, examining what layers they occur at, how much redundancy\nthey exhibit, and which model components are involved -- finding that the\n``recall\" pathway occurs via both task-specific attention mechanisms and a\nrelation extraction step in the output of the attention and the feedforward\nnetworks at the final layers before next token prediction.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86LLM\u5728\u5fae\u8c03\u65f6\u5b66\u4e60\u7684\u5173\u7cfb\u4fe1\u606f\u7684\u5b58\u50a8\u548c\u63d0\u53d6\u65b9\u5f0f\uff0c\u63d0\u51fa\u4e86\u52a8\u6001\u6743\u91cd\u5ac1\u63a5\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4fe1\u606f\u5728\u6a21\u578b\u4e2d\u7684\u4e24\u79cd\u8def\u5f84\uff1a\u63d0\u53d6\u548c\u201c\u56de\u5fc6\u201d\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u7406\u89e3LLM\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u7684\u5173\u7cfb\u4fe1\u606f\u5982\u4f55\u5728\u6a21\u578b\u4e2d\u5b58\u50a8\u548c\u63d0\u53d6\uff0c\u586b\u8865\u73b0\u6709\u5c40\u90e8\u5316\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u52a8\u6001\u6743\u91cd\u5ac1\u63a5\u6280\u672f\uff0c\u5bf9\u6bd4\u5fae\u8c03\u6a21\u578b\u548c\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5206\u6790\u5173\u7cfb\u4fe1\u606f\u7684\u63d0\u53d6\u548c\u201c\u56de\u5fc6\u201d\u8def\u5f84\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u4fe1\u606f\u901a\u8fc7\u4e24\u79cd\u8def\u5f84\u5904\u7406\uff1a\u5b9e\u4f53\u5904\u7406\u65f6\u7684\u63d0\u53d6\u548c\u9884\u6d4b\u65f6\u7684\u201c\u56de\u5fc6\u201d\uff0c\u4e14\u8def\u5f84\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\u56e0\u60c5\u51b5\u800c\u5f02\u3002", "conclusion": "LLM\u901a\u8fc7\u7279\u5b9a\u6ce8\u610f\u529b\u673a\u5236\u548c\u5173\u7cfb\u63d0\u53d6\u6b65\u9aa4\u5b9e\u73b0\u4fe1\u606f\u7684\u201c\u56de\u5fc6\u201d\uff0c\u63ed\u793a\u4e86\u5fae\u8c03\u4fe1\u606f\u5904\u7406\u7684\u591a\u8def\u5f84\u673a\u5236\u3002", "keywords": "LLM, fine-tuning, relation information, dynamic weight-grafting, localization approaches"}}
{"id": "2506.21031", "pdf": "https://arxiv.org/pdf/2506.21031", "abs": "https://arxiv.org/abs/2506.21031", "authors": ["Jatin Gupta", "Akhil Sharma", "Saransh Singhania", "Mohammad Adnan", "Sakshi Deo", "Ali Imam Abidi", "Keshav Gupta"], "title": "Large Language Models Acing Chartered Accountancy", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted for publication at MoStart 2025: International Conference on\n  Digital Transformation in Education and Applications of Artificial\n  Intelligence, Bosnia and Herzegovina, 2025", "summary": "Advanced intelligent systems, particularly Large Language Models (LLMs), are\nsignificantly reshaping financial practices through advancements in Natural\nLanguage Processing (NLP). However, the extent to which these models\neffectively capture and apply domain-specific financial knowledge remains\nuncertain. Addressing a critical gap in the expansive Indian financial context,\nthis paper introduces CA-Ben, a Chartered Accountancy benchmark specifically\ndesigned to evaluate the financial, legal, and quantitative reasoning\ncapabilities of LLMs. CA-Ben comprises structured question-answer datasets\nderived from the rigorous examinations conducted by the Institute of Chartered\nAccountants of India (ICAI), spanning foundational, intermediate, and advanced\nCA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1\n405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated\nusing standardized protocols. Results indicate variations in performance, with\nClaude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and\nlegal reasoning. Notable challenges emerged in numerical computations and legal\ninterpretations. The findings emphasize the strengths and limitations of\ncurrent LLMs, suggesting future improvements through hybrid reasoning and\nretrieval-augmented generation methods, particularly for quantitative analysis\nand accurate legal interpretation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86CA-Ben\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u548c\u5b9a\u91cf\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u5728\u5370\u5ea6\u8d22\u52a1\u80cc\u666f\u4e0b\u6d4b\u8bd5\u4e86\u591a\u79cd\u6a21\u578b\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u586b\u8865\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u91d1\u878d\u9886\u57df\u77e5\u8bc6\u5e94\u7528\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u7279\u522b\u662f\u5728\u5370\u5ea6\u8d22\u52a1\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7CA-Ben\u57fa\u51c6\uff08\u57fa\u4e8e\u5370\u5ea6\u7279\u8bb8\u4f1a\u8ba1\u5e08\u8003\u8bd5\u9898\u5e93\uff09\u8bc4\u4f30\u516d\u79cd\u4e3b\u6d41LLM\uff0c\u91c7\u7528\u6807\u51c6\u5316\u534f\u8bae\u8fdb\u884c\u5206\u6790\u3002", "result": "Claude 3.5 Sonnet\u548cGPT-4o\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u5728\u6982\u5ff5\u548c\u6cd5\u5f8b\u63a8\u7406\u65b9\u9762\uff0c\u4f46\u6570\u503c\u8ba1\u7b97\u548c\u6cd5\u5f8b\u89e3\u91ca\u4ecd\u662f\u6311\u6218\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u91d1\u878d\u9886\u57df\u5b58\u5728\u5c40\u9650\u6027\uff0c\u672a\u6765\u9700\u7ed3\u5408\u6df7\u5408\u63a8\u7406\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u6539\u8fdb\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b, \u91d1\u878d\u77e5\u8bc6, CA-Ben\u57fa\u51c6, \u5370\u5ea6\u7279\u8bb8\u4f1a\u8ba1\u5e08, \u6cd5\u5f8b\u63a8\u7406"}}
{"id": "2506.21393", "pdf": "https://arxiv.org/pdf/2506.21393", "abs": "https://arxiv.org/abs/2506.21393", "authors": ["Junwen Zhang", "Pu Chen", "Yin Zhang"], "title": "TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding", "categories": ["cs.AI", "68T07 (Primary), 68T50, 68T30, 68T45 (Secondary)", "F.2.2; I.2.7; I.2.10"], "comment": "43 pages and 11 figures", "summary": "Multimodal understanding of tables in real-world contexts is challenging due\nto the complexity of structure, symbolic density, and visual degradation (blur,\nskew, watermarking, incomplete structures or fonts, multi-span or\nhierarchically nested layouts). Existing multimodal large language models\n(MLLMs) struggle with such WildStruct conditions, resulting in limited\nperformance and poor generalization. To address these challenges, we propose\nTableMoE, a neuro-symbolic Mixture-of-Connector-Experts (MoCE) architecture\nspecifically designed for robust, structured reasoning over multimodal table\ndata. TableMoE features an innovative Neuro-Symbolic Routing mechanism, which\npredicts latent semantic token roles (e.g., header, data cell, axis, formula)\nand dynamically routes table elements to specialized experts (Table-to-HTML,\nTable-to-JSON, Table-to-Code) using a confidence-aware gating strategy informed\nby symbolic reasoning graphs. To facilitate effective alignment-driven\npretraining, we introduce the large-scale TableMoE-Align dataset, consisting of\n1.2M table-HTML-JSON-code quadruples across finance, science, biomedicine and\nindustry, utilized exclusively for model pretraining. For evaluation, we curate\nand release four challenging WildStruct benchmarks: WMMFinQA, WMMTatQA,\nWMMTabDialog, and WMMFinanceMath, designed specifically to stress-test models\nunder real-world multimodal degradation and structural complexity. Experimental\nresults demonstrate that TableMoE significantly surpasses existing\nstate-of-the-art models. Extensive ablation studies validate each core\ncomponent, emphasizing the critical role of Neuro-Symbolic Routing and\nstructured expert alignment. Through qualitative analyses, we further showcase\nTableMoE's interpretability and enhanced robustness, underscoring the\neffectiveness of integrating neuro-symbolic reasoning for multimodal table\nunderstanding.", "AI": {"tldr": "TableMoE\u662f\u4e00\u79cd\u4e13\u4e3a\u591a\u6a21\u6001\u8868\u683c\u6570\u636e\u8bbe\u8ba1\u7684\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u8fde\u63a5\u4e13\u5bb6\u67b6\u6784\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u795e\u7ecf\u7b26\u53f7\u8def\u7531\u673a\u5236\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u771f\u5b9e\u590d\u6742\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u8868\u683c\u7ed3\u6784\u3001\u7b26\u53f7\u5bc6\u5ea6\u9ad8\u53ca\u89c6\u89c9\u9000\u5316\u7b49\u95ee\u9898\u65f6\u7684\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u8fde\u63a5\u4e13\u5bb6\u67b6\u6784\uff08TableMoE\uff09\uff0c\u5f15\u5165\u795e\u7ecf\u7b26\u53f7\u8def\u7531\u673a\u5236\uff0c\u52a8\u6001\u5206\u914d\u8868\u683c\u5143\u7d20\u81f3\u4e13\u95e8\u4e13\u5bb6\u6a21\u5757\uff0c\u5e76\u5229\u7528\u5927\u89c4\u6a21\u6570\u636e\u96c6TableMoE-Align\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "TableMoE\u5728\u56db\u4e2aWildStruct\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6838\u5fc3\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u7684\u96c6\u6210\uff0cTableMoE\u5728\u591a\u6a21\u6001\u8868\u683c\u7406\u89e3\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u7a33\u5065\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "keywords": "\u591a\u6a21\u6001\u7406\u89e3\u3001\u8868\u683c\u5904\u7406\u3001\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u3001Mixture-of-Experts\u3001WildStruct"}}
{"id": "2506.20752", "pdf": "https://arxiv.org/pdf/2506.20752", "abs": "https://arxiv.org/abs/2506.20752", "authors": ["Huangyuan Su", "Mujin Kwun", "Stephanie Gil", "Sham Kakade", "Nikhil Anand"], "title": "Characterization and Mitigation of Training Instabilities in Microscaling Formats", "categories": ["cs.LG", "cs.AR"], "comment": "14 pages + appendices", "summary": "Training large language models is an expensive, compute-bound process that\nmust be repeated as models scale, algorithms improve, and new data is\ncollected. To address this, next-generation hardware accelerators increasingly\nsupport lower-precision arithmetic formats, such as the Microscaling (MX)\nformats introduced in NVIDIA's Blackwell architecture. These formats use a\nshared scale within blocks of parameters to extend representable range and\nperform forward/backward GEMM operations in reduced precision for efficiency\ngains. In this work, we investigate the challenges and viability of\nblock-scaled precision formats during model training. Across nearly one\nthousand language models trained from scratch -- spanning compute budgets from\n$2 \\times 10^{17}$ to $4.8 \\times 10^{19}$ FLOPs and sweeping over a broad\nrange of weight-activation precision combinations -- we consistently observe\nthat training in MX formats exhibits sharp, stochastic instabilities in the\nloss, particularly at larger compute scales. To explain this phenomenon, we\nconduct controlled experiments and ablations on a smaller proxy model that\nexhibits similar behavior as the language model, sweeping across architectural\nsettings, hyperparameters, and precision formats. These experiments motivate a\nsimple model in which multiplicative gradient bias introduced by the\nquantization of layer-norm affine parameters and a small fraction of\nactivations can trigger runaway divergence. Through \\emph{in situ} intervention\nexperiments on our proxy model, we demonstrate that instabilities can be\naverted or delayed by modifying precision schemes mid-training. Guided by these\nfindings, we evaluate stabilization strategies in the LLM setting and show that\ncertain hybrid configurations recover performance competitive with\nfull-precision training. We release our code at\nhttps://github.com/Hither1/systems-scaling.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4f4e\u7cbe\u5ea6\u7b97\u672f\u683c\u5f0f\uff08\u5982MX\u683c\u5f0f\uff09\u4e0b\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u51fa\u73b0\u7684\u635f\u5931\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u63d0\u51fa\u4e86\u4e00\u4e9b\u7a33\u5b9a\u7b56\u7565\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6210\u672c\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u7814\u7a76\u8005\u5728\u786c\u4ef6\u52a0\u901f\u5668\u4e2d\u5f15\u5165\u4e86\u4f4e\u7cbe\u5ea6\u7b97\u672f\u683c\u5f0f\uff08\u5982MX\u683c\u5f0f\uff09\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u683c\u5f0f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u5bfc\u81f4\u635f\u5931\u7684\u4e0d\u7a33\u5b9a\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u8ba1\u7b97\u65f6\u3002", "method": "\u901a\u8fc7\u5728\u4e00\u5343\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7814\u7a76\u8005\u53d1\u73b0MX\u683c\u5f0f\u8bad\u7ec3\u65f6\u4f1a\u51fa\u73b0\u635f\u5931\u4e0d\u7a33\u5b9a\u73b0\u8c61\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u548c\u6a21\u578b\u5206\u6790\uff0c\u53d1\u73b0\u8fd9\u79cd\u4e0d\u7a33\u5b9a\u662f\u7531\u68af\u5ea6\u504f\u5dee\u5f15\u8d77\u7684\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u8c03\u6574\u91cf\u5316\u7b56\u7565\u4e2d\u7684\u7cbe\u5ea6\u65b9\u6848\uff0c\u53ef\u4ee5\u907f\u514d\u6216\u5ef6\u8fdf\u4e0d\u7a33\u5b9a\u7684\u53d1\u751f\uff0c\u5e76\u5728\u67d0\u4e9b\u6df7\u5408\u914d\u7f6e\u4e0b\u6062\u590d\u4e0e\u5168\u7cbe\u5ea6\u8bad\u7ec3\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "MX\u683c\u5f0f\u867d\u7136\u80fd\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u4f1a\u5f15\u5165\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002\u901a\u8fc7\u8c03\u6574\u7cbe\u5ea6\u65b9\u6848\uff0c\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "keywords": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u4f4e\u7cbe\u5ea6\u7b97\u672f\u3001MX\u683c\u5f0f\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u91cf\u5316"}}
{"id": "2506.21049", "pdf": "https://arxiv.org/pdf/2506.21049", "abs": "https://arxiv.org/abs/2506.21049", "authors": ["Chunyuan Yuan", "Chong Zhang", "Zheng Fang", "Ming Pang", "Xue Jiang", "Changping Peng", "Zhangang Lin", "Ching Law"], "title": "A Semi-supervised Scalable Unified Framework for E-commerce Query Classification", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted by ACL 2025", "summary": "Query classification, including multiple subtasks such as intent and category\nprediction, is vital to e-commerce applications. E-commerce queries are usually\nshort and lack context, and the information between labels cannot be used,\nresulting in insufficient prior information for modeling. Most existing\nindustrial query classification methods rely on users' posterior click behavior\nto construct training samples, resulting in a Matthew vicious cycle.\nFurthermore, the subtasks of query classification lack a unified framework,\nleading to low efficiency for algorithm optimization.\n  In this paper, we propose a novel Semi-supervised Scalable Unified Framework\n(SSUF), containing multiple enhanced modules to unify the query classification\ntasks. The knowledge-enhanced module uses world knowledge to enhance query\nrepresentations and solve the problem of insufficient query information. The\nlabel-enhanced module uses label semantics and semi-supervised signals to\nreduce the dependence on posterior labels. The structure-enhanced module\nenhances the label representation based on the complex label relations. Each\nmodule is highly pluggable, and input features can be added or removed as\nneeded according to each subtask. We conduct extensive offline and online A/B\nexperiments, and the results show that SSUF significantly outperforms the\nstate-of-the-art models.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.21458", "pdf": "https://arxiv.org/pdf/2506.21458", "abs": "https://arxiv.org/abs/2506.21458", "authors": ["Baiqiao Yin", "Qineng Wang", "Pingyue Zhang", "Jianshu Zhang", "Kangrui Wang", "Zihan Wang", "Jieyu Zhang", "Keshigeyan Chandrasegaran", "Han Liu", "Ranjay Krishna", "Saining Xie", "Manling Li", "Jiajun Wu", "Li Fei-Fei"], "title": "Spatial Mental Modeling from Limited Views", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Preprint version", "summary": "Can Vision Language Models (VLMs) imagine the full scene from just a few\nviews, like humans do? Humans form spatial mental models, internal\nrepresentations of unseen space, to reason about layout, perspective, and\nmotion. Our new MindCube benchmark with 21,154 questions across 3,268 images\nexposes this critical gap, where existing VLMs exhibit near-random performance.\nUsing MindCube, we systematically evaluate how well VLMs build robust spatial\nmental models through representing positions (cognitive mapping), orientations\n(perspective-taking), and dynamics (mental simulation for \"what-if\" movements).\nWe then explore three approaches to help VLMs approximate spatial mental\nmodels, including unseen intermediate views, natural language reasoning chains,\nand cognitive maps. The significant improvement comes from a synergistic\napproach, \"map-then-reason\", that jointly trains the model to first generate a\ncognitive map and then reason upon it. By training models to reason over these\ninternal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding\nreinforcement learning pushed performance even further to 70.7% (+32.9%). Our\nkey insight is that such scaffolding of spatial mental models, actively\nconstructing and utilizing internal structured spatial representations with\nflexible reasoning processes, significantly improves understanding of\nunobservable space.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20771", "pdf": "https://arxiv.org/pdf/2506.20771", "abs": "https://arxiv.org/abs/2506.20771", "authors": ["Xinghao Dong", "Huchen Yang", "Jin-Long Wu"], "title": "Stochastic and Non-local Closure Modeling for Nonlinear Dynamical Systems via Latent Score-based Generative Models", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "comment": null, "summary": "We propose a latent score-based generative AI framework for learning\nstochastic, non-local closure models and constitutive laws in nonlinear\ndynamical systems of computational mechanics. This work addresses a key\nchallenge of modeling complex multiscale dynamical systems without a clear\nscale separation, for which numerically resolving all scales is prohibitively\nexpensive, e.g., for engineering turbulent flows. While classical closure\nmodeling methods leverage domain knowledge to approximate subgrid-scale\nphenomena, their deterministic and local assumptions can be too restrictive in\nregimes lacking a clear scale separation. Recent developments of\ndiffusion-based stochastic models have shown promise in the context of closure\nmodeling, but their prohibitive computational inference cost limits practical\napplications for many real-world applications. This work addresses this\nlimitation by jointly training convolutional autoencoders with conditional\ndiffusion models in the latent spaces, significantly reducing the\ndimensionality of the sampling process while preserving essential physical\ncharacteristics. Numerical results demonstrate that the joint training approach\nhelps discover a proper latent space that not only guarantees small\nreconstruction errors but also ensures good performance of the diffusion model\nin the latent space. When integrated into numerical simulations, the proposed\nstochastic modeling framework via latent conditional diffusion models achieves\nsignificant computational acceleration while maintaining comparable predictive\naccuracy to standard diffusion models in physical spaces.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u8bc4\u5206\u7684\u751f\u6210\u5f0fAI\u6846\u67b6\uff0c\u7528\u4e8e\u5b66\u4e60\u8ba1\u7b97\u529b\u5b66\u4e2d\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u968f\u673a\u3001\u975e\u5c40\u90e8\u95ed\u5408\u6a21\u578b\u548c\u672c\u6784\u5b9a\u5f8b\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u591a\u5c3a\u5ea6\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u6ca1\u6709\u660e\u786e\u5c3a\u5ea6\u5206\u79bb\u7684\u60c5\u51b5\uff0c\u4f20\u7edf\u65b9\u6cd5\u56e0\u8ba1\u7b97\u6210\u672c\u9ad8\u800c\u53d7\u9650\u3002", "method": "\u8054\u5408\u8bad\u7ec3\u5377\u79ef\u81ea\u7f16\u7801\u5668\u4e0e\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u964d\u7ef4\u5e76\u4fdd\u7559\u7269\u7406\u7279\u6027\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u53d1\u73b0\u5408\u9002\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u786e\u4fdd\u91cd\u6784\u8bef\u5dee\u5c0f\u4e14\u6269\u6563\u6a21\u578b\u6027\u80fd\u597d\uff0c\u8ba1\u7b97\u52a0\u901f\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u968f\u673a\u5efa\u6a21\u6846\u67b6\u5728\u6f5c\u5728\u6761\u4ef6\u6269\u6563\u6a21\u578b\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u7269\u7406\u7a7a\u95f4\u6807\u51c6\u6269\u6563\u6a21\u578b\u76f8\u5f53\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "keywords": "\u751f\u6210\u5f0fAI\uff1b\u968f\u673a\u6a21\u578b\uff1b\u591a\u5c3a\u5ea6\u52a8\u529b\u7cfb\u7edf\uff1b\u6f5c\u5728\u7a7a\u95f4\uff1b\u6269\u6563\u6a21\u578b"}}
{"id": "2506.21053", "pdf": "https://arxiv.org/pdf/2506.21053", "abs": "https://arxiv.org/abs/2506.21053", "authors": ["Fuqiang Niu", "Genan Dai", "Yisha Lu", "Jiayu Liao", "Xiang Li", "Hu Huang", "Bowen Zhang"], "title": "MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection", "categories": ["cs.CL"], "comment": null, "summary": "In the realm of contemporary social media, automatic stance detection is\npivotal for opinion mining, as it synthesizes and examines user perspectives on\ncontentious topics to uncover prevailing trends and sentiments. Traditional\nstance detection research often targets individual instances, thereby limiting\nits capacity to model multi-party discussions typical in real social media\nscenarios. This shortcoming largely stems from the scarcity of datasets that\nauthentically capture the dynamics of social media interactions, hindering\nadvancements in conversational stance detection. In this paper, we introduce\nMT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational\nstance detection. To the best of our knowledge, MT2-CSD is the largest dataset\navailable for this purpose, comprising 24,457 annotated instances and\nexhibiting the greatest conversational depth, thereby presenting new challenges\nfor stance detection. To address these challenges, we propose the Large\nLanguage model enhanced Conversational Relational Attention Network (LLM-CRAN),\nwhich exploits the reasoning capabilities of LLMs to improve conversational\nunderstanding. We conduct extensive experiments to evaluate the efficacy of\nLLM-CRAN on the MT2-CSD dataset. The experimental results indicate that\nLLM-CRAN significantly outperforms strong baseline models in the task of\nconversational stance detection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86MT2-CSD\u6570\u636e\u96c6\u548cLLM-CRAN\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u793e\u4ea4\u5a92\u4f53\u591a\u76ee\u6807\u591a\u8f6e\u5bf9\u8bdd\u59ff\u6001\u68c0\u6d4b\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u59ff\u6001\u68c0\u6d4b\u7814\u7a76\u591a\u9488\u5bf9\u5355\u5b9e\u4f8b\uff0c\u96be\u4ee5\u5efa\u6a21\u771f\u5b9e\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u591a\u8f6e\u52a8\u6001\u4ea4\u4e92\uff0c\u7f3a\u4e4f\u5408\u9002\u7684\u6570\u636e\u96c6\u662f\u4e3b\u8981\u9650\u5236\u3002", "method": "\u63d0\u51faMT2-CSD\u6570\u636e\u96c6\uff0824,457\u6807\u6ce8\u5b9e\u4f8b\uff09\u548cLLM-CRAN\u6a21\u578b\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u5bf9\u8bdd\u7406\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLM-CRAN\u5728\u591a\u8f6e\u5bf9\u8bdd\u59ff\u6001\u68c0\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "MT2-CSD\u548cLLM-CRAN\u4e3a\u793e\u4ea4\u5a92\u4f53\u591a\u76ee\u6807\u591a\u8f6e\u5bf9\u8bdd\u59ff\u6001\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u59ff\u6001\u68c0\u6d4b, \u793e\u4ea4\u5a92\u4f53, \u591a\u8f6e\u5bf9\u8bdd, \u6570\u636e\u96c6, \u5927\u8bed\u8a00\u6a21\u578b"}}
{"id": "2506.21490", "pdf": "https://arxiv.org/pdf/2506.21490", "abs": "https://arxiv.org/abs/2506.21490", "authors": ["Tin Dizdarevi\u0107", "Ravi Hammond", "Tobias Gessler", "Anisoara Calinescu", "Jonathan Cook", "Matteo Gallici", "Andrei Lupu", "Jakob Nicolaus Foerster"], "title": "Ad-Hoc Human-AI Coordination Challenge", "categories": ["cs.AI", "cs.HC", "cs.MA"], "comment": "Published at ICML 2025", "summary": "Achieving seamless coordination between AI agents and humans is crucial for\nreal-world applications, yet it remains a significant open challenge. Hanabi is\na cooperative card game featuring imperfect information, constrained\ncommunication, theory of mind requirements, and coordinated action -- making it\nan ideal testbed for human-AI coordination. However, its use for human-AI\ninteraction has been limited by the challenges of human evaluation. In this\nwork, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to\novercome the constraints of costly and difficult-to-reproduce human\nevaluations. We develop \\textit{human proxy agents} on a large-scale human\ndataset that serve as robust, cheap, and reproducible human-like evaluation\npartners in AH2AC2. To encourage the development of data-efficient methods, we\nopen-source a dataset of 3,079 games, deliberately limiting the amount of\navailable human gameplay data. We present baseline results for both two- and\nthree- player Hanabi scenarios. To ensure fair evaluation, we host the proxy\nagents through a controlled evaluation system rather than releasing them\npublicly. The code is available at\n\\href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Ad-Hoc Human-AI Coordination Challenge\uff08AH2AC2\uff09\uff0c\u901a\u8fc7\u5f00\u53d1\u4eba\u673a\u4ee3\u7406\u5e76\u5f00\u6e90\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4eba\u673a\u534f\u8c03\u8bc4\u4f30\u4e2d\u7684\u6210\u672c\u548c\u53ef\u91cd\u590d\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4eba\u673a\u534f\u8c03\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5408\u4f5c\u6e38\u620fHanabi\u4e2d\u7684\u4eba\u673a\u4ea4\u4e92\u8bc4\u4f30\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4eba\u673a\u4ee3\u7406\u4f5c\u4e3a\u8bc4\u4f30\u4f19\u4f34\uff0c\u5e76\u5f00\u6e90\u6709\u9650\u7684\u6e38\u620f\u6570\u636e\u96c6\u3002", "result": "\u63d0\u51fa\u4e86\u4eba\u673a\u4ee3\u7406\u548c\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u4e2a\u548c\u4e09\u73a9\u5bb6\u573a\u666f\u7684\u57fa\u7ebf\u7ed3\u679c\u3002", "conclusion": "AH2AC2\u4e3a\u4eba\u673a\u534f\u8c03\u7814\u7a76\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "keywords": "\u4eba\u673a\u534f\u8c03\uff0cHanabi\uff0c\u4ee3\u7406\u8bc4\u4f30\uff0c\u5f00\u6e90\u6570\u636e\u96c6"}}
{"id": "2506.20790", "pdf": "https://arxiv.org/pdf/2506.20790", "abs": "https://arxiv.org/abs/2506.20790", "authors": ["Lucius Bushnaq", "Dan Braun", "Lee Sharkey"], "title": "Stochastic Parameter Decomposition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A key step in reverse engineering neural networks is to decompose them into\nsimpler parts that can be studied in relative isolation. Linear parameter\ndecomposition -- a framework that has been proposed to resolve several issues\nwith current decomposition methods -- decomposes neural network parameters into\na sum of sparsely used vectors in parameter space. However, the current main\nmethod in this framework, Attribution-based Parameter Decomposition (APD), is\nimpractical on account of its computational cost and sensitivity to\nhyperparameters. In this work, we introduce \\textit{Stochastic Parameter\nDecomposition} (SPD), a method that is more scalable and robust to\nhyperparameters than APD, which we demonstrate by decomposing models that are\nslightly larger and more complex than was possible to decompose with APD. We\nalso show that SPD avoids other issues, such as shrinkage of the learned\nparameters, and better identifies ground truth mechanisms in toy models. By\nbridging causal mediation analysis and network decomposition methods, this\ndemonstration opens up new research possibilities in mechanistic\ninterpretability by removing barriers to scaling linear parameter decomposition\nmethods to larger models. We release a library for running SPD and reproducing\nour experiments at https://github.com/goodfire-ai/spd.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u968f\u673a\u53c2\u6570\u5206\u89e3\uff08SPD\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709APD\u65b9\u6cd5\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8d85\u53c2\u6570\u654f\u611f\u6027\u95ee\u9898\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u8bc6\u522b\u771f\u5b9e\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u7ebf\u6027\u53c2\u6570\u5206\u89e3\u65b9\u6cd5\u4e2d\u7684APD\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8d85\u53c2\u6570\u654f\u611f\u6027\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51faSPD\u65b9\u6cd5\uff0c\u76f8\u6bd4APD\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u8d85\u53c2\u6570\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u968f\u673a\u5316\u6539\u8fdb\u5206\u89e3\u6027\u80fd\u3002", "result": "SPD\u80fd\u5206\u89e3\u66f4\u5927\u66f4\u590d\u6742\u6a21\u578b\uff0c\u907f\u514d\u53c2\u6570\u840e\u7f29\u95ee\u9898\uff0c\u5e76\u5728\u73a9\u5177\u6a21\u578b\u4e2d\u66f4\u597d\u8bc6\u522b\u771f\u5b9e\u673a\u5236\u3002", "conclusion": "SPD\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u969c\u788d\uff0c\u4e3a\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "keywords": "\u795e\u7ecf\u7f51\u7edc\u5206\u89e3,\u7ebf\u6027\u53c2\u6570\u5206\u89e3,SPD,APD,\u673a\u68b0\u53ef\u89e3\u91ca\u6027"}}
{"id": "2506.21096", "pdf": "https://arxiv.org/pdf/2506.21096", "abs": "https://arxiv.org/abs/2506.21096", "authors": ["Kang He", "Yuzhe Ding. Haining Wang", "Fei Li", "Chong Teng", "Donghong Ji"], "title": "DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Findings", "summary": "Previous multimodal sentence representation learning methods have achieved\nimpressive performance. However, most approaches focus on aligning images and\ntext at a coarse level, facing two critical challenges:cross-modal misalignment\nbias and intra-modal semantic divergence, which significantly degrade sentence\nrepresentation quality. To address these challenges, we propose DALR\n(Dual-level Alignment Learning for Multimodal Sentence Representation). For\ncross-modal alignment, we propose a consistency learning module that softens\nnegative samples and utilizes semantic similarity from an auxiliary task to\nachieve fine-grained cross-modal alignment. Additionally, we contend that\nsentence relationships go beyond binary positive-negative labels, exhibiting a\nmore intricate ranking structure. To better capture these relationships and\nenhance representation quality, we integrate ranking distillation with global\nintra-modal alignment learning. Comprehensive experiments on semantic textual\nsimilarity (STS) and transfer (TR) tasks validate the effectiveness of our\napproach, consistently demonstrating its superiority over state-of-the-art\nbaselines.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.21506", "pdf": "https://arxiv.org/pdf/2506.21506", "abs": "https://arxiv.org/abs/2506.21506", "authors": ["Boyu Gou", "Zanming Huang", "Yuting Ning", "Yu Gu", "Michael Lin", "Weijian Qi", "Andrei Kopanev", "Botao Yu", "Bernal Jim\u00e9nez Guti\u00e9rrez", "Yiheng Shu", "Chan Hee Song", "Jiaman Wu", "Shijie Chen", "Hanane Nour Moussa", "Tianshu Zhang", "Jian Xie", "Yifei Li", "Tianci Xue", "Zeyi Liao", "Kai Zhang", "Boyuan Zheng", "Zhaowei Cai", "Viktor Rozgic", "Morteza Ziyadi", "Huan Sun", "Yu Su"], "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "categories": ["cs.AI", "cs.CL"], "comment": "Project Homepage: https://osu-nlp-group.github.io/Mind2Web2/", "summary": "Agentic search such as Deep Research systems, where large language models\nautonomously browse the web, synthesize information, and return comprehensive\ncitation-backed answers, represents a major shift in how users interact with\nweb-scale information. While promising greater efficiency and cognitive\noffloading, the growing complexity and open-endedness of agentic search have\noutpaced existing evaluation benchmarks and methodologies, which largely assume\nshort search horizons and static answers. In this paper, we introduce Mind2Web\n2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that\nrequire real-time web browsing and extensive information synthesis, constructed\nwith over 1,000 hours of human labor. To address the challenge of evaluating\ntime-varying and complex answers, we propose a novel Agent-as-a-Judge\nframework. Our method constructs task-specific judge agents based on a\ntree-structured rubric design to automatically assess both answer correctness\nand source attribution. We conduct a comprehensive evaluation of nine frontier\nagentic search systems and human performance, along with a detailed error\nanalysis to draw insights for future development. The best-performing system,\nOpenAI Deep Research, can already achieve 50-70% of human performance while\nspending half the time, showing a great potential. Altogether, Mind2Web 2\nprovides a rigorous foundation for developing and benchmarking the next\ngeneration of agentic search systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "keywords": "Error", "conclusion": "Error"}}
{"id": "2506.20807", "pdf": "https://arxiv.org/pdf/2506.20807", "abs": "https://arxiv.org/abs/2506.20807", "authors": ["Martin Andrews", "Sam Witteveen"], "title": "GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "comment": "4 page paper plus Appendices. Accepted to the ES-FoMo \"Efficient\n  Systems for Foundation Models\" workshop at ICML 2025", "summary": "Optimizing GPU kernels for high performance is a complex task, often\ndemanding deep architectural knowledge, extensive profiling, and iterative\nexperimentation. This challenge is amplified when targeting newer or\nless-documented GPU architectures where traditional development aids are\nscarce. This paper introduces an LLM-powered \"GPU Kernel Scientist,\" an\nautomated methodology for iteratively refining accelerator kernels.\n  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)\nstrategically selecting promising prior code versions as a basis for new\niterations; (b) generating hypotheses for optimization experiments, based on\nexisting code and assimilated knowledge from general GPU literature; and (c)\nautonomously implementing these experiments through code modification and\nsubsequent submission to an external evaluation system, using only observed\ntiming data as performance feedback. We detail how this approach navigates the\nchallenges of the AMD MI300 target architecture and leverages LLMs to\ncompensate for limited domain-specific human expertise.\n  Since quantitative results from an ongoing performance competition were\nembargoed on paper submission date, we present the architectural design,\noperational workflow, and qualitative insights, highlighting the potential of\nLLM-driven agents to democratise and accelerate GPU kernel optimization,\nespecially in resource-constrained or rapidly evolving hardware environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8fdb\u5316\u8fc7\u7a0b\u4f18\u5316GPU\u5185\u6838\uff0c\u5c24\u5176\u9488\u5bf9\u7f3a\u4e4f\u6587\u6863\u7684\u65b0\u67b6\u6784\u3002", "motivation": "\u9488\u5bf9GPU\u5185\u6838\u4f18\u5316\u7684\u590d\u6742\u6027\uff0c\u5c24\u5176\u662f\u5728\u65b0\u6216\u6587\u6863\u4e0d\u8db3\u7684\u67b6\u6784\u4e0a\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528LLM\u8fdb\u884c\u591a\u9636\u6bb5\u8fdb\u5316\u4f18\u5316\uff1a\u9009\u62e9\u57fa\u7840\u4ee3\u7801\u3001\u751f\u6210\u4f18\u5316\u5047\u8bbe\u3001\u81ea\u52a8\u5b9e\u65bd\u5b9e\u9a8c\u3002", "result": "\u7531\u4e8e\u6027\u80fd\u6570\u636e\u5c1a\u672a\u516c\u5f00\uff0c\u8bba\u6587\u91cd\u70b9\u4ecb\u7ecd\u4e86\u67b6\u6784\u8bbe\u8ba1\u548c\u5b9a\u6027\u5206\u6790\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u5de5\u5177\u6709\u6f5c\u529b\u5728\u8d44\u6e90\u53d7\u9650\u6216\u5feb\u901f\u6f14\u8fdb\u7684\u786c\u4ef6\u73af\u5883\u4e2d\u7b80\u5316GPU\u5185\u6838\u4f18\u5316\u3002", "keywords": "GPU\u4f18\u5316, LLM, \u81ea\u52a8\u5316, AMD MI300"}}
{"id": "2506.21098", "pdf": "https://arxiv.org/pdf/2506.21098", "abs": "https://arxiv.org/abs/2506.21098", "authors": ["Qinwen Chen", "Wenbiao Tao", "Zhiwei Zhu", "Mingfan Xi", "Liangzhong Guo", "Yuan Wang", "Wei Wang", "Yunshi Lan"], "title": "ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry", "categories": ["cs.CL", "cs.AI"], "comment": "7 pages, 4 figures. Accepted at ACL 2025 Industry Track", "summary": "Community Question Answering (CQA) platforms can be deemed as important\nknowledge bases in community, but effectively leveraging historical\ninteractions and domain knowledge in real-time remains a challenge. Existing\nmethods often underutilize external knowledge, fail to incorporate dynamic\nhistorical QA context, or lack memory mechanisms suited for industrial\ndeployment. We propose ComRAG, a retrieval-augmented generation framework for\nreal-time industrial CQA that integrates static knowledge with dynamic\nhistorical QA pairs via a centroid-based memory mechanism designed for\nretrieval, generation, and efficient storage. Evaluated on three industrial CQA\ndatasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%\nimprovement in vector similarity, reducing latency by 8.7% to 23.3%, and\nlowering chunk growth from 20.23% to 2.06% over iterations.", "AI": {"tldr": "ComRAG \u662f\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u5de5\u4e1a\u793e\u533a\u95ee\u7b54\uff0c\u901a\u8fc7\u57fa\u4e8e\u8d28\u5fc3\u7684\u8bb0\u5fc6\u673a\u5236\u6574\u5408\u9759\u6001\u77e5\u8bc6\u548c\u52a8\u6001\u5386\u53f2\u95ee\u7b54\u5bf9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u793e\u533a\u95ee\u7b54\uff08CQA\uff09\u5e73\u53f0\u662f\u91cd\u8981\u7684\u77e5\u8bc6\u5e93\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u5916\u90e8\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u52a8\u6001\u5386\u53f2\u4e0a\u4e0b\u6587\u6216\u9002\u5408\u5de5\u4e1a\u90e8\u7f72\u7684\u8bb0\u5fc6\u673a\u5236\u3002", "method": "\u63d0\u51fa ComRAG \u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u77e5\u8bc6\u548c\u52a8\u6001\u5386\u53f2\u95ee\u7b54\u5bf9\uff0c\u91c7\u7528\u57fa\u4e8e\u8d28\u5fc3\u7684\u8bb0\u5fc6\u673a\u5236\uff0c\u652f\u6301\u68c0\u7d22\u3001\u751f\u6210\u548c\u9ad8\u6548\u5b58\u50a8\u3002", "result": "\u5728\u4e09\u4e2a\u5de5\u4e1a CQA \u6570\u636e\u96c6\u4e0a\uff0cComRAG \u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5411\u91cf\u76f8\u4f3c\u5ea6\u63d0\u5347 25.9%\uff0c\u5ef6\u8fdf\u964d\u4f4e 8.7%-23.3%\uff0c\u8fed\u4ee3\u4e2d\u5757\u589e\u957f\u4ece 20.23% \u964d\u81f3 2.06%\u3002", "conclusion": "ComRAG \u662f\u4e00\u4e2a\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a CQA \u4efb\u52a1\u3002", "keywords": "\u793e\u533a\u95ee\u7b54, \u68c0\u7d22\u589e\u5f3a\u751f\u6210, \u5b9e\u65f6\u5de5\u4e1a\u90e8\u7f72, \u8bb0\u5fc6\u673a\u5236, \u6027\u80fd\u63d0\u5347"}}
{"id": "2506.21536", "pdf": "https://arxiv.org/pdf/2506.21536", "abs": "https://arxiv.org/abs/2506.21536", "authors": ["Fangjun Ding", "Renyu Zhang", "Xinyu Feng", "Chengye Xie", "Zheng Zhang", "Yanting Zhang"], "title": "PsyLite Technical Report", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "With the rapid development of digital technology, AI-driven psychological\ncounseling has gradually become an important research direction in the field of\nmental health. However, existing models still have deficiencies in dialogue\nsafety, detailed scenario handling, and lightweight deployment. To address\nthese issues, this study proposes PsyLite, a lightweight psychological\ncounseling large language model agent developed based on the base model\nInternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation\ndata fine-tuning and ORPO preference optimization), PsyLite enhances the\nmodel's deep-reasoning ability, psychological counseling ability, and safe\ndialogue ability. After deployment using Ollama and Open WebUI, a custom\nworkflow is created with Pipelines. An innovative conditional RAG is designed\nto introduce crosstalk humor elements at appropriate times during psychological\ncounseling to enhance user experience and decline dangerous requests to\nstrengthen dialogue safety. Evaluations show that PsyLite outperforms the\nbaseline models in the Chinese general evaluation (CEval), psychological\ncounseling professional evaluation (CPsyCounE), and dialogue safety evaluation\n(SafeDialBench), particularly in psychological counseling professionalism\n(CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score\nimprovement of 2.4\\%). Additionally, the model uses quantization technology\n(GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient\nfor operation), providing a feasible solution for psychological counseling\napplications in resource-constrained environments.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faPsyLite\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5fc3\u7406\u54a8\u8be2\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u548c\u6761\u4ef6RAG\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u5fc3\u7406\u54a8\u8be2\u4e13\u4e1a\u6027\uff0847.6%\uff09\u548c\u5bf9\u8bdd\u5b89\u5168\u6027\uff082.4%\uff09\uff0c\u5e76\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u90e8\u7f72\uff08\u4ec5\u97005GB\u5185\u5b58\uff09\u3002", "motivation": "\u73b0\u6709AI\u5fc3\u7406\u54a8\u8be2\u6a21\u578b\u5728\u5bf9\u8bdd\u5b89\u5168\u3001\u573a\u666f\u5904\u7406\u53ca\u8f7b\u91cf\u5316\u90e8\u7f72\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u3002", "method": "\u57fa\u4e8eInternLM2.5-7B-chat\uff0c\u91c7\u7528\u6df7\u5408\u84b8\u998f\u6570\u636e\u5fae\u8c03\u548cORPO\u504f\u597d\u4f18\u5316\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u6761\u4ef6RAG\u8bbe\u8ba1\u3002", "result": "\u5728CEval\u3001CPsyCounE\u548cSafeDialBench\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5fc3\u7406\u54a8\u8be2\u4e13\u4e1a\u6027\u63d0\u534747.6%\uff0c\u5bf9\u8bdd\u5b89\u5168\u6027\u63d0\u53472.4%\u3002", "conclusion": "PsyLite\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u9ad8\u6548\u3001\u5b89\u5168\u7684\u5fc3\u7406\u54a8\u8be2\u89e3\u51b3\u65b9\u6848\u3002", "keywords": "\u5fc3\u7406\u54a8\u8be2, AI\u5bf9\u8bdd, \u8f7b\u91cf\u5316\u6a21\u578b, \u6761\u4ef6RAG, ORPO\u8bad\u7ec3"}}
{"id": "2506.20810", "pdf": "https://arxiv.org/pdf/2506.20810", "abs": "https://arxiv.org/abs/2506.20810", "authors": ["Shashwat Khandelwal", "Jakoba Petri-Koenig", "Thomas B. Preu\u00dfer", "Michaela Blott", "Shreejith Shanker"], "title": "FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs", "categories": ["cs.LG", "cs.AI", "cs.AR", "eess.SP"], "comment": "9 pages, 6 figures, 5 tables, Accepted for publication in IEEE\n  FPL-2025 (https://2025.fpl.org/)", "summary": "Recurrent neural networks (RNNs), particularly LSTMs, are effective for\ntime-series tasks like sentiment analysis and short-term stock prediction.\nHowever, their computational complexity poses challenges for real-time\ndeployment in resource constrained environments. While FPGAs offer a promising\nplatform for energy-efficient AI acceleration, existing tools mainly target\nfeed-forward networks, and LSTM acceleration typically requires full custom\nimplementation. In this paper, we address this gap by leveraging the\nopen-source and extensible FINN framework to enable the generalized deployment\nof LSTMs on FPGAs. Specifically, we leverage the Scan operator from the Open\nNeural Network Exchange (ONNX) specification to model the recurrent nature of\nLSTM computations, enabling support for mixed quantisation within them and\nfunctional verification of LSTM-based models. Furthermore, we introduce custom\ntransformations within the FINN compiler to map the quantised ONNX computation\ngraph to hardware blocks from the HLS kernel library of the FINN compiler and\nVitis HLS. We validate the proposed tool-flow by training a quantised ConvLSTM\nmodel for a mid-price stock prediction task using the widely used dataset and\ngenerating a corresponding hardware IP of the model using our flow, targeting\nthe XCZU7EV device. We show that the generated quantised ConvLSTM accelerator\nthrough our flow achieves a balance between performance (latency) and resource\nconsumption, while matching (or bettering) inference accuracy of\nstate-of-the-art models with reduced precision. We believe that the\ngeneralisable nature of the proposed flow will pave the way for\nresource-efficient RNN accelerator designs on FPGAs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFINN\u6846\u67b6\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728FPGA\u4e0a\u90e8\u7f72LSTM\u7f51\u7edc\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u4e3b\u8981\u9488\u5bf9\u524d\u9988\u7f51\u7edc\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u91cf\u5316\u6280\u672f\u548c\u786c\u4ef6\u6620\u5c04\u4f18\u5316\u5b9e\u73b0\u4e86\u6027\u80fd\u548c\u8d44\u6e90\u7684\u5e73\u8861\u3002", "motivation": "\u5f53\u524dRNN\uff08\u5c24\u5176\u662fLSTM\uff09\u5728\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u90e8\u7f72\u5b58\u5728\u6311\u6218\u3002FPGA\u662f\u4e00\u79cd\u9ad8\u6548\u7684AI\u52a0\u901f\u5e73\u53f0\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u5bf9LSTM\u7684\u652f\u6301\uff0c\u901a\u5e38\u9700\u8981\u5b8c\u5168\u81ea\u5b9a\u4e49\u5b9e\u73b0\u3002", "method": "\u5229\u7528\u5f00\u6e90\u7684FINN\u6846\u67b6\u548cONNX\u7684Scan\u64cd\u4f5c\u7b26\u5efa\u6a21LSTM\u7684\u8ba1\u7b97\u7279\u6027\uff0c\u652f\u6301\u6df7\u5408\u91cf\u5316\u548c\u529f\u80fd\u9a8c\u8bc1\uff1b\u901a\u8fc7\u81ea\u5b9a\u4e49\u8f6c\u6362\u5c06\u91cf\u5316ONNX\u8ba1\u7b97\u56fe\u6620\u5c04\u5230\u786c\u4ef6\u5757\uff0c\u751f\u6210\u9ad8\u6548\u7684\u786c\u4ef6IP\u3002", "result": "\u5728\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u751f\u6210\u7684\u91cf\u5316ConvLSTM\u52a0\u901f\u5668\u5728\u6027\u80fd\u548c\u8d44\u6e90\u6d88\u8017\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u4e14\u63a8\u7406\u7cbe\u5ea6\u4e0e\u73b0\u6709\u6700\u4f73\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "\u63d0\u51fa\u7684\u901a\u7528\u6d41\u7a0b\u4e3aFPGA\u4e0a\u8d44\u6e90\u9ad8\u6548\u7684RNN\u52a0\u901f\u5668\u8bbe\u8ba1\u94fa\u5e73\u4e86\u9053\u8def\u3002", "keywords": "LSTM, FPGA, \u91cf\u5316, FINN\u6846\u67b6, ONNX"}}
{"id": "2506.21119", "pdf": "https://arxiv.org/pdf/2506.21119", "abs": "https://arxiv.org/abs/2506.21119", "authors": ["Xiaoshuang Ji", "Zhendong Zhao", "Xiaojun Chen", "Xin Zhao", "Zeyao Liu"], "title": "Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICONIP 2024", "summary": "Fine-tuning is a promising technique for leveraging Transformer-based\nlanguage models in downstream tasks. As model sizes continue to grow, updating\nall model parameters becomes increasingly costly. Parameter-efficient\nfine-tuning methods effectively address this issue by selectively updating a\nsmall subset of parameters. However, fine-tuning and most existing\nparameter-efficient fine-tuning methods require updating the same number of\nparameters as the initial size, ignoring the unequal contribution across\nTransformer blocks and leading to extremely inefficient allocation of computing\nresources. In this paper, we propose Progtuning, the novel fine-tuning\nframework combined with progressive learning for Transformer-based language\nmodels. Specifically, Progtuning progressively reduces the number of updated\ntransformer blocks based on the contribution. Remarkably, Progtuning optimizes\nresource allocation and reduces the number of updated parameters by\napproximately 25\\%, while still maintaining competitive performance. And it\nalso exhibits high adaptability with parameter-efficient fine-tuning methods,\ndemonstrating excellent performance across various adaptation scenarios.", "AI": {"tldr": "Progtuning\u662f\u4e00\u79cd\u7ed3\u5408\u6e10\u8fdb\u5f0f\u5b66\u4e60\u7684\u65b0\u578b\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u9010\u6b65\u51cf\u5c11\u66f4\u65b0\u7684Transformer\u5757\u6570\u91cf\u6765\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u957f\uff0c\u5168\u53c2\u6570\u5fae\u8c03\u6210\u672c\u9ad8\u6602\uff0c\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u672a\u8003\u8651Transformer\u5757\u8d21\u732e\u4e0d\u5747\uff0c\u5bfc\u81f4\u8d44\u6e90\u5206\u914d\u4f4e\u6548\u3002", "method": "Progtuning\u901a\u8fc7\u6e10\u8fdb\u5f0f\u5b66\u4e60\u9010\u6b65\u51cf\u5c11\u66f4\u65b0\u7684Transformer\u5757\u6570\u91cf\uff0c\u57fa\u4e8e\u8d21\u732e\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "result": "Progtuning\u51cf\u5c11\u7ea625%\u7684\u66f4\u65b0\u53c2\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u4e14\u4e0e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u9002\u914d\u6027\u597d\u3002", "conclusion": "Progtuning\u6709\u6548\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u9002\u914d\u573a\u666f\u3002", "keywords": "\u5fae\u8c03, Transformer, \u8d44\u6e90\u5206\u914d, \u6e10\u8fdb\u5f0f\u5b66\u4e60, \u53c2\u6570\u9ad8\u6548"}}
{"id": "2504.15217", "pdf": "https://arxiv.org/pdf/2504.15217", "abs": "https://arxiv.org/abs/2504.15217", "authors": ["Yatong Bai", "Jonah Casebeer", "Somayeh Sojoudi", "Nicholas J. Bryan"], "title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM"], "comment": null, "summary": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a\nversatile framework for fine-tuning media generation models towards a desired\noutcome. Compared with traditional reinforcement learning with human feedback\n(RLHF) or pairwise preference approaches such as direct preference optimization\n(DPO), DRAGON is more flexible. It can optimize reward functions that evaluate\neither individual examples or distributions of them, making it compatible with\na broad spectrum of instance-wise, instance-to-distribution, and\ndistribution-to-distribution rewards. Leveraging this versatility, we construct\nnovel reward functions by selecting an encoder and a set of reference examples\nto create an exemplar distribution. When cross-modality encoders such as CLAP\nare used, the reference examples may be of a different modality (e.g., text\nversus audio). Then, DRAGON gathers online and on-policy generations, scores\nthem to construct a positive demonstration set and a negative set, and\nleverages the contrast between the two sets to maximize the reward. For\nevaluation, we fine-tune an audio-domain text-to-music diffusion model with 20\ndifferent reward functions, including a custom music aesthetics model, CLAP\nscore, Vendi diversity, and Frechet audio distance (FAD). We further compare\ninstance-wise (per-song) and full-dataset FAD settings while ablating multiple\nFAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an\n81.45% average win rate. Moreover, reward functions based on exemplar sets\nindeed enhance generations and are comparable to model-based rewards. With an\nappropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality\nwin rate without training on human preference annotations. As such, DRAGON\nexhibits a new approach to designing and optimizing reward functions for\nimproving human-perceived quality. Sound examples at\nhttps://ml-dragon.github.io/web.", "AI": {"tldr": "DRAGON\u662f\u4e00\u79cd\u7075\u6d3b\u7684\u751f\u6210\u6a21\u578b\u4f18\u5316\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u4f18\u5316\u591a\u79cd\u5956\u52b1\u51fd\u6570\uff0c\u5305\u62ec\u5b9e\u4f8b\u7ea7\u548c\u5206\u5e03\u7ea7\u5956\u52b1\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRLHF\u6216DPO\u65b9\u6cd5\u7075\u6d3b\u6027\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5e94\u5bf9\u591a\u79cd\u5956\u52b1\u51fd\u6570\uff08\u5982\u5b9e\u4f8b\u7ea7\u548c\u5206\u5e03\u7ea7\uff09\uff0cDRAGON\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u9009\u62e9\u7f16\u7801\u5668\u548c\u53c2\u8003\u96c6\u6784\u5efa\u5956\u52b1\u51fd\u6570\uff0c\u5229\u7528\u6b63\u8d1f\u5bf9\u6bd4\u96c6\u4f18\u5316\u5956\u52b1\u3002\u5728\u97f3\u9891\u9886\u57df\u6d4b\u8bd5\u4e8620\u79cd\u5956\u52b1\u51fd\u6570\u3002", "result": "DRAGON\u5728\u6240\u670920\u79cd\u5956\u52b1\u4e0a\u5e73\u5747\u80dc\u7387\u4e3a81.45%\uff0c\u4e14\u57fa\u4e8e\u8303\u4f8b\u96c6\u7684\u5956\u52b1\u6548\u679c\u4e0e\u6a21\u578b\u5956\u52b1\u76f8\u5f53\u3002", "conclusion": "DRAGON\u4e3a\u4f18\u5316\u4eba\u7c7b\u611f\u77e5\u8d28\u91cf\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u7c7b\u504f\u597d\u6807\u6ce8\u3002", "keywords": "DRAGON, \u5956\u52b1\u51fd\u6570, \u751f\u6210\u6a21\u578b\u4f18\u5316, \u5206\u5e03\u7ea7\u5956\u52b1, \u97f3\u9891\u751f\u6210"}}
{"id": "2506.20814", "pdf": "https://arxiv.org/pdf/2506.20814", "abs": "https://arxiv.org/abs/2506.20814", "authors": ["Jakub Piwko", "J\u0119drzej Ruci\u0144ski", "Dawid P\u0142udowski", "Antoni Zajko", "Patryzja \u017bak", "Mateusz Zacharecki", "Anna Kozak", "Katarzyna Wo\u017anica"], "title": "Divide, Specialize, and Route: A New Approach to Efficient Ensemble Learning", "categories": ["cs.LG"], "comment": "14 pages, 6 figures", "summary": "Ensemble learning has proven effective in boosting predictive performance,\nbut traditional methods such as bagging, boosting, and dynamic ensemble\nselection (DES) suffer from high computational cost and limited adaptability to\nheterogeneous data distributions. To address these limitations, we propose\nHellsemble, a novel and interpretable ensemble framework for binary\nclassification that leverages dataset complexity during both training and\ninference. Hellsemble incrementally partitions the dataset into circles of\ndifficulty by iteratively passing misclassified instances from simpler models\nto subsequent ones, forming a committee of specialised base learners. Each\nmodel is trained on increasingly challenging subsets, while a separate router\nmodel learns to assign new instances to the most suitable base model based on\ninferred difficulty. Hellsemble achieves strong classification accuracy while\nmaintaining computational efficiency and interpretability. Experimental results\non OpenML-CC18 and Tabzilla benchmarks demonstrate that Hellsemble often\noutperforms classical ensemble methods. Our findings suggest that embracing\ninstance-level difficulty offers a promising direction for constructing\nefficient and robust ensemble systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHellsemble\u7684\u65b0\u578b\u96c6\u6210\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6839\u636e\u6837\u672c\u96be\u5ea6\u589e\u91cf\u8bad\u7ec3\u548c\u52a8\u6001\u5206\u914d\uff0c\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff08\u5982bagging\u3001boosting\u548cDES\uff09\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9002\u5e94\u5f02\u6784\u6570\u636e\u5206\u5e03\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "Hellsemble\u901a\u8fc7\u5c06\u6570\u636e\u96c6\u9010\u7ea7\u5212\u5206\u4e3a\u96be\u5ea6\u9012\u589e\u7684\u5b50\u96c6\uff0c\u8bad\u7ec3\u4e13\u95e8\u5316\u7684\u57fa\u5b66\u4e60\u5668\uff0c\u5e76\u5229\u7528\u8def\u7531\u6a21\u578b\u52a8\u6001\u5206\u914d\u65b0\u6837\u672c\u3002", "result": "\u5728OpenML-CC18\u548cTabzilla\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u96c6\u6210\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u6837\u672c\u96be\u5ea6\u6784\u5efa\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u96c6\u6210\u7cfb\u7edf\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\u3002", "keywords": "\u96c6\u6210\u5b66\u4e60\u3001\u4e8c\u8fdb\u5236\u5206\u7c7b\u3001\u52a8\u6001\u5206\u914d\u3001\u53ef\u89e3\u91ca\u6027"}}
