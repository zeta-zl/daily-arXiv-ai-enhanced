<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.AI](#cs.AI) [Total: 8]
- [eess.IV](#eess.IV) [Total: 5]
- [cs.RO](#cs.RO) [Total: 4]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [math.OC](#math.OC) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.HC](#cs.HC) [Total: 4]
- [cs.DS](#cs.DS) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 2]
- [cs.CY](#cs.CY) [Total: 7]
- [cs.SD](#cs.SD) [Total: 6]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [stat.ML](#stat.ML) [Total: 7]
- [eess.SY](#eess.SY) [Total: 2]
- [cs.CR](#cs.CR) [Total: 12]
- [math.DS](#math.DS) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [stat.ME](#stat.ME) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.SP](#eess.SP) [Total: 3]
- [cs.CV](#cs.CV) [Total: 33]
- [stat.AP](#stat.AP) [Total: 2]
- [q-bio.PE](#q-bio.PE) [Total: 1]
- [physics.med-ph](#physics.med-ph) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
*Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju,Mohit Agarwal,Sławek Kwasiborski,Paramjit Sandhu,Patrick Siegler,Ahmet Iscen,Eyal Ben-David,Shiraz Butt,Miltos Allamanis,Seth Benjamin,Robert Busa-Fekete,Felix Hernandez-Campos,Sasha Goldshtein,Matt Dibb,Weiyang Zhang,Annie Marsden,Carey Radebaugh,Stephen Roller,Abhishek Nayyar,Jacob Austin,Tayfun Terzi,Bhargav Kanagal Shamanna,Pete Shaw,Aayush Singh,Florian Luisier,Artur Mendonça,Vaibhav Aggarwal,Larisa Markeeva,Claudio Fantacci,Sergey Brin,HyunJeong Choe,Guanyu Wang,Hartwig Adam,Avigail Dabush,Tatsuya Kiyono,Eyal Marcus,Jeremy Cole,Theophane Weber,Hongrae Lee,Ronny Huang,Alex Muzio,Leandro Kieliger,Maigo Le,Courtney Biles,Long Le,Archit Sharma,Chengrun Yang,Avery Lamp,Dave Dopson,Nate Hurley,Katrina,Xu,Zhihao Shan,Shuang Song,Jiewen Tan,Alexandre Senges,George Zhang,Chong You,Yennie Jun,David Raposo,Susanna Ricco,Xuan Yang,Weijie Chen,Prakhar Gupta,Arthur Szlam,Kevin Villela,Chun-Sung Ferng,Daniel Kasenberg,Chen Liang,Rui Zhu,Arunachalam Narayanaswamy,Florence Perot,Paul Pucciarelli,Anna Shekhawat,Alexey Stern,Rishikesh Ingale,Stefani Karp,Sanaz Bahargam,Adrian Goedeckemeyer,Jie Han,Sicheng Li,Andrea Tacchetti,Dian Yu,Abhishek Chakladar,Zhiying Zhang,Mona El Mahdy,Xu Gao,Dale Johnson,Samrat Phatale,AJ Piergiovanni,Hyeontaek Lim,Clement Farabet,Carl Lebsack,Theo Guidroz,John Blitzer,Nico Duduta,David Madras,Steve Li,Daniel von Dincklage,Xin Li,Mahdis Mahdieh,George Tucker,Ganesh Jawahar,Owen Xiao,Danny Tarlow,Robert Geirhos,Noam Velan,Daniel Vlasic,Kalesha Bullard,SK Park,Nishesh Gupta,Kellie Webster,Ayal Hitron,Jieming Mao,Julian Eisenschlos,Laurel Prince,Nina D'Souza,Kelvin Zheng,Sara Nasso,Gabriela Botea,Carl Doersch,Caglar Unlu,Chris Alberti,Alexey Svyatkovskiy,Ankita Goel,Krzysztof Choromanski,Pan-Pan Jiang,Richard Nguyen,Four Flynn,Daria Ćurko,Peter Chen,Nicholas Roth,Kieran Milan,Caleb Habtegebriel,Shashi Narayan,Michael Moffitt,Jake Marcus,Thomas Anthony,Brendan McMahan,Gowoon Cheon,Ruibo Liu,Megan Barnes,Lukasz Lew,Rebeca Santamaria-Fernandez,Mayank Upadhyay,Arjun Akula,Arnar Mar Hrafnkelsson,Alvaro Caceres,Andrew Bunner,Michal Sokolik,Subha Puttagunta,Lawrence Moore,Berivan Isik,Weilun Chen,Jay Hartford,Lawrence Chan,Pradeep Shenoy,Dan Holtmann-Rice,Jane Park,Fabio Viola,Alex Salcianu,Sujeevan Rajayogam,Ian Stewart-Binks,Zelin Wu,Richard Everett,Xi Xiong,Pierre-Antoine Manzagol,Gary Leung,Carl Saroufim,Bo Pang,Dawid Wegner,George Papamakarios,Jennimaria Palomaki,Helena Pankov,Guangda Lai,Guilherme Tubone,Shubin Zhao,Theofilos Strinopoulos,Seth Neel,Mingqiu Wang,Joe Kelley,Li Li,Pingmei Xu,Anitha Vijayakumar,Andrea D'olimpio,Omer Levy,Massimo Nicosia,Grigory Rozhdestvenskiy,Ni Lao,Sirui Xie,Yash Katariya,Jon Simon,Sanjiv Kumar,Florian Hartmann,Michael Kilgore,Jinhyuk Lee,Aroma Mahendru,Roman Ring,Tom Hennigan,Fiona Lang,Colin Cherry,David Steiner,Dawsen Hwang,Ray Smith,Pidong Wang,Jeremy Chen,Ming-Hsuan Yang,Sam Kwei,Philippe Schlattner,Donnie Kim,Ganesh Poomal Girirajan,Nikola Momchev,Ayushi Agarwal,Xingyi Zhou,Ilkin Safarli,Zachary Garrett,AJ Pierigiovanni,Sarthak Jauhari,Alif Raditya Rochman,Shikhar Vashishth,Quan Yuan,Christof Angermueller,Jon Blanton,Xinying Song,Nitesh Bharadwaj Gundavarapu,Thi Avrahami,Maxine Deines,Subhrajit Roy,Manish Gupta,Christopher Semturs,Shobha Vasudevan,Aditya Srikanth Veerubhotla,Shriya Sharma,Josh Jacob,Zhen Yang,Andreas Terzis,Dan Karliner,Auriel Wright,Tania Rojas-Esponda,Ashley Brown,Abhijit Guha Roy,Pawan Dogra,Andrei Kapishnikov,Peter Young,Wendy Kan,Vinodh Kumar Rajendran,Maria Ivanova,Salil Deshmukh,Chia-Hua Ho,Mike Kwong,Stav Ginzburg,Annie Louis,KP Sawhney,Slav Petrov,Jing Xie,Yunfei Bai,Georgi Stoyanov,Alex Fabrikant,Rajesh Jayaram,Yuqi Li,Joe Heyward,Justin Gilmer,Yaqing Wang,Radu Soricut,Luyang Liu,Qingnan Duan,Jamie Hayes,Maura O'Brien,Gaurav Singh Tomar,Sivan Eiger,Bahar Fatemi,Jeffrey Hui,Catarina Barros,Adaeze Chukwuka,Alena Butryna,Saksham Thakur,Austin Huang,Zhufeng Pan,Haotian Tang,Serkan Cabi,Tulsee Doshi,Michiel Bakker,Sumit Bagri,Ruy Ley-Wild,Adam Lelkes,Jennie Lees,Patrick Kane,David Greene,Shimu Wu,Jörg Bornschein,Gabriela Surita,Sarah Hodkinson,Fangtao Li,Chris Hidey,Sébastien Pereira,Sean Ammirati,Phillip Lippe,Adam Kraft,Pu Han,Sebastian Gerlach,Zifeng Wang,Liviu Panait,Feng Han,Brian Farris,Yingying Bi,Hannah DeBalsi,Miaosen Wang,Gladys Tyen,James Cohan,Susan Zhang,Jarred Barber,Da-Woon Chung,Jaeyoun Kim,Markus Kunesch,Steven Pecht,Nami Akazawa,Abe Friesen,James Lyon,Ali Eslami,Junru Wu,Jie Tan,Yue Song,Ravi Kumar,Chris Welty,Ilia Akolzin,Gena Gibson,Sean Augenstein,Arjun Pillai,Nancy Yuen,Du Phan,Xin Wang,Iain Barr,Heiga Zen,Nan Hua,Casper Liu,Jilei,Wang,Tanuj Bhatia,Hao Xu,Oded Elyada,Pushmeet Kohli,Mirek Olšák,Ke Chen,Azalia Mirhoseini,Noam Shazeer,Shoshana Jakobovits,Maggie Tran,Nolan Ramsden,Tarun Bharti,Fred Alcober,Yunjie Li,Shilpa Shetty,Jing Chen,Dmitry Kalashnikov,Megha Nawhal,Sercan Arik,Hanwen Chen,Michiel Blokzijl,Shubham Gupta,James Rubin,Rigel Swavely,Sophie Bridgers,Ian Gemp,Chen Su,Arun Suggala,Juliette Pluto,Mary Cassin,Alain Vaucher,Kaiyang Ji,Jiahao Cai,Andrew Audibert,Animesh Sinha,David Tian,Efrat Farkash,Amy Hua,Jilin Chen,Duc-Hieu Tran,Edward Loper,Nicole Brichtova,Lara McConnaughey,Ballie Sandhu,Robert Leland,Doug DeCarlo,Andrew Over,James Huang,Xing Wu,Connie Fan,Eric Li,Yun Lei,Deepak Sharma,Cosmin Paduraru,Luo Yu,Matko Bošnjak,Phuong Dao,Min Choi,Sneha Kudugunta,Jakub Adamek,Carlos Guía,Ali Khodaei,Jie Feng,Wenjun Zeng,David Welling,Sandeep Tata,Christina Butterfield,Andrey Vlasov,Seliem El-Sayed,Swaroop Mishra,Tara Sainath,Shentao Yang,RJ Skerry-Ryan,Jeremy Shar,Robert Berry,Arunkumar Rajendran,Arun Kandoor,Andrea Burns,Deepali Jain,Tom Stone,Wonpyo Park,Shibo Wang,Albin Cassirer,Guohui Wang,Hayato Kobayashi,Sergey Rogulenko,Vineetha Govindaraj,Mikołaj Rybiński,Nadav Olmert,Colin Evans,Po-Sen Huang,Kelvin Xu,Premal Shah,Terry Thurk,Caitlin Sikora,Mu Cai,Jin Xie,Elahe Dabir,Saloni Shah,Norbert Kalb,Carrie Zhang,Shruthi Prabhakara,Amit Sabne,Artiom Myaskovsky,Vikas Raunak,Blanca Huergo,Behnam Neyshabur,Jon Clark,Ye Zhang,Shankar Krishnan,Eden Cohen,Dinesh Tewari,James Lottes,Yumeya Yamamori,Hui,Li,Mohamed Elhawaty,Ada Maksutaj Oflazer,Adrià Recasens,Sheryl Luo,Duy Nguyen,Taylor Bos,Kalyan Andra,Ana Salazar,Ed Chi,Jeongwoo Ko,Matt Ginsberg,Anders Andreassen,Anian Ruoss,Todor Davchev,Elnaz Davoodi,Chenxi Liu,Min Kim,Santiago Ontanon,Chi Ming To,Dawei Jia,Rosemary Ke,Jing Wang,Anna Korsun,Moran Ambar,Ilya Kornakov,Irene Giannoumis,Toni Creswell,Denny Zhou,Yi Su,Ishaan Watts,Aleksandr Zaks,Evgenii Eltyshev,Ziqiang Feng,Sidharth Mudgal,Alex Kaskasoli,Juliette Love,Kingshuk Dasgupta,Sam Shleifer,Richard Green,Sungyong Seo,Chansoo Lee,Dale Webster,Prakash Shroff,Ganna Raboshchuk,Isabel Leal,James Manyika,Sofia Erell,Daniel Murphy,Zhisheng Xiao,Anton Bulyenov,Julian Walker,Mark Collier,Matej Kastelic,Nelson George,Sushant Prakash,Sailesh Sidhwani,Alexey Frolov,Steven Hansen,Petko Georgiev,Tiberiu Sosea,Chris Apps,Aishwarya Kamath,David Reid,Emma Cooney,Charlotte Magister,Oriana Riva,Alec Go,Pu-Chin Chen,Sebastian Krause,Nir Levine,Marco Fornoni,Ilya Figotin,Nick Roy,Parsa Mahmoudieh,Vladimir Magay,Mukundan Madhavan,Jin Miao,Jianmo Ni,Yasuhisa Fujii,Ian Chou,George Scrivener,Zak Tsai,Siobhan Mcloughlin,Jeremy Selier,Sandra Lefdal,Jeffrey Zhao,Abhijit Karmarkar,Kushal Chauhan,Shivanker Goel,Zhaoyi Zhang,Vihan Jain,Parisa Haghani,Mostafa Dehghani,Jacob Scott,Erin Farnese,Anastasija Ilić,Steven Baker,Julia Pawar,Li Zhong,Josh Camp,Yoel Zeldes,Shravya Shetty,Anand Iyer,Vít Listík,Jiaxian Guo,Luming Tang,Mark Geller,Simon Bucher,Yifan Ding,Hongzhi Shi,Carrie Muir,Dominik Grewe,Ramy Eskander,Octavio Ponce,Boqing Gong,Derek Gasaway,Samira Khan,Umang Gupta,Angelos Filos,Weicheng Kuo,Klemen Kloboves,Jennifer Beattie,Christian Wright,Leon Li,Alicia Jin,Sandeep Mariserla,Miteyan Patel,Jens Heitkaemper,Dilip Krishnan,Vivek Sharma,David Bieber,Christian Frank,John Lambert,Paul Caron,Martin Polacek,Mai Giménez,Himadri Choudhury,Xing Yu,Sasan Tavakkol,Arun Ahuja,Franz Och,Rodolphe Jenatton,Wojtek Skut,Bryan Richter,David Gaddy,Andy Ly,Misha Bilenko,Megh Umekar,Ethan Liang,Martin Sevenich,Mandar Joshi,Hassan Mansoor,Rebecca Lin,Sumit Sanghai,Abhimanyu Singh,Xiaowei Li,Sudheendra Vijayanarasimhan,Zaheer Abbas,Yonatan Bitton,Hansa Srinivasan,Manish Reddy Vuyyuru,Alexander Frömmgen,Yanhua Sun,Ralph Leith,Alfonso Castaño,DJ Strouse,Le Yan,Austin Kyker,Satish Kambala,Mary Jasarevic,Thibault Sellam,Chao Jia,Alexander Pritzel,Raghavender R,Huizhong Chen,Natalie Clay,Sudeep Gandhe,Sean Kirmani,Sayna Ebrahimi,Hannah Kirkwood,Jonathan Mallinson,Chao Wang,Adnan Ozturel,Kuo Lin,Shyam Upadhyay,Vincent Cohen-Addad,Sean Purser-haskell,Yichong Xu,Ebrahim Songhori,Babi Seal,Alberto Magni,Almog Gueta,Tingting Zou,Guru Guruganesh,Thais Kagohara,Hung Nguyen,Khalid Salama,Alejandro Cruzado Ruiz,Justin Frye,Zhenkai Zhu,Matthias Lochbrunner,Simon Osindero,Wentao Yuan,Lisa Lee,Aman Prasad,Lam Nguyen Thiet,Daniele Calandriello,Victor Stone,Qixuan Feng,Han Ke,Maria Voitovich,Geta Sampemane,Lewis Chiang,Ling Wu,Alexander Bykovsky,Matt Young,Luke Vilnis,Ishita Dasgupta,Aditya Chawla,Qin Cao,Bowen Liang,Daniel Toyama,Szabolcs Payrits,Anca Stefanoiu,Dimitrios Vytiniotis,Ankesh Anand,Tianxiao Shen,Blagoj Mitrevski,Michael Tschannen,Sreenivas Gollapudi,Aishwarya P S,José Leal,Zhe Shen,Han Fu,Wei Wang,Arvind Kannan,Doron Kukliansky,Sergey Yaroshenko,Svetlana Grant,Umesh Telang,David Wood,Alexandra Chronopoulou,Alexandru Ţifrea,Tao Zhou,Tony,Nguy\~ên,Muge Ersoy,Anima Singh,Meiyan Xie,Emanuel Taropa,Woohyun Han,Eirikur Agustsson,Andrei Sozanschi,Hui Peng,Alex Chen,Yoel Drori,Efren Robles,Yang Gao,Xerxes Dotiwalla,Ying Chen,Anudhyan Boral,Alexei Bendebury,John Nham,Chris Tar,Luis Castro,Jiepu Jiang,Canoee Liu,Felix Halim,Jinoo Baek,Andy Wan,Jeremiah Liu,Yuan Cao,Shengyang Dai,Trilok Acharya,Ruoxi Sun,Fuzhao Xue,Saket Joshi,Morgane Lustman,Yongqin Xian,Rishabh Joshi,Deep Karkhanis,Nora Kassner,Jamie Hall,Xiangzhuo Ding,Gan Song,Gang Li,Chen Zhu,Yana Kulizhskaya,Bin Ni,Alexey Vlaskin,Solomon Demmessie,Lucio Dery,Salah Zaiem,Yanping Huang,Cindy Fan,Felix Gimeno,Ananth Balashankar,Koji Kojima,Hagai Taitelbaum,Maya Meng,Dero Gharibian,Sahil Singla,Wei Chen,Ambrose Slone,Guanjie Chen,Sujee Rajayogam,Max Schumacher,Suyog Kotecha,Rory Blevins,Qifei Wang,Mor Hazan Taege,Alex Morris,Xin Liu,Fayaz Jamil,Richard Zhang,Pratik Joshi,Ben Ingram,Tyler Liechty,Ahmed Eleryan,Scott Baird,Alex Grills,Gagan Bansal,Shan Han,Kiran Yalasangi,Shawn Xu,Majd Al Merey,Isabel Gao,Felix Weissenberger,Igor Karpov,Robert Riachi,Ankit Anand,Gautam Prasad,Kay Lamerigts,Reid Hayes,Jamie Rogers,Mandy Guo,Ashish Shenoy,Qiong,Hu,Kyle He,Yuchen Liu,Polina Zablotskaia,Sagar Gubbi,Yifan Chang,Jay Pavagadhi,Kristian Kjems,Archita Vadali,Diego Machado,Yeqing Li,Renshen Wang,Dipankar Ghosh,Aahil Mehta,Dana Alon,George Polovets,Alessio Tonioni,Nate Kushman,Joel D'sa,Lin Zhuo,Allen Wu,Rohin Shah,John Youssef,Jiayu Ye,Justin Snyder,Karel Lenc,Senaka Buthpitiya,Matthew Tung,Jichuan Chang,Tao Chen,David Saxton,Jenny Lee,Lydia Lihui Zhang,James Qin,Prabakar Radhakrishnan,Maxwell Chen,Piotr Ambroszczyk,Metin Toksoz-Exley,Yan Zhong,Nitzan Katz,Brendan O'Donoghue,Tamara von Glehn,Adi Gerzi Rosenthal,Aga Świetlik,Xiaokai Zhao,Nick Fernando,Jinliang Wei,Jieru Mei,Sergei Vassilvitskii,Diego Cedillo,Pranjal Awasthi,Hui Zheng,Koray Kavukcuoglu,Itay Laish,Joseph Pagadora,Marc Brockschmidt,Christopher A. Choquette-Choo,Arunkumar Byravan,Yifeng Lu,Xu Chen,Mia Chen,Kenton Lee,Rama Pasumarthi,Sijal Bhatnagar,Aditya Shah,Qiyin Wu,Zhuoyuan Chen,Zack Nado,Bartek Perz,Zixuan Jiang,David Kao,Ganesh Mallya,Nino Vieillard,Lantao Mei,Sertan Girgin,Mandy Jordan,Yeongil Ko,Alekh Agarwal,Yaxin Liu,Yasemin Altun,Raoul de Liedekerke,Anastasios Kementsietsidis,Daiyi Peng,Dangyi Liu,Utku Evci,Peter Humphreys,Austin Tarango,Xiang Deng,Yoad Lewenberg,Kevin Aydin,Chengda Wu,Bhavishya Mittal,Tsendsuren Munkhdalai,Kleopatra Chatziprimou,Rodrigo Benenson,Uri First,Xiao Ma,Jinning Li,Armand Joulin,Hamish Tomlinson,Tingnan Zhang,Milad Nasr,Zhi Hong,Michaël Sander,Lisa Anne Hendricks,Anuj Sharma,Andrew Bolt,Eszter Vértes,Jiri Simsa,Tomer Levinboim,Olcan Sercinoglu,Divyansh Shukla,Austin Wu,Craig Swanson,Danny Vainstein,Fan Bu,Bo Wang,Ryan Julian,Charles Yoon,Sergei Lebedev,Antonious Girgis,Bernd Bandemer,David Du,Todd Wang,Xi Chen,Ying Xiao,Peggy Lu,Natalie Ha,Vlad Ionescu,Simon Rowe,Josip Matak,Federico Lebron,Andreas Steiner,Lalit Jain,Manaal Faruqui,Nicolas Lacasse,Georgie Evans,Neesha Subramaniam,Dean Reich,Giulia Vezzani,Aditya Pandey,Joe Stanton,Tianhao Zhou,Liam McCafferty,Henry Griffiths,Verena Rieser,Soheil Hassas Yeganeh,Eleftheria Briakou,Lu Huang,Zichuan Wei,Liangchen Luo,Erik Jue,Gabby Wang,Victor Cotruta,Myriam Khan,Jongbin Park,Qiuchen Guo,Peiran Li,Rong Rong,Diego Antognini,Anastasia Petrushkina,Chetan Tekur,Eli Collins,Parul Bhatia,Chester Kwak,Wenhu Chen,Arvind Neelakantan,Immanuel Odisho,Sheng Peng,Vincent Nallatamby,Vaibhav Tulsyan,Fabian Pedregosa,Peng Xu,Raymond Lin,Yulong Wang,Emma Wang,Sholto Douglas,Reut Tsarfaty,Elena Gribovskaya,Renga Aravamudhan,Manu Agarwal,Mara Finkelstein,Qiao Zhang,Elizabeth Cole,Phil Crone,Sarmishta Velury,Anil Das,Chris Sauer,Luyao Xu,Danfeng Qin,Chenjie Gu,Dror Marcus,CJ Zheng,Wouter Van Gansbeke,Sobhan Miryoosefi,Haitian Sun,YaGuang Li,Charlie Chen,Jae Yoo,Pavel Dubov,Alex Tomala,Adams Yu,Paweł Wesołowski,Alok Gunjan,Eddie Cao,Jiaming Luo,Nikhil Sethi,Arkadiusz Socala,Laura Graesser,Tomas Kocisky,Arturo BC,Minmin Chen,Edward Lee,Sophie Wang,Weize Kong,Qiantong Xu,Nilesh Tripuraneni,Yiming Li,Xinxin Yu,Allen Porter,Paul Voigtlaender,Biao Zhang,Arpi Vezer,Sarah York,Qing Wei,Geoffrey Cideron,Mark Kurzeja,Seungyeon Kim,Benny Li,Angéline Pouget,Hyo Lee,Kaspar Daugaard,Yang Li,Dave Uthus,Aditya Siddhant,Paul Cavallaro,Sriram Ganapathy,Maulik Shah,Rolf Jagerman,Jeff Stanway,Piermaria Mendolicchio,Li Xiao,Kayi Lee,Tara Thompson,Shubham Milind Phal,Jason Chase,Sun Jae Lee,Adrian N Reyes,Disha Shrivastava,Zhen Qin,Roykrong Sukkerd,Seth Odoom,Lior Madmoni,John Aslanides,Jonathan Herzig,Elena Pochernina,Sheng Zhang,Parker Barnes,Daisuke Ikeda,Qiujia Li,Shuo-yiin Chang,Shakir Mohamed,Jim Sproch,Richard Powell,Bidisha Samanta,Domagoj Ćevid,Anton Kovsharov,Shrestha Basu Mallick,Srinivas Tadepalli,Anne Zheng,Kareem Ayoub,Andreas Noever,Christian Reisswig,Zhuo Xu,Junhyuk Oh,Martin Matysiak,Tim Blyth,Shereen Ashraf,Julien Amelot,Boone Severson,Michele Bevilacqua,Motoki Sano,Ethan Dyer,Ofir Roval,Anu Sinha,Yin Zhong,Sagi Perel,Tea Sabolić,Johannes Mauerer,Willi Gierke,Mauro Verzetti,Rodrigo Cabrera,Alvin Abdagic,Steven Hemingray,Austin Stone,Jong Lee,Farooq Ahmad,Karthik Raman,Lior Shani,Jonathan Lai,Orhan Firat,Nathan Waters,Eric Ge,Mo Shomrat,Himanshu Gupta,Rajeev Aggarwal,Tom Hudson,Bill Jia,Simon Baumgartner,Palak Jain,Joe Kovac,Junehyuk Jung,Ante Žužul,Will Truong,Morteza Zadimoghaddam,Songyou Peng,Marco Liang,Rachel Sterneck,Balaji Lakshminarayanan,Machel Reid,Oliver Woodman,Tong Zhou,Jianling Wang,Vincent Coriou,Arjun Narayanan,Jay Hoover,Yenai Ma,Apoorv Jindal,Clayton Sanford,Doug Reid,Swaroop Ramaswamy,Alex Kurakin,Roland Zimmermann,Yana Lunts,Dragos Dena,Zalán Borsos,Vered Cohen,Shujian Zhang,Will Grathwohl,Robert Dadashi,Morgan Redshaw,Joshua Kessinger,Julian Odell,Silvano Bonacina,Zihang Dai,Grace Chen,Ayush Dubey,Pablo Sprechmann,Mantas Pajarskas,Wenxuan Zhou,Niharika Ahuja,Tara Thomas,Martin Nikoltchev,Matija Kecman,Bharath Mankalale,Andrey Ryabtsev,Jennifer She,Christian Walder,Jiaming Shen,Lu Li,Carolina Parada,Sheena Panthaplackel,Okwan Kwon,Matt Lawlor,Utsav Prabhu,Yannick Schroecker,Marc'aurelio Ranzato,Pete Blois,Iurii Kemaev,Ting Yu,Dmitry,Lepikhin,Hao Xiong,Sahand Sharifzadeh,Oleaser Johnson,Jeremiah Willcock,Rui Yao,Greg Farquhar,Sujoy Basu,Hidetoshi Shimokawa,Nina Anderson,Haiguang Li,Khiem Pham,Yizhong Liang,Sebastian Borgeaud,Alexandre Moufarek,Hideto Kazawa,Blair Kutzman,Marcin Sieniek,Sara Smoot,Ruth Wang,Natalie Axelsson,Nova Fallen,Prasha Sundaram,Yuexiang Zhai,Varun Godbole,Petros Maniatis,Alek Wang,Ilia Shumailov,Santhosh Thangaraj,Remi Crocker,Nikita Gupta,Gang Wu,Phil Chen,Gellért Weisz,Celine Smith,Mojtaba Seyedhosseini,Boya Fang,Xiyang Luo,Roey Yogev,Zeynep Cankara,Andrew Hard,Helen Ran,Rahul Sukthankar,George Necula,Gaël Liu,Honglong Cai,Praseem Banzal,Daniel Keysers,Sanjay Ghemawat,Connie Tao,Emma Dunleavy,Aditi Chaudhary,Wei Li,Maciej Mikuła,Chen-Yu Lee,Tiziana Refice,Krishna Somandepalli,Alexandre Fréchette,Dan Bahir,John Karro,Keith Rush,Sarah Perrin,Bill Rosgen,Xiaomeng Yang,Clara Huiyi Hu,Mahmoud Alnahlawi,Justin Mao-Jones,Roopal Garg,Hoang Nguyen,Bat-Orgil Batsaikhan,Iñaki Iturrate,Anselm Levskaya,Avi Singh,Ashyana Kachra,Tony Lu,Denis Petek,Zheng Xu,Mark Graham,Lukas Zilka,Yael Karov,Marija Kostelac,Fangyu Liu,Yaohui Guo,Weiyue Wang,Bernd Bohnet,Emily Pitler,Tony Bruguier,Keisuke Kinoshita,Chrysovalantis Anastasiou,Nilpa Jha,Ting Liu,Jerome Connor,Phil Wallis,Philip Pham,Eric Bailey,Shixin Li,Heng-Tze Cheng,Sally Ma,Haiqiong Li,Akanksha Maurya,Kate Olszewska,Manfred Warmuth,Christy Koh,Dominik Paulus,Siddhartha Reddy Jonnalagadda,Enrique Piqueras,Ali Elqursh,Geoff Brown,Hadar Shemtov,Loren Maggiore,Fei Xia,Ryan Foley,Beka Westberg,George van den Driessche,Livio Baldini Soares,Arjun Kar,Michael Quinn,Siqi Zuo,Jialin Wu,Kyle Kastner,Anna Bortsova,Aijun Bai,Ales Mikhalap,Luowei Zhou,Jennifer Brennan,Vinay Ramasesh,Honglei Zhuang,John Maggs,Johan Schalkwyk,Yuntao Xu,Hui Huang,Andrew Howard,Sasha Brown,Linting Xue,Gloria Shen,Brian Albert,Neha Jha,Daniel Zheng,Varvara Krayvanova,Spurthi Amba Hombaiah,Olivier Lacombe,Gautam Vasudevan,Dan Graur,Tian Xie,Meet Gandhi,Bangju Wang,Dustin Zelle,Harman Singh,Dahun Kim,Sébastien Cevey,Victor Ungureanu,Natasha Noy,Fei Liu,Annie Xie,Fangxiaoyu Feng,Katerina Tsihlas,Daniel Formoso,Neera Vats,Quentin Wellens,Yinan Wang,Niket Kumar Bhumihar,Samrat Ghosh,Matt Hoffman,Tom Lieber,Oran Lang,Kush Bhatia,Tom Paine,Aroonalok Pyne,Ronny Votel,Madeleine Clare Elish,Benoit Schillings,Alex Panagopoulos,Haichuan Yang,Adam Raveret,Zohar Yahav,Shuang Liu,Warren Chen,Dalia El Badawy,Nishant Agrawal,Mohammed Badawi,Mahdi Mirzazadeh,Carla Bromberg,Fan Ye,Chang Liu,Tatiana Sholokhova,George-Cristian Muraru,Gargi Balasubramaniam,Jonathan Malmaud,Alen Carin,Danilo Martins,Irina Jurenka,Pankil Botadra,Dave Lacey,Richa Singh,Mariano Schain,Dan Zheng,Isabelle Guyon,Victor Lavrenko,Seungji Lee,Xiang Zhou,Demis Hassabis,Jeshwanth Challagundla,Derek Cheng,Nikhil Mehta,Matthew Mauger,Michela Paganini,Pushkar Mishra,Kate Lee,Zhang Li,Lexi Baugher,Ondrej Skopek,Max Chang,Amir Zait,Gaurav Menghani,Lizzetth Bellot,Guangxing Han,Jean-Michel Sarr,Sharat Chikkerur,Himanshu Sahni,Rohan Anil,Arun Narayanan,Chandu Thekkath,Daniele Pighin,Hana Strejček,Marko Velic,Fred Bertsch,Manuel Tragut,Keran Rong,Alicia Parrish,Kai Bailey,Jiho Park,Isabela Albuquerque,Abhishek Bapna,Rajesh Venkataraman,Alec Kosik,Johannes Griesser,Zhiwei Deng,Alek Andreev,Qingyun Dou,Kevin Hui,Fanny Wei,Xiaobin Yu,Lei Shu,Avia Aharon,David Barker,Badih Ghazi,Sebastian Flennerhag,Chris Breaux,Yuchuan Liu,Matthew Bilotti,Josh Woodward,Uri Alon,Stephanie Winkler,Tzu-Kuo Huang,Kostas Andriopoulos,João Gabriel Oliveira,Penporn Koanantakool,Berkin Akin,Michael Wunder,Cicero Nogueira dos Santos,Mohammad Hossein Bateni,Lin Yang,Dan Horgan,Beer Changpinyo,Keyvan Amiri,Min Ma,Dayeong Lee,Lihao Liang,Anirudh Baddepudi,Tejasi Latkar,Raia Hadsell,Jun Xu,Hairong Mu,Michael Han,Aedan Pope,Snchit Grover,Frank Kim,Ankit Bhagatwala,Guan Sun,Yamini Bansal,Amir Globerson,Alireza Nazari,Samira Daruki,Hagen Soltau,Jane Labanowski,Laurent El Shafey,Matt Harvey,Yanif Ahmad,Elan Rosenfeld,William Kong,Etienne Pot,Yi-Xuan Tan,Aurora Wei,Victoria Langston,Marcel Prasetya,Petar Veličković,Richard Killam,Robin Strudel,Darren Ni,Zhenhai Zhu,Aaron Archer,Kavya Kopparapu,Lynn Nguyen,Emilio Parisotto,Hussain Masoom,Sravanti Addepalli,Jordan Grimstad,Hexiang Hu,Joss Moore,Avinatan Hassidim,Le Hou,Mukund Raghavachari,Jared Lichtarge,Adam R. Brown,Hilal Dib,Natalia Ponomareva,Justin Fu,Yujing Zhang,Altaf Rahman,Joana Iljazi,Edouard Leurent,Gabriel Dulac-Arnold,Cosmo Du,Chulayuth Asawaroengchai,Larry Jin,Ela Gruzewska,Ziwei Ji,Benigno Uria,Daniel De Freitas,Paul Barham,Lauren Beltrone,Víctor Campos,Jun Yan,Neel Kovelamudi,Arthur Nguyen,Elinor Davies,Zhichun Wu,Zoltan Egyed,Kristina Toutanova,Nithya Attaluri,Hongliang Fei,Peter Stys,Siddhartha Brahma,Martin Izzard,Siva Velusamy,Scott Lundberg,Vincent Zhuang,Kevin Sequeira,Adam Santoro,Ehsan Amid,Ophir Aharoni,Shuai Ye,Mukund Sundararajan,Lijun Yu,Yu-Cheng Ling,Stephen Spencer,Hugo Song,Josip Djolonga,Christo Kirov,Sonal Gupta,Alessandro Bissacco,Clemens Meyer,Mukul Bhutani,Andrew Dai,Weiyi Wang,Siqi Liu,Ashwin Sreevatsa,Qijun Tan,Maria Wang,Lucy Kim,Yicheng Wang,Alex Irpan,Yang Xiao,Stanislav Fort,Yifan He,Alex Gurney,Bryan Gale,Yue Ma,Monica Roy,Viorica Patraucean,Taylan Bilal,Golnaz Ghiasi,Anahita Hosseini,Melvin Johnson,Zhuowan Li,Yi Tay,Benjamin Beyret,Katie Millican,Josef Broder,Mayank Lunayach,Danny Swisher,Eugen Vušak,David Parkinson,MH Tessler,Adi Mayrav Gilady,Richard Song,Allan Dafoe,Yves Raimond,Masa Yamaguchi,Itay Karo,Elizabeth Nielsen,Kevin Kilgour,Mike Dusenberry,Rajiv Mathews,Jiho Choi,Siyuan Qiao,Harsh Mehta,Sahitya Potluri,Chris Knutsen,Jialu Liu,Tat Tan,Kuntal Sengupta,Keerthana Gopalakrishnan,Abodunrinwa Toki,Mencher Chiang,Mike Burrows,Grace Vesom,Zafarali Ahmed,Ilia Labzovsky,Siddharth Vashishtha,Preeti Singh,Ankur Sharma,Ada Ma,Jinyu Xie,Pranav Talluri,Hannah Forbes-Pollard,Aarush Selvan,Joel Wee,Loic Matthey,Tom Funkhouser,Parthasarathy Gopavarapu,Lev Proleev,Cheng Li,Matt Thomas,Kashyap Kolipaka,Zhipeng Jia,Ashwin Kakarla,Srinivas Sunkara,Joan Puigcerver,Suraj Satishkumar Sheth,Emily Graves,Chen Wang,Sadh MNM Khan,Kai Kang,Shyamal Buch,Fred Zhang,Omkar Savant,David Soergel,Kevin Lee,Linda Friso,Xuanyi Dong,Rahul Arya,Shreyas Chandrakaladharan,Connor Schenck,Greg Billock,Tejas Iyer,Anton Bakalov,Leslie Baker,Alex Ruiz,Angad Chandorkar,Trieu Trinh,Matt Miecnikowski,Yanqi Zhou,Yangsibo Huang,Jiazhong Nie,Ali Shah,Ashish Thapliyal,Sam Haves,Lun Wang,Uri Shaham,Patrick Morris-Suzuki,Soroush Radpour,Leonard Berrada,Thomas Strohmann,Chaochao Yan,Jingwei Shen,Sonam Goenka,Tris Warkentin,Petar Dević,Dan Belov,Albert Webson,Madhavi Yenugula,Puranjay Datta,Jerry Chang,Nimesh Ghelani,Aviral Kumar,Vincent Perot,Jessica Lo,Yang Song,Herman Schmit,Jianmin Chen,Vasilisa Bashlovkina,Xiaoyue Pan,Diana Mincu,Paul Roit,Isabel Edkins,Andy Davis,Yujia Li,Ben Horn,Xinjian Li,Pradeep Kumar S,Eric Doi,Wanzheng Zhu,Sri Gayatri Sundara Padmanabhan,Siddharth Verma,Jasmine Liu,Heng Chen,Mihajlo Velimirović,Malcolm Reynolds,Priyanka Agrawal,Nick Sukhanov,Abhinit Modi,Siddharth Goyal,John Palowitch,Nima Khajehnouri,Wing Lowe,David Klinghoffer,Sharon Silver,Vinh Tran,Candice Schumann,Francesco Piccinno,Xi Liu,Mario Lučić,Xiaochen Yang,Sandeep Kumar,Ajay Kannan,Ragha Kotikalapudi,Mudit Bansal,Fabian Fuchs,Javad Hosseini,Abdelrahman Abdelhamed,Dawn Bloxwich,Tianhe Yu,Ruoxin Sang,Gregory Thornton,Karan Gill,Yuchi Liu,Virat Shejwalkar,Jason Lin,Zhipeng Yan,Kehang Han,Thomas Buschmann,Michael Pliskin,Zhi Xing,Susheel Tatineni,Junlin Zhang,Sissie Hsiao,Gavin Buttimore,Marcus Wu,Zefei Li,Geza Kovacs,Legg Yeung,Tao Huang,Aaron Cohen,Bethanie Brownfield,Averi Nowak,Mikel Rodriguez,Tianze Shi,Hado van Hasselt,Kevin Cen,Deepanway Ghoshal,Kushal Majmundar,Weiren Yu,Warren,Chen,Danila Sinopalnikov,Hao Zhang,Vlado Galić,Di Lu,Zeyu Zheng,Maggie Song,Gary Wang,Gui Citovsky,Swapnil Gawde,Isaac Galatzer-Levy,David Silver,Ivana Balazevic,Dipanjan Das,Kingshuk Majumder,Yale Cong,Praneet Dutta,Dustin Tran,Hui Wan,Junwei Yuan,Daniel Eppens,Alanna Walton,Been Kim,Harry Ragan,James Cobon-Kerr,Lu Liu,Weijun Wang,Bryce Petrini,Jack Rae,Rakesh Shivanna,Yan Xiong,Chace Lee,Pauline Coquinot,Yiming Gu,Lisa Patel,Blake Hechtman,Aviel Boag,Orion Jankowski,Alex Wertheim,Alex Lee,Paul Covington,Hila Noga,Sam Sobell,Shanthal Vasanth,William Bono,Chirag Nagpal,Wei Fan,Xavier Garcia,Kedar Soparkar,Aybuke Turker,Nathan Howard,Sachit Menon,Yuankai Chen,Vikas Verma,Vladimir Pchelin,Harish Rajamani,Valentin Dalibard,Ana Ramalho,Yang Guo,Kartikeya Badola,Seojin Bang,Nathalie Rauschmayr,Julia Proskurnia,Sudeep Dasari,Xinyun Chen,Mikhail Sushkov,Anja Hauth,Pauline Sho,Abhinav Singh,Bilva Chandra,Allie Culp,Max Dylla,Olivier Bachem,James Besley,Heri Zhao,Timothy Lillicrap,Wei Wei,Wael Al Jishi,Ning Niu,Alban Rrustemi,Raphaël Lopez Kaufman,Ryan Poplin,Jewel Zhao,Minh Truong,Shikhar Bharadwaj,Ester Hlavnova,Eli Stickgold,Cordelia Schmid,Georgi Stephanov,Zhaoqi Leng,Frederick Liu,Léonard Hussenot,Shenil Dodhia,Juliana Vicente Franco,Lesley Katzen,Abhanshu Sharma,Sarah Cogan,Zuguang Yang,Aniket Ray,Sergi Caelles,Shen Yan,Ravin Kumar,Daniel Gillick,Renee Wong,Joshua Ainslie,Jonathan Hoech,Séb Arnold,Dan Abolafia,Anca Dragan,Ben Hora,Grace Hu,Alexey Guseynov,Yang Lu,Chas Leichner,Jinmeng Rao,Abhimanyu Goyal,Nagabhushan Baddi,Daniel Hernandez Diaz,Tim McConnell,Max Bain,Jake Abernethy,Qiqi Yan,Rylan Schaeffer,Paul Vicol,Will Thompson,Montse Gonzalez Arenas,Mathias Bellaiche,Pablo Barrio,Stefan Zinke,Riccardo Patana,Pulkit Mehta,JK Kearns,Avraham Ruderman,Scott Pollom,David D'Ambrosio,Cath Hope,Yang Yu,Andrea Gesmundo,Kuang-Huei Lee,Aviv Rosenberg,Yiqian Zhou,Yaoyiran Li,Drew Garmon,Yonghui Wu,Safeen Huda,Gil Fidel,Martin Baeuml,Jian Li,Phoebe Kirk,Rhys May,Tao Tu,Sara Mc Carthy,Toshiyuki Fukuzawa,Miranda Aperghis,Chih-Kuan Yeh,Toshihiro Yoshino,Bo Li,Austin Myers,Kaisheng Yao,Ben Limonchik,Changwan Ryu,Rohun Saxena,Alex Goldin,Ruizhe Zhao,Rocky Rhodes,Tao Zhu,Divya Tyam,Heidi Howard,Nathan Byrd,Hongxu Ma,Yan Wu,Ryan Mullins,Qingze Wang,Aida Amini,Sebastien Baur,Yiran Mao,Subhashini Venugopalan,Will Song,Wen Ding,Paul Collins,Sashank Reddi,Megan Shum,Andrei Rusu,Luisa Zintgraf,Kelvin Chan,Sheela Goenka,Mathieu Blondel,Michael Collins,Renke Pan,Marissa Giustina,Nikolai Chinaev,Christian Schuler,Ce Zheng,Jonas Valfridsson,Alyssa Loo,Alex Yakubovich,Jamie Smith,Tao Jiang,Rich Munoz,Gabriel Barcik,Rishabh Bansal,Mingyao Yang,Yilun Du,Pablo Duque,Mary Phuong,Alexandra Belias,Kunal Lad,Zeyu Liu,Tal Schuster,Karthik Duddu,Jieru Hu,Paige Kunkle,Matthew Watson,Jackson Tolins,Josh Smith,Denis Teplyashin,Garrett Bingham,Marvin Ritter,Marco Andreetto,Divya Pitta,Mohak Patel,Shashank Viswanadha,Trevor Strohman,Catalin Ionescu,Jincheng Luo,Yogesh Kalley,Jeremy Wiesner,Dan Deutsch,Derek Lockhart,Peter Choy,Rumen Dangovski,Chawin Sitawarin,Cat Graves,Tanya Lando,Joost van Amersfoort,Ndidi Elue,Zhouyuan Huo,Pooya Moradi,Jean Tarbouriech,Henryk Michalewski,Wenting Ye,Eunyoung Kim,Alex Druinsky,Florent Altché,Xinyi Chen,Artur Dwornik,Da-Cheng Juan,Rivka Moroshko,Horia Toma,Jarrod Kahn,Hai Qian,Maximilian Sieb,Irene Cai,Roman Goldenberg,Praneeth Netrapalli,Sindhu Raghuram,Yuan Gong,Lijie Fan,Evan Palmer,Yossi Matias,Valentin Gabeur,Shreya Pathak,Tom Ouyang,Don Metzler,Geoff Bacon,Srinivasan Venkatachary,Sridhar Thiagarajan,Alex Cullum,Eran Ofek,Vytenis Sakenas,Mohamed Hammad,Cesar Magalhaes,Mayank Daswani,Oscar Chang,Ashok Popat,Ruichao Li,Komal Jalan,Yanhan Hou,Josh Lipschultz,Antoine He,Wenhao Jia,Pier Giuseppe Sessa,Prateek Kolhar,William Wong,Sumeet Singh,Lukas Haas,Jay Whang,Hanna Klimczak-Plucińska,Georges Rotival,Grace Chung,Yiqing Hua,Anfal Siddiqui,Nicolas Serrano,Dongkai Chen,Billy Porter,Libin Bai,Keshav Shivam,Sho Arora,Partha Talukdar,Tom Cobley,Sangnie Bhardwaj,Evgeny Gladchenko,Simon Green,Kelvin Guu,Felix Fischer,Xiao Wu,Eric Wang,Achintya Singhal,Tatiana Matejovicova,James Martens,Hongji Li,Roma Patel,Elizabeth Kemp,Jiaqi Pan,Lily Wang,Blake JianHang Chen,Jean-Baptiste Alayrac,Navneet Potti,Erika Gemzer,Eugene Ie,Kay McKinney,Takaaki Saeki,Edward Chou,Pascal Lamblin,SQ Mah,Zach Fisher,Martin Chadwick,Jon Stritar,Obaid Sarvana,Andrew Hogue,Artem Shtefan,Hadi Hashemi,Yang Xu,Jindong Gu,Sharad Vikram,Chung-Ching Chang,Sabela Ramos,Logan Kilpatrick,Weijuan Xi,Jenny Brennan,Yinghao Sun,Abhishek Jindal,Ionel Gog,Dawn Chen,Felix Wu,Jason Lee,Sudhindra Kopalle,Srinadh Bhojanapalli,Oriol Vinyals,Natan Potikha,Burcu Karagol Ayan,Yuan Yuan,Michael Riley,Piotr Stanczyk,Sergey Kishchenko,Bing Wang,Dan Garrette,Antoine Yang,Vlad Feinberg,CJ Carey,Javad Azizi,Viral Shah,Erica Moreira,Chongyang Shi,Josh Feldman,Elizabeth Salesky,Thomas Lampe,Aneesh Pappu,Duhyeon Kim,Jonas Adler,Avi Caciularu,Brian Walker,Yunhan Xu,Yochai Blau,Dylan Scandinaro,Terry Huang,Sam El-Husseini,Abhishek Sinha,Lijie Ren,Taylor Tobin,Patrik Sundberg,Tim Sohn,Vikas Yadav,Mimi Ly,Emily Xue,Jing Xiong,Afzal Shama Soudagar,Sneha Mondal,Nikhil Khadke,Qingchun Ren,Ben Vargas,Stan Bileschi,Sarah Chakera,Cindy Wang,Boyu Wang,Yoni Halpern,Joe Jiang,Vikas Sindhwani,Petre Petrov,Pranavaraj Ponnuramu,Sanket Vaibhav Mehta,Yu Watanabe,Betty Chan,Matheus Wisniewski,Trang Pham,Jingwei Zhang,Conglong Li,Dario de Cesare,Art Khurshudov,Alex Vasiloff,Melissa Tan,Zoe Ashwood,Bobak Shahriari,Maryam Majzoubi,Garrett Tanzer,Olga Kozlova,Robin Alazard,James Lee-Thorp,Nguyet Minh Phu,Isaac Tian,Junwhan Ahn,Andy Crawford,Lauren Lax,Yuan,Shangguan,Iftekhar Naim,David Ross,Oleksandr Ferludin,Tongfei Guo,Andrea Banino,Hubert Soyer,Xiaoen Ju,Dominika Rogozińska,Ishaan Malhi,Marcella Valentine,Daniel Balle,Apoorv Kulshreshtha,Maciej Kula,Yiwen Song,Sophia Austin,John Schultz,Roy Hirsch,Arthur Douillard,Apoorv Reddy,Michael Fink,Summer Yue,Khyatti Gupta,Adam Zhang,Norman Rink,Daniel McDuff,Lei Meng,András György,Yasaman Razeghi,Ricky Liang,Kazuki Osawa,Aviel Atias,Matan Eyal,Tyrone Hill,Nikolai Grigorev,Zhengdong Wang,Nitish Kulkarni,Rachel Soh,Ivan Lobov,Zachary Charles,Sid Lall,Kazuma Hashimoto,Ido Kessler,Victor Gomes,Zelda Mariet,Danny Driess,Alessandro Agostini,Canfer Akbulut,Jingcao Hu,Marissa Ikonomidis,Emily Caveness,Kartik Audhkhasi,Saurabh Agrawal,Ioana Bica,Evan Senter,Jayaram Mudigonda,Kelly Chen,Jingchen Ye,Xuanhui Wang,James Svensson,Philipp Fränken,Josh Newlan,Li Lao,Eva Schnider,Sami Alabed,Joseph Kready,Jesse Emond,Afief Halumi,Tim Zaman,Chengxi Ye,Naina Raisinghani,Vilobh Meshram,Bo Chang,Ankit Singh Rawat,Axel Stjerngren,Sergey Levi,Rui Wang,Xiangzhu Long,Mitchelle Rasquinha,Steven Hand,Aditi Mavalankar,Lauren Agubuzu,Sudeshna Roy,Junquan Chen,Jarek Wilkiewicz,Hao Zhou,Michal Jastrzebski,Qiong Hu,Agustin Dal Lago,Ramya Sree Boppana,Wei-Jen Ko,Jennifer Prendki,Yao Su,Zhi Li,Eliza Rutherford,Girish Ramchandra Rao,Ramona Comanescu,Adrià Puigdomènech,Qihang Chen,Dessie Petrova,Christine Chan,Vedrana Milutinovic,Felipe Tiengo Ferreira,Chin-Yi Cheng,Ming Zhang,Tapomay Dey,Sherry Yang,Ramesh Sampath,Quoc Le,Howard Zhou,Chu-Cheng Lin,Hoi Lam,Christine Kaeser-Chen,Kai Hui,Dean Hirsch,Tom Eccles,Basil Mustafa,Shruti Rijhwani,Morgane Rivière,Yuanzhong Xu,Junjie Wang,Xinyang Geng,Xiance Si,Arjun Khare,Cheolmin Kim,Vahab Mirrokni,Kamyu Lee,Khuslen Baatarsukh,Nathaniel Braun,Lisa Wang,Pallavi LV,Richard Tanburn,Yuvein,Zhu,Fangda Li,Setareh Ariafar,Dan Goldberg,Ken Burke,Daniil Mirylenka,Meiqi Guo,Olaf Ronneberger,Hadas Natalie Vogel,Liqun Cheng,Nishita Shetty,Johnson Jia,Thomas Jimma,Corey Fry,Ted Xiao,Martin Sundermeyer,Ryan Burnell,Yannis Assael,Mario Pinto,JD Chen,Rohit Sathyanarayana,Donghyun Cho,Jing Lu,Rishabh Agarwal,Sugato Basu,Lucas Gonzalez,Dhruv Shah,Meng Wei,Dre Mahaarachchi,Rohan Agrawal,Tero Rissa,Yani Donchev,Ramiro Leal-Cavazos,Adrian Hutter,Markus Mircea,Alon Jacovi,Faruk Ahmed,Jiageng Zhang,Shuguang Hu,Bo-Juen Chen,Jonni Kanerva,Guillaume Desjardins,Andrew Lee,Nikos Parotsidis,Asier Mujika,Tobias Weyand,Jasper Snoek,Jo Chick,Kai Chen,Paul Chang,Ethan Mahintorabi,Zi Wang,Tolly Powell,Orgad Keller,Abhirut Gupta,Claire Sha,Kanav Garg,Nicolas Heess,Ágoston Weisz,Cassidy Hardin,Bartek Wydrowski,Ben Coleman,Karina Zainullina,Pankaj Joshi,Alessandro Epasto,Terry Spitz,Binbin Xiong,Kai Zhao,Arseniy Klimovskiy,Ivy Zheng,Johan Ferret,Itay Yona,Waleed Khawaja,Jean-Baptiste Lespiau,Maxim Krikun,Siamak Shakeri,Timothee Cour,Bonnie Li,Igor Krivokon,Dan Suh,Alex Hofer,Jad Al Abdallah,Nikita Putikhin,Oscar Akerlund,Silvio Lattanzi,Anurag Kumar,Shane Settle,Himanshu Srivastava,Folawiyo Campbell-Ajala,Edouard Rosseel,Mihai Dorin Istin,Nishanth Dikkala,Anand Rao,Nick Young,Kate Lin,Dhruva Bhaswar,Yiming Wang,Jaume Sanchez Elias,Kritika Muralidharan,James Keeling,Dayou Du,Siddharth Gopal,Gregory Dibb,Charles Blundell,Manolis Delakis,Jacky Liang,Marco Tulio Ribeiro,Georgi Karadzhov,Guillermo Garrido,Ankur Bapna,Jiawei Cao,Adam Sadovsky,Pouya Tafti,Arthur Guez,Coline Devin,Yixian Di,Jinwei Xing,Chuqiao,Xu,Hanzhao Lin,Chun-Te Chu,Sameera Ponda,Wesley Helmholz,Fan Yang,Yue Gao,Sara Javanmardi,Wael Farhan,Alex Ramirez,Ricardo Figueira,Khe Chai Sim,Yuval Bahat,Ashwin Vaswani,Liangzhe Yuan,Gufeng Zhang,Leland Rechis,Hanjun Dai,Tayo Oguntebi,Alexandra Cordell,Eugénie Rives,Kaan Tekelioglu,Naveen Kumar,Bing Zhang,Aurick Zhou,Nikolay Savinov,Andrew Leach,Alex Tudor,Sanjay Ganapathy,Yanyan Zheng,Mirko Rossini,Vera Axelrod,Arnaud Autef,Yukun Zhu,Zheng Zheng,Mingda Zhang,Baochen Sun,Jie Ren,Nenad Tomasev,Nithish Kannan,Amer Sinha,Charles Chen,Louis O'Bryan,Alex Pak,Aditya Kusupati,Weel Yang,Deepak Ramachandran,Patrick Griffin,Seokhwan Kim,Philipp Neubeck,Craig Schiff,Tammo Spalink,Mingyang Ling,Arun Nair,Ga-Young Joung,Linda Deng,Avishkar Bhoopchand,Lora Aroyo,Tom Duerig,Jordan Griffith,Gabe Barth-Maron,Jake Ades,Alex Haig,Ankur Taly,Yunting Song,Paul Michel,Dave Orr,Dean Weesner,Corentin Tallec,Carrie Grimes Bostock,Paul Niemczyk,Andy Twigg,Mudit Verma,Rohith Vallu,Henry Wang,Marco Gelmi,Kiranbir Sodhia,Aleksandr Chuklin,Omer Goldman,Jasmine George,Liang Bai,Kelvin Zhang,Petar Sirkovic,Efrat Nehoran,Golan Pundak,Jiaqi Mu,Alice Chen,Alex Greve,Paulo Zacchello,David Amos,Heming Ge,Eric Noland,Colton Bishop,Jeffrey Dudek,Youhei Namiki,Elena Buchatskaya,Jing Li,Dorsa Sadigh,Masha Samsikova,Dan Malkin,Damien Vincent,Robert David,Rob Willoughby,Phoenix Meadowlark,Shawn Gao,Yan Li,Raj Apte,Amit Jhindal,Stein Xudong Lin,Alex Polozov,Zhicheng Wang,Tomas Mery,Anirudh GP,Varun Yerram,Sage Stevens,Tianqi Liu,Noah Fiedel,Charles Sutton,Matthew Johnson,Xiaodan Song,Kate Baumli,Nir Shabat,Muqthar Mohammad,Hao Liu,Marco Selvi,Yichao Zhou,Mehdi Hafezi Manshadi,Chu-ling Ko,Anthony Chen,Michael Bendersky,Jorge Gonzalez Mendez,Nisarg Kothari,Amir Zandieh,Yiling Huang,Daniel Andor,Ellie Pavlick,Idan Brusilovsky,Jitendra Harlalka,Sally Goldman,Andrew Lampinen,Guowang Li,Asahi Ushio,Somit Gupta,Lei Zhang,Chuyuan Kelly Fu,Madhavi Sewak,Timo Denk,Jed Borovik,Brendan Jou,Avital Zipori,Prateek Jain,Junwen Bai,Thang Luong,Jonathan Tompson,Alice Li,Li Liu,George Powell,Jiajun Shen,Alex Feng,Grishma Chole,Da Yu,Yinlam Chow,Tongxin Yin,Eric Malmi,Kefan Xiao,Yash Pande,Shachi Paul,Niccolò Dal Santo,Adil Dostmohamed,Sergio Guadarrama,Aaron Phillips,Thanumalayan Sankaranarayana Pillai,Gal Yona,Amin Ghafouri,Preethi Lahoti,Benjamin Lee,Dhruv Madeka,Eren Sezener,Simon Tokumine,Adrian Collister,Nicola De Cao,Richard Shin,Uday Kalra,Parker Beak,Emily Nottage,Ryo Nakashima,Ivan Jurin,Vikash Sehwag,Meenu Gaba,Junhao Zeng,Kevin R. McKee,Fernando Pereira,Tamar Yakar,Amayika Panda,Arka Dhar,Peilin Zhong,Daniel Sohn,Mark Brand,Lars Lowe Sjoesund,Viral Carpenter,Sharon Lin,Shantanu Thakoor,Marcus Wainwright,Ashwin Chaugule,Pranesh Srinivasan,Muye Zhu,Bernett Orlando,Jack Weber,Ayzaan Wahid,Gilles Baechler,Apurv Suman,Jovana Mitrović,Gabe Taubman,Honglin Yu,Helen King,Josh Dillon,Cathy Yip,Dhriti Varma,Tomas Izo,Levent Bolelli,Borja De Balle Pigem,Julia Di Trapani,Fotis Iliopoulos,Adam Paszke,Nishant Ranka,Joe Zou,Francesco Pongetti,Jed McGiffin,Alex Siegman,Rich Galt,Ross Hemsley,Goran Žužić,Victor Carbune,Tao Li,Myle Ott,Félix de Chaumont Quitry,David Vilar Torres,Yuri Chervonyi,Tomy Tsai,Prem Eruvbetine,Samuel Yang,Matthew Denton,Jake Walker,Slavica Andačić,Idan Heimlich Shtacher,Vittal Premachandran,Harshal Tushar Lehri,Cip Baetu,Damion Yates,Lampros Lamprou,Mariko Iinuma,Ioana Mihailescu,Ben Albrecht,Shachi Dave,Susie Sargsyan,Bryan Perozzi,Lucas Manning,Chiyuan Zhang,Denis Vnukov,Igor Mordatch,Raia Hadsell Wolfgang Macherey,Ryan Kappedal,Jim Stephan,Aditya Tripathi,Klaus Macherey,Jun Qian,Abhishek Bhowmick,Shekoofeh Azizi,Rémi Leblond,Shiva Mohan Reddy Garlapati,Timothy Knight,Matthew Wiethoff,Wei-Chih Hung,Anelia Angelova,Georgios Evangelopoulos,Pawel Janus,Dimitris Paparas,Matthew Rahtz,Ken Caluwaerts,Vivek Sampathkumar,Daniel Jarrett,Shadi Noghabi,Antoine Miech,Chak Yeung,Geoff Clark,Henry Prior,Fei Zheng,Jean Pouget-Abadie,Indro Bhattacharya,Kalpesh Krishna,Will Bishop,Zhe Yuan,Yunxiao Deng,Ashutosh Sathe,Kacper Krasowiak,Ciprian Chelba,Cho-Jui Hsieh,Kiran Vodrahalli,Buhuang Liu,Thomas Köppe,Amr Khalifa,Lubo Litchev,Pichi Charoenpanit,Reed Roberts,Sachin Yadav,Yasumasa Onoe,Desi Ivanov,Megha Mohabey,Vighnesh Birodkar,Nemanja Rakićević,Pierre Sermanet,Vaibhav Mehta,Krishan Subudhi,Travis Choma,Will Ng,Luheng He,Kathie Wang,Tasos Kementsietsidis,Shane Gu,Mansi Gupta,Andrew Nystrom,Mehran Kazemi,Timothy Chung,Nacho Cano,Nikhil Dhawan,Yufei Wang,Jiawei Xia,Trevor Yacovone,Eric Jia,Mingqing Chen,Simeon Ivanov,Ashrith Sheshan,Sid Dalmia,Paweł Stradomski,Pengcheng Yin,Salem Haykal,Congchao Wang,Dennis Duan,Neslihan Bulut,Greg Kochanski,Liam MacDermed,Namrata Godbole,Shitao Weng,Jingjing Chen,Rachana Fellinger,Ramin Mehran,Daniel Suo,Hisham Husain,Tong He,Kaushal Patel,Joshua Howland,Randall Parker,Kelvin Nguyen,Sharath Maddineni,Chris Rawles,Mina Khan,Shlomi Cohen-Ganor,Amol Mandhane,Xinyi Wu,Chenkai Kuang,Iulia Comşa,Ramya Ganeshan,Hanie Sedghi,Adam Bloniarz,Nuo Wang Pierse,Anton Briukhov,Petr Mitrichev,Anita Gergely,Serena Zhan,Allan Zhou,Nikita Saxena,Eva Lu,Josef Dean,Ashish Gupta,Nicolas Perez-Nieves,Renjie Wu,Cory McLean,Wei Liang,Disha Jindal,Anton Tsitsulin,Wenhao Yu,Kaiz Alarakyia,Tom Schaul,Piyush Patil,Peter Sung,Elijah Peake,Hongkun Yu,Feryal Behbahani,JD Co-Reyes,Alan Ansell,Sean Sun,Clara Barbu,Jonathan Lee,Seb Noury,James Allingham,Bilal Piot,Mohit Sharma,Christopher Yew,Ivan Korotkov,Bibo Xu,Demetra Brady,Goran Petrovic,Shibl Mourad,Claire Cui,Aditya Gupta,Parker Schuh,Saarthak Khanna,Anna Goldie,Abhinav Arora,Vadim Zubov,Amy Stuart,Mark Epstein,Yun Zhu,Jianqiao Liu,Yury Stuken,Ziyue Wang,Karolis Misiunas,Dee Guo,Ashleah Gill,Ale Hartman,Zaid Nabulsi,Aurko Roy,Aleksandra Faust,Jason Riesa,Ben Withbroe,Mengchao Wang,Marco Tagliasacchi,Andreea Marzoca,James Noraky,Serge Toropov,Malika Mehrotra,Bahram Raad,Sanja Deur,Steve Xu,Marianne Monteiro,Zhongru Wu,Yi Luan,Sam Ritter,Nick Li,Håvard Garnes,Yanzhang He,Martin Zlocha,Jifan Zhu,Matteo Hessel,Will Wu,Spandana Raj Babbula,Chizu Kawamoto,Yuanzhen Li,Mehadi Hassen,Yan Wang,Brian Wieder,James Freedman,Yin Zhang,Xinyi Bai,Tianli Yu,David Reitter,XiangHai Sheng,Mateo Wirth,Aditya Kini,Dima Damen,Mingcen Gao,Rachel Hornung,Michael Voznesensky,Brian Roark,Adhi Kuncoro,Yuxiang Zhou,Rushin Shah,Anthony Brohan,Kuangyuan Chen,James Wendt,David Rim,Paul Kishan Rubenstein,Jonathan Halcrow,Michelle Liu,Ty Geri,Yunhsuan Sung,Jane Shapiro,Shaan Bijwadia,Chris Duvarney,Christina Sorokin,Paul Natsev,Reeve Ingle,Pramod Gupta,Young Maeng,Ndaba Ndebele,Kexin Zhu,Valentin Anklin,Katherine Lee,Yuan Liu,Yaroslav Akulov,Shaleen Gupta,Guolong Su,Flavien Prost,Tianlin Liu,Vitaly Kovalev,Pol Moreno,Martin Scholz,Sam Redmond,Zongwei Zhou,Alex Castro-Ros,André Susano Pinto,Dia Kharrat,Michal Yarom,Rachel Saputro,Jannis Bulian,Ben Caine,Ji Liu,Abbas Abdolmaleki,Shariq Iqbal,Tautvydas Misiunas,Mikhail Sirotenko,Shefali Garg,Guy Bensky,Huan Gui,Xuezhi Wang,Raphael Koster,Mike Bernico,Da Huang,Romal Thoppilan,Trevor Cohn,Ben Golan,Wenlei Zhou,Andrew Rosenberg,Markus Freitag,Tynan Gangwani,Vincent Tsang,Anand Shukla,Xiaoqi Ren,Minh Giang,Chi Zou,Andre Elisseeff,Charline Le Lan,Dheeru Dua,Shuba Lall,Pranav Shyam,Frankie Garcia,Sarah Nguyen,Michael Guzman,AJ Maschinot,Marcello Maggioni,Ming-Wei Chang,Karol Gregor,Lotte Weerts,Kumaran Venkatesan,Bogdan Damoc,Leon Liu,Jan Wassenberg,Lewis Ho,Becca Roelofs,Majid Hadian,François-Xavier Aubet,Yu Liang,Sami Lachgar,Danny Karmon,Yong Cheng,Amelio Vázquez-Reina,Angie Chen,Zhuyun Dai,Andy Brock,Shubham Agrawal,Chenxi Pang,Peter Garst,Mariella Sanchez-Vargas,Ivor Rendulic,Aditya Ayyar,Andrija Ražnatović,Olivia Ma,Roopali Vij,Neha Sharma,Ashwin Balakrishna,Bingyuan Liu,Ian Mackinnon,Sorin Baltateanu,Petra Poklukar,Gabriel Ibagon,Colin Ji,Hongyang Jiao,Isaac Noble,Wojciech Stokowiec,Zhihao Li,Jeff Dean,David Lindner,Mark Omernick,Kristen Chiafullo,Mason Dimarco,Vitor Rodrigues,Vittorio Selo,Garrett Honke,Xintian,Wu,Wei He,Adam Hillier,Anhad Mohananey,Vihari Piratla,Chang Ye,Chase Malik,Sebastian Riedel,Samuel Albanie,Zi Yang,Kenny Vassigh,Maria Bauza,Sheng Li,Yiqing Tao,Nevan Wichers,Andrii Maksai,Abe Ittycheriah,Ross Mcilroy,Bryan Seybold,Noah Goodman,Romina Datta,Steven M. Hernandez,Tian Shi,Yony Kochinski,Anna Bulanova,Ken Franko,Mikita Sazanovich,Nicholas FitzGerald,Praneeth Kacham,Shubha Srinivas Raghvendra,Vincent Hellendoorn,Alexander Grushetsky,Julian Salazar,Angeliki Lazaridou,Jason Chang,Jan-Thorsten Peter,Sushant Kafle,Yann Dauphin,Abhishek Rao,Filippo Graziano,Izhak Shafran,Yuguo Liao,Tianli Ding,Geng Yan,Grace Chu,Zhao Fu,Vincent Roulet,Gabriel Rasskin,Duncan Williams,Shahar Drath,Alex Mossin,Raphael Hoffmann,Jordi Orbay,Francesco Bertolini,Hila Sheftel,Justin Chiu,Siyang Xue,Yuheng Kuang,Ferjad Naeem,Swaroop Nath,Nana Nti,Phil Culliton,Kashyap Krishnakumar,Michael Isard,Pei Sun,Ayan Chakrabarti,Nathan Clement,Regev Cohen,Arissa Wongpanich,GS Oh,Ashwin Murthy,Hao Zheng,Jessica Hamrick,Oskar Bunyan,Suhas Ganesh,Nitish Gupta,Roy Frostig,John Wieting,Yury Malkov,Pierre Marcenac,Zhixin,Lai,Xiaodan Tang,Mohammad Saleh,Fedir Zubach,Chinmay Kulkarni,Huanjie Zhou,Vicky Zayats,Nan Ding,Anshuman Tripathi,Arijit Pramanik,Patrik Zochbauer,Harish Ganapathy,Vedant Misra,Zach Behrman,Hugo Vallet,Mingyang Zhang,Mukund Sridhar,Ye Jin,Mohammad Babaeizadeh,Siim Põder,Megha Goel,Divya Jain,Tajwar Nasir,Shubham Mittal,Tim Dozat,Diego Ardila,Aliaksei Severyn,Fabio Pardo,Sammy Jerome,Siyang Qin,Louis Rouillard,Amir Yazdanbakhsh,Zizhao Zhang,Shivani Agrawal,Kaushik Shivakumar,Caden Lu,Praveen Kallakuri,Rachita Chhaparia,Kanishka Rao,Charles Kwong,Asya Fadeeva,Shitij Nigam,Yan Virin,Yuan Zhang,Balaji Venkatraman,Beliz Gunel,Marc Wilson,Huiyu Wang,Abhinav Gupta,Xiaowei Xu,Adrien Ali Taïga,Kareem Mohamed,Doug Fritz,Daniel Rodriguez,Zoubin Ghahramani,Harry Askham,Lior Belenki,James Zhao,Rahul Gupta,Krzysztof Jastrzębski,Takahiro Kosakai,Kaan Katircioglu,Jon Schneider,Rina Panigrahy,Konstantinos Bousmalis,Peter Grabowski,Prajit Ramachandran,Chaitra Hegde,Mihaela Rosca,Angelo Scorza Scarpati,Kyriakos Axiotis,Ying Xu,Zach Gleicher,Assaf Hurwitz Michaely,Mandar Sharma,Sanil Jain,Christoph Hirnschall,Tal Marian,Xuhui Jia,Kevin Mather,Kilol Gupta,Linhai Qiu,Nigamaa Nayakanti,Lucian Ionita,Steven Zheng,Lucia Loher,Kurt Shuster,Igor Petrovski,Roshan Sharma,Rahma Chaabouni,Angel Yeh,James An,Arushi Gupta,Steven Schwarcz,Seher Ellis,Sam Conway-Rahman,Javier Snaider,Alex Zhai,James Atwood,Daniel Golovin,Liqian Peng,Te I,Vivian Xia,Salvatore Scellato,Mahan Malihi,Arthur Bražinskas,Vlad-Doru Ion,Younghoon Jun,James Swirhun,Soroosh Mariooryad,Jiao Sun,Steve Chien,Rey Coaguila,Ariel Brand,Yi Gao,Tom Kwiatkowski,Roee Aharoni,Cheng-Chun Lee,Mislav Žanić,Yichi Zhang,Dan Ethier,Vitaly Nikolaev,Pranav Nair,Yoav Ben Shalom,Hen Fitoussi,Jai Gupta,Hongbin Liu,Dee Cattle,Tolga Bolukbasi,Ben Murdoch,Fantine Huot,Yin Li,Chris Hahn*

Key words: Gemini 2.X, multimodal, reasoning, long context

TL;DR: 介绍了Gemini 2.X模型家族，包括2.5 Pro和2.5 Flash等版本，分别针对高性能和低成本需求，其中2.5 Pro在多模态理解和长上下文处理上表现突出。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 通过推出Gemini 2.X模型家族，满足用户在编码、推理、多模态理解等方面的多样化需求，同时覆盖性能和成本的平衡。

Method: Gemini 2.5 Pro具备长上下文处理和多模态能力，2.5 Flash在推理能力上高效低延迟，2.0系列则注重低成本高性能。

Result: Gemini 2.5 Pro在编码和推理基准测试中达到前沿水平，2.5 Flash提供高效推理，全系列覆盖性能与成本需求。

Conclusion: Gemini 2.X模型家族通过多样化的设计，为用户提供了复杂问题解决的全面工具。

Abstract: In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and
Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite
models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA
performance on frontier coding and reasoning benchmarks. In addition to its
incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that
excels at multimodal understanding and it is now able to process up to 3 hours
of video content. Its unique combination of long context, multimodal and
reasoning capabilities can be combined to unlock new agentic workflows. Gemini
2.5 Flash provides excellent reasoning abilities at a fraction of the compute
and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high
performance at low latency and cost. Taken together, the Gemini 2.X model
generation spans the full Pareto frontier of model capability vs cost, allowing
users to explore the boundaries of what is possible with complex agentic
problem solving.

</details>


### [2] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

Key words: 大语言模型,多语言校准,过度自信,用户依赖,认识标记

TL;DR: 研究发现，多语言大模型存在语言过度自信问题，不同语言的用户对其生成的回应依赖行为不同，强调跨语言校准和评估的重要性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 评估大语言模型在多语言环境中的响应校准和安全性，防止用户因模型过度自信而过度依赖其输出。

Method: 分析五种语言中模型生成的认识标记分布，并测量用户在不同语言中的依赖行为。

Result: 模型在多语言中普遍过度自信，用户对自信生成的依赖行为因语言而异（如日语用户更依赖不确定性表达）。

Conclusion: 多语言校准面临挑战，需结合文化和语言背景进行安全性评估。

Abstract: As large language models (LLMs) are deployed globally, it is crucial that
their responses are calibrated across languages to accurately convey
uncertainty and limitations. Previous work has shown that LLMs are
linguistically overconfident in English, leading users to overrely on confident
generations. However, the usage and interpretation of epistemic markers (e.g.,
'It's definitely,' 'I think') can differ sharply across languages. Here, we
study the risks of multilingual linguistic (mis)calibration, overconfidence,
and overreliance across five languages to evaluate the safety of LLMs in a
global context.
  We find that overreliance risks are high across all languages. We first
analyze the distribution of LLM-generated epistemic markers, and observe that
while LLMs are cross-linguistically overconfident, they are also sensitive to
documented linguistic variation. For example, models generate the most markers
of uncertainty in Japanese and the most markers of certainty in German and
Mandarin. We then measure human reliance rates across languages, finding that
while users strongly rely on confident LLM generations in all languages,
reliance behaviors differ cross-linguistically: for example, users rely
significantly more on expressions of uncertainty in Japanese than in English.
Taken together, these results indicate high risk of reliance on overconfident
model generations across languages. Our findings highlight the challenges of
multilingual linguistic calibration and stress the importance of culturally and
linguistically contextualized model safety evaluations.

</details>


### [3] [ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time](https://arxiv.org/abs/2507.06313)
*Kiarash Zahirnia,Zahra Golpayegani,Walid Ahmad,Yang Liu*

Key words: Transformer语言模型,上下文扩展,高效微调,ETT,长序列处理

TL;DR: 论文提出了一种名为ETT的方法，通过高效微调模型参数来扩展短上下文Transformer语言模型的上下文长度，具有恒定内存和线性计算开销，显著提升了模型准确性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 现有Transformer语言模型在处理长序列时，计算和内存开销随序列长度呈二次增长，限制了其应用。

Method: ETT方法通过将输入上下文分块为重叠小子序列，在测试时高效微调模型参数以扩展上下文长度。

Result: 实验表明，ETT将GPT-Large和Phi-2的上下文长度从1k扩展到32k，准确性提升30%。微调FFN的第二层比全微调更有效。

Conclusion: ETT提供了一种高效扩展Transformer语言模型上下文长度的方法，显著提升了长序列处理的性能。

Abstract: Transformer-based Language Models' computation and memory overhead increase
quadratically as a function of sequence length. The quadratic cost poses
challenges when employing LLMs for processing long sequences. In this work, we
introduce \ourmodelacronym~(Extend at Test-Time), method for extending the
context length of short context Transformer-based LLMs, with constant memory
requirement and linear computation overhead. ETT enable the extension of the
context length at test-time by efficient fine-tuning the model's parameters on
the input context, chunked into overlapping small subsequences. We evaluate ETT
on LongBench by extending the context length of GPT-Large and Phi-2 up to 32
times, increasing from 1k to 32k tokens. This results in up to a 30 percent
improvement in the model's accuracy. We also study how context can be stored in
LLM's weights effectively and efficiently. Through a detailed ablation study,
we examine which Transformer modules are most beneficial to fine-tune at
test-time. Interestingly, we find that fine-tuning the second layer of the FFNs
is more effective than full fine-tuning, leading to a further improvement in
the models' accuracy.

</details>


### [4] [Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?](https://arxiv.org/abs/2507.06335)
*Casey Kennington,David Schlangen*

Key words: 计算语义学, 词作为分类器, 形式理论, 分布理论, 接地理论

TL;DR: 本文主张通过‘词作为分类器’模型统一形式、分布和接地语义理论，结合现有文献和实验，并展望统一语义模型的潜力。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 当前计算语义学的形式、分布和接地理论各有优缺点，需要通过统一方法结合它们的优势。

Method: 基于‘词作为分类器’模型，结合文献回顾和认知科学的最新研究，并开展小型实验。

Result: 展示了‘词作为分类器’模型在交互对话中的有效性，并提出了统一语义模型的初步框架。

Conclusion: ‘词作为分类器’模型有望成为统一形式、分布和接地语义理论的可行路径。

Abstract: Formal, Distributional, and Grounded theories of computational semantics each
have their uses and their drawbacks. There has been a shift to ground models of
language by adding visual knowledge, and there has been a call to enrich models
of language with symbolic methods to gain the benefits from formal,
distributional, and grounded theories. In this paper, we attempt to make the
case that one potential path forward in unifying all three semantic fields is
paved with the words-as-classifier model, a model of word-level grounded
semantics that has been incorporated into formalisms and distributional
language models in the literature, and it has been well-tested within
interactive dialogue settings. We review that literature, motivate the
words-as-classifiers model with an appeal to recent work in cognitive science,
and describe a small experiment. Finally, we sketch a model of semantics
unified through words-as-classifiers.

</details>


### [5] [Evaluating Morphological Alignment of Tokenizers in 70 Languages](https://arxiv.org/abs/2507.06378)
*Catherine Arnett,Marisa Hudspeth,Brendan O'Connor*

Key words: 分词器, 语言模型, 形态对齐, MorphScore, 下游任务

TL;DR: 本文评估了分词器质量对语言模型性能的影响，发现形态对齐与模型性能相关性较弱。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 研究分词器质量（特别是形态对齐）如何影响语言模型性能，扩展了MorphScore以覆盖更多语言。

Method: 扩展MorphScore至70种语言，并分析形态对齐分数与下游任务性能的相关性。

Result: 形态对齐无法显著解释模型性能差异，表明其单独不足以衡量分词器质量。

Conclusion: 分词器质量的评估需考虑更多维度，形态对齐并非关键指标。

Abstract: While tokenization is a key step in language modeling, with effects on model
training and performance, it remains unclear how to effectively evaluate
tokenizer quality. One proposed dimension of tokenizer quality is the extent to
which tokenizers preserve linguistically meaningful subwords, aligning token
boundaries with morphological boundaries within a word. We expand MorphScore
(Arnett & Bergen, 2025), which previously covered 22 languages, to support a
total of 70 languages. The updated MorphScore offers more flexibility in
evaluation and addresses some of the limitations of the original version. We
then correlate our alignment scores with downstream task performance for five
pre-trained languages models on seven tasks, with at least one task in each of
the languages in our sample. We find that morphological alignment does not
explain very much variance in model performance, suggesting that morphological
alignment alone does not measure dimensions of tokenization quality relevant to
model performance.

</details>


### [6] [Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles](https://arxiv.org/abs/2507.06393)
*Matilde Marcolli,Riny Huijbregts,Richard K. Larson*

Key words: 头函数, 超磁石, 彩色操作, 句法结构, 内合并

TL;DR: 该论文展示了头函数如何将语法对象的磁石结构扩展为超磁石结构，并提出了一种基于彩色操作的结构生成系统，用于描述句法结构的形成。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 研究目的是将语法结构的形成和操作（如合并和移动）形式化为数学结构（如超磁石和彩色操作），以更统一地解释句法现象。

Method: 通过将头函数、补足语、指示语等句法关系映射为彩色操作的生成规则，并利用超磁石结构的兼容性，提出了一种新的结构生成系统。

Result: 研究结果表明，句法结构的形成和移动规则（如内合并、扩展投射原则等）可以通过彩色操作的生成规则统一描述。

Conclusion: 论文提出了一种基于数学结构的统一框架，能够有效解释句法现象和结构形成的机制。

Abstract: We show that head functions on syntactic objects extend the magma structure
to a hypermagma, with the c-command relation compatible with the magma
operation and the m-command relation with the hypermagma. We then show that the
structure of head and complement and specifier, additional modifier positions,
and the structure of phases in the Extended Projection can be formulated as a
bud generating system of a colored operad, in a form similar to the structure
of theta roles. We also show that, due to the special form of the colored
operad generators, the filtering of freely generated syntactic objects by these
coloring rules can be equivalently formulated as a filtering in the course of
structure formation via a colored Merge, which can in turn be related to the
hypermagma structure. The rules on movement by Internal Merge with respect to
phases, the Extended Projection Principle, Empty Category Principle, and Phase
Impenetrability Condition are all subsumed into the form of the colored operad
generators. Movement compatibilities between the phase structure and the theta
roles assignments can then be formulated in terms of the respective colored
operads and a transduction of colored operads.

</details>


### [7] [PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning](https://arxiv.org/abs/2507.06415)
*Zeming Chen,Angelika Romanou,Gail Weiss,Antoine Bosselut*

Key words: 长上下文推理, 参数高效, 元学习, LoRA, 测试时学习

TL;DR: PERK（Parameter Efficient Reasoning over Knowledge）是一种高效的方法，通过梯度更新轻量级模型适配器，在测试时实现对长上下文的编码和推理。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决现有元学习方法在长上下文推理中的高内存消耗问题。

Method: 采用双嵌套优化循环的元训练方法，内循环快速编码上下文到低秩适配器（LoRA），外循环学习利用更新后的适配器进行推理。

Result: PERK在长上下文推理任务中显著优于标准基准，性能提升高达90%（小模型）和27%（大模型）。

Conclusion: PERK在训练时可能内存密集，但在推理时比基于提示的方法更高效。

Abstract: Long-context reasoning requires accurately identifying relevant information
in extensive, noisy input contexts. Previous research shows that using
test-time learning to encode context directly into model parameters can
effectively enable reasoning over noisy information. However, meta-learning
methods for enabling test-time learning are prohibitively memory-intensive,
preventing their application to long context settings. In this work, we propose
PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for
learning to encode long input contexts using gradient updates to a lightweight
model adapter at test time. Specifically, PERK employs two nested optimization
loops in a meta-training phase. The inner loop rapidly encodes contexts into a
low-rank adapter (LoRA) that serves as a parameter-efficient memory module for
the base model. Concurrently, the outer loop learns to use the updated adapter
to accurately recall and reason over relevant information from the encoded long
context. Our evaluations on several long-context reasoning tasks show that PERK
significantly outperforms the standard prompt-based long-context baseline,
achieving average absolute performance gains of up to 90% for smaller models
(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In
general, PERK is more robust to reasoning complexity, length extrapolation, and
the locations of relevant information in contexts. Finally, we show that while
PERK is memory-intensive during training, it scales more efficiently at
inference time than prompt-based long-context inference.

</details>


### [8] [Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling](https://arxiv.org/abs/2507.06419)
*Pankayaraj Pathmanathan,Furong Huang*

Key words: 奖励建模, 大语言模型, 抗干扰性, 对抗样本, 自增强框架

TL;DR: 本文提出了一种名为REFORM的自增强奖励建模框架，通过奖励引导的解码方法发现奖励模型的失败模式，并利用生成的对抗样本增强训练数据，以提高其鲁棒性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 现有的奖励模型由于人类偏好的复杂性和数据集的有限覆盖，容易在分布偏移或对抗扰动下失效。然而，当前方法依赖于对偏好分布或失败属性的先验知识，实际应用中难以获得这些信息。

Method: 提出了REFORM框架，通过奖励模型自身引导生成错误评分的响应作为对抗样本，用于增强训练数据和修正奖励模型的对齐行为。

Result: 在Anthropic Helpful Harmless (HH)和PKU Beavertails数据集上的实验表明，REFORM显著提升了模型的鲁棒性，同时保持了奖励质量。

Conclusion: REFORM不仅在下游策略训练中表现优异，还能通过消除虚假相关性进一步提高对齐质量。

Abstract: Reward modeling (RM), which captures human preferences to align large
language models (LLMs), is increasingly employed in tasks such as model
finetuning, response filtering, and ranking. However, due to the inherent
complexity of human preferences and the limited coverage of available datasets,
reward models often fail under distributional shifts or adversarial
perturbations. Existing approaches for identifying such failure modes typically
rely on prior knowledge about preference distributions or failure attributes,
limiting their practicality in real-world settings where such information is
unavailable. In this work, we propose a tractable, preference-distribution
agnostic method for discovering reward model failure modes via reward guided
controlled decoding. Building on this, we introduce REFORM, a self-improving
reward modeling framework that enhances robustness by using the reward model
itself to guide the generation of falsely scored responses. These adversarial
examples are then used to augment the training data and patch the reward
model's misaligned behavior. We evaluate REFORM on two widely used preference
datasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate
that it significantly improves robustness without sacrificing reward quality.
Notably, REFORM preserves performance both in direct evaluation and in
downstream policy training, and further improves alignment quality by removing
spurious correlations.

</details>


### [9] [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](https://arxiv.org/abs/2507.06427)
*Shun Wang,Tyler Loakman,Youbo Lei,Yi Liu,Bohao Yang,Yuting Zhao,Dong Yang,Chenghua Lin*

Key words: 大型语言模型, 字典学习, 稀疏自编码器, 单义特征, 数学推理, 隐喻检测

TL;DR: 该论文提出了一种基于字典学习和稀疏自编码器的大型语言模型分解方法，用于提取单义特征并提升模型性能。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 传统的大型语言模型（LLMs）被视为黑盒算法，降低了可信度且难以提升下游任务性能。

Method: 采用字典学习和稀疏自编码器的方法分解LLM，提取单义特征并识别模型内部误解。

Result: 该方法显著提升了数学推理和隐喻检测等下游任务的性能，并通过自动改进提示词增强了模型解释能力。

Conclusion: 通过分解LLM提取单义特征，可以有效提升模型性能和可解释性。

Abstract: Large Language Models (LLMs) are traditionally viewed as black-box
algorithms, therefore reducing trustworthiness and obscuring potential
approaches to increasing performance on downstream tasks. In this work, we
apply an effective LLM decomposition method using a dictionary-learning
approach with sparse autoencoders. This helps extract monosemantic features
from polysemantic LLM neurons. Remarkably, our work identifies model-internal
misunderstanding, allowing the automatic reformulation of the prompts with
additional annotations to improve the interpretation by LLMs. Moreover, this
approach demonstrates a significant performance improvement in downstream
tasks, such as mathematical reasoning and metaphor detection.

</details>


### [10] [Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling](https://arxiv.org/abs/2507.06435)
*Rafiu Adekoya Badekale,Adewale Akinfaderin*

Key words: 气候变化, 政策语言, 动态嵌入主题模型, 联合国气候变化框架公约, 时间分析

TL;DR: 该论文提出了一种基于动态嵌入主题模型（DETM）的新方法，用于分析全球气候政策语言的演变，揭示了从温室气体到实施与技术合作的主题转变。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 评估全球政策语言演变对于应对气候变化等复杂挑战至关重要，传统方法效率低且难以捕捉复杂性。

Method: 使用DETM模型分析1995年至2023年UNFCCC政策决策语料库，结合预处理和可视化技术。

Result: 模型成功捕捉了主题的动态变化，从早期温室气体话题转向实施、技术合作等新主题。

Conclusion: DETM是一种可扩展且有效的工具，为政策语言分析提供了新思路，未来可扩展至其他政策领域。

Abstract: Understanding how policy language evolves over time is critical for assessing
global responses to complex challenges such as climate change. Temporal
analysis helps stakeholders, including policymakers and researchers, to
evaluate past priorities, identify emerging themes, design governance
strategies, and develop mitigation measures. Traditional approaches, such as
manual thematic coding, are time-consuming and limited in capturing the
complex, interconnected nature of global policy discourse. With the increasing
relevance of unsupervised machine learning, these limitations can be addressed,
particularly under high-volume, complex, and high-dimensional data conditions.
In this work, we explore a novel approach that applies the dynamic embedded
topic model (DETM) to analyze the evolution of global climate policy discourse.
A probabilistic model designed to capture the temporal dynamics of topics over
time. We collected a corpus of United Nations Framework Convention on Climate
Change (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the
postponement of COP26 as a result of the COVID-19 pandemic. The model reveals
shifts from early emphases on greenhouse gases and international conventions to
recent focuses on implementation, technical collaboration, capacity building,
finance, and global agreements. Section 3 presents the modeling pipeline,
including preprocessing, model training, and visualization of temporal word
distributions. Our results show that DETM is a scalable and effective tool for
analyzing the evolution of global policy discourse. Section 4 discusses the
implications of these findings and we concluded with future directions and
refinements to extend this approach to other policy domains.

</details>


### [11] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
*Zhenhailong Wang,Xuehang Guo,Sofia Stoica,Haiyang Xu,Hongru Wang,Hyeonjeong Ha,Xiusi Chen,Yangyi Chen,Ming Yan,Fei Huang,Heng Ji*

Key words: 强化学习,多模态推理,视觉感知,PAPO,KL散度

TL;DR: 论文提出了PAPO方法，通过在GRPO目标中引入隐式感知损失，显著提升多模态推理任务的性能，尤其在视觉依赖高的任务中效果更明显。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 现有强化学习方法在纯文本领域表现良好，但在多模态推理任务中表现不佳，主要因为视觉输入的感知能力不足。

Method: 提出PAPO方法，结合KL散度的隐式感知损失，从内部监督信号中学习感知和推理。

Result: PAPO在多模态基准上提升4.4%，在视觉依赖高的任务中提升近8.0%，且感知错误减少30.5%。

Conclusion: PAPO通过感知感知监督的深度集成，为视觉基础推理的新RL框架奠定了基础。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a
highly effective strategy for endowing Large Language Models (LLMs) with robust
multi-step reasoning abilities. However, its design and optimizations remain
tailored to purely textual domains, resulting in suboptimal performance when
applied to multimodal reasoning tasks. In particular, we observe that a major
source of error in current multimodal reasoning lies in the perception of
visual inputs. To address this bottleneck, we propose Perception-Aware Policy
Optimization (PAPO), a simple yet effective extension of GRPO that encourages
the model to learn to perceive while learning to reason, entirely from internal
supervision signals. Notably, PAPO does not rely on additional data curation,
external reward models, or proprietary models. Specifically, we introduce the
Implicit Perception Loss in the form of a KL divergence term to the GRPO
objective, which, despite its simplicity, yields significant overall
improvements (4.4%) on diverse multimodal benchmarks. The improvements are more
pronounced, approaching 8.0%, on tasks with high vision dependency. We also
observe a substantial reduction (30.5%) in perception errors, indicating
improved perceptual capabilities with PAPO. We conduct comprehensive analysis
of PAPO and identify a unique loss hacking issue, which we rigorously analyze
and mitigate through a Double Entropy Loss. Overall, our work introduces a
deeper integration of perception-aware supervision into RLVR learning
objectives and lays the groundwork for a new RL framework that encourages
visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.

</details>


### [12] [A Semantic Parsing Framework for End-to-End Time Normalization](https://arxiv.org/abs/2507.06450)
*Xin Su,Sungduk Yu,Phillip Howard,Steven Bethard*

Key words: 时间规范化、SCATE框架、代码生成、LLM、数据增强

TL;DR: 论文提出了一种基于SCATE框架的时间规范化新方法，通过代码生成任务和LLM辅助数据增强，实现了高性能、可解释的时间表达式转换。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 传统基于ISO-TimeML的系统在表达复杂时间表达式时存在限制，需要一种更灵活、可解释的新方法。

Method: 将时间规范化重新定义为SCATE框架下的代码生成任务，利用LLM生成可执行代码，并通过数据增强生成大规模标注数据。

Result: 实验表明，小模型在增强数据上训练后性能优于LLM，且具备部署性和可解释性。

Conclusion: SCATE框架与LLM辅助数据增强的结合为时间规范化提供了高效、准确的解决方案。

Abstract: Time normalization is the task of converting natural language temporal
expressions into machine-readable representations. It underpins many downstream
applications in information retrieval, question answering, and clinical
decision-making. Traditional systems based on the ISO-TimeML schema limit
expressivity and struggle with complex constructs such as compositional,
event-relative, and multi-span time expressions. In this work, we introduce a
novel formulation of time normalization as a code generation task grounded in
the SCATE framework, which defines temporal semantics through symbolic and
compositional operators. We implement a fully executable SCATE Python library
and demonstrate that large language models (LLMs) can generate executable SCATE
code. Leveraging this capability, we develop an automatic data augmentation
pipeline using LLMs to synthesize large-scale annotated data with code-level
validation. Our experiments show that small, locally deployable models trained
on this augmented data can achieve strong performance, outperforming even their
LLM parents and enabling practical, accurate, and interpretable time
normalization.

</details>


### [13] [A Systematic Analysis of Hybrid Linear Attention](https://arxiv.org/abs/2507.06457)
*Dustin Wang,Rui-Jie Zhu,Steven Abreu,Yong Shan,Taylor Kergan,Yuqi Pan,Yuhong Chou,Zheng Li,Ge Zhang,Wenhao Huang,Jason Eshraghian*

Key words: Transformer,线性注意力,混合架构,语言建模,召回任务

TL;DR: 本文系统评估了多种线性注意力模型在混合架构中的表现，发现独立表现优越的模型在混合架构中未必出色，并提出了优化混合模型的关键因素和推荐架构。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 为了解决Transformer在处理长序列时的二次复杂性和内存问题，并探索线性注意力模型在混合架构中的表现。

Method: 通过训练和开源72个模型，覆盖六种线性注意力变体和五种混合比例，在语言建模和召回任务上进行基准测试。

Result: 发现语言建模性能稳定，而召回性能随全注意力层比例增加而显著提升，尤其在线性与全注意力比例低于3:1时。

Conclusion: 选择性门控、分层循环和受控遗忘是有效混合模型的关键，推荐HGRN-2或GatedDeltaNet架构并以3:1至6:1比例实现高效召回。

Abstract: Transformers face quadratic complexity and memory issues with long sequences,
prompting the adoption of linear attention mechanisms using fixed-size hidden
states. However, linear models often suffer from limited recall performance,
leading to hybrid architectures that combine linear and full attention layers.
Despite extensive hybrid architecture research, the choice of linear attention
component has not been deeply explored. We systematically evaluate various
linear attention models across generations - vector recurrences to advanced
gating mechanisms - both standalone and hybridized. To enable this
comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M
parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six
linear attention variants across five hybridization ratios. Benchmarking on
standard language modeling and recall tasks reveals that superior standalone
linear models do not necessarily excel in hybrids. While language modeling
remains stable across linear-to-full attention ratios, recall significantly
improves with increased full attention layers, particularly below a 3:1 ratio.
Our study highlights selective gating, hierarchical recurrence, and controlled
forgetting as critical for effective hybrid models. We recommend architectures
such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1
to achieve Transformer-level recall efficiently. Our models are open-sourced at
https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.

</details>


### [14] [On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489)
*Stephen Obadinma,Xiaodan Zhu*

Key words: 大型语言模型, verbal confidence, 对抗攻击, 鲁棒性, 提示策略

TL;DR: 该研究首次全面分析了大型语言模型（LLMs）的verbal confidence在对抗攻击下的鲁棒性，揭示了现有方法的脆弱性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 确保LLMs在人类-AI交互中的透明性、信任和安全性，特别是在高风险的场景下。

Method: 提出了一种新的攻击框架，包括扰动和jailbreak方法，并在多种提示策略、模型规模和应用领域中测试。

Result: 攻击能显著影响verbal confidence估计，导致频繁的答案变动，现有防御方法大多无效。

Conclusion: 研究呼吁设计更鲁棒的confidence表达机制，因为即使是微小的语义保留修改也可能导致误导性的confidence。

Abstract: Robust verbal confidence generated by large language models (LLMs) is crucial
for the deployment of LLMs to ensure transparency, trust, and safety in
human-AI interactions across many high-stakes applications. In this paper, we
present the first comprehensive study on the robustness of verbal confidence
under adversarial attacks. We introduce a novel framework for attacking verbal
confidence scores through both perturbation and jailbreak-based methods, and
show that these attacks can significantly jeopardize verbal confidence
estimates and lead to frequent answer changes. We examine a variety of
prompting strategies, model sizes, and application domains, revealing that
current confidence elicitation methods are vulnerable and that commonly used
defence techniques are largely ineffective or counterproductive. Our findings
underscore the urgent need to design more robust mechanisms for confidence
expression in LLMs, as even subtle semantic-preserving modifications can lead
to misleading confidence in responses.

</details>


### [15] [Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings](https://arxiv.org/abs/2507.06506)
*Russell Taylor,Benjamin Herbert,Michael Sana*

Key words: 双关语翻译、大型语言模型、语音语义嵌入、多代理框架、计算语言学

TL;DR: 论文提出了一种结合大型语言模型和专门技术的三阶段方法，用于将英语双关语翻译成法语，注重保留幽默和语言创意，而非字面翻译。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决双关语在跨语言翻译中面临的独特挑战，填补翻译研究与计算语言学之间的空白。

Method: 采用三阶段方法：基线模型对比学习、引导思维链管道、多代理生成-判别框架。

Result: 在CLEF JOKER 2025竞赛中获得第一和第二名，证明了方法的有效性。

Conclusion: 研究通过语言学技术推进了语言模型在双关语翻译中的应用，强调了语义模糊性、语音相似性和文化意识的重要性。

Abstract: Translating wordplay across languages presents unique challenges that have
long confounded both professional human translators and machine translation
systems. This research proposes a novel approach for translating puns from
English to French by combining state-of-the-art large language models with
specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a
baseline using multiple frontier large language models with feedback based on a
new contrastive learning dataset. Second, we implement a guided
chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we
implement a multi-agent generator-discriminator framework for evaluating and
regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's
primary objective is to capture the linguistic creativity and humor of the
source text wordplay, rather than simply duplicating its vocabulary. Our best
runs earned first and second place in the CLEF JOKER 2025 Task 2 competition
where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational
linguistics by implementing linguistically-informed techniques for wordplay
translation, advancing our understanding of how language models can be
leveraged to handle the complex interplay between semantic ambiguity, phonetic
similarity, and the implicit cultural and linguistic awareness needed for
successful humor.

</details>


### [16] [SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](https://arxiv.org/abs/2507.06517)
*Zicong Tang,Shi Luohe,Zuchao Li,Baoyuan Qi,Guoming Liu,Lefei Zhang,Ping Wang*

Key words: Large Language Models, KV缓存, SpindleKV, 注意力机制, GQA

TL;DR: SpindleKV提出了一种新的KV缓存缩减方法，平衡浅层和深层的处理，提升LLMs推理效率。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: LLMs的KV缓存内存消耗问题显著，尤其在浅层缓存缩减不足，而深层已有优化。

Method: SpindleKV结合注意力权重驱逐（深层）和基于代码本替换（浅层），并解决了GQA问题。

Result: 实验表明SpindleKV在KV缓存缩减效果上优于基线方法，同时保持或提升模型性能。

Conclusion: SpindleKV有效解决了LLMs推理中的KV缓存问题，适用于不同模型。

Abstract: Large Language Models (LLMs) have achieved impressive accomplishments in
recent years. However, the increasing memory consumption of KV cache has
possessed a significant challenge to the inference system. Eviction methods
have revealed the inherent redundancy within the KV cache, demonstrating its
potential for reduction, particularly in deeper layers. However, KV cache
reduction for shallower layers has been found to be insufficient. Based on our
observation that, the KV cache exhibits a high degree of similarity. Based on
this observation, we proposed a novel KV cache reduction method, SpindleKV,
which balances both shallow and deep layers. For deep layers, we employ an
attention weight based eviction method, while for shallow layers, we apply a
codebook based replacement approach which is learnt by similarity and merging
policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma
faced by other attention based eviction methods. Experiments on two common
benchmarks with three different LLMs shown that SpindleKV obtained better KV
cache reduction effect compared to baseline methods, while preserving similar
or even better model performance.

</details>


### [17] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

Key words: 大语言模型, 监督微调, 行为金融, 群体行为, 最优投资

TL;DR: 论文提出InvestAlign框架，通过理论生成的简单投资问题数据替代真实用户数据，用于监督微调大语言模型（LLMs），以提高与投资者群体行为决策的对齐效率。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决行为金融中LLMs与投资者群体行为决策对齐的挑战，尤其是真实用户数据稀缺导致的监督微调（SFT）成本高和隐私风险问题。

Method: 提出InvestAlign框架，利用理论生成的简单投资问题数据构建高质量SFT数据集，而非依赖复杂场景的真实数据。开发InvestAgent代理，用于验证对齐效果。

Result: InvestAlign生成的数据比真实数据能更快实现参数收敛，InvestAgent在简单和复杂投资问题上均更贴近真实用户数据。

Conclusion: InvestAlign是一种有潜力的方法，可有效对齐LLMs与投资者群体行为决策，并解决复杂最优投资问题。

Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

</details>


### [18] [Large Language Model for Extracting Complex Contract Information in Industrial Scenes](https://arxiv.org/abs/2507.06539)
*Yunyang Cao,Yanjun Li,Silong Dai*

Key words: 合同信息抽取, 数据集构建, 大型语言模型, 数据增强, LoRA

TL;DR: 提出了一种高质量的工业合同信息抽取数据集构建方法，并基于此微调大型语言模型，取得了优异性能。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决工业场景中复杂合同信息抽取任务的挑战，提供高效解决方案。

Method: 通过聚类分析、GPT-4/GPT-3.5完成高质量数据标注，采用数据增强和随机关键词生成新文本，并微调大型语言模型。

Result: 模型在召回率、精确度和解析效率上表现优异，LoRA、数据平衡和数据增强提升了准确性和鲁棒性。

Conclusion: 该方法为工业合同信息抽取任务提供了新颖且高效的解决方案。

Abstract: This paper proposes a high-quality dataset construction method for complex
contract information extraction tasks in industrial scenarios and fine-tunes a
large language model based on this dataset. Firstly, cluster analysis is
performed on industrial contract texts, and GPT-4 and GPT-3.5 are used to
extract key information from the original contract data, obtaining high-quality
data annotations. Secondly, data augmentation is achieved by constructing new
texts, and GPT-3.5 generates unstructured contract texts from randomly combined
keywords, improving model robustness. Finally, the large language model is
fine-tuned based on the high-quality dataset. Experimental results show that
the model achieves excellent overall performance while ensuring high field
recall and precision and considering parsing efficiency. LoRA, data balancing,
and data augmentation effectively enhance model accuracy and robustness. The
proposed method provides a novel and efficient solution for industrial contract
information extraction tasks.

</details>


### [19] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
*Juan B. Gutiérrez*

Key words: 大型语言模型, 讨论网络, 无效性, 同行评审, 错误率

TL;DR: 论文提出了一种讨论网络模型，将人类和大型语言模型（LLMs）视为平等节点，分析其交互中的无效性（如事实、逻辑或结构错误），并揭示了四种风险。通过数学模型发现，网络在漂移和自我修复下会稳定在较低错误率，而增加伪造则会导致高错误率。引入同行评审后，系统会趋向真理主导状态。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 研究人类与LLMs交互中的无效性问题，探索如何通过讨论网络模型提升可靠性。

Method: 提出讨论网络模型，定义无效性及其四种风险（漂移、自我修复、伪造、外部检测），并开发数学模型分析其动态。

Result: 发现漂移和自我修复下网络稳定在低错误率，伪造导致高错误率；同行评审可推动系统趋向真理。

Conclusion: 提升LLMs可靠性的关键在于将不完美的模型组织成相互监督的网络，而非追求单一模型的完美。

Abstract: Large-language models turn writing into a live exchange between humans and
software. We capture this new medium with a discursive-network model that
treats people and LLMs as equal nodes and tracks how their statements
circulate. Broadening the focus from isolated hallucinations, we define
invalidation (any factual, logical, or structural breach) and show it follows
four hazards: drift from truth, self-repair, fresh fabrication, and external
detection. A general mathematical model of discursive networks is developed to
provide valuable insights: A network governed only by drift and self-repair
stabilizes at a modest error rate; adding fabrication reproduces the high rates
seen in current LLMs. Giving each false claim even a small chance of peer
review shifts the system to a truth-dominant state. We operationalize peer
review with the open-source \emph{Flaws-of-Others (FOO) algorithm}: a
configurable loop in which any set of agents critique one another while a
harmoniser merges their verdicts. The takeaway is practical and cultural:
reliability in this new medium comes not from perfecting single models but from
wiring imperfect ones into networks that keep each other honest.

</details>


### [20] [Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis](https://arxiv.org/abs/2507.06571)
*Srihari K B,Pushpak Bhattacharyya*

Key words: 多模态知识图谱, 生成式AI, 食品问答, 联合微调, 视觉保真度

TL;DR: 提出了一个结合多模态知识图谱（MMKG）与生成式AI的食品领域问答框架，显著提升了性能。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 通过结合结构化知识与多模态生成，提升食品问答的可靠性与多样性。

Method: 构建大规模MMKG，生成问答对，联合微调Meta LLaMA 3.1-8B和Stable Diffusion 3.5-Large，并采用检索-生成混合策略。

Result: BERTScore提升16.2
o: 7.3%），并实现94.1%的图像重新利用准确率和85%的合成充足率。

Conclusion: 结构和多模态生成结合显著提升食品问答系统的性能。

Abstract: We propose a unified food-domain QA framework that combines a large-scale
multimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000
recipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate
40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint
fine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves
BERTScore by 16.2\%, reduces FID by 37.8\%, and boosts CLIP alignment by
31.1\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\% to 7.3\%) and
LLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid
retrieval-generation strategy achieves 94.1\% accurate image reuse and 85\%
adequacy in synthesis. Our results demonstrate that structured knowledge and
multimodal generation together enhance reliability and diversity in food QA.

</details>


### [21] [Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation](https://arxiv.org/abs/2507.06607)
*Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen*

Key words: State Space Models, Gated Memory Unit, SambaY, decoding efficiency, long-context performance

TL;DR: 论文提出一种名为Gated Memory Unit (GMU)的机制，通过跨层共享状态空间模型(SSM)的记忆状态，提升解码效率，并在SambaY架构中实现线性预填充时间复杂度和长上下文性能提升。实验证明其在推理任务中表现优于基线模型。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 为了探索状态空间模型(SSM)层间表示共享的效率潜力，提升序列建模的性能和解码效率。

Method: 提出Gated Memory Unit (GMU)，并将其应用于SambaY架构，通过跨解码器共享Samba自解码器的记忆读取状态。结合Differential Attention技术优化模型性能。

Result: SambaY显著提升了解码效率，长期上下文性能，并在大规模计算下表现出更低的不可减少损失。Phi4-mini-Flash-Reasoning模型在推理任务中表现优异，解码吞吐量提升10倍。

Conclusion: GMU机制和SambaY架构有效提升了SSM模型的效率与性能，尤其在长上下文和大规模计算场景下表现突出。

Abstract: Recent advances in language modeling have demonstrated the effectiveness of
State Space Models (SSMs) for efficient sequence modeling. While hybrid
architectures such as Samba and the decoder-decoder architecture, YOCO, have
shown promising performance gains over Transformers, prior works have not
investigated the efficiency potential of representation sharing between SSM
layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet
effective mechanism for efficient memory sharing across layers. We apply it to
create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in
the cross-decoder to share memory readout states from a Samba-based
self-decoder. SambaY significantly enhances decoding efficiency, preserves
linear pre-filling time complexity, and boosts long-context performance, all
while eliminating the need for explicit positional encoding. Through extensive
scaling experiments, we demonstrate that our model exhibits a significantly
lower irreducible loss compared to a strong YOCO baseline, indicating superior
performance scalability under large-scale compute regimes. Our largest model
enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves
significantly better performance than Phi4-mini-Reasoning on reasoning tasks
such as Math500, AIME24/25, and GPQA Diamond without any reinforcement
learning, while delivering up to 10x higher decoding throughput on 2K-length
prompts with 32K generation length under the vLLM inference framework. We
release our training codebase on open-source data at
https://github.com/microsoft/ArchScale.

</details>


### [22] [FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation](https://arxiv.org/abs/2507.06622)
*Boshko Koloski,Senja Pollak,Roberto Navigli,Blaž Škrlj*

Key words: LLM, 文档表示, 贝叶斯优化, 领域知识, 分类性能

TL;DR: 介绍了一种名为FuDoBa的方法，通过贝叶斯优化将LLM生成的高维嵌入与领域特定知识结合，生成低维且任务相关的文档表示，提高分类性能。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决LLM生成的高维嵌入在领域特定应用中过于通用或低效的问题。

Method: 提出FuDoBa方法，结合LLM嵌入与领域知识（本地和外部如WikiData），通过贝叶斯优化生成低维表示。

Result: 在六个数据集上验证，FuDoBa结合AutoML分类器性能与或优于纯LLM嵌入基线。

Conclusion: FuDoBa生成的表示在低维、高效和可解释性上表现优越，适合领域特定任务。

Abstract: Building on the success of Large Language Models (LLMs), LLM-based
representations have dominated the document representation landscape, achieving
great performance on the document embedding benchmarks. However, the
high-dimensional, computationally expensive embeddings from LLMs tend to be
either too generic or inefficient for domain-specific applications. To address
these limitations, we introduce FuDoBa a Bayesian optimisation-based method
that integrates LLM-based embeddings with domain-specific structured knowledge,
sourced both locally and from external repositories like WikiData. This fusion
produces low-dimensional, task-relevant representations while reducing training
complexity and yielding interpretable early-fusion weights for enhanced
classification performance. We demonstrate the effectiveness of our approach on
six datasets in two domains, showing that when paired with robust AutoML-based
classifiers, our proposed representation learning approach performs on par
with, or surpasses, those produced solely by the proprietary LLM-based
embedding baselines.

</details>


### [23] [Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review](https://arxiv.org/abs/2507.06623)
*James Stewart-Evans,Emma Wilson,Tessa Langley,Andrew Prayle,Angela Hands,Karen Exley,Jo Leonardi-Bee*

Key words: 大型语言模型, 数据提取, 审查协议, Claude 3.5 Sonnet, 精确度, 召回率

TL;DR: 论文探讨了使用Claude 3.5 Sonnet和审查协议加速数据提取的两种方法，发现其在提取简单数据时准确率高，但复杂数据时表现不佳。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 为减少数据提取的资源消耗，研究者尝试使用大型语言模型(LLM)和审查协议来加速提取过程。

Method: 使用Claude 3.5 Sonnet和审查协议从10个证据源中提取数据，并对提取的数据进行审查。

Result: 简单数据的提取准确率为83.3%和100%；复杂数据的准确率仅为9.6%和15.8%。整体上，方法精确度高但召回率和F1分数低。

Conclusion: 基于LLM和审查协议的提取方法需进一步评估和优化，研究人员应报告LLM性能以改进未来应用。

Abstract: The data extraction stages of reviews are resource-intensive, and researchers
may seek to expediate data extraction using online (large language models) LLMs
and review protocols. Claude 3.5 Sonnet was used to trial two approaches that
used a review protocol to prompt data extraction from 10 evidence sources
included in a case study scoping review. A protocol-based approach was also
used to review extracted data. Limited performance evaluation was undertaken
which found high accuracy for the two extraction approaches (83.3% and 100%)
when extracting simple, well-defined citation details; accuracy was lower (9.6%
and 15.8%) when extracting more complex, subjective data items. Considering all
data items, both approaches had precision >90% but low recall (<25%) and F1
scores (<40%). The context of a complex scoping review, open response types and
methodological approach likely impacted performance due to missed and
misattributed data. LLM feedback considered the baseline extraction accurate
and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of
38 (21.1%) to key findings data items were considered to potentially add value.
However, when repeating the process with a dataset featuring deliberate errors,
only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for
expediency require more robust performance evaluation across a range of LLMs
and review contexts with comparison to conventional prompt engineering
approaches. We recommend researchers evaluate and report LLM performance if
using them similarly to conduct data extraction or review extracted data. LLM
feedback contributed to protocol adaptation and may assist future review
protocol drafting.

</details>


### [24] [Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models](https://arxiv.org/abs/2507.06658)
*Gennadii Iakovlev*

Key words: 精英极化, 人工智能, 议会演讲, 情感分析, 政治极化

TL;DR: 利用AI技术通过分析政客在议会演讲中的相互提及情况，提出了一种新的精英极化测量方法，构建了相互敌意指数，适用于多国数据分析。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 研究精英极化现象，开发一种能够量化政客间相互敌意的测量工具，为政治极化研究提供新视角。

Method: 通过人工智能识别议会演讲中的发言者和被提及对象，并评估这些提及的情感温度，构建精英极化指数。分析了英国40年、匈牙利和意大利20年的数据。

Result: 提出的指数能按政党和季度汇总，对选举活动、政党危机等事件反应敏感，验证了其表面效度。

Conclusion: 该方法为欧盟范围内20年的时间序列数据集奠定了基础，为精英极化研究提供了实用的测量工具。

Abstract: This project introduces a new measure of elite polarization via actor and
subject detection using artificial intelligence. I identify when politicians
mention one another in parliamentary speeches, note who is speaking and who is
being addressed, and assess the emotional temperature behind these evaluations.
This maps how elites evaluate their various out-parties, allowing us to create
an index of mutual out-party hostility, that is, elite polarization. While I
analyzed polarization data over the past four decades for the UK, and two
decades for Hungary and Italy, my approach lays the groundwork for a
twenty-year, EU-wide time-series dataset on elite polarization. I obtain the
results that can be aggregated by party and quarter. The resulting index
demonstrates a good face validity: it reacts to events such as electoral
campaigns, country- and party-level crises, and to parties losing and assuming
power.

</details>


### [25] [CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs](https://arxiv.org/abs/2507.06715)
*Garapati Keerthana,Manik Gupta*

Key words: LLMs, 临床文本生成, CLI-RAG, 检索增强生成, MIMIC-III

TL;DR: 介绍CLI-RAG，一种针对临床文本生成的领域特定框架，通过分层分块和双阶段检索机制解决LLMs在临床应用中数据分散和上下文长度限制的问题。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决LLMs在临床文本生成中面对的非结构化数据和长文本挑战。

Method: 提出CLI-RAG框架，包含分层分块策略和双阶段检索机制（全局阶段识别相关笔记类型，局部阶段提取高价值内容）。

Result: 在MIMIC-III数据集上生成结构化进度笔记，平均对齐分数87.7%，优于基线80.7%，且输出一致性高。

Conclusion: CLI-RAG有效解决临床文本生成问题，提升生成质量与一致性。

Abstract: Large language models (LLMs), including zero-shot and few-shot paradigms,
have shown promising capabilities in clinical text generation. However,
real-world applications face two key challenges: (1) patient data is highly
unstructured, heterogeneous, and scattered across multiple note types and (2)
clinical notes are often long and semantically dense, making naive prompting
infeasible due to context length constraints and the risk of omitting
clinically relevant information.
  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a
domain-specific framework for structured and clinically grounded text
generation using LLMs. It incorporates a novel hierarchical chunking strategy
that respects clinical document structure and introduces a task-specific
dual-stage retrieval mechanism. The global stage identifies relevant note types
using evidence-based queries, while the local stage extracts high-value content
within those notes creating relevance at both document and section levels.
  We apply the system to generate structured progress notes for individual
hospital visits using 15 clinical note types from the MIMIC-III dataset.
Experiments show that it preserves temporal and semantic alignment across
visits, achieving an average alignment score of 87.7%, surpassing the 80.7%
baseline from real clinician-authored notes. The generated outputs also
demonstrate high consistency across LLMs, reinforcing deterministic behavior
essential for reproducibility, reliability, and clinical trust.

</details>


### [26] [On the Effect of Uncertainty on Layer-wise Inference Dynamics](https://arxiv.org/abs/2507.06722)
*Sunwoo Kim,Haneul Yoo,Alice Oh*

Key words: 大语言模型, 不确定性, 可解释性, Tuned Lens, 推理动态

TL;DR: 论文探讨了大语言模型（LLMs）在处理不确定性的内部机制，发现确定性预测和不确定性预测在输出概率动态上高度一致，挑战了简单方法检测不确定性的可行性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 研究目的是理解LLMs如何在内部表示和处理不确定性，以防止模型幻觉并改进不确定性检测方法。

Method: 研究使用了Tuned Lens（Logit Lens的变体），分析了5个模型在11个数据集上最终预测词的概率轨迹，特别是错误预测（代表高不确定性）的动态。

Result: 结果表明，确定性预测和不确定性预测的概率轨迹高度一致，且都在相似的层级上出现置信度骤增的现象。然而，更优秀的模型可能学会以不同方式处理不确定性。

Conclusion: 研究发现不确定性并不影响推理动态，挑战了简单检测不确定性的方法，并展示了可解释性方法在研究不确定性影响中的潜力。

Abstract: Understanding how large language models (LLMs) internally represent and
process their predictions is central to detecting uncertainty and preventing
hallucinations. While several studies have shown that models encode uncertainty
in their hidden states, it is underexplored how this affects the way they
process such hidden states. In this work, we demonstrate that the dynamics of
output token probabilities across layers for certain and uncertain outputs are
largely aligned, revealing that uncertainty does not seem to affect inference
dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to
analyze the layer-wise probability trajectories of final prediction tokens
across 11 datasets and 5 models. Using incorrect predictions as those with
higher epistemic uncertainty, our results show aligned trajectories for certain
and uncertain predictions that both observe abrupt increases in confidence at
similar layers. We balance this finding by showing evidence that more competent
models may learn to process uncertainty differently. Our findings challenge the
feasibility of leveraging simplistic methods for detecting uncertainty at
inference. More broadly, our work demonstrates how interpretability methods may
be used to investigate the way uncertainty affects inference.

</details>


### [27] [KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution](https://arxiv.org/abs/2507.06753)
*Ye Kyaw Thu,Thura Aung,Thazin Myint Oo,Thepchai Supnithi*

Key words: KAConvText, 文本分类, fastText, 不平衡分类

TL;DR: 首次将Kolmogorov-Arnold卷积应用于文本分类（KAConvText），在三种任务中表现优异，最佳结果达到99.82%准确率。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 探索KAConvText在句子分类中的效果，解决不平衡和平衡分类问题。

Method: 比较不同嵌入配置（随机与fastText），使用静态和微调设置，结合MLP和KAN分类头。

Result: KAConvText-MLP在微调fastText嵌入下表现最佳，尤其在语言识别任务中准确率达99.82%。

Conclusion: KAConvText是一种高效且可解释的文本分类方法。

Abstract: This paper presents the first application of Kolmogorov-Arnold Convolution
for Text (KAConvText) in sentence classification, addressing three tasks:
imbalanced binary hate speech detection, balanced multiclass news
classification, and imbalanced multiclass ethnic language identification. We
investigate various embedding configurations, comparing random to fastText
embeddings in both static and fine-tuned settings, with embedding dimensions of
100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs
and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we
investigated KAConvText with different classification heads - MLP and KAN,
where using KAN head supports enhanced interpretability. Results show that
KAConvText-MLP with fine-tuned fastText embeddings achieves the best
performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,
92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%
accuracy (F1-score = 0.9982) for language identification.

</details>


### [28] [Checklist Engineering Empowers Multilingual LLM Judges](https://arxiv.org/abs/2507.06774)
*Mohammad Ghiasvand Mohammadkhani,Hamid Beigy*

Key words: LLM, 多语言评估, 开源模型, 检查表工程

TL;DR: 本文提出了CE-Judge框架，一种无需训练的LLM评估方法，通过检查表工程在多语言环境下表现优异，与GPT-4o相当。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 探索LLM作为评估器的多语言应用，克服现有方法的成本和效率问题。

Method: 提出基于检查表工程的CE-Judge框架，使用开源模型进行多语言评估。

Result: 在多种语言和数据集上表现优于基线，与GPT-4o相当。

Conclusion: CE-Judge是一种高效、低成本的多语言评估方法。

Abstract: Automated text evaluation has long been a central issue in Natural Language
Processing (NLP). Recently, the field has shifted toward using Large Language
Models (LLMs) as evaluators-a trend known as the LLM-as-a-Judge paradigm. While
promising and easily adaptable across tasks, this approach has seen limited
exploration in multilingual contexts. Existing multilingual studies often rely
on proprietary models or require extensive training data for fine-tuning,
raising concerns about cost, time, and efficiency. In this paper, we propose
Checklist Engineering based LLM-as-a-Judge (CE-Judge), a training-free
framework that uses checklist intuition for multilingual evaluation with an
open-source model. Experiments across multiple languages and three benchmark
datasets, under both pointwise and pairwise settings, show that our method
generally surpasses the baselines and performs on par with the GPT-4o model.

</details>


### [29] [Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications](https://arxiv.org/abs/2507.06795)
*Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon*

Key words: 领域自适应持续预训练（DACP），小型LLMs（sLLMs），企业应用，性能提升

TL;DR: 本文验证了基于领域自适应持续预训练（DACP）的方法在多种基础模型和服务领域中的有效性，证明其能显著提升目标领域性能，同时保持通用能力，为企业级部署提供高效解决方案。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 开源大型语言模型（LLMs）虽为企业应用提供了新机会，但许多组织缺乏部署和维护大型模型的基础设施。小型LLMs（sLLMs）成为替代方案，但其性能有限。DACP在商业应用中的效用尚未充分研究。

Method: 使用DACP方法对不同基础模型和服务领域进行领域自适应持续预训练。

Result: 实验和实际评估表明，应用DACP的sLLMs在目标领域性能显著提升，同时保留了通用能力。

Conclusion: DACP为sLLMs提供了一种成本高效且可扩展的解决方案，适用于企业级部署。

Abstract: The emergence of open-source large language models (LLMs) has expanded
opportunities for enterprise applications; however, many organizations still
lack the infrastructure to deploy and maintain large-scale models. As a result,
small LLMs (sLLMs) have become a practical alternative, despite their inherent
performance limitations. While Domain Adaptive Continual Pretraining (DACP) has
been previously explored as a method for domain adaptation, its utility in
commercial applications remains under-examined. In this study, we validate the
effectiveness of applying a DACP-based recipe across diverse foundation models
and service domains. Through extensive experiments and real-world evaluations,
we demonstrate that DACP-applied sLLMs achieve substantial gains in target
domain performance while preserving general capabilities, offering a
cost-efficient and scalable solution for enterprise-level deployment.

</details>


### [30] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
*Matthew Anderson Hendricks,Alice Cicirello*

Key words: 动力学系统、SysML、NLP、LLMs、自动化建模、代码生成

TL;DR: 提出一种利用领域和专家知识自动化生成动力学系统计算模型的策略，通过五步实现，结合SysML图表和NLP/LLM技术提升效率。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 加速工程动力学系统的设计和部署，减少手动建模的复杂性和时间成本。

Method: 五步策略：利用SysML图表提取组件关系，结合NLP和LLM优化中间输出（如关键名词、关系列表等），并通过代码生成实现计算模型。

Result: 展示了从文本到模型的端到端案例（单摆），性能优于仅使用LLM的结果。

Conclusion: 该方法通用性强，适用于不同系统和领域，显著提升了建模效率。

Abstract: This paper contributes to speeding up the design and deployment of
engineering dynamical systems by proposing a strategy for exploiting domain and
expert knowledge for the automated generation of dynamical system computational
model starting from a corpus of document relevant to the dynamical system of
interest and an input document describing the specific system. This strategy is
implemented in five steps and, crucially, it uses system modeling language
diagrams (SysML) to extract accurate information about the dependencies,
attributes, and operations of components. Natural Language Processing (NLP)
strategies and Large Language Models (LLMs) are employed in specific tasks to
improve intermediate outputs of the SySML diagrams automated generation, such
as: list of key nouns; list of extracted relationships; list of key phrases and
key relationships; block attribute values; block relationships; and BDD diagram
generation. The applicability of automated SysML diagram generation is
illustrated with different case studies. The computational models of complex
dynamical systems from SysML diagrams are then obtained via code generation and
computational model generation steps. In the code generation step, NLP
strategies are used for summarization, while LLMs are used for validation only.
The proposed approach is not limited to a specific system, domain, or
computational software. The applicability of the proposed approach is shown via
an end-to-end example from text to model of a simple pendulum, showing improved
performance compared to results yielded by LLMs only.

</details>


### [31] [Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework](https://arxiv.org/abs/2507.06829)
*Zenan Xu,Zexuan Qiu,Guanhua Huang,Kun Li,Siheng Li,Chenchen Zhang,Kejiao Li,Qi Yi,Yuhao Jiang,Bo Zhou,Fengzong Lian,Zhanhui Kang*

Key words: 大语言模型, 推理扩展, 语义熵, 协作推理

TL;DR: 论文提出了一种结合序列推理和并行推理优势的测试时协作推理框架，并引入语义熵（SE）作为质量指标。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 为了解决序列推理和并行推理各自的局限性，设计一个灵活的协作推理框架。

Method: 开发了语义熵（SE）指标，用于动态评估并行模型响应的语义多样性。

Result: 语义熵与准确性呈强负相关，能够有效指导推理过程的动态控制和早期终止。

Conclusion: 语义熵为协作推理提供了高效且准确的质量评估方法。

Abstract: Recent advances in large language models (LLMs) have accelerated progress
toward artificial general intelligence, with inference-time scaling emerging as
a key technique. Contemporary approaches leverage either sequential reasoning
(iteratively extending chains of thought) or parallel reasoning (generating
multiple solutions simultaneously) to scale inference. However, both paradigms
face fundamental limitations: sequential scaling typically relies on arbitrary
token budgets for termination, leading to inefficiency or premature cutoff;
while parallel scaling often lacks coordination among parallel branches and
requires intrusive fine-tuning to perform effectively. In light of these
challenges, we aim to design a flexible test-time collaborative inference
framework that exploits the complementary strengths of both sequential and
parallel reasoning paradigms. Towards this goal, the core challenge lies in
developing an efficient and accurate intrinsic quality metric to assess model
responses during collaborative inference, enabling dynamic control and early
termination of the reasoning trace. To address this challenge, we introduce
semantic entropy (SE), which quantifies the semantic diversity of parallel
model responses and serves as a robust indicator of reasoning quality due to
its strong negative correlation with accuracy...

</details>


### [32] [Shifting from Ranking to Set Selection for Retrieval Augmented Generation](https://arxiv.org/abs/2507.06838)
*Dahyun Lee,Yongrae Jo,Haeju Park,Moontae Lee*

Key words: 检索增强生成,多跳问答,段落选择,Chain-of-Thought,SETR

TL;DR: 本文提出了一种名为SETR的集合式段落选择方法，通过Chain-of-Thought推理明确查询需求，并选择最优段落集合以提升检索增强生成（RAG）中的多跳问答性能。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 现有方法基于段落个体相关性重排序，难以满足复杂多跳问答的信息需求。

Method: 提出SETR方法，通过Chain-of-Thought推理明确查询需求，选择最优段落集合。

Result: 实验表明SETR在答案正确性和检索质量上优于现有方法。

Conclusion: SETR为RAG系统提供了一种高效且有效的替代方案。

Abstract: Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved
passages are not only individually relevant but also collectively form a
comprehensive set. Existing approaches primarily rerank top-k passages based on
their individual relevance, often failing to meet the information needs of
complex queries in multi-hop question answering. In this work, we propose a
set-wise passage selection approach and introduce SETR, which explicitly
identifies the information requirements of a query through Chain-of-Thought
reasoning and selects an optimal set of passages that collectively satisfy
those requirements. Experiments on multi-hop RAG benchmarks show that SETR
outperforms both proprietary LLM-based rerankers and open-source baselines in
terms of answer correctness and retrieval quality, providing an effective and
efficient alternative to traditional rerankers in RAG systems. The code is
available at https://github.com/LGAI-Research/SetR

</details>


### [33] [Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights](https://arxiv.org/abs/2507.06893)
*Alexandra Abbas,Celia Waggoner,Justin Olive*

Key words: AI评估,开源工具,社群贡献,统计方法,质量控制

TL;DR: 论文总结了维护开源AI评估工具的经验，提出了解决评估挑战的三个方案，并指出AI评估需要专门的基础设施和统计方法。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: AI评估是评估大型语言模型能力和安全性的重要工具，但实现和维护评估工具面临诸多挑战，需寻找解决方案。

Method: 1. 结构化社群贡献管理框架；2. 最优重采样和跨模型比较的统计方法；3. 系统化的质量控制流程。

Result: 提出了一套解决AI评估挑战的方案，并验证了其有效性。

Conclusion: AI评估需要专门的基础设施、统计严谨性和社群协作，远超传统软件开发实践。

Abstract: AI evaluations have become critical tools for assessing large language model
capabilities and safety. This paper presents practical insights from eight
months of maintaining $inspect\_evals$, an open-source repository of 70+
community-contributed AI evaluations. We identify key challenges in
implementing and maintaining AI evaluations and develop solutions including:
(1) a structured cohort management framework for scaling community
contributions, (2) statistical methodologies for optimal resampling and
cross-model comparison with uncertainty quantification, and (3) systematic
quality control processes for reproducibility. Our analysis reveals that AI
evaluation requires specialized infrastructure, statistical rigor, and
community coordination beyond traditional software development practices.

</details>


### [34] [SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN](https://arxiv.org/abs/2507.06895)
*Luca Mariotti,Veronica Guidetti,Federica Mandreoli*

Key words: 关系抽取, 知识图增强, 低监督学习, SCoRE, 对比学习

TL;DR: SCoRE是一种模块化、成本效益高的句子级关系抽取系统，支持预训练大语言模型的灵活切换，无需微调，性能优于现有方法。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 为解决知识图（KG）增强的需求，以及低监督环境下关系抽取（RE）的适应性和噪声抗性问题，提出了SCoRE系统。

Method: 结合监督对比学习和贝叶斯k近邻分类器进行多标签分类，提出CSD和P@R两种新评估指标。

Result: 在五个基准测试中，SCoRE性能与或优于现有方法，且显著降低能耗。

Conclusion: SCoRE以高效性、模块化和可扩展性成为现实世界RE应用的理想选择。

Abstract: The growing demand for efficient knowledge graph (KG) enrichment leveraging
external corpora has intensified interest in relation extraction (RE),
particularly under low-supervision settings. To address the need for adaptable
and noise-resilient RE solutions that integrate seamlessly with pre-trained
large language models (PLMs), we introduce SCoRE, a modular and cost-effective
sentence-level RE system. SCoRE enables easy PLM switching, requires no
finetuning, and adapts smoothly to diverse corpora and KGs. By combining
supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)
classifier for multi-label classification, it delivers robust performance
despite the noisy annotations of distantly supervised corpora. To improve RE
evaluation, we propose two novel metrics: Correlation Structure Distance (CSD),
measuring the alignment between learned relational patterns and KG structures,
and Precision at R (P@R), assessing utility as a recommender system. We also
release Wiki20d, a benchmark dataset replicating real-world RE conditions where
only KG-derived annotations are available. Experiments on five benchmarks show
that SCoRE matches or surpasses state-of-the-art methods while significantly
reducing energy consumption. Further analyses reveal that increasing model
complexity, as seen in prior work, degrades performance, highlighting the
advantages of SCoRE's minimal design. Combining efficiency, modularity, and
scalability, SCoRE stands as an optimal choice for real-world RE applications.

</details>


### [35] [VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation](https://arxiv.org/abs/2507.06899)
*Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua*

Key words: GUI代理, 后门攻击, 视觉接地, VisualTrap, 安全漏洞

TL;DR: 本文揭示了GUI代理在视觉接地过程中存在的新类型后门攻击漏洞，提出了一种名为VisualTrap的攻击方法，能够有效劫持代理行为，并强调了进一步研究GUI代理后门攻击风险的紧迫性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 随着GUI代理在个人设备中的广泛应用，其安全风险尚未得到充分研究，尤其是视觉接地环节可能引入的后门攻击漏洞。

Method: 提出VisualTrap攻击方法，通过在视觉接地的预训练阶段注入5%的毒化数据，误导代理将文本计划映射到触发位置而非目标位置。

Result: 实验证明VisualTrap能高效劫持代理行为，且触发视觉隐蔽、可跨环境和任务泛化。

Conclusion: GUI代理的视觉接地环节存在显著安全漏洞，需进一步研究其防御机制。

Abstract: Graphical User Interface (GUI) agents powered by Large Vision-Language Models
(LVLMs) have emerged as a revolutionary approach to automating human-machine
interactions, capable of autonomously operating personal devices (e.g., mobile
phones) or applications within the device to perform complex real-world tasks
in a human-like manner. However, their close integration with personal devices
raises significant security concerns, with many threats, including backdoor
attacks, remaining largely unexplored. This work reveals that the visual
grounding of GUI agent-mapping textual plans to GUI elements-can introduce
vulnerabilities, enabling new types of backdoor attacks. With backdoor attack
targeting visual grounding, the agent's behavior can be compromised even when
given correct task-solving plans. To validate this vulnerability, we propose
VisualTrap, a method that can hijack the grounding by misleading the agent to
locate textual plans to trigger locations instead of the intended targets.
VisualTrap uses the common method of injecting poisoned data for attacks, and
does so during the pre-training of visual grounding to ensure practical
feasibility of attacking. Empirical results show that VisualTrap can
effectively hijack visual grounding with as little as 5% poisoned data and
highly stealthy visual triggers (invisible to the human eye); and the attack
can be generalized to downstream tasks, even after clean fine-tuning. Moreover,
the injected trigger can remain effective across different GUI environments,
e.g., being trained on mobile/web and generalizing to desktop environments.
These findings underscore the urgent need for further research on backdoor
attack risks in GUI agents.

</details>


### [36] [MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection](https://arxiv.org/abs/2507.06908)
*Ziyan Liu,Chunxiao Fan,Haoran Lou,Yuexin Wu,Kaiwei Deng*

Key words: 有害迷因检测, 零样本学习, 多代理框架, 社交媒体

TL;DR: 提出了一种名为MIND的多代理框架，用于零样本检测有害网络迷因，无需依赖标注数据，通过检索相似迷因、双向洞察机制和多代理辩论机制实现。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 随着迷因在社交媒体的迅速传播，亟需有效检测有害内容的方法。传统数据驱动方法难以应对不断变化的迷因和缺乏标注数据的问题。

Method: 采用多代理框架MIND，包括检索相似迷因提供上下文、双向洞察机制提取全面理解、多代理辩论机制确保鲁棒决策。

Result: 在三个迷因数据集上的实验表明，MIND不仅优于现有零样本方法，且在不同模型架构和参数规模下表现出强泛化能力。

Conclusion: MIND为有害迷因检测提供了一种可扩展的解决方案，解决了传统方法的局限性。

Abstract: The rapid expansion of memes on social media has highlighted the urgent need
for effective approaches to detect harmful content. However, traditional
data-driven approaches struggle to detect new memes due to their evolving
nature and the lack of up-to-date annotated data. To address this issue, we
propose MIND, a multi-agent framework for zero-shot harmful meme detection that
does not rely on annotated data. MIND implements three key strategies: 1) We
retrieve similar memes from an unannotated reference set to provide contextual
information. 2) We propose a bi-directional insight derivation mechanism to
extract a comprehensive understanding of similar memes. 3) We then employ a
multi-agent debate mechanism to ensure robust decision-making through reasoned
arbitration. Extensive experiments on three meme datasets demonstrate that our
proposed framework not only outperforms existing zero-shot approaches but also
shows strong generalization across different model architectures and parameter
scales, providing a scalable solution for harmful meme detection. The code is
available at https://github.com/destroy-lonely/MIND.

</details>


### [37] [MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction](https://arxiv.org/abs/2507.06909)
*Xiao Wang,Jiahuan Pei,Diancheng Shui,Zhiguang Han,Xin Sun,Dawei Zhu,Xiaoyu Shen*

Key words: 法律判决预测,多被告,多罪名,LLMs,MPMCP

TL;DR: 该论文引入了一个新的数据集MPMCP，用于研究多被告多罪名在司法判决预测中的表现，并评估了不同法律大语言模型在四种场景下的性能。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 探讨多被告和多罪名是否应在法律判决预测中分开处理，填补研究空白。

Method: 使用四种司法场景（S1-S4）和两种任务（罪名预测和刑期预测），评估多种法律大语言模型的性能表现。

Result: S4（多被告多罪名）最具挑战性，不同模型表现差异显著，例如InternLM2和Lawformer在S4中的表现差异较大。

Conclusion: 多被告和多罪名场景对法律判决预测模型的性能有显著影响，建议进一步研究优化模型在这些复杂场景中的表现。

Abstract: Legal judgment prediction offers a compelling method to aid legal
practitioners and researchers. However, the research question remains
relatively under-explored: Should multiple defendants and charges be treated
separately in LJP? To address this, we introduce a new dataset namely
multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating
the performance of several prevailing legal large language models (LLMs) on
four practical legal judgment scenarios: (S1) single defendant with a single
charge, (S2) single defendant with multiple charges, (S3) multiple defendants
with a single charge, and (S4) multiple defendants with multiple charges. We
evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty
term prediction. We have conducted extensive experiments and found that the
scenario involving multiple defendants and multiple charges (S4) poses the
greatest challenges, followed by S2, S3, and S1. The impact varies
significantly depending on the model. For example, in S4 compared to S1,
InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD,
while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD.
Our dataset and code are available at
https://github.com/lololo-xiao/MultiJustice-MPMCP.

</details>


### [38] [Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues](https://arxiv.org/abs/2507.06910)
*Fareya Ikram,Alexander Scarlatos,Andrew Lan*

Key words: tutoring dialogues, LLMs, tutor strategy, student outcomes, prediction

TL;DR: 使用LLMs预测导师策略和学生结果的研究，发现现有模型在预测导师策略上仍有困难。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 在线学习和AI导师的兴起，使导师策略对学生结果的影响备受关注，但目前缺乏预测导师策略的研究。

Method: 利用现代LLMs（Llama 3和GPT-4o）预测导师行为和学生学习成果，基于两个数学辅导对话数据集。

Result: 即使是最先进的LLMs也难以预测导师策略，但导师策略对学生结果有显著指示作用。

Conclusion: 需要更强大的方法来预测导师策略及其对学生的影响。

Abstract: Tutoring dialogues have gained significant attention in recent years, given
the prominence of online learning and the emerging tutoring abilities of
artificial intelligence (AI) agents powered by large language models (LLMs).
Recent studies have shown that the strategies used by tutors can have
significant effects on student outcomes, necessitating methods to predict how
tutors will behave and how their actions impact students. However, few works
have studied predicting tutor strategy in dialogues. Therefore, in this work we
investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to
predict both future tutor moves and student outcomes in dialogues, using two
math tutoring dialogue datasets. We find that even state-of-the-art LLMs
struggle to predict future tutor strategy while tutor strategy is highly
indicative of student outcomes, outlining a need for more powerful methods to
approach this task.

</details>


### [39] [Rethinking Verification for LLM Code Generation: From Generation to Testing](https://arxiv.org/abs/2507.06920)
*Zihan Ma,Taolin Zhang,Maosong Cao,Wenwei Zhang,Minnan Luo,Songyang Zhang,Kai Chen*

Key words: LLMs, 代码生成, 测试用例生成, SAGA, TCGBench

TL;DR: 论文通过提出多维度量标准和人机协作方法SAGA，改进了代码生成评估的全面性，显著提升了测试用例的质量和覆盖率。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 评估套件通常只有少量同质化测试用例，导致细微错误未被发现，影响性能评估和奖励估计的准确性。

Method: 引入SAGA方法，结合人类编程经验和LLM推理能力，开发TCGBench以量化测试套件的全面性。

Result: SAGA在TCGBench上的检测率达90.62%，验证准确率提高10.78%，证明其有效性。

Conclusion: 该方法为可靠LLM代码评估奠定了基础，推动了代码生成中的RLVR发展。

Abstract: Large language models (LLMs) have recently achieved notable success in
code-generation benchmarks such as HumanEval and LiveCodeBench. However, a
detailed examination reveals that these evaluation suites often comprise only a
limited number of homogeneous test cases, resulting in subtle faults going
undetected. This not only artificially inflates measured performance but also
compromises accurate reward estimation in reinforcement learning frameworks
utilizing verifiable rewards (RLVR). To address these critical shortcomings, we
systematically investigate the test-case generation (TCG) task by proposing
multi-dimensional metrics designed to rigorously quantify test-suite
thoroughness. Furthermore, we introduce a human-LLM collaborative method
(SAGA), leveraging human programming expertise with LLM reasoning capability,
aimed at significantly enhancing both the coverage and the quality of generated
test cases. In addition, we develop a TCGBench to facilitate the study of the
TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a
verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc)
of the code generation evaluation benchmark synthesized by SAGA is 10.78%
higher than that of LiveCodeBench-v6. These results demonstrate the
effectiveness of our proposed method. We hope this work contributes to building
a scalable foundation for reliable LLM code evaluation, further advancing RLVR
in code generation, and paving the way for automated adversarial test synthesis
and adaptive benchmark integration.

</details>


### [40] [Investigating the Robustness of Retrieval-Augmented Generation at the Query Level](https://arxiv.org/abs/2507.06956)
*Sezen Perçin,Xin Su,Qutub Sha Syed,Phillip Howard,Aleksei Kuvshinov,Leo Schwinn,Kay-Ulrich Scholl*

Key words: RAG,查询扰动,大型语言模型,鲁棒性评估

TL;DR: 本文探讨了检索增强生成（RAG）对查询扰动的敏感性，分析了各模块的性能变化，并提出评估框架与实用建议。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 针对大型语言模型（LLMs）更新成本高的问题，RAG虽能动态引入外部知识，但其表现高度依赖查询质量，亟需研究其鲁棒性。

Method: 通过孤立分析和端到端实验，研究了RAG各模块对查询扰动的敏感性，并设计了系统性评估框架。

Result: 实验显示常用检索器性能在轻微查询变化下显著下降，基于1092次实验提出了实用建议。

Conclusion: RAG系统需提升对查询扰动的鲁棒性，研究结果为实践者提供了改进方向。

Abstract: Large language models (LLMs) are very costly and inefficient to update with
new information. To address this limitation, retrieval-augmented generation
(RAG) has been proposed as a solution that dynamically incorporates external
knowledge during inference, improving factual consistency and reducing
hallucinations. Despite its promise, RAG systems face practical challenges-most
notably, a strong dependence on the quality of the input query for accurate
retrieval. In this paper, we investigate the sensitivity of different
components in the RAG pipeline to various types of query perturbations. Our
analysis reveals that the performance of commonly used retrievers can degrade
significantly even under minor query variations. We study each module in
isolation as well as their combined effect in an end-to-end question answering
setting, using both general-domain and domain-specific datasets. Additionally,
we propose an evaluation framework to systematically assess the query-level
robustness of RAG pipelines and offer actionable recommendations for
practitioners based on the results of more than 1092 experiments we performed.

</details>


### [41] [FRaN-X: FRaming and Narratives-eXplorer](https://arxiv.org/abs/2507.06974)
*Artur Muratov,Hana Fatima Shaikh,Vanshikaa Jani,Tarek Mahmoud,Zhuohan Xie,Daniil Orel,Aaryamonvikram Singh,Yuxia Wang,Aadi Joshi,Hasan Iqbal,Ming Shan Hee,Dhruv Sahnan,Nikolaos Nikolaidis,Purificação Silvano,Dimitar Dimitrov,Roman Yangarber,Ricardo Campos,Alípio Jorge,Nuno Guimarães,Elisa Sartori,Nicolas Stefanovitch,Giovanni Da San Martino,Jakub Piskorski,Preslav Nakov*

Key words: FRaN-X, 叙事角色, 框架分析, 多语言, 交互式界面

TL;DR: FRaN-X是一个自动检测实体提及并将其叙事角色分类的系统，支持多语言和多领域分析，并提供交互式界面和可视化工具。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 解决从原始文本中自动检测和标记实体叙事角色的挑战，帮助媒体分析师探索和比较不同来源的框架。

Method: 采用两阶段系统，结合序列标记和细粒度角色分类，支持五种语言和两个领域。

Result: 系统提供交互式网络界面、搜索功能、时间线视图和图形可视化，已在MIT许可下公开。

Conclusion: FRaN-X成功实现了自动检测和标记实体叙事角色的目标，并提供了强大的分析工具。

Abstract: We present FRaN-X, a Framing and Narratives Explorer that automatically
detects entity mentions and classifies their narrative roles directly from raw
text. FRaN-X comprises a two-stage system that combines sequence labeling with
fine-grained role classification to reveal how entities are portrayed as
protagonists, antagonists, or innocents, using a unique taxonomy of 22
fine-grained roles nested under these three main categories. The system
supports five languages (Bulgarian, English, Hindi, Russian, and Portuguese)
and two domains (the Russia-Ukraine Conflict and Climate Change). It provides
an interactive web interface for media analysts to explore and compare framing
across different sources, tackling the challenge of automatically detecting and
labeling how entities are framed. Our system allows end users to focus on a
single article as well as analyze up to four articles simultaneously. We
provide aggregate level analysis including an intuitive graph visualization
that highlights the narrative a group of articles are pushing. Our system
includes a search feature for users to look up entities of interest, along with
a timeline view that allows analysts to track an entity's role transitions
across different contexts within the article. The FRaN-X system and the trained
models are licensed under an MIT License. FRaN-X is publicly accessible at
https://fran-x.streamlit.app/ and a video demonstration is available at
https://youtu.be/VZVi-1B6yYk.

</details>


### [42] [FlexOlmo: Open Language Models for Flexible Data Use](https://arxiv.org/abs/2507.07024)
*Weijia Shi,Akshita Bhagia,Kevin Farhat,Niklas Muennighoff,Pete Walsh,Jacob Morrison,Dustin Schwenk,Shayne Longpre,Jake Poznanski,Allyson Ettinger,Daogao Liu,Margaret Li,Dirk Groeneveld,Mike Lewis,Wen-tau Yih,Luca Soldaini,Kyle Lo,Noah A. Smith,Luke Zettlemoyer,Pang Wei Koh,Hannaneh Hajishirzi,Ali Farhadi,Sewon Min*

Key words: FlexOlmo, 混合专家, 分布式训练, 数据灵活推理, 封闭数据

TL;DR: FlexOlmo是一种新型语言模型，支持分布式训练和数据灵活推理，无需共享数据。采用混合专家架构和领域感知路由，在封闭数据集上训练，显著提升性能并支持数据访问控制。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 为解决敏感或受保护数据在语言模型训练中的使用问题，同时尊重数据所有者的隐私和许可要求。

Method: 使用混合专家（MoE）架构，独立训练专家模型，并通过新的领域感知路由集成。训练数据来自FlexMix语料库，包括公开和封闭数据集。

Result: 在31项任务上评估，相比现有方法平均提升41%，并在相同计算资源下优于标准MoE。

Conclusion: FlexOlmo为处理敏感数据提供了可行方案，既提升性能，又支持数据访问的精细控制。

Abstract: We introduce FlexOlmo, a new class of language models (LMs) that supports (1)
distributed training without data sharing, where different model parameters are
independently trained on closed datasets, and (2) data-flexible inference,
where these parameters along with their associated data can be flexibly
included or excluded from model inferences with no further training. FlexOlmo
employs a mixture-of-experts (MoE) architecture where each expert is trained
independently on closed datasets and later integrated through a new
domain-informed routing without any joint training. FlexOlmo is trained on
FlexMix, a corpus we curate comprising publicly available datasets alongside
seven domain-specific sets, representing realistic approximations of closed
sets. We evaluate models with up to 37 billion parameters (20 billion active)
on 31 diverse downstream tasks. We show that a general expert trained on public
data can be effectively combined with independently trained experts from other
data owners, leading to an average 41% relative improvement while allowing
users to opt out of certain data based on data licensing or permission
requirements. Our approach also outperforms prior model merging methods by
10.1% on average and surpasses the standard MoE trained without data
restrictions using the same training FLOPs. Altogether, this research presents
a solution for both data owners and researchers in regulated industries with
sensitive or protected data. FlexOlmo enables benefiting from closed data while
respecting data owners' preferences by keeping their data local and supporting
fine-grained control of data access during inference.

</details>


### [43] [UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations](https://arxiv.org/abs/2507.07030)
*Fengran Mo,Yifan Gao,Chuan Meng,Xin Liu,Zhuofeng Wu,Kelong Mao,Zhengyang Wang,Pei Chen,Zheng Li,Xian Li,Bing Yin,Meng Jiang*

Key words: 对话搜索、密集检索、响应生成、统一模型、联合微调

TL;DR: 本研究提出了一种将密集检索与响应生成统一的大型语言模型方法，通过联合微调解决现有对话搜索模型的局限性，并在多个数据集上验证了其优越性。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 现有的对话搜索系统通常采用分离的模型，无法同时利用其内在知识，从而限制了检索与生成的协同效果。

Method: 采用联合微调方法，设计两种机制以减少不一致风险并缓解数据差异。

Result: 在五个对话搜索数据集上的评估显示，统一模型在两项任务上均优于现有基线。

Conclusion: 统一密集检索与响应生成的方法能提升对话搜索系统的整体性能。

Abstract: The rapid advancement of conversational search systems revolutionizes how
information is accessed by enabling the multi-turn interaction between the user
and the system. Existing conversational search systems are usually built with
two different models. This separation restricts the system from leveraging the
intrinsic knowledge of the models simultaneously, which cannot ensure the
effectiveness of retrieval benefiting the generation. The existing studies for
developing unified models cannot fully address the aspects of understanding
conversational context, managing retrieval independently, and generating
responses. In this paper, we explore how to unify dense retrieval and response
generation for large language models in conversation. We conduct joint
fine-tuning with different objectives and design two mechanisms to reduce the
inconsistency risks while mitigating data discrepancy. The evaluations on five
conversational search datasets demonstrate that our unified model can mutually
improve both tasks and outperform the existing baselines.

</details>


### [44] [Discrete Diffusion Models for Language Generation](https://arxiv.org/abs/2507.07050)
*Ashen Weligalle*

Key words: 扩散模型、自然语言生成、D3PM、自回归模型、并行生成

TL;DR: 论文探讨了离散扩散模型（D3PM）在自然语言生成中的可行性与性能，并与传统自回归模型（AR）进行了对比。结果显示D3PM在并行生成速度上有优势，但AR在数据压缩方面表现更好。

<details>
  <summary>Details</summary>

Main category: cs.CL

Motivation: 研究离散扩散模型在自然语言生成中的应用，解决其在离散数据（如文本）中因缺乏明确生成顺序和依赖关系复杂性带来的挑战。

Method: 使用D3PM和AR模型，通过Bits Per Token（BPT）、Negative Log-Likelihood（NLL）、Perplexity（PPL）和Batch Processing Speed等指标评估性能。

Result: D3PM在并行生成速度上表现出色（3.97批/秒），但AR在BPT（4.59）上优于D3PM（8.05）。

Conclusion: 扩散模型在离散数据生成中具有潜力，但在生成质量和效率上需权衡，支持未来非自回归语言生成的研究。

Abstract: Diffusion models have emerged as a powerful class of generative models,
achieving state-of-the-art results in continuous data domains such as image and
video generation. Their core mechanism involves a forward diffusion process
that gradually transforms structured data into a Gaussian-like distribution,
followed by a learned reverse process to reconstruct the data. While successful
in continuous modalities, applying this framework to discrete data-particularly
natural language-remains challenging due to token dependency complexities and
the lack of a defined generation order.This thesis investigates the feasibility
and performance of discrete diffusion models for natural language generation.
Specifically, we evaluate the Discrete Denoising Diffusion Probabilistic Model
(D3PM) and compare it with traditional autoregressive (AR) language models. To
assess generative performance, we use Bits Per Token (BPT), Negative
Log-Likelihood (NLL), Perplexity (PPL), and Batch Processing Speed.
  Results show the best-performing D3PM model achieves a BPT of 5.72, with a
mean of 8.05. The AR model outperforms in compression with a lower mean BPT of
4.59, but D3PM achieves higher processing speed, reaching up to 3.97 batches
per sec., indicating potential for parallel generation.All evaluations were
conducted under consistent conditions-generating 100,000 tokens per model with
a fixed batch size of four-for fair comparison. This research presents a
detailed analysis of diffusion-based vs. autoregressive models, highlighting
trade-offs in generative quality and efficiency. Findings emphasize both the
promise and limitations of diffusion models for discrete data, supporting
future work in non-autoregressive language generation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [Neural Network-Based Parameter Estimation for Non-Autonomous Differential Equations with Discontinuous Signals](https://arxiv.org/abs/2507.06267)
*Hyeontae Jo,Krešimir Josić,Jae Kyoung Kim*

Key words: 非自治微分方程；神经网络；参数估计；HADES-NN；突变信号

TL;DR: 提出了一种基于神经网络的新型参数估计方法（HADES-NN），用于拟合非自治微分方程模型中突变的外部信号，通过两阶段迭代实现高精度参数估计。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决非自治微分方程模型在外部信号突变时难以拟合数据的问题。

Method: 采用神经网络分两阶段处理：第一阶段用神经网络平滑逼近突变信号；第二阶段使用平滑后的信号进行参数估计。

Result: HADES-NN在多种应用中实现了高精度的参数估计，扩展了模型系统的适用范围。

Conclusion: HADES-NN显著提升了拟合真实数据的能力，适用于更广泛的模型系统。

Abstract: Non-autonomous differential equations are crucial for modeling systems
influenced by external signals, yet fitting these models to data becomes
particularly challenging when the signals change abruptly. To address this
problem, we propose a novel parameter estimation method utilizing functional
approximations with artificial neural networks. Our approach, termed Harmonic
Approximation of Discontinuous External Signals using Neural Networks
(HADES-NN), operates in two iterated stages. In the first stage, the algorithm
employs a neural network to approximate the discontinuous signal with a smooth
function. In the second stage, it uses this smooth approximate signal to
estimate model parameters. HADES-NN gives highly accurate and precise parameter
estimates across various applications, including circadian clock systems
regulated by external light inputs measured via wearable devices and the mating
response of yeast to external pheromone signals. HADES-NN greatly extends the
range of model systems that can be fit to real-world measurements.

</details>


### [46] [Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease](https://arxiv.org/abs/2507.06326)
*Harsh Ravivarapu,Gaurav Bagwe,Xiaoyong Yuan,Chunxiu Yu,Lan Zhang*

Key words: 深脑刺激，强化学习，样本效率，自适应控制，帕金森病

TL;DR: SEA-DBS是一种高效的强化学习框架，用于自适应深脑刺激，解决了现有方法的样本复杂性和硬件资源限制问题。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统的DBS缺乏适应性和个性化，现有RL方法存在样本复杂性高和资源受限硬件兼容性问题。

Method: SEA-DBS结合预测奖励模型和Gumbel Softmax探索策略，优化了样本效率和探索稳定性。

Result: 在帕金森病模型测试中，SEA-DBS表现出更快的收敛性和更强的病理信号抑制能力。

Conclusion: SEA-DBS为资源受限的实时神经调控提供了实用且有效的解决方案。

Abstract: Deep brain stimulation (DBS) is an established intervention for Parkinson's
disease (PD), but conventional open-loop systems lack adaptability, are
energy-inefficient due to continuous stimulation, and provide limited
personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a
closed-loop alternative, using biomarkers such as beta-band oscillations to
dynamically modulate stimulation. While reinforcement learning (RL) holds
promise for personalized aDBS control, existing methods suffer from high sample
complexity, unstable exploration in binary action spaces, and limited
deployability on resource-constrained hardware.
  We propose SEA-DBS, a sample-efficient actor-critic framework that addresses
the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a
predictive reward model to reduce reliance on real-time feedback and employs
Gumbel Softmax-based exploration for stable, differentiable policy updates in
binary action spaces. Together, these components improve sample efficiency,
exploration robustness, and compatibility with resource-constrained
neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic
simulation of Parkinsonian basal ganglia activity, demonstrating faster
convergence, stronger suppression of pathological beta-band power, and
resilience to post-training FP16 quantization. Our results show that SEA-DBS
offers a practical and effective RL-based aDBS framework for real-time,
resource-constrained neuromodulation.

</details>


### [47] [SymFlux: deep symbolic regression of Hamiltonian vector fields](https://arxiv.org/abs/2507.06342)
*M. A. Evangelista-Alvarado,P. Suárez-Serrato*

Key words: SymFlux, 深度学习, 符号回归, 哈密顿力学, CNN-LSTM

TL;DR: SymFlux框架通过深度学习进行符号回归，从标准辛平面上的向量场中识别哈密顿函数，采用CNN-LSTM架构输出哈密顿量的符号表达式。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 推动哈密顿力学中的自动化发现，通过新开发的哈密顿向量场数据集验证模型有效性。

Method: 采用混合CNN-LSTM架构进行训练和验证，利用符号回归识别哈密顿函数。

Result: 模型能准确恢复哈密顿量的符号表达式。

Conclusion: SymFlux成功提升了哈密顿力学中的自动化符号发现能力。

Abstract: We present SymFlux, a novel deep learning framework that performs symbolic
regression to identify Hamiltonian functions from their corresponding vector
fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM
architectures to learn and output the symbolic mathematical expression of the
underlying Hamiltonian. Training and validation are conducted on newly
developed datasets of Hamiltonian vector fields, a key contribution of this
work. Our results demonstrate the model's effectiveness in accurately
recovering these symbolic expressions, advancing automated discovery in
Hamiltonian mechanics.

</details>


### [48] [DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction](https://arxiv.org/abs/2507.06366)
*Yupu Zhang,Zelin Xu,Tingsong Xiao,Gustavo Seabra,Yanjun Li,Chenglong Li,Zhe Jiang*

Key words: 蛋白质-配体复合物, 结合亲和力预测, 自监督学习, 图对比学习, DecoyDB

TL;DR: 论文提出了一种名为DecoyDB的大规模、结构感知数据集，用于蛋白质-配体复合物的自监督图对比学习（GCL），并设计了一个定制的GCL框架。通过实验验证，该方法在准确性、标签效率和泛化能力上表现出色。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 当前蛋白质-配体复合物结合亲和力预测面临大规模高质量标记数据不足的问题，自监督学习，尤其是图对比学习，为解决这一问题提供了可能。然而，缺乏全面的无标记数据集和适合的GCL算法是主要挑战。

Method: 提出DecoyDB数据集，包含高分辨率真实复合物和多样化的计算生成的结构。设计了一个定制的GCL框架，用于预训练图神经网络，并在PDBbind标记数据上进行微调。

Result: 实验表明，基于DecoyDB预训练的模型在准确性、标签效率和泛化能力上显著优于其他方法。

Conclusion: DecoyDB和定制的GCL框架为蛋白质-配体复合物的结合亲和力预测提供了有效的解决方案，显著提升了模型性能。

Abstract: Predicting the binding affinity of protein-ligand complexes plays a vital
role in drug discovery. Unfortunately, progress has been hindered by the lack
of large-scale and high-quality binding affinity labels. The widely used
PDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,
especially graph contrastive learning (GCL), provides a unique opportunity to
break the barrier by pre-training graph neural network models based on vast
unlabeled complexes and fine-tuning the models on much fewer labeled complexes.
However, the problem faces unique challenges, including a lack of a
comprehensive unlabeled dataset with well-defined positive/negative complex
pairs and the need to design GCL algorithms that incorporate the unique
characteristics of such data. To fill the gap, we propose DecoyDB, a
large-scale, structure-aware dataset specifically designed for self-supervised
GCL on protein-ligand complexes. DecoyDB consists of high-resolution ground
truth complexes (less than 2.5 Angstrom) and diverse decoy structures with
computationally generated binding poses that range from realistic to suboptimal
(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation
(RMSD) from the native pose. We further design a customized GCL framework to
pre-train graph neural networks based on DecoyDB and fine-tune the models with
labels from PDBbind. Extensive experiments confirm that models pre-trained with
DecoyDB achieve superior accuracy, label efficiency, and generalizability.

</details>


### [49] [The Riemannian Geometry associated to Gradient Flows of Linear Convolutional Networks](https://arxiv.org/abs/2507.06367)
*El Mehdi Achour,Kathlén Kohn,Holger Rauhut*

Key words: 卷积网络, 梯度流, 黎曼几何, 优化

TL;DR: 研究深度线性卷积网络梯度流的几何性质，发现梯度流在参数空间与函数空间上可以表示为黎曼梯度流，且与初始条件无关。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 探讨线性卷积网络在参数空间梯度流与函数空间黎曼梯度流的关系，扩展全连接网络的已有结果。

Method: 分析梯度流在参数空间的表示，证明其在函数空间上为黎曼梯度流，适用于多维卷积和特定步长的一维卷积。

Result: 梯度流在函数空间上可表示为黎曼梯度流，其黎曼度量依赖于初始化条件。

Conclusion: 研究揭示了线性卷积网络梯度流的几何特性，为理解其优化行为提供了新的视角。

Abstract: We study geometric properties of the gradient flow for learning deep linear
convolutional networks. For linear fully connected networks, it has been shown
recently that the corresponding gradient flow on parameter space can be written
as a Riemannian gradient flow on function space (i.e., on the product of weight
matrices) if the initialization satisfies a so-called balancedness condition.
We establish that the gradient flow on parameter space for learning linear
convolutional networks can be written as a Riemannian gradient flow on function
space regardless of the initialization. This result holds for $D$-dimensional
convolutions with $D \geq 2$, and for $D =1$ it holds if all so-called strides
of the convolutions are greater than one. The corresponding Riemannian metric
depends on the initialization.

</details>


### [50] [Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation](https://arxiv.org/abs/2507.06380)
*Habibur Rahaman,Atri Chatterjee,Swarup Bhunia*

Key words: WINGs, 神经网络, 权重压缩, PCA, SVR, 边缘计算

TL;DR: WINGs利用PCA和SVR动态生成全连接层权重并压缩CNN权重，显著减少存储需求，同时保持高精度。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 复杂神经网络的突触权重存储需求高，WINGs旨在解决内存占用问题，适用于资源受限的边缘应用。

Method: 使用PCA降维和轻量级SVR预测全连接层权重，结合敏感性分析压缩CNN低敏感性层权重。

Result: 全连接层压缩53倍，AlexNet在MNIST数据集压缩28倍，CIFAR-10数据集压缩18倍，精度损失仅1-2%。

Conclusion: WINGs显著降低内存需求，提升推理效率，适用于边缘计算。

Abstract: Complex neural networks require substantial memory to store a large number of
synaptic weights. This work introduces WINGs (Automatic Weight Generator for
Secure and Storage-Efficient Deep Learning Models), a novel framework that
dynamically generates layer weights in a fully connected neural network (FC)
and compresses the weights in convolutional neural networks (CNNs) during
inference, significantly reducing memory requirements without sacrificing
accuracy. WINGs framework uses principal component analysis (PCA) for
dimensionality reduction and lightweight support vector regression (SVR) models
to predict layer weights in the FC networks, removing the need for storing
full-weight matrices and achieving substantial memory savings. It also
preferentially compresses the weights in low-sensitivity layers of CNNs using
PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers
an added level of security, as any bit-flip attack with weights in compressed
layers has an amplified and readily detectable effect on accuracy. WINGs
achieves 53x compression for the FC layers and 28x for AlexNet with MNIST
dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss.
This significant reduction in memory results in higher throughput and lower
energy for DNN inference, making it attractive for resource-constrained edge
applications.

</details>


### [51] [KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks](https://arxiv.org/abs/2507.06381)
*James Hazelden,Laura Driscoll,Eli Shlizerman,Eric Shea-Brown*

Key words: 梯度下降、循环神经网络、神经ODE、潜在动力学、多任务学习

TL;DR: 该论文提出了一种分解梯度流的方法，用于理解非线性循环模型中梯度下降学习的机制，并展示了其在低维潜在动力学和多任务训练中的应用。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 理解梯度下降在非线性循环模型（如RNNs、神经ODE和GRUs）中的学习机制，尤其是如何形成潜在表示和神经坍缩等现象。

Method: 将梯度流分解为两个算子（参数算子K和线性化流传播器P）的乘积，分析其在梯度下降中的作用。

Result: 通过分解揭示了低维潜在动力学的形成机制，并提出了衡量多任务目标对齐的工具。实验和理论验证均支持这一方法。

Conclusion: 该研究为理解非线性循环模型中的梯度下降学习提供了新的理论工具和分析方法，推动了这一领域的进一步发展。

Abstract: Gradient Descent (GD) and its variants are the primary tool for enabling
efficient training of recurrent dynamical systems such as Recurrent Neural
Networks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics
that are formed in these models exhibit features such as neural collapse and
emergence of latent representations that may support the remarkable
generalization properties of networks. In neuroscience, qualitative features of
these representations are used to compare learning in biological and artificial
systems. Despite recent progress, there remains a need for theoretical tools to
rigorously understand the mechanisms shaping learned representations,
especially in finite, non-linear models. Here, we show that the gradient flow,
which describes how the model's dynamics evolve over GD, can be decomposed into
a product that involves two operators: a Parameter Operator, K, and a
Linearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in
feed-forward neural networks, while P appears in Lyapunov stability and optimal
control theory. We demonstrate two applications of our decomposition. First, we
show how their interplay gives rise to low-dimensional latent dynamics under
GD, and, specifically, how the collapse is a result of the network structure,
over and above the nature of the underlying task. Second, for multi-task
training, we show that the operators can be used to measure how objectives
relevant to individual sub-tasks align. We experimentally and theoretically
validate these findings, providing an efficient Pytorch package, \emph{KPFlow},
implementing robust analysis tools for general recurrent architectures. Taken
together, our work moves towards building a next stage of understanding of GD
learning in non-linear recurrent models.

</details>


### [52] [Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning](https://arxiv.org/abs/2507.06402)
*Siddhant Deshpande,Yalemzerf Getnet,Waltenegus Dargie*

Key words: ECG, 篡改检测, CNN, ResNet, Transformer, Siamese网络

TL;DR: 该论文研究了CNN、ResNet和混合Transformer-CNN模型在ECG信号篡改检测中的表现，并评估了Siamese网络在ECG身份验证中的性能。实验显示，在高度碎片化的篡改场景中，模型准确率超过99.5%，Siamese网络验证准确率达100%。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 随着无线ECG系统在健康监测和身份验证中的普及，保护信号完整性免受篡改变得至关重要。

Method: 论文采用CNN、ResNet和混合Transformer-CNN模型进行篡改检测，并使用Siamese网络进行身份验证。ECG信号通过连续小波变换（CWT）转为二维时频表示。

Result: 在高度碎片化或细微篡改场景中，模型准确率超过99.5%或98%。Siamese网络中，混合CNN-Transformer模型实现100%准确率。

Conclusion: 混合Transformer-CNN和Siamese网络在ECG篡改检测和身份验证中表现出色，适用于实际应用。

Abstract: With the proliferation of wireless electrocardiogram (ECG) systems for health
monitoring and authentication, protecting signal integrity against tampering is
becoming increasingly important. This paper analyzes the performance of CNN,
ResNet, and hybrid Transformer-CNN models for tamper detection. It also
evaluates the performance of a Siamese network for ECG based identity
verification. Six tampering strategies, including structured segment
substitutions and random insertions, are emulated to mimic real world attacks.
The one-dimensional ECG signals are transformed into a two dimensional
representation in the time frequency domain using the continuous wavelet
transform (CWT). The models are trained and evaluated using ECG data from 54
subjects recorded in four sessions 2019 to 2025 outside of clinical settings
while the subjects performed seven different daily activities. Experimental
results show that in highly fragmented manipulation scenarios, CNN,
FeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding
99.5 percent . Similarly, for subtle manipulations (for example, 50 percent
from A and 50 percent from B and, 75 percent from A and 25 percent from B
substitutions) our FeatCNN-TranCNN model demonstrated consistently reliable
performance, achieving an average accuracy of 98 percent . For identity
verification, the pure Transformer-Siamese network achieved an average accuracy
of 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model
delivered perfect verification performance with 100 percent accuracy.

</details>


### [53] [Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction](https://arxiv.org/abs/2507.06432)
*Mingcheng Zhu,Yu Liu,Zhiyao Luo,Tingting Zhu*

Key words: ICU、罕见病症、深度学习、领域适应、临床预测

TL;DR: KnowRare是一个基于领域适应的深度学习框架，旨在解决ICU中罕见病症的数据稀缺和异质性问题，通过自监督预训练和条件知识图谱提升临床预测效果。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: ICU中罕见病症因数据稀缺和异质性难以获得准确预测，需开发新方法优化临床决策。

Method: KnowRare结合自监督预训练和条件知识图谱，从相似病症中迁移知识，优化预测模型。

Result: 在两项ICU数据集和五项预测任务中，KnowRare表现优于现有模型和ICU评分系统。

Conclusion: KnowRare为ICU罕见病症提供了一种通用且灵活的预测解决方案。

Abstract: Artificial Intelligence has revolutionised critical care for common
conditions. Yet, rare conditions in the intensive care unit (ICU), including
recognised rare diseases and low-prevalence conditions in the ICU, remain
underserved due to data scarcity and intra-condition heterogeneity. To bridge
such gaps, we developed KnowRare, a domain adaptation-based deep learning
framework for predicting clinical outcomes for rare conditions in the ICU.
KnowRare mitigates data scarcity by initially learning condition-agnostic
representations from diverse electronic health records through self-supervised
pre-training. It addresses intra-condition heterogeneity by selectively
adapting knowledge from clinically similar conditions with a developed
condition knowledge graph. Evaluated on two ICU datasets across five clinical
prediction tasks (90-day mortality, 30-day readmission, ICU mortality,
remaining length of stay, and phenotyping), KnowRare consistently outperformed
existing state-of-the-art models. Additionally, KnowRare demonstrated superior
predictive performance compared to established ICU scoring systems, including
APACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in
adapting its parameters to accommodate dataset-specific and task-specific
characteristics, its generalisation to common conditions under limited data
scenarios, and its rationality in selecting source conditions. These findings
highlight KnowRare's potential as a robust and practical solution for
supporting clinical decision-making and improving care for rare conditions in
the ICU.

</details>


### [54] [eegFloss: A Python package for refining sleep EEG recordings using machine learning models](https://arxiv.org/abs/2507.06433)
*Niloy Sikder,Paul Zerr,Mahdad Jafarzadeh Esfahani,Martin Dresler,Matthias Krauledat*

Key words: EEG, 睡眠研究, 机器学习, 伪影检测, eegFloss

TL;DR: 论文介绍了eegFloss，一个开源的Python包，用于检测睡眠EEG记录中的伪影，提高睡眠研究的分析精度和结果可靠性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: EEG信号在睡眠研究中易受伪影干扰，导致自动睡眠分期错误，影响研究结果的准确性。

Method: 使用eegUsability（基于机器学习的模型）检测EEG信号中的伪影，并在15名参与者的127晚数据上训练和评估。

Result: 模型表现良好（F1分数约0.85，Cohen's kappa 0.78），能高效识别可用EEG数据（召回率约94%）。

Conclusion: eegFloss解决了睡眠研究中的关键问题，提升了分析的精确性和结果的可靠性。

Abstract: Electroencephalography (EEG) allows monitoring of brain activity, providing
insights into the functional dynamics of various brain regions and their roles
in cognitive processes. EEG is a cornerstone in sleep research, serving as the
primary modality of polysomnography, the gold standard in the field. However,
EEG signals are prone to artifacts caused by both internal (device-specific)
factors and external (environmental) interferences. As sleep studies are
becoming larger, most rely on automatic sleep staging, a process highly
susceptible to artifacts, leading to erroneous sleep scores. This paper
addresses this challenge by introducing eegFloss, an open-source Python package
to utilize eegUsability, a novel machine learning (ML) model designed to detect
segments with artifacts in sleep EEG recordings. eegUsability has been trained
and evaluated on manually artifact-labeled EEG data collected from 15
participants over 127 nights using the Zmax headband. It demonstrates solid
overall classification performance (F1-score is approximately 0.85, Cohens
kappa is 0.78), achieving a high recall rate of approximately 94% in
identifying channel-wise usable EEG data, and extends beyond Zmax.
Additionally, eegFloss offers features such as automatic time-in-bed detection
using another ML model named eegMobility, filtering out certain artifacts, and
generating hypnograms and sleep statistics. By addressing a fundamental
challenge faced by most sleep studies, eegFloss can enhance the precision and
rigor of their analysis as well as the accuracy and reliability of their
outcomes.

</details>


### [55] [Can Interpretation Predict Behavior on Unseen Data?](https://arxiv.org/abs/2507.06445)
*Victoria R. Li,Jenny Kaufmann,Martin Wattenberg,David Alvarez-Melis,Naomi Saphra*

Key words: 解释性研究、OOD泛化、注意力模式、Transformer模型

TL;DR: 本文探讨了解释性研究如何预测模型在未见数据（OOD）上的行为，发现简单的观测工具（如注意力模式）可以预测OOD性能。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 研究解释性工具是否能有效预测模型在OOD数据上的行为，以验证解释性方法的实际应用潜力。

Method: 通过分析数百个独立训练的Transformer模型在合成分类任务中的注意力模式与OOD泛化能力之间的相关性。

Result: 发现当分布内注意力呈现分层模式时，模型在OOD数据上更可能分层泛化，即使其实现不依赖分层模式。

Conclusion: 研究结果为未来解释性工作提供了一个概念验证，支持其预测未见模型行为的潜力。

Abstract: Interpretability research often aims to predict how a model will respond to
targeted interventions on specific mechanisms. However, it rarely predicts how
a model will respond to unseen input data. This paper explores the promises and
challenges of interpretability as a tool for predicting out-of-distribution
(OOD) model behavior. Specifically, we investigate the correspondence between
attention patterns and OOD generalization in hundreds of Transformer models
independently trained on a synthetic classification task. These models exhibit
several distinct systematic generalization rules OOD, forming a diverse
population for correlational analysis. In this setting, we find that simple
observational tools from interpretability can predict OOD performance. In
particular, when in-distribution attention exhibits hierarchical patterns, the
model is likely to generalize hierarchically on OOD data -- even when the
rule's implementation does not rely on these hierarchical patterns, according
to ablation tests. Our findings offer a proof-of-concept to motivate further
interpretability work on predicting unseen model behavior.

</details>


### [56] [FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models](https://arxiv.org/abs/2507.06449)
*Qianyu Long,Qiyuan Wang,Christos Anagnostopoulos,Daning Bi*

Key words: 联邦学习,扩散模型,数据异质性,通信成本,分布式剪枝

TL;DR: FedPhD是一种新颖的联邦学习方法，用于高效训练扩散模型，通过分层联邦学习和同质性感知策略解决数据异质性，并通过分布式结构化剪枝降低通信成本和计算负担。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 联邦学习（FL）在训练扩散模型（DMs）时面临高通信成本和数据异质性的挑战，现有研究较少解决这些问题。

Method: FedPhD采用分层联邦学习、同质性感知模型聚合与选择策略，并引入分布式结构化剪枝技术。

Result: 在多数据集实验中，FedPhD显著降低了88%的通信成本，FID得分提升至少34%，仅需56%的总计算和通信资源。

Conclusion: FedPhD在降低资源消耗的同时，显著提升了扩散模型在联邦学习环境中的性能。

Abstract: Federated Learning (FL), as a distributed learning paradigm, trains models
over distributed clients' data. FL is particularly beneficial for distributed
training of Diffusion Models (DMs), which are high-quality image generators
that require diverse data. However, challenges such as high communication costs
and data heterogeneity persist in training DMs similar to training Transformers
and Convolutional Neural Networks. Limited research has addressed these issues
in FL environments. To address this gap and challenges, we introduce a novel
approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD
leverages Hierarchical FL with homogeneity-aware model aggregation and
selection policy to tackle data heterogeneity while reducing communication
costs. The distributed structured pruning of FedPhD enhances computational
efficiency and reduces model storage requirements in clients. Our experiments
across multiple datasets demonstrate that FedPhD achieves high model
performance regarding Fr\'echet Inception Distance (FID) scores while reducing
communication costs by up to $88\%$. FedPhD outperforms baseline methods
achieving at least a $34\%$ improvement in FID, while utilizing only $56\%$ of
the total computation and communication resources.

</details>


### [57] [Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models](https://arxiv.org/abs/2507.06458)
*Arjun Banerjee,David Martinez,Camille Dang,Ethan Tam*

Key words: 蛋白质语言模型,神经元标记,激活引导,蛋白质生成,缩放规律

TL;DR: 提出了首个自动标记蛋白质语言模型（PLM）神经元的框架，揭示了神经元对生化特性的选择性敏感，并开发了一种激活引导的蛋白质生成方法。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 理解PLM神经元表示及利用其生成具有目标特性的蛋白质。

Method: 自动化框架标记神经元，开发神经元激活引导的生成方法。

Result: 成功标记大量神经元并生成目标特性的蛋白质，揭示了PLM的缩放规律。

Conclusion: 自动化标记和激活引导方法为PLM的生物学理解和应用提供了新途径。

Abstract: Protein language models (PLMs) encode rich biological information, yet their
internal neuron representations are poorly understood. We introduce the first
automated framework for labeling every neuron in a PLM with biologically
grounded natural language descriptions. Unlike prior approaches relying on
sparse autoencoders or manual annotation, our method scales to hundreds of
thousands of neurons, revealing individual neurons are selectively sensitive to
diverse biochemical and structural properties. We then develop a novel neuron
activation-guided steering method to generate proteins with desired traits,
enabling convergence to target biochemical properties like molecular weight and
instability index as well as secondary and tertiary structural motifs,
including alpha helices and canonical Zinc Fingers. We finally show that
analysis of labeled neurons in different model sizes reveals PLM scaling laws
and a structured neuron space distribution.

</details>


### [58] [Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm](https://arxiv.org/abs/2507.06461)
*Risi Jaiswal,Supriyo Datta,Joseph G. Makin*

Key words: 机器学习, 能效, 前向-前向算法, 二值化, 随机单元

TL;DR: 这篇论文提出了一种基于二值化和随机单元的前向-前向算法，以解决传统反向传播算法在硬件加速中的能效问题，并展示了接近实值算法的性能。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现代机器学习在大型神经网络上的高能耗问题已成为迫切需求。反向传播算法因其串行依赖性和内存占用大，对硬件加速器提出了挑战。本研究旨在探索能效更高的替代方案。

Method: 采用前向-前向算法结合二值化激活和随机单元。二值化将矩阵乘法转换为索引操作，而随机性和权重绑定则绕过二值单元的信息瓶颈。此外，利用p-bit（概率比特）实现快速且廉价的二进制采样。

Result: 在MNIST、Fashion-MNIST和CIFAR-10数据集上的实验表明，该算法性能接近实值前向-前向算法，同时能效估计提升约一个数量级。

Conclusion: 二值化和随机单元的前向-前向算法在保持性能的同时显著降低了能耗，为节能硬件加速提供了可行方案。

Abstract: Reducing energy consumption has become a pressing need for modern machine
learning, which has achieved many of its most impressive results by scaling to
larger and more energy-consumptive neural networks. Unfortunately, the main
algorithm for training such networks, backpropagation, poses significant
challenges for custom hardware accelerators, due to both its serial
dependencies and the memory footprint needed to store forward activations for
the backward pass. Alternatives to backprop, although less effective, do exist;
here the main computational bottleneck becomes matrix multiplication. In this
study, we derive forward-forward algorithms for binary, stochastic units.
Binarization of the activations transforms matrix multiplications into indexing
operations, which can be executed efficiently in hardware. Stochasticity,
combined with tied weights across units with different biases, bypasses the
information bottleneck imposed by binary units. Furthermore, although slow and
expensive in traditional hardware, binary sampling that is very fast can be
implemented cheaply with p-bits (probabilistic bits), novel devices made up of
unstable magnets. We evaluate our proposed algorithms on the MNIST,
Fashion-MNIST, and CIFAR-10 datasets, showing that its performance is close to
real-valued forward-forward, but with an estimated energy savings of about one
order of magnitude.

</details>


### [59] [SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam](https://arxiv.org/abs/2507.06464)
*Hanyang Peng,Shuang Qin,Yue Yu,Fangqing Jiang,Hui Wang,Wen Gao*

Key words: Adam, SignSoftSGD, 优化器, 深度学习, 收敛性

TL;DR: 本文分析了Adam优化器的成功与局限，并提出了一种名为SignSoftSGD (S3)的新优化器，通过灵活的p阶动量、统一的指数移动平均系数和Nesterov加速梯度模块，显著提升了性能和稳定性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: Adam在训练深度神经网络中表现出色，但其成功机制和局限性尚未充分探索。本文旨在通过改进Adam的更新策略，增强其优势并减少其局限性。

Method: 提出SignSoftSGD (S3)优化器，包括：(1) 灵活的p阶动量，(2) 统一的指数移动平均系数，(3) Nesterov加速梯度模块，以提升稳定性和收敛速度。

Result: S3实现了非凸随机优化的最优收敛速率，并在视觉和语言任务中表现出更高的性能和稳定性，即使使用更大的学习率也能减少损失尖峰。

Conclusion: S3在效率和最终任务性能上优于AdamW，证实了其作为高效优化器的潜力。

Abstract: Adam has proven remarkable successful in training deep neural networks, but
the mechanisms underlying its empirical successes and limitations remain
underexplored. In this study, we demonstrate that the effectiveness of Adam
stems largely from its similarity to SignSGD in robustly handling large
gradient fluctuations, yet it is also vulnerable to destabilizing loss spikes
due to its uncontrolled update scaling. To enhance the advantage of Adam and
mitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with
three key innovations. \emph{First}, S3 generalizes the sign-like update by
employing a flexible $p$-th order momentum ($p \geq 1$) in the denominator,
departing from the conventional second-order momentum (variance)
preconditioning. This design enables enhanced performance while achieving
stable training even with aggressive learning rates. \emph{Second}, S3
minimizes the occurrences of loss spikes through unified exponential moving
average coefficients for numerator and denominator momenta, which inherently
bound updates to $[-1, 1]$ and simplify hyperparameter tuning. \emph{Third}, S3
incorporates an equivalent Nesterov's accelerated gradient(NAG) module,
accelerating convergence without memory overhead. Theoretically, we prove that
S3 achieves the optimal convergence rate of
$O\left(\frac{1}{T^{\sfrac{1}{4}}}\right)$ for general nonconvex stochastic
optimization under weak assumptions. Extensive experiments across a range of
vision and language tasks show that \textsf{\small S3} not only converges more
rapidly and improves performance but also rarely experiences loss spikes, even
with a \textbf{$\bm{10 \times}$} larger learning rate. In fact, S3 delivers
performance comparable to or better than AdamW with \textbf{$2 \times$} the
training steps, establishing its efficacy in both efficiency and final task
performance.

</details>


### [60] [Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models](https://arxiv.org/abs/2507.06466)
*Aaron Dharna,Cong Lu,Jeff Clune*

Key words: 自博弈（SP）、基础模型、策略多样性、强化学习、AI安全

TL;DR: 论文提出了一种名为Foundation-Model Self-Play (FMSP)的新方法，利用基础模型的代码生成能力和广泛知识，克服传统自博弈算法（SP）在局部最优解中停滞和缺乏多样性的问题。FMSP包括三种变体：vFMSP、NSSP和QDSP，并在Car Tag和Gandalf实验中验证了其有效性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统自博弈算法（SP）虽然可以通过不断对抗提升策略质量，但容易陷入局部最优解且缺乏多样性。FMSP旨在通过基础模型的强大能力，克服这些局限性。

Method: FMSP包含三种方法：1) vFMSP通过竞争性自博弈持续优化策略；2) NSSP专注于生成多样化策略；3) QDSP结合多样性和高质量策略优化。实验在Car Tag（连续控制的追逐-逃避场景）和Gandalf（AI安全模拟）中进行。

Result: 在Car Tag中，FMSP和vFMSP超越了人类设计的策略；在Gandalf中，FMSP成功攻破并越狱了六个逐步加强的防御级别。此外，FMSP还能自动修补发现的漏洞。

Conclusion: FMSP为自博弈研究开辟了新的前沿，通过结合基础模型的能力，实现了更开放和多样化的策略发现。

Abstract: Multi-agent interactions have long fueled innovation, from natural
predator-prey dynamics to the space race. Self-play (SP) algorithms try to
harness these dynamics by pitting agents against ever-improving opponents,
thereby creating an implicit curriculum toward learning high-quality solutions.
However, SP often fails to produce diverse solutions and can get stuck in
locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a
new direction that leverages the code-generation capabilities and vast
knowledge of foundation models (FMs) to overcome these challenges by leaping
across local optima in policy space. We propose a family of approaches: (1)
\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent
policies via competitive self-play; (2) \textbf{Novelty-Search Self-Play
(NSSP)} builds a diverse population of strategies, ignoring performance; and
(3) the most promising variant, \textbf{Quality-Diveristy Self-Play (QDSP)},
creates a diverse set of high-quality policies by combining the diversity of
NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a
continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety
simulation in which an attacker tries to jailbreak an LLM's defenses. In Car
Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and
heuristic-based methods, to name just a few. In terms of discovered policy
quality, \ouralgo and vFMSP surpass strong human-designed strategies. In
Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through
and jailbreaking six different, progressively stronger levels of defense.
Furthermore, FMSPs can automatically proceed to patch the discovered
vulnerabilities. Overall, FMSPs represent a promising new research frontier of
improving self-play with foundation models, opening fresh paths toward more
creative and open-ended strategy discovery

</details>


### [61] [Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning](https://arxiv.org/abs/2507.06469)
*Yudan Song,Yuecen Wei,Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu*

Key words: 图表示学习, 欺诈检测, 拓扑不平衡, 类别不平衡, 双视图学习

TL;DR: 该论文提出了一种基于双视图图表示学习的方法（MimbFD），用于解决欺诈检测中因拓扑和类别不平衡导致的监督信息不平衡问题，并通过实验验证了其有效性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 图表示学习在欺诈检测中因局部交互导致的全局拓扑信息传输不平衡，以及欺诈节点与良性节点类别不平衡问题影响了性能。作者旨在解决这些问题。

Method: 提出MimbFD方法，包含拓扑消息可达性模块（提升节点表征穿透欺诈伪装）和局部混杂去偏模块（调整节点表征以平衡类别影响）。

Result: 在三个公开欺诈数据集上的实验表明，MimbFD在欺诈检测中表现优异。

Conclusion: MimbFD通过双视图学习有效缓解了消息不平衡问题，提升了欺诈检测性能。

Abstract: Graph representation learning has become a mainstream method for fraud
detection due to its strong expressive power, which focuses on enhancing node
representations through improved neighborhood knowledge capture. However, the
focus on local interactions leads to imbalanced transmission of global
topological information and increased risk of node-specific information being
overwhelmed during aggregation due to the imbalance between fraud and benign
nodes. In this paper, we first summarize the impact of topology and class
imbalance on downstream tasks in GNN-based fraud detection, as the problem of
imbalanced supervisory messages is caused by fraudsters' topological behavior
obfuscation and identity feature concealment. Based on statistical validation,
we propose a novel dual-view graph representation learning method to mitigate
Message imbalance in Fraud Detection(MimbFD). Specifically, we design a
topological message reachability module for high-quality node representation
learning to penetrate fraudsters' camouflage and alleviate insufficient
propagation. Then, we introduce a local confounding debiasing module to adjust
node representations, enhancing the stable association between node
representations and labels to balance the influence of different classes.
Finally, we conducted experiments on three public fraud datasets, and the
results demonstrate that MimbFD exhibits outstanding performance in fraud
detection.

</details>


### [62] [FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning](https://arxiv.org/abs/2507.06482)
*Huan Wang,Haoran Li,Huaming Chen,Jun Yan,Jiahua Shi,Jun Shen*

Key words: 联邦学习, 扩散模型, 数据异构性, 文本驱动对比学习, 噪声驱动正则化

TL;DR: 联邦学习通常面临数据异构性问题，本文提出了一种基于扩散模型的联邦学习方法FedDifRC，通过文本驱动对比学习和噪声驱动正则化来缓解数据异质性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决联邦学习中因数据异构性导致的模型收敛和性能问题。

Method: 引入扩散模型，提出FedDifRC方法，包含文本驱动扩散对比和噪声驱动扩散正则化。

Result: 实验验证了FedDifRC在多种场景下的有效性和关键组件的效率。

Conclusion: FedDifRC通过扩散模型的语义信息和一致性信号，有效缓解了数据异构性问题。

Abstract: Federated learning aims at training models collaboratively across
participants while protecting privacy. However, one major challenge for this
paradigm is the data heterogeneity issue, where biased data preferences across
multiple clients, harming the model's convergence and performance. In this
paper, we first introduce powerful diffusion models into the federated learning
paradigm and show that diffusion representations are effective steers during
federated training. To explore the possibility of using diffusion
representations in handling data heterogeneity, we propose a novel
diffusion-inspired Federated paradigm with Diffusion Representation
Collaboration, termed FedDifRC, leveraging meaningful guidance of diffusion
models to mitigate data heterogeneity. The key idea is to construct text-driven
diffusion contrasting and noise-driven diffusion regularization, aiming to
provide abundant class-related semantic information and consistent convergence
signals. On the one hand, we exploit the conditional feedback from the
diffusion model for different text prompts to build a text-driven contrastive
learning strategy. On the other hand, we introduce a noise-driven consistency
regularization to align local instances with diffusion denoising
representations, constraining the optimization region in the feature space. In
addition, FedDifRC can be extended to a self-supervised scheme without relying
on any labeled data. We also provide a theoretical analysis for FedDifRC to
ensure convergence under non-convex objectives. The experiments on different
scenarios validate the effectiveness of FedDifRC and the efficiency of crucial
components.

</details>


### [63] [MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models](https://arxiv.org/abs/2507.06502)
*Yiwen Liu,Chenyu Zhang,Junjie Song,Siqi Chen,Sun Yin,Zihan Wang,Lingming Zeng,Yuji Cao,Junming Jiao*

Key words: 时间序列预测, 大语言模型, 混合专家网络, 预训练-微调, 时间和频率特征

TL;DR: 论文提出了一种名为MoFE-Time的时间序列预测模型，通过结合时间和频率域特征，并采用混合专家网络（MoE）和预训练-微调范式，显著提升了复杂时间序列的预测性能。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有的时间序列模型在预训练-微调范式中往往无法同时建模时间和频率特性，导致在复杂时间序列预测中的性能不佳。MoFE-Time旨在解决这一问题。

Method: MoFE-Time将时间和频率单元作为专家网络，结合MoE路由机制构建多维稀疏表示，并在预训练-微调框架中进行训练。

Result: 在六个公共基准测试中，MoFE-Time达到了新的最优性能，MSE和MAE分别降低了6.95%和6.02%。在私有数据集NEV-sales上也表现优异。

Conclusion: MoFE-Time通过结合时间和频率域特征，显著提升了时间序列预测的性能，展示了在实际商业应用中的潜力。

Abstract: As a prominent data modality task, time series forecasting plays a pivotal
role in diverse applications. With the remarkable advancements in Large
Language Models (LLMs), the adoption of LLMs as the foundational architecture
for time series modeling has gained significant attention. Although existing
models achieve some success, they rarely both model time and frequency
characteristics in a pretraining-finetuning paradigm leading to suboptimal
performance in predictions of complex time series, which requires both modeling
periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an
innovative time series forecasting model that integrates time and frequency
domain features within a Mixture of Experts (MoE) network. Moreover, we use the
pretraining-finetuning paradigm as our training framework to effectively
transfer prior pattern knowledge across pretraining and finetuning datasets
with different periodicity distributions. Our method introduces both frequency
and time cells as experts after attention modules and leverages the MoE routing
mechanism to construct multidimensional sparse representations of input
signals. In experiments on six public benchmarks, MoFE-Time has achieved new
state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared
to the representative methods Time-MoE. Beyond the existing evaluation
benchmarks, we have developed a proprietary dataset, NEV-sales, derived from
real-world business scenarios. Our method achieves outstanding results on this
dataset, underscoring the effectiveness of the MoFE-Time model in practical
commercial applications.

</details>


### [64] [Instance-Wise Monotonic Calibration by Constrained Transformation](https://arxiv.org/abs/2507.06516)
*Yunrui Zhang,Gustavo Batista,Salil S. Kanhere*

Key words: 深度神经网络, 概率校准, 单调性, 可解释性, 约束优化

TL;DR: 本文提出一种新的单调后处理校准方法，通过约束优化问题设计校准映射，确保表达性、鲁棒性和可解释性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决深度神经网络概率估计的校准问题，现有方法无法保证单调性或缺乏可解释性。

Method: 提出基于线性参数化的单调校准映射，用约束优化问题确保相对排序不变。

Result: 在多个数据集上表现优于现有校准方法，且数据与计算效率高。

Conclusion: 该方法在性能和实用性上优于现有技术，适合实际应用。

Abstract: Deep neural networks often produce miscalibrated probability estimates,
leading to overconfident predictions. A common approach for calibration is
fitting a post-hoc calibration map on unseen validation data that transforms
predicted probabilities. A key desirable property of the calibration map is
instance-wise monotonicity (i.e., preserving the ranking of probability
outputs). However, most existing post-hoc calibration methods do not guarantee
monotonicity. Previous monotonic approaches either use an under-parameterized
calibration map with limited expressive ability or rely on black-box neural
networks, which lack interpretability and robustness. In this paper, we propose
a family of novel monotonic post-hoc calibration methods, which employs a
constrained calibration map parameterized linearly with respect to the number
of classes. Our proposed approach ensures expressiveness, robustness, and
interpretability while preserving the relative ordering of the probability
output by formulating the proposed calibration map as a constrained
optimization problem. Our proposed methods achieve state-of-the-art performance
across datasets with different deep neural network models, outperforming
existing calibration methods while being data and computation-efficient. Our
code is available at
https://github.com/YunruiZhang/Calibration-by-Constrained-Transformation

</details>


### [65] [AdaDPIGU: Differentially Private SGD with Adaptive Clipping and Importance-Based Gradient Updates for Deep Neural Networks](https://arxiv.org/abs/2507.06525)
*Huiqi Zhang,Fang Xie*

Key words: 差分隐私,SGD,梯度更新,自适应稀疏化,深度神经网络

TL;DR: 论文提出一种新的差分隐私SGD框架AdaDPIGU，通过重要性梯度更新解决高维噪声问题，理论证明其满足差分隐私并保持收敛性，实验在MNIST和CIFAR-10上取得显著效果。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有差分隐私方法在高维设置下因噪声规模增加导致性能下降，因此提出AdaDPIGU以优化梯度更新过程并提升隐私保护效果。

Method: 采用预训练阶段差分隐私高斯机制估计参数重要性，梯度更新阶段裁剪低重要性坐标并引入自适应稀疏化机制。

Result: MNIST上在ε=8时达到99.12%准确率，CIFAR-10上在ε=4时超越非隐私基线（73.21% vs. 71.12%）。

Conclusion: AdaDPIGU通过自适应稀疏化提高隐私和效用，适用于高维深度学习任务。

Abstract: Differential privacy has been proven effective for stochastic gradient
descent; however, existing methods often suffer from performance degradation in
high-dimensional settings, as the scale of injected noise increases with
dimensionality. To tackle this challenge, we propose AdaDPIGU--a new
differentially private SGD framework with importance-based gradient updates
tailored for deep neural networks. In the pretraining stage, we apply a
differentially private Gaussian mechanism to estimate the importance of each
parameter while preserving privacy. During the gradient update phase, we prune
low-importance coordinates and introduce a coordinate-wise adaptive clipping
mechanism, enabling sparse and noise-efficient gradient updates. Theoretically,
we prove that AdaDPIGU satisfies $(\varepsilon, \delta)$-differential privacy
and retains convergence guarantees. Extensive experiments on standard
benchmarks validate the effectiveness of AdaDPIGU. All results are reported
under a fixed retention ratio of 60%. On MNIST, our method achieves a test
accuracy of 99.12% under a privacy budget of $\epsilon = 8$, nearly matching
the non-private model. Remarkably, on CIFAR-10, it attains 73.21% accuracy at
$\epsilon = 4$, outperforming the non-private baseline of 71.12%, demonstrating
that adaptive sparsification can enhance both privacy and utility.

</details>


### [66] [Direct Regret Optimization in Bayesian Optimization](https://arxiv.org/abs/2507.06529)
*Fengxue Zhang,Yuxin Chen*

Key words: 贝叶斯优化, 直接后悔优化, 高斯过程, 决策变换器

TL;DR: 提出了一种新颖的直接后悔优化方法，联合学习最优模型和非短视获取函数，旨在最小化多步后悔。该方法通过集合高斯过程和多种获取函数生成模拟轨迹，训练决策变换器以优化目标。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统贝叶斯优化方法依赖手工设计的获取函数和替代模型，且常为短视行为，无法有效优化多步后悔。本文旨在解决这一问题。

Method: 利用集合高斯过程和多种获取函数生成模拟轨迹，训练端到端决策变换器，结合离线密集训练和在线稀疏学习。

Result: 在合成和真实基准测试中表现优于基线，实现了更低简单后悔且在高维或噪声环境中更稳健。

Conclusion: 提出的方法通过联合学习和非短视策略，显著提升了贝叶斯优化的性能。

Abstract: Bayesian optimization (BO) is a powerful paradigm for optimizing expensive
black-box functions. Traditional BO methods typically rely on separate
hand-crafted acquisition functions and surrogate models for the underlying
function, and often operate in a myopic manner. In this paper, we propose a
novel direct regret optimization approach that jointly learns the optimal model
and non-myopic acquisition by distilling from a set of candidate models and
acquisitions, and explicitly targets minimizing the multi-step regret. Our
framework leverages an ensemble of Gaussian Processes (GPs) with varying
hyperparameters to generate simulated BO trajectories, each guided by an
acquisition function chosen from a pool of conventional choices, until a
Bayesian early stop criterion is met. These simulated trajectories, capturing
multi-step exploration strategies, are used to train an end-to-end decision
transformer that directly learns to select next query points aimed at improving
the ultimate objective. We further adopt a dense training--sparse learning
paradigm: The decision transformer is trained offline with abundant simulated
data sampled from ensemble GPs and acquisitions, while a limited number of real
evaluations refine the GPs online. Experimental results on synthetic and
real-world benchmarks suggest that our method consistently outperforms BO
baselines, achieving lower simple regret and demonstrating more robust
exploration in high-dimensional or noisy settings.

</details>


### [67] [Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits](https://arxiv.org/abs/2507.06535)
*Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu*

Key words: 图表示学习、对比学习、AMS电路、寄生估计、标签平衡

TL;DR: CircuitGCL提出了一种新的图对比学习框架，通过表示散射和标签重新平衡解决AMS电路图中数据稀缺和标签不平衡问题，显著提升了寄生电容估计的准确性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决AMS电路图学习中数据稀缺、标签分布不平衡及电路实现多样性带来的挑战。

Method: 采用自监督策略和表示散射技术，结合平衡MSE和bsmCE损失函数。

Result: 在寄生电容估计和接地电容分类任务中，性能超越现有方法，R²提升33.64%~44.20%，F1分数增益0.9~2.1倍。

Conclusion: CircuitGCL为AMS电路的鲁棒和可迁移表示学习提供了有效框架。

Abstract: Graph representation learning on Analog-Mixed Signal (AMS) circuits is
crucial for various downstream tasks, e.g., parasitic estimation. However, the
scarcity of design data, the unbalanced distribution of labels, and the
inherent diversity of circuit implementations pose significant challenges to
learning robust and transferable circuit representations. To address these
limitations, we propose CircuitGCL, a novel graph contrastive learning
framework that integrates representation scattering and label rebalancing to
enhance transferability across heterogeneous circuit graphs. CircuitGCL employs
a self-supervised strategy to learn topology-invariant node embeddings through
hyperspherical representation scattering, eliminating dependency on large-scale
data. Simultaneously, balanced mean squared error (MSE) and softmax
cross-entropy (bsmCE) losses are introduced to mitigate label distribution
disparities between circuits, enabling robust and transferable parasitic
estimation. Evaluated on parasitic capacitance estimation (edge-level task) and
ground capacitance classification (node-level task) across TSMC 28nm AMS
designs, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the
$R^2$ improvement of $33.64\% \sim 44.20\%$ for edge regression and F1-score
gain of $0.9\times \sim 2.1\times$ for node classification. Our code is
available at
\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.

</details>


### [68] [Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction](https://arxiv.org/abs/2507.06538)
*Shan Shen,Yibin Zhang,Hector Rodriguez Rodriguez,Wenjian Yu*

Key words: 图表示学习, AMS电路, 少样本学习, 寄生效应预测

TL;DR: CircuitGPS是一种少样本学习方法，用于预测模拟/混合信号电路中的寄生效应，通过图表示学习和预训练技术显著提高了预测精度。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 由于集成电路设计数据的稀缺性，训练深度学习模型用于模拟/混合信号（AMS）电路设计具有挑战性。

Method: 将电路网表表示为异构图，通过小跳采样技术将链接或节点转换为子图，并使用混合图Transformer学习子图嵌入，结合低成本位置编码。

Result: CircuitGP将耦合存在预测的准确性提高了至少20%，电容估计的MAE降低了至少0.067。

Conclusion: CircuitGPS展示了强大的可扩展性，能够通过零样本学习直接应用于多样化的AMS电路设计。

Abstract: Graph representation learning is a powerful method to extract features from
graph-structured data, such as analog/mixed-signal (AMS) circuits. However,
training deep learning models for AMS designs is severely limited by the
scarcity of integrated circuit design data. In this work, we present
CircuitGPS, a few-shot learning method for parasitic effect prediction in AMS
circuits. The circuit netlist is represented as a heterogeneous graph, with the
coupling capacitance modeled as a link. CircuitGPS is pre-trained on link
prediction and fine-tuned on edge regression. The proposed method starts with a
small-hop sampling technique that converts a link or a node into a subgraph.
Then, the subgraph embeddings are learned with a hybrid graph Transformer.
Additionally, CircuitGPS integrates a low-cost positional encoding that
summarizes the positional and structural information of the sampled subgraph.
CircuitGPS improves the accuracy of coupling existence by at least 20\% and
reduces the MAE of capacitance estimation by at least 0.067 compared to
existing methods. Our method demonstrates strong inherent scalability, enabling
direct application to diverse AMS circuit designs through zero-shot learning.
Furthermore, the ablation studies provide valuable insights into graph models
for representation learning.

</details>


### [69] [A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning](https://arxiv.org/abs/2507.06542)
*Tongtian Zhu,Tianyu Zhang,Mingze Wang,Zhanpeng Zhou,Can Wang*

Key words: 去中心化学习,通信调度,模型合并,泛化能力,数据异构

TL;DR: 去中心化学习中，后期集中通信预算显著提升训练效果，单次全局合并即可媲美中心化训练，挑战了传统观念。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 研究去中心化学习中通信调度的问题，以克服其对训练性能的限制。

Method: 通过调整通信时间与频率，包括后期集中通信和单次全局合并。

Result: 后期集中通信能显著提升泛化能力，单次全局合并可匹配中心化训练效果。

Conclusion: 去中心化学习在数据异构与有限通信下仍能高效泛化，提出模型合并与损失景观的新见解。

Abstract: Decentralized learning provides a scalable alternative to traditional
parameter-server-based training, yet its performance is often hindered by
limited peer-to-peer communication. In this paper, we study how communication
should be scheduled over time, including determining when and how frequently
devices synchronize. Our empirical results show that concentrating
communication budgets in the later stages of decentralized training markedly
improves global generalization. Surprisingly, we uncover that fully connected
communication at the final step, implemented by a single global merging, is
sufficient to match the performance of server-based training. We further show
that low communication in decentralized learning preserves the
\textit{mergeability} of local models throughout training. Our theoretical
contributions, which explains these phenomena, are first to establish that the
globally merged model of decentralized SGD can converge faster than centralized
mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy
among local models, which were previously considered as detrimental noise, as
constructive components that accelerate convergence. This work challenges the
common belief that decentralized learning generalizes poorly under data
heterogeneity and limited communication, while offering new insights into model
merging and neural network loss landscapes.

</details>


### [70] [Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs](https://arxiv.org/abs/2507.06549)
*Shan Shen,Dingcheng Yang,Yuyang Xie,Chunyan Pei,Wenjian Yu,Bei Yu*

Key words: SRAM, 寄生效应, 图神经网络, 多层感知机, 深度学习

TL;DR: 提出了一种基于深度学习的2阶段模型，用于在预布局阶段准确预测SRAM电路的寄生效应，显著提高了仿真速度和预测精度。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 预布局和后布局仿真间的寄生效应差异导致设计参数难以收敛，设计迭代次数增多，影响了系统能效的提升。

Method: 结合图神经网络分类器和多层感知机回归器，采用Focal Loss处理类别不平衡，并利用子电路信息抽象层次结构。

Result: 在4个实际SRAM设计上，最大减少19倍预测误差，仿真速度提升598倍。

Conclusion: 该方法显著优化了寄生预测和仿真流程，为SRAM设计提供了高效解决方案。

Abstract: To achieve higher system energy efficiency, SRAM in SoCs is often customized.
The parasitic effects cause notable discrepancies between pre-layout and
post-layout circuit simulations, leading to difficulty in converging design
parameters and excessive design iterations. Is it possible to well predict the
parasitics based on the pre-layout circuit, so as to perform parasitic-aware
pre-layout simulation? In this work, we propose a deep-learning-based 2-stage
model to accurately predict these parasitics in pre-layout stages. The model
combines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron
(MLP) regressors, effectively managing class imbalance of the net parasitics in
SRAM circuits. We also employ Focal Loss to mitigate the impact of abundant
internal net samples and integrate subcircuit information into the graph to
abstract the hierarchical structure of schematics. Experiments on 4 real SRAM
designs show that our approach not only surpasses the state-of-the-art model in
parasitic prediction by a maximum of 19X reduction of error but also
significantly boosts the simulation process by up to 598X speedup.

</details>


### [71] [The Primacy of Magnitude in Low-Rank Adaptation](https://arxiv.org/abs/2507.06558)
*Zicheng Zhang,Haoran Li,Yifeng Zhang,Guoqiang Gong,Jiaxing Wang,Pengzhang Liu,Qixia Jiang,Junxing Hu*

Key words: Low-Rank Adaptation, LoRA, initialization, magnitude, efficiency

TL;DR: LoRAM提出了一种高效的低秩自适应初始化方案，通过调控权重更新的幅度来优化性能，无需额外计算或存储开销。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 为了克服现有低秩自适应方法在计算和存储上的低效问题，同时利用权重更新幅度对性能的关键影响。

Method: 提出了LoRAM，一种基于幅度驱动的初始化方案，通过确定性正交基和预训练权重幅度模拟光谱增益。

Result: LoRAM在保持LoRA高效性的同时，性能与光谱初始化相当或更优。

Conclusion: 幅度调控是低秩自适应性能的关键驱动因素，LoRAM为高效初始化提供了新思路。

Abstract: Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning
large models. While recent spectral initialization methods improve convergence
and performance over the naive "Noise & Zeros" scheme, their extra
computational and storage overhead undermines efficiency. In this paper, we
establish update magnitude as the fundamental driver of LoRA performance and
propose LoRAM, a magnitude-driven "Basis & Basis" initialization scheme that
matches spectral methods without their inefficiencies. Our key contributions
are threefold: (i) Magnitude of weight updates determines convergence. We prove
low-rank structures intrinsically bound update magnitudes, unifying
hyperparameter tuning in learning rate, scaling factor, and initialization as
mechanisms to optimize magnitude regulation. (ii) Spectral initialization
succeeds via magnitude amplification. We demystify that the presumed
knowledge-driven benefit of the spectral component essentially arises from the
boost in the weight update magnitude. (iii) A novel and compact initialization
strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight
magnitudes to simulate spectral gains. Extensive experiments show that LoRAM
serves as a strong baseline, retaining the full efficiency of LoRA while
matching or outperforming spectral initialization across benchmarks.

</details>


### [72] [SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference](https://arxiv.org/abs/2507.06567)
*Qian Chen,Xianhao Chen,Kaibin Huang*

Key words: 混合专家模型,边缘计算,分布式推理,缓存优化,推理延迟

TL;DR: 研究了混合专家（MoE）模型在边缘设备上的分布式推理优化问题，提出了针对不同专家选择策略的缓存优化方法，显著降低了推理延迟。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决MoE模型在边缘设备上的存储和推理延迟问题，通过分布式缓存优化提升效率。

Method: 针对Top-$K$专家选择策略，分别设计了贪心算法和动态规划的分解方法，并结合max-convolution加速。

Result: 仿真结果表明，该方法显著优于现有基线，降低了推理延迟。

Conclusion: 提出的优化方法有效解决了MoE模型在边缘网络中的分布式推理挑战。

Abstract: Mixture-of-Experts (MoE) models improve the scalability of large language
models (LLMs) by activating only a small subset of relevant experts per input.
However, the sheer number of expert networks in an MoE model introduces a
significant storage burden for an edge device. To address this challenge, we
consider a scenario where experts are dispersed within an edge network for
distributed inference. Based on the popular Top-$K$ expert selection strategy,
we formulate a latency minimization problem by optimizing expert caching on
edge servers under storage constraints. When $K=1$, the problem reduces to a
monotone submodular maximization problem with knapsack constraints, for which
we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee.
For the general case where $K\geq1$, expert co-activation within the same MoE
layer introduces non-submodularity, causing greedy methods to be ineffective.
To tackle this issue, we propose a successive greedy decomposition method to
decompose the original problem into a series of subproblems, with each being
solved by a dynamic programming approach. Furthermore, we design an accelerated
algorithm based on the max-convolution technique to obtain the approximate
solution with a provable guarantee in polynomial time. Simulation results on
various MoE models demonstrate that our method significantly reduces inference
latency compared to existing baselines.

</details>


### [73] [From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization](https://arxiv.org/abs/2507.06573)
*Xinjie Chen,Minpeng Liao,Guoxin Chen,Chengxi Li,Biao Fu,Kai Fan,Xinggao Liu*

Key words: 强化学习,语言模型,前缀引导,学习进度,数学推理

TL;DR: 该论文提出了LPPO框架，通过前缀引导采样和学习进度加权，优化了小规模高质量数据在强化学习中的作用，显著提升了模型在数学推理任务中的性能。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 旨在探索如何更高效地利用少量高质量示范数据，而非简单扩大数据规模，从而提升语言模型的推理能力。

Method: 提出前缀引导采样和学习进度加权两种方法，分别通过引入专家示范部分解前缀和动态调整样本权重来优化模型训练。

Result: 在数学推理基准测试中，LPPO框架表现优于基线方法，实现了更快的收敛速度和更高的性能上限。

Conclusion: LPPO框架通过样本中心化的渐进优化技术，显著提升了语言模型在复杂任务中的推理能力。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has recently advanced
the reasoning capabilities of large language models (LLMs). While prior work
has emphasized algorithmic design, data curation, and reward shaping, we
investigate RLVR from a sample-centric perspective and introduce LPPO
(Learning-Progress and Prefix-guided Optimization), a framework of progressive
optimization techniques. Our work addresses a critical question: how to best
leverage a small set of trusted, high-quality demonstrations, rather than
simply scaling up data volume. First, motivated by how hints aid human
problem-solving, we propose prefix-guided sampling, an online data augmentation
method that incorporates partial solution prefixes from expert demonstrations
to guide the policy, particularly for challenging instances. Second, inspired
by how humans focus on important questions aligned with their current
capabilities, we introduce learning-progress weighting, a dynamic strategy that
adjusts each training sample's influence based on model progression. We
estimate sample-level learning progress via an exponential moving average of
per-sample pass rates, promoting samples that foster learning and
de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks
demonstrate that our methods outperform strong baselines, yielding faster
convergence and a higher performance ceiling.

</details>


### [74] [Learning controllable dynamics through informative exploration](https://arxiv.org/abs/2507.06582)
*Peter N. Loxley,Friedrich T. Sommer*

Key words: 预测信息增益、强化学习、环境探索、可控动态

TL;DR: 本文探索利用预测信息增益作为信息度量，指导环境中最具信息量的区域探索，结合强化学习方法，优于短视探索策略。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 研究中发现显式模型并不总是可用，需通过探索学习环境动态，因此提出利用预测信息增益解决这一问题。

Method: 采用预测信息增益度量，结合强化学习方法，寻找最优子探索策略以估计可控动态。

Result: 该方法在实验中优于多种短视探索策略，能可靠估计环境动态。

Conclusion: 预测信息增益结合强化学习是一种有效的环境探索方法，优于传统短视策略。

Abstract: Environments with controllable dynamics are usually understood in terms of
explicit models. However, such models are not always available, but may
sometimes be learned by exploring an environment. In this work, we investigate
using an information measure called "predicted information gain" to determine
the most informative regions of an environment to explore next. Applying
methods from reinforcement learning allows good suboptimal exploring policies
to be found, and leads to reliable estimates of the underlying controllable
dynamics. This approach is demonstrated by comparing with several myopic
exploration approaches.

</details>


### [75] [Generalization in Reinforcement Learning for Radio Access Networks](https://arxiv.org/abs/2507.06602)
*Burak Demirel,Yu Wang,Cristian Tatino,Pablo Soldati*

Key words: RAN控制、强化学习、注意力图表示、领域随机化、分布式训练

TL;DR: 该论文提出了一种基于强化学习的RAN控制框架，通过注意力图表示、领域随机化和分布式数据生成，提高了5G网络中的性能和泛化能力。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统基于规则的RRM算法在动态异构环境中表现不佳，而现有的RL方法容易过拟合，难以适应多样化的部署和不可预测的无线电条件。

Method: 使用了注意力图表示编码拓扑和节点属性，应用领域随机化扩展训练分布，并通过分布式数据生成和集中训练实现高效架构。

Result: 在五个5G基准测试中，该策略的平均吞吐量和频谱效率提升了约10%-20%，在多小区部署中，GAT模型的吞吐量比MLP基线高30%。

Conclusion: 该框架为AI原生的6G RAN提供了一条可行路径，能够通过单一、泛化能力强的RL代理适应多样化场景。

Abstract: Modern RAN operate in highly dynamic and heterogeneous environments, where
hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass
such heuristics in constrained settings, the diversity of deployments and
unpredictable radio conditions introduce major generalization challenges.
Data-driven policies frequently overfit to training conditions, degrading
performance in unseen scenarios. To address this, we propose a
generalization-centered RL framework for RAN control that: (i) encodes cell
topology and node attributes via attention-based graph representations; (ii)
applies domain randomization to broaden the training distribution; and (iii)
distributes data generation across multiple actors while centralizing training
in a cloud-compatible architecture aligned with O-RAN principles. Although
generalization increases computational and data-management complexity, our
distributed design mitigates this by scaling data collection and training
across diverse network conditions. Applied to downlink link adaptation in five
5G benchmarks, our policy improves average throughput and spectral efficiency
by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and
by >20% under high mobility. It matches specialized RL in full-buffer traffic
and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks,
respectively. In nine-cell deployments, GAT models offer 30% higher throughput
over MLP baselines. These results, combined with our scalable architecture,
offer a path toward AI-native 6G RAN using a single, generalizable RL agent.

</details>


### [76] [Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation](https://arxiv.org/abs/2507.06613)
*Anshuk Uppal,Yuhta Takida,Chieh-Hsin Lai,Yuki Mitsufuji*

Key words: $eta$-VAE, 解耦性, 生成模型, 潜在表示, 非线性扩散模型

TL;DR: 论文提出了一种新的生成模型框架，通过结合不同$eta$值的潜在表示，实现了解耦性与生成质量的平衡。通过非线性扩散模型过渡不同$eta$值对应的表示，最终实现高质量的重建和生成。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决传统$eta$-VAE在解耦性和重建质量之间的权衡问题，提出一种能同时优化两者的新方法。

Method: 训练单VAE并结合新损失函数控制潜在表示的信息保留，随后引入非线性扩散模型过渡不同$eta$值的表示。

Result: 实现了高质量的重建和解耦性，同时支持独立生成样本，并在潜在空间中观察到平滑过渡。

Conclusion: 该方法成功平衡了解耦性与生成质量，为生成模型提供了新的研究方向。

Abstract: Disentangled and interpretable latent representations in generative models
typically come at the cost of generation quality. The $\beta$-VAE framework
introduces a hyperparameter $\beta$ to balance disentanglement and
reconstruction quality, where setting $\beta > 1$ introduces an information
bottleneck that favors disentanglement over sharp, accurate reconstructions. To
address this trade-off, we propose a novel generative modeling framework that
leverages a range of $\beta$ values to learn multiple corresponding latent
representations. First, we obtain a slew of representations by training a
single variational autoencoder (VAE), with a new loss function that controls
the information retained in each latent representation such that the higher
$\beta$ value prioritize disentanglement over reconstruction fidelity. We then,
introduce a non-linear diffusion model that smoothly transitions latent
representations corresponding to different $\beta$ values. This model denoises
towards less disentangled and more informative representations, ultimately
leading to (almost) lossless representations, enabling sharp reconstructions.
Furthermore, our model supports sample generation without input images,
functioning as a standalone generative model. We evaluate our framework in
terms of both disentanglement and generation quality. Additionally, we observe
smooth transitions in the latent spaces with respect to changes in $\beta$,
facilitating consistent manipulation of generated outputs.

</details>


### [77] [Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance](https://arxiv.org/abs/2507.06615)
*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Key words: 多任务强化学习, 跨任务策略指导, 门控机制, 参数共享

TL;DR: 本文提出了跨任务策略指导（CTPG）框架，通过利用已掌握任务的策略指导未掌握任务，提升多任务强化学习的效率。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有的多任务强化学习方法主要关注参数共享，但忽视了跨任务相似性的直接利用。CTPG通过已掌握任务的策略为未掌握任务提供显式指导。

Method: CTPG为每个任务训练一个指导策略，从所有任务的控制策略中选择与环境交互的行为策略，并提出两个门控机制优化学习效率。

Result: 实验表明，CTPG与现有参数共享方法结合后，在操作和运动基准测试中显著提升了性能。

Conclusion: CTPG为多任务强化学习提供了一种通用且有效的框架，能够通过跨任务策略指导加速技能获取。

Abstract: Multi-task reinforcement learning endeavors to efficiently leverage shared
information across various tasks, facilitating the simultaneous learning of
multiple tasks. Existing approaches primarily focus on parameter sharing with
carefully designed network structures or tailored optimization procedures.
However, they overlook a direct and complementary way to exploit cross-task
similarities: the control policies of tasks already proficient in some skills
can provide explicit guidance for unmastered tasks to accelerate skills
acquisition. To this end, we present a novel framework called Cross-Task Policy
Guidance (CTPG), which trains a guide policy for each task to select the
behavior policy interacting with the environment from all tasks' control
policies, generating better training trajectories. In addition, we propose two
gating mechanisms to improve the learning efficiency of CTPG: one gate filters
out control policies that are not beneficial for guidance, while the other gate
blocks tasks that do not necessitate guidance. CTPG is a general framework
adaptable to existing parameter sharing approaches. Empirical evaluations
demonstrate that incorporating CTPG with these approaches significantly
enhances performance in manipulation and locomotion benchmarks.

</details>


### [78] [Steps Adaptive Decay DPSGD: Enhancing Performance on Imbalanced Datasets with Differential Privacy with HAM10000](https://arxiv.org/abs/2507.06619)
*Xiaobo Huang,Fang Xie*

Key words: 医学图像分类、差分隐私、数据泄露、不平衡数据集、SAD-DPSGD

TL;DR: 论文提出了一种名为SAD-DPSGD的新方法，通过动态调整噪声和裁剪阈值，解决了在小规模不平衡医学数据集（如HAM10000）上使用差分隐私时数据泄露的问题，提升了模型性能。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 在医学图像分类中，数据泄露是一个关键问题。现有方法（如为差分隐私添加噪声）在大型数据集上表现良好，但在小型不平衡数据集上失效，因为少数类的梯度信息被裁剪丢失，导致模型陷入次优解。

Method: 提出了SAD-DPSGD方法，采用线性衰减机制动态调整噪声和裁剪阈值，初期分配更多隐私预算和更高裁剪阈值，避免模型陷入次优解。

Result: 实验表明，SAD-DPSGD在HAM10000数据集上优于Auto-DPSGD，在隐私预算$ϵ = 3.0$时准确率提升了2.15%。

Conclusion: SAD-DPSGD有效解决了不平衡医学数据集上的隐私保护问题，提升了模型性能。

Abstract: When applying machine learning to medical image classification, data leakage
is a critical issue. Previous methods, such as adding noise to gradients for
differential privacy, work well on large datasets like MNIST and CIFAR-100, but
fail on small, imbalanced medical datasets like HAM10000. This is because the
imbalanced distribution causes gradients from minority classes to be clipped
and lose crucial information, while majority classes dominate. This leads the
model to fall into suboptimal solutions early. To address this, we propose
SAD-DPSGD, which uses a linear decaying mechanism for noise and clipping
thresholds. By allocating more privacy budget and using higher clipping
thresholds in the initial training phases, the model avoids suboptimal
solutions and enhances performance. Experiments show that SAD-DPSGD outperforms
Auto-DPSGD on HAM10000, improving accuracy by 2.15% under $\epsilon = 3.0$ ,
$\delta = 10^{-3}$.

</details>


### [79] [UniOD: A Universal Model for Outlier Detection across Diverse Domains](https://arxiv.org/abs/2507.06624)
*Dazhi Fu,Jicong Fan*

Key words: 异常检测, 无监督学习, 跨领域泛化, 图表示学习

TL;DR: 本文提出了一种通用的异常检测框架UniOD，通过利用标记数据集训练单一模型，能够跨领域检测异常，避免了繁琐的超参数调整和模型训练，提高了实际应用的便利性和准确性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 异常检测在无标签数据集中至关重要，但现有方法通常需要复杂的超参数调整和高成本训练。本文旨在提出一种通用框架，解决这些问题。

Method: UniOD通过将数据集转换为多个图，生成一致的节点特征，并将异常检测任务转化为节点分类问题，从而实现了跨领域的泛化能力。

Result: 实验表明，UniOD在15个基准数据集上优于15种现有方法，证明了其有效性。

Conclusion: UniOD避免了模型选择和超参数调整的麻烦，降低了计算成本，并能有效利用历史数据集的知识，提升了异常检测的准确性和便利性。

Abstract: Outlier detection (OD) seeks to distinguish inliers and outliers in
completely unlabeled datasets and plays a vital role in science and
engineering. Most existing OD methods require troublesome dataset-specific
hyperparameter tuning and costly model training before they can be deployed to
identify outliers. In this work, we propose UniOD, a universal OD framework
that leverages labeled datasets to train a single model capable of detecting
outliers of datasets from diverse domains. Specifically, UniOD converts each
dataset into multiple graphs, produces consistent node features, and frames
outlier detection as a node-classification task, and is able to generalize to
unseen domains. As a result, UniOD avoids effort on model selection and
hyperparameter tuning, reduces computational cost, and effectively utilizes the
knowledge from historical datasets, which improves the convenience and accuracy
in real applications. We evaluate UniOD on 15 benchmark OD datasets against 15
state-of-the-art baselines, demonstrating its effectiveness.

</details>


### [80] [Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning](https://arxiv.org/abs/2507.06628)
*Jinmin He,Kai Li,Yifan Zang,Haobo Fu,Qiang Fu,Junliang Xing,Jian Cheng*

Key words: 离线强化学习,多任务学习,技能抽象,机器人操作

TL;DR: GO-Skill是一种新颖的离线多任务强化学习方法，通过目标导向的技能抽象和分层策略学习，有效提升了知识共享和任务性能。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 离线多任务强化学习面临跨任务知识共享的挑战，受人类学习中高效知识抽象的启发，提出GO-Skill以提升知识迁移和任务表现。

Method: 1.通过目标导向技能提取过程挖掘可重用技能；2.利用向量量化构建离散技能库；3.引入技能增强阶段平衡技能类别；4.通过分层策略学习动态编排技能。

Result: 在MetaWorld基准测试的多样机器人操作任务中，GO-Skill表现出高效性和多功能性。

Conclusion: GO-Skill通过技能抽象和分层策略学习，显著提升了离线多任务强化学习的性能。

Abstract: Offline multi-task reinforcement learning aims to learn a unified policy
capable of solving multiple tasks using only pre-collected task-mixed datasets,
without requiring any online interaction with the environment. However, it
faces significant challenges in effectively sharing knowledge across tasks.
Inspired by the efficient knowledge abstraction observed in human learning, we
propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed
to extract and utilize reusable skills to enhance knowledge transfer and task
performance. Our approach uncovers reusable skills through a goal-oriented
skill extraction process and leverages vector quantization to construct a
discrete skill library. To mitigate class imbalances between broadly applicable
and task-specific skills, we introduce a skill enhancement phase to refine the
extracted skills. Furthermore, we integrate these skills using hierarchical
policy learning, enabling the construction of a high-level policy that
dynamically orchestrates discrete skills to accomplish specific tasks.
Extensive experiments on diverse robotic manipulation tasks within the
MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.

</details>


### [81] [Prevention of Overfitting on Mesh-Structured Data Regressions with a Modified Laplace Operator](https://arxiv.org/abs/2507.06631)
*Enda D. V. Bigarella*

Key words: 过拟合, 网格数据, 拉普拉斯算子, 超参数优化

TL;DR: 提出了一种检测和防止数据回归过拟合的方法，适用于网格数据结构的应用。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 通过拉普拉斯算子二阶导数的计算来减少训练模型中的不必要振荡，避免过拟合。

Method: 在训练网格上计算原始数据的导数作为真实标签，在交错网格上计算训练数据的导数以识别振荡，利用拉普拉斯算子导数损失进行超参数优化。

Result: 通过最小化训练模型的熵，实现了对不必要振荡的减少。

Conclusion: 该方法无需拆分训练数据点，可直接在所有可用数据上进行训练和测试。

Abstract: This document reports on a method for detecting and preventing overfitting on
data regressions, herein applied to mesh-like data structures. The mesh
structure allows for the straightforward computation of the Laplace-operator
second-order derivatives in a finite-difference fashion for noiseless data.
Derivatives of the training data are computed on the original training mesh to
serve as a true label of the entropy of the training data. Derivatives of the
trained data are computed on a staggered mesh to identify oscillations in the
interior of the original training mesh cells. The loss of the Laplace-operator
derivatives is used for hyperparameter optimisation, achieving a reduction of
unwanted oscillation through the minimisation of the entropy of the trained
model. In this setup, testing does not require the splitting of points from the
training data, and training is thus directly performed on all available
training points. The Laplace operator applied to the trained data on a
staggered mesh serves as a surrogate testing metric based on diffusion
properties.

</details>


### [82] [Deep Disentangled Representation Network for Treatment Effect Estimation](https://arxiv.org/abs/2507.06650)
*Hui Meng,Keping Yang,Xuyu Peng,Bo Zheng*

Key words: 因果推理、治疗效果估计、多头注意力、正交正则化、去偏技术

TL;DR: 本文提出了一种新颖的算法，用于从观测数据中估计个体层面的治疗效果，通过多头注意力和线性正交正则化软分解协变量，并结合重要性采样去偏技术，显著优于现有方法。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 个体层面的治疗效果估计是因果推理中的核心问题，尤其在教育、医疗和公共政策领域具有重要意义。现有方法通常通过生成模型或硬分解协变量来实现，但难以确保精确分离的协变量因子。

Method: 提出了一种结合多头注意力混合专家模型和线性正交正则化的新算法，软分解预处理变量，同时利用重要性采样重加权技术消除选择偏差。

Result: 在公共半合成和真实世界数据集上的实验表明，该算法在个体治疗效果估计方面优于现有最先进方法。

Conclusion: 该方法通过软分解协变量和去偏技术的结合，显著提升了治疗效果估计的准确性。

Abstract: Estimating individual-level treatment effect from observational data is a
fundamental problem in causal inference and has attracted increasing attention
in the fields of education, healthcare, and public policy.In this work, we
concentrate on the study of disentangled representation methods that have shown
promising outcomes by decomposing observed covariates into instrumental,
confounding, and adjustment factors. However, most of the previous work has
primarily revolved around generative models or hard decomposition methods for
covariates, which often struggle to guarantee the attainment of precisely
disentangled factors. In order to effectively model different causal
relationships, we propose a novel treatment effect estimation algorithm that
incorporates a mixture of experts with multi-head attention and a linear
orthogonal regularizer to softly decompose the pre-treatment variables, and
simultaneously eliminates selection bias via importance sampling re-weighting
techniques. We conduct extensive experiments on both public semi-synthetic and
real-world production datasets. The experimental results clearly demonstrate
that our algorithm outperforms the state-of-the-art methods focused on
individual treatment effects.

</details>


### [83] [Federated Learning Inspired Fuzzy Systems: Decentralized Rule Updating for Privacy and Scalable Decision Making](https://arxiv.org/abs/2507.06652)
*Arthur Alexander Lim,Zhen Bin It,Jovan Bowen Heng,Tee Hui Teo*

Key words: 模糊系统, 机器学习, 联邦学习, 不确定性, 优化

TL;DR: 本文探讨了如何利用机器学习和联邦学习改进模糊系统，以处理不确定性，并分析其潜在改进与限制。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 为了提高模糊系统在处理不确定性方面的能力，作者提出从机器学习和联邦学习中汲取灵感，以改进模糊系统的性能。

Method: 提出将机器学习和联邦学习的理念（如更新模糊规则）应用于模糊系统，逐步优化其表现。

Result: 研究发现这些改进有潜力提升模糊系统，但需要进一步研究以验证其实际效果。

Conclusion: 尽管改进的潜力存在，但需进一步研究确定其具体效果，模糊系统仍有优化空间。

Abstract: Fuzzy systems are a way to allow machines, systems and frameworks to deal
with uncertainty, which is not possible in binary systems that most computers
use. These systems have already been deployed for certain use cases, and fuzzy
systems could be further improved as proposed in this paper. Such technologies
to draw inspiration from include machine learning and federated learning.
Machine learning is one of the recent breakthroughs of technology and could be
applied to fuzzy systems to further improve the results it produces. Federated
learning is also one of the recent technologies that have huge potential, which
allows machine learning training to improve by reducing privacy risk, reducing
burden on networking infrastructure, and reducing latency of the latest model.
Aspects from federated learning could be used to improve federated learning,
such as applying the idea of updating the fuzzy rules that make up a key part
of fuzzy systems, to further improve it over time. This paper discusses how
these improvements would be implemented in fuzzy systems, and how it would
improve fuzzy systems. It also discusses certain limitations on the potential
improvements. It concludes that these proposed ideas and improvements require
further investigation to see how far the improvements are, but the potential is
there to improve fuzzy systems.

</details>


### [84] [Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study](https://arxiv.org/abs/2507.06694)
*Raffael Theiler,Olga Fink*

Key words: 电力系统, 状态预测, 图神经网络, 异构数据, 多物理域

TL;DR: 该论文提出了一种基于异构图注意力网络的电力系统短期状态预测方法，解决了多物理域传感器数据的异构性问题。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 随着可再生能源和分布式能源的引入，电力系统的变异性增加，准确的短期状态预测对系统稳定性和控制决策至关重要。

Method: 采用异构图注意力网络（Heterogeneous Graph Attention Networks），对液压和电气两个物理域的传感器数据进行建模，捕捉同质和异质关系。

Result: 实验结果表明，该方法在归一化均方根误差上平均优于传统基线35.5%。

Conclusion: 异构图注意力网络能有效处理多物理域、多速率电力系统的状态预测问题。

Abstract: Accurate short-term state forecasting is essential for efficient and stable
operation of modern power systems, especially in the context of increasing
variability introduced by renewable and distributed energy resources. As these
systems evolve rapidly, it becomes increasingly important to reliably predict
their states in the short term to ensure operational stability, support control
decisions, and enable interpretable monitoring of sensor and machine behavior.
Modern power systems often span multiple physical domains - including
electrical, mechanical, hydraulic, and thermal - posing significant challenges
for modeling and prediction. Graph Neural Networks (GNNs) have emerged as a
promising data-driven framework for system state estimation and state
forecasting in such settings. By leveraging the topological structure of sensor
networks, GNNs can implicitly learn inter-sensor relationships and propagate
information across the network. However, most existing GNN-based methods are
designed under the assumption of homogeneous sensor relationships and are
typically constrained to a single physical domain. This limitation restricts
their ability to integrate and reason over heterogeneous sensor data commonly
encountered in real-world energy systems, such as those used in energy
conversion infrastructure. In this work, we propose the use of Heterogeneous
Graph Attention Networks to address these limitations. Our approach models both
homogeneous intra-domain and heterogeneous inter-domain relationships among
sensor data from two distinct physical domains - hydraulic and electrical -
which exhibit fundamentally different temporal dynamics. Experimental results
demonstrate that our method significantly outperforms conventional baselines on
average by 35.5% in terms of normalized root mean square error, confirming its
effectiveness in multi-domain, multi-rate power system state forecasting.

</details>


### [85] [Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement](https://arxiv.org/abs/2507.06701)
*Michael Bloesch,Markus Wulfmeier,Philemon Brakel,Todor Davchev,Martina Zambelli,Jost Tobias Springenberg,Abbas Abdolmaleki,William F Whitney,Nicolas Heess,Roland Hafner,Martin Riedmiller*

Key words: 模仿学习, 观察学习, 强化学习, 数据分布, 自改进

TL;DR: 该论文研究了从观察中模仿学习（IfO）的局限性，并提出了一种新方法，通过自改进迭代学习，增强了IfO的实用性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有IfO研究多集中在理想化场景中，数据分布较为单一，限制了结果的实用性。论文旨在探索更复杂的数据分布，并提出改进方法。

Method: 论文采用基于强化学习的模仿学习方法，利用价值函数在专家和非专家数据间传递信息。

Result: 通过全面评估，论文揭示了不同数据分布与算法适用性之间的关系，并指出了现有方法的局限性。

Conclusion: 研究结果为开发更鲁棒、实用的IfO技术提供了有价值的见解，推动了可扩展行为学习的发展。

Abstract: Imitation Learning from Observation (IfO) offers a powerful way to learn
behaviors at large-scale: Unlike behavior cloning or offline reinforcement
learning, IfO can leverage action-free demonstrations and thus circumvents the
need for costly action-labeled demonstrations or reward functions. However,
current IfO research focuses on idealized scenarios with mostly bimodal-quality
data distributions, restricting the meaningfulness of the results. In contrast,
this paper investigates more nuanced distributions and introduces a method to
learn from such data, moving closer to a paradigm in which imitation learning
can be performed iteratively via self-improvement. Our method adapts RL-based
imitation learning to action-free demonstrations, using a value function to
transfer information between expert and non-expert data. Through comprehensive
evaluation, we delineate the relation between different data distributions and
the applicability of algorithms and highlight the limitations of established
methods. Our findings provide valuable insights for developing more robust and
practical IfO techniques on a path to scalable behaviour learning.

</details>


### [86] [PINN-Obs: Physics-Informed Neural Network-Based Observer for Nonlinear Dynamical Systems](https://arxiv.org/abs/2507.06712)
*Ayoub Farkane,Mohamed Boutayeb,Mustapha Oudani,Mounir Ghogho*

Key words: 状态估计,非线性系统,物理信息神经网络,自适应观测器

TL;DR: 提出了一种基于自适应物理信息神经网络的观测器（PINN-Obs），用于非线性系统的精确状态估计，优于传统方法。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 非线性系统的状态估计在部分和噪声测量下具有挑战性，需要更准确和鲁棒的解决方案。

Method: 直接集成系统动力学和传感器数据到物理信息学习过程中，自适应学习最优增益矩阵。

Result: 理论分析证明均匀误差最小化，实验验证了其在多种非线性系统中的优越性能。

Conclusion: PINN-Obs在准确性和适应性上优于现有方法，适用于复杂非线性系统。

Abstract: State estimation for nonlinear dynamical systems is a critical challenge in
control and engineering applications, particularly when only partial and noisy
measurements are available. This paper introduces a novel Adaptive
Physics-Informed Neural Network-based Observer (PINN-Obs) for accurate state
estimation in nonlinear systems. Unlike traditional model-based observers,
which require explicit system transformations or linearization, the proposed
framework directly integrates system dynamics and sensor data into a
physics-informed learning process. The observer adaptively learns an optimal
gain matrix, ensuring convergence of the estimated states to the true system
states. A rigorous theoretical analysis establishes formal convergence
guarantees, demonstrating that the proposed approach achieves uniform error
minimization under mild observability conditions. The effectiveness of PINN-Obs
is validated through extensive numerical simulations on diverse nonlinear
systems, including an induction motor model, a satellite motion system, and
benchmark academic examples. Comparative experimental studies against existing
observer designs highlight its superior accuracy, robustness, and adaptability.

</details>


### [87] [Mathematical artificial data for operator learning](https://arxiv.org/abs/2507.06752)
*Heng Wu,Benzhuo Lu*

Key words: 机器学习, 微分方程, 物理嵌入, 数据驱动, 算子学习, 科学计算

TL;DR: 提出MAD框架，结合物理定律与数据驱动学习，通过生成物理嵌入的解析解和合成数据，解决了传统方法的局限，实现了高效且准确的算子学习。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统方法在解决微分方程时面临数据依赖性和效率-准确率权衡的问题，亟需一种新的方法以结合物理定律与机器学习的优势。

Method: MAD框架利用微分方程的数学结构生成物理嵌入的解析解和合成数据，消除对实验或模拟数据的依赖，实现大规模算子发现。

Result: MAD框架在2D参数问题中展示了其普适性和高效性/准确性，能够处理复杂的参数空间。

Conclusion: MAD框架为科学计算中的物理信息机器学习提供了一个潜在通用范式。

Abstract: Machine learning has emerged as a transformative tool for solving
differential equations (DEs), yet prevailing methodologies remain constrained
by dual limitations: data-driven methods demand costly labeled datasets while
model-driven techniques face efficiency-accuracy trade-offs. We present the
Mathematical Artificial Data (MAD) framework, a new paradigm that integrates
physical laws with data-driven learning to facilitate large-scale operator
discovery. By exploiting DEs' intrinsic mathematical structure to generate
physics-embedded analytical solutions and associated synthetic data, MAD
fundamentally eliminates dependence on experimental or simulated training data.
This enables computationally efficient operator learning across multi-parameter
systems while maintaining mathematical rigor. Through numerical demonstrations
spanning 2D parametric problems where both the boundary values and source term
are functions, we showcase MAD's generalizability and superior
efficiency/accuracy across various DE scenarios. This
physics-embedded-data-driven framework and its capacity to handle complex
parameter spaces gives it the potential to become a universal paradigm for
physics-informed machine intelligence in scientific computing.

</details>


### [88] [Robust Deep Network Learning of Nonlinear Regression Tasks by Parametric Leaky Exponential Linear Units (LELUs) and a Diffusion Metric](https://arxiv.org/abs/2507.06765)
*Enda D. V. Bigarella*

Key words: 激活函数, 非线性回归, 过拟合, 平滑性, 梯度特性

TL;DR: 本文提出了一种参数化激活函数（Leaky Exponential Linear Unit），通过改进平滑性和梯度特性，提升了多维非线性数据回归的性能，并提出了一种新的扩散损失度量来衡量模型过拟合。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 非线性激活函数在非线性数据集学习中必不可少，但现有平滑但梯度消失的激活函数（如ELU或SiLU）以及非平滑激活函数（如RELU和Leaky-RELU）在性能或连续性上存在不足，影响了神经网络的性能。

Method: 提出了一种平滑且梯度非零的参数化激活函数（Leaky Exponential Linear Unit），并设计了一种新的扩散损失度量来评估模型的过拟合情况。

Result: 实验表明，改进的激活函数在性能上优于现有方案，并且扩散损失度量能有效评估模型的过拟合程度。

Conclusion: 平滑且梯度非零的激活函数能够显著提升神经网络在非线性数据回归中的性能，新的扩散损失度量则为模型评估提供了新工具。

Abstract: This document proposes a parametric activation function (ac.f.) aimed at
improving multidimensional nonlinear data regression. It is a established
knowledge that nonlinear ac.f.'s are required for learning nonlinear datasets.
This work shows that smoothness and gradient properties of the ac.f. further
impact the performance of large neural networks in terms of overfitting and
sensitivity to model parameters. Smooth but vanishing-gradient ac.f.'s such as
ELU or SiLU have limited performance and non-smooth ac.f.'s such as RELU and
Leaky-RELU further impart discontinuity in the trained model. Improved
performance is demonstrated with a smooth "Leaky Exponential Linear Unit", with
non-zero gradient that can be trained. A novel diffusion-loss metric is also
proposed to gauge the performance of the trained models in terms of
overfitting.

</details>


### [89] [Mutual Information Free Topological Generalization Bounds via Stability](https://arxiv.org/abs/2507.06775)
*Mario Tuci,Lennart Bastian,Benjamin Dupuis,Nassir Navab,Tolga Birdal,Umut Şimşekli*

Key words: 泛化误差, 拓扑数据分析, 轨迹稳定性, 随机优化

TL;DR: 研究提出了基于拓扑数据分析和轨迹稳定性的新型泛化误差上界，避免传统方法中复杂的信息论项，并通过实验验证其有效性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决随机优化算法泛化性能的理论问题，特别是摆脱现有泛化误差上界对不实用的信息论项的依赖。

Method: 引入轨迹稳定性的新概念，结合拓扑数据分析技术，提出新的泛化误差上界框架。

Result: 实验表明，拓扑复杂性在样本增多时对泛化误差至关重要，验证了所提方法的实用性。

Conclusion: 所提出的方法不仅理论可解释性强，且在实际算法中的应用更为可行。

Abstract: Providing generalization guarantees for stochastic optimization algorithms is
a major challenge in modern learning theory. Recently, several studies
highlighted the impact of the geometry of training trajectories on the
generalization error, both theoretically and empirically. Among these works, a
series of topological generalization bounds have been proposed, relating the
generalization error to notions of topological complexity that stem from
topological data analysis (TDA). Despite their empirical success, these bounds
rely on intricate information-theoretic (IT) terms that can be bounded in
specific cases but remain intractable for practical algorithms (such as ADAM),
potentially reducing the relevance of the derived bounds. In this paper, we
seek to formulate comprehensive and interpretable topological generalization
bounds free of intractable mutual information terms. To this end, we introduce
a novel learning theoretic framework that departs from the existing strategies
via proof techniques rooted in algorithmic stability. By extending an existing
notion of \textit{hypothesis set stability}, to \textit{trajectory stability},
we prove that the generalization error of trajectory-stable algorithms can be
upper bounded in terms of (i) TDA quantities describing the complexity of the
trajectory of the optimizer in the parameter space, and (ii) the trajectory
stability parameter of the algorithm. Through a series of experimental
evaluations, we demonstrate that the TDA terms in the bound are of great
importance, especially as the number of training samples grows. This ultimately
forms an explanation of the empirical success of the topological generalization
bounds.

</details>


### [90] [Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm](https://arxiv.org/abs/2507.06780)
*George Papadopoulos,George A. Vouros*

Key words: 模仿学习, 最大熵策略, KL散度, 双重梯度下降, 约束强化学习

TL;DR: 提出了一种模仿学习方法，用于学习符合专家轨迹约束的最大熵策略，通过KL散度连接性能，并利用双重梯度下降优化目标。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 研究如何通过模仿学习在强化学习中实现符合约束的最大熵策略。

Method: 结合KL散度性能边界和概率推断框架，使用双重梯度下降优化目标。

Result: 实验表明，该方法能学习符合多种约束的有效策略，并具备泛化能力。

Conclusion: 该方法能有效学习约束行为策略，适用于多约束和多模态任务。

Abstract: This article introduces an imitation learning method for learning maximum
entropy policies that comply with constraints demonstrated by expert
trajectories executing a task. The formulation of the method takes advantage of
results connecting performance to bounds for the KL-divergence between
demonstrated and learned policies, and its objective is rigorously justified
through a connection to a probabilistic inference framework for reinforcement
learning, incorporating the reinforcement learning objective and the objective
to abide by constraints in an entropy maximization setting. The proposed
algorithm optimizes the learning objective with dual gradient descent,
supporting effective and stable training. Experiments show that the proposed
method can learn effective policy models for constraints-abiding behaviour, in
settings with multiple constraints of different types, accommodating different
modalities of demonstrated behaviour, and with abilities to generalize.

</details>


### [91] [Speech Tokenizer is Key to Consistent Representation](https://arxiv.org/abs/2507.06802)
*Wonjin Jung,Sungil Kang,Dong-Yeon Cho*

Key words: 语音分词器、声学特征、语言信息、多任务应用、AI语音处理

TL;DR: 本文提出了一种新颖的语音分词器，能够同时编码语言和声学信息，显著提升语音表示的保真度，并在多种任务中表现出色。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决现有语音分词器忽略关键声学特征的问题，提升语音处理的多样性和实用性。

Method: 采用先进方法同时编码语言和声学信息，保留韵律和情感内容。

Result: 在语音编码、声转换、情感识别和多模态语言建模等任务中表现出色。

Conclusion: 该方法具有广泛适用性，可推动AI驱动的语音处理发展。

Abstract: Speech tokenization is crucial in digital speech processing, converting
continuous speech signals into discrete units for various computational tasks.
This paper introduces a novel speech tokenizer with broad applicability across
downstream tasks. While recent advances in residual vector quantization (RVQ)
have incorporated semantic elements, they often neglect critical acoustic
features. We propose an advanced approach that simultaneously encodes both
linguistic and acoustic information, preserving prosodic and emotional content.
Our method significantly enhances speech representation fidelity across diverse
applications. Empirical evaluations demonstrate its effectiveness in speech
coding, voice conversion, emotion recognition, and multimodal language
modeling, without requiring additional training. This versatility underscores
its potential as a key tool for advancing AI-driven speech processing.

</details>


### [92] [Intrinsic Training Signals for Federated Learning Aggregation](https://arxiv.org/abs/2507.06813)
*Cosimo Fiorini,Matteo Mosconi,Pietro Buzzega,Riccardo Salami,Simone Calderara*

Key words: 联邦学习,模型聚合,LIVAR,SHAP分析

TL;DR: 提出了一种名为LIVAR的新方法，通过利用现有训练信号实现高效联邦模型聚合，无需修改架构或损失函数。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有联邦学习方法在聚合客户端特定分类头和调整主干参数时需要修改架构或损失函数，LIVAR旨在通过利用现有训练信号解决这一问题。

Method: LIVAR结合了方差加权分类器聚合方案和基于SHAP分析的LoRA合并技术，无需额外架构开销。

Result: 在多个基准测试中实现了最佳性能，并保持与现有联邦学习方法的无缝集成。

Conclusion: LIVAR证明有效的模型聚合可以通过现有训练信号实现，为联邦学习提供了新范式。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients while preserving data privacy. While existing approaches
for aggregating client-specific classification heads and adapted backbone
parameters require architectural modifications or loss function changes, our
method uniquely leverages intrinsic training signals already available during
standard optimization. We present LIVAR (Layer Importance and VARiance-based
merging), which introduces: i) a variance-weighted classifier aggregation
scheme using naturally emergent feature statistics, and ii) an
explainability-driven LoRA merging technique based on SHAP analysis of existing
update parameter patterns. Without any architectural overhead, LIVAR achieves
state-of-the-art performance on multiple benchmarks while maintaining seamless
integration with existing FL methods. This work demonstrates that effective
model merging can be achieved solely through existing training signals,
establishing a new paradigm for efficient federated model aggregation. The code
will be made publicly available upon acceptance.

</details>


### [93] [Comprehensive Evaluation of Prototype Neural Networks](https://arxiv.org/abs/2507.06819)
*Philipp Schlinge,Steffen Meinert,Martin Atzmueller*

Key words: 原型模型, 可解释人工智能, 指标评估, 开源工具

TL;DR: 本文对原型模型（如ProtoPNet、ProtoPool、PIPNet）进行了深入分析，提出并应用了多种新指标来评估其可解释性，并在多样数据集上进行了实验。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 原型模型是可解释人工智能（XAI）的重要方法，但目前对其评估指标的全面性不足，需要进一步补充。

Method: 采用综合指标体系评估原型模型，包括标准指标和新提出的指标，并在不同数据集上进行测试。

Result: 通过实验验证了新指标的有效性，并提供了开源工具以支持模型的评估和扩展。

Conclusion: 研究为原型模型的可解释性评估提供了更全面的方法，并推动了相关工具的发展。

Abstract: Prototype models are an important method for explainable artificial
intelligence (XAI) and interpretable machine learning. In this paper, we
perform an in-depth analysis of a set of prominent prototype models including
ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive
set of metrics. In addition to applying standard metrics from literature, we
propose several new metrics to further complement the analysis of model
interpretability. In our experimentation, we apply the set of prototype models
on a diverse set of datasets including fine-grained classification, Non-IID
settings and multi-label classification to further contrast the performance.
Furthermore, we also provide our code as an open-source library, which
facilitates simple application of the metrics itself, as well as extensibility
- providing the option for easily adding new metrics and models.
https://github.com/uos-sis/quanproto

</details>


### [94] [HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning](https://arxiv.org/abs/2507.06821)
*Chuhang Zheng,Chunwei Tian,Jie Wen,Daoqiang Zhang,Qi Zhu*

Key words: 多模态情绪识别，情绪分布学习，异质性挖掘，标签相关性，优化传输

TL;DR: 提出了一种名为HeLo的多模态情绪分布学习框架，旨在探索多模态数据中的异质性和互补信息，并通过优化传输和可学习标签嵌入提升情绪分布学习的准确性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 多模态情绪识别在人机交互中作用重要，但现有方法在多模态异质性挖掘和情绪标签关联性利用上存在不足。

Method: 采用跨注意力机制融合生理数据，设计基于优化传输的异质性挖掘模块，并通过可学习标签嵌入优化标签相关性。

Result: 在两个公开数据集上的实验结果表明，该方法在情绪分布学习中具有优越性。

Conclusion: HeLo框架成功提升了多模态情绪分布学习的性能，弥补了现有方法的不足。

Abstract: Multi-modal emotion recognition has garnered increasing attention as it plays
a significant role in human-computer interaction (HCI) in recent years. Since
different discrete emotions may exist at the same time, compared with
single-class emotion recognition, emotion distribution learning (EDL) that
identifies a mixture of basic emotions has gradually emerged as a trend.
However, existing EDL methods face challenges in mining the heterogeneity among
multiple modalities. Besides, rich semantic correlations across arbitrary basic
emotions are not fully exploited. In this paper, we propose a multi-modal
emotion distribution learning framework, named HeLo, aimed at fully exploring
the heterogeneity and complementary information in multi-modal emotional data
and label correlation within mixed basic emotions. Specifically, we first adopt
cross-attention to effectively fuse the physiological data. Then, an optimal
transport (OT)-based heterogeneity mining module is devised to mine the
interaction and heterogeneity between the physiological and behavioral
representations. To facilitate label correlation learning, we introduce a
learnable label embedding optimized by correlation matrix alignment. Finally,
the learnable label embeddings and label correlation matrices are integrated
with the multi-modal representations through a novel label correlation-driven
cross-attention mechanism for accurate emotion distribution learning.
Experimental results on two publicly available datasets demonstrate the
superiority of our proposed method in emotion distribution learning.

</details>


### [95] [Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning](https://arxiv.org/abs/2507.06825)
*Matej Straka,Martin Schmid*

Key words: 实时战略游戏, 多智能体强化学习, Generals.io, 自对战, 奖励塑造

TL;DR: 文章介绍了一个基于Generals.io的实时战略游戏环境，兼容Gymnasium和PettingZoo，并能高效运行。通过监督预训练和自对战训练的智能体表现优异，且学习过程中采用了奖励塑造等技术。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 为多智能体强化学习研究提供一个可访问且具有挑战性的平台。

Method: 开发了一个模块化的实时战略游戏环境，并结合监督预训练、自对战、潜在奖励塑造和记忆特征训练智能体。

Result: 训练36小时后，智能体在1v1人类排行榜上达到前0.003%的水平。

Conclusion: 该环境和基线智能体为多智能体强化学习研究提供了有效工具。

Abstract: We introduce a real-time strategy game environment built on Generals.io, a
game that hosts thousands of active players each week across multiple game
formats. Our environment is fully compatible with Gymnasium and PettingZoo,
capable of running thousands of frames per second on commodity hardware. Our
reference agent -- trained with supervised pre-training and self-play -- hits
the top 0.003\% of the 1v1 human leaderboard after just 36 hours on a single
H100 GPU. To accelerate learning, we incorporate potential-based reward shaping
and memory features. Our contributions -- a modular RTS benchmark and a
competitive, state-of-the-art baseline agent -- provide an accessible yet
challenging platform for advancing multi-agent reinforcement learning research.

</details>


### [96] [Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model](https://arxiv.org/abs/2507.06892)
*Jing Liang,Hongyao Tang,Yi Ma,Jinyi Liu,Yan Zheng,Shuyue Hu,Lei Bai,Jianye Hao*

Key words: 强化学习, 大型语言模型, 离策略学习, 数学推理, 训练效率

TL;DR: ReMix通过混合策略和策略再生技术，高效利用离策略数据，显著降低强化学习微调的计算和训练成本，并在数学推理任务上达到先进水平。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有强化学习微调方法（如PPO、GRPO）需高成本实时生成数据，限制了扩展的经济性和效率，ReMix旨在通过离策略数据利用解决这一问题。

Method: ReMix结合混合策略近端策略梯度（高UTD比）、KL凸约束（稳定性与灵活性的平衡）和策略再生技术（平滑过渡学习阶段）。

Result: 1.5B和7B模型在多项数学推理基准测试中表现优异，训练成本降低30x至450x，准确率最高达64.39%。

Conclusion: ReMix为高效RL微调提供了新思路，同时揭示了离策略偏好和自反思行为崩溃等深层现象。

Abstract: Reinforcement Learning (RL) has demonstrated its potential to improve the
reasoning ability of Large Language Models (LLMs). One major limitation of most
existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL
in nature, i.e., data generated during the past learning process is not fully
utilized. This inevitably comes at a significant cost of compute and time,
posing a stringent bottleneck on continuing economic and efficient scaling. To
this end, we launch the renaissance of off-policy RL and propose Reincarnating
Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable
on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix
consists of three major components: (1) Mix-policy proximal policy gradient
with an increased Update-To-Data (UTD) ratio for efficient training; (2)
KL-Convex policy constraint to balance the trade-off between stability and
flexibility; (3) Policy reincarnation to achieve a seamless transition from
efficient early-stage learning to steady asymptotic improvement. In our
experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base
models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with
0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B
model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math
reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and
MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level
performance with an over 30x to 450x reduction in training cost in terms of
rollout data volume. In addition, we reveal insightful findings via
multifaceted analysis, including the implicit preference for shorter responses
due to the Whipping Effect of off-policy discrepancy, the collapse mode of
self-reflection behavior under the presence of severe off-policyness, etc.

</details>


### [97] [Scalable Gaussian Processes: Advances in Iterative Methods and Pathwise Conditioning](https://arxiv.org/abs/2507.06839)
*Jihao Andreas Lin*

Key words: 高斯过程, 迭代方法, 路径条件化, 大规模计算, 矩阵乘法

TL;DR: 该论文提出了一种结合迭代方法和路径条件化的方法，显著提高了高斯过程在大规模数据下的可扩展性和计算效率。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 高斯过程在不确定性感知函数逼近和序列决策中表现强大，但其经典方法在大数据与现代硬件并行计算环境下扩展性较差，需要改进。

Method: 结合迭代线性系统求解器和路径条件化，将昂贵计算转化为线性方程组的求解，利用矩阵乘法作为主要计算操作。

Result: 大幅降低了内存需求，使其能处理更大规模数据，同时优化了现代硬件的使用效率。

Conclusion: 通过迭代方法和路径条件化的结合，高斯过程在大规模计算中表现更高效和可扩展。

Abstract: Gaussian processes are a powerful framework for uncertainty-aware function
approximation and sequential decision-making. Unfortunately, their classical
formulation does not scale gracefully to large amounts of data and modern
hardware for massively-parallel computation, prompting many researchers to
develop techniques which improve their scalability. This dissertation focuses
on the powerful combination of iterative methods and pathwise conditioning to
develop methodological contributions which facilitate the use of Gaussian
processes in modern large-scale settings. By combining these two techniques
synergistically, expensive computations are expressed as solutions to systems
of linear equations and obtained by leveraging iterative linear system solvers.
This drastically reduces memory requirements, facilitating application to
significantly larger amounts of data, and introduces matrix multiplication as
the main computational operation, which is ideal for modern hardware.

</details>


### [98] [DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models](https://arxiv.org/abs/2507.06853)
*Liang Wang,Yu Rong,Tingyang Xu,Zhenyi Zhong,Zhiyuan Liu,Pengju Wang,Deli Zhao,Qiang Liu,Shu Wu,Liang Wang*

Key words: 分子结构解析,扩散模型,多模态光谱,生成模型,SE(3)-等变

TL;DR: DiffSpectra是一种生成框架，利用扩散模型直接从多模态光谱数据推断分子结构，解决了传统方法和现有机器学习方法的局限性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统分子结构解析方法依赖专家解读且难以扩展，现有机器学习方法受限于有限分子库，无法推广到新分子。DiffSpectra旨在通过生成模型解决这一问题。

Method: DiffSpectra采用扩散模型作为生成框架，其中去噪网络由SE(3)-等变的Diffusion Molecule Transformer参数化，光谱条件由基于Transformer的SpecFormer编码器提供。

Result: 实验表明，DiffSpectra在结构解析中表现出高准确性，采样后精确结构的top-1准确率为16.01%，top-20准确率为96.86%。3D几何建模和SpecFormer预训练显著提升了性能。

Conclusion: DiffSpectra首次统一了多模态光谱推理和2D/3D联合生成建模，验证了光谱条件扩散模型在分子结构解析中的有效性。

Abstract: Molecular structure elucidation from spectra is a foundational problem in
chemistry, with profound implications for compound identification, synthesis,
and drug development. Traditional methods rely heavily on expert interpretation
and lack scalability. Pioneering machine learning methods have introduced
retrieval-based strategies, but their reliance on finite libraries limits
generalization to novel molecules. Generative models offer a promising
alternative, yet most adopt autoregressive SMILES-based architectures that
overlook 3D geometry and struggle to integrate diverse spectral modalities. In
this work, we present DiffSpectra, a generative framework that directly infers
both 2D and 3D molecular structures from multi-modal spectral data using
diffusion models. DiffSpectra formulates structure elucidation as a conditional
generation process. Its denoising network is parameterized by Diffusion
Molecule Transformer, an SE(3)-equivariant architecture that integrates
topological and geometric information. Conditioning is provided by SpecFormer,
a transformer-based spectral encoder that captures intra- and inter-spectral
dependencies from multi-modal spectra. Extensive experiments demonstrate that
DiffSpectra achieves high accuracy in structure elucidation, recovering exact
structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through
sampling. The model benefits significantly from 3D geometric modeling,
SpecFormer pre-training, and multi-modal conditioning. These results highlight
the effectiveness of spectrum-conditioned diffusion modeling in addressing the
challenge of molecular structure elucidation. To our knowledge, DiffSpectra is
the first framework to unify multi-modal spectral reasoning and joint 2D/3D
generative modeling for de novo molecular structure elucidation.

</details>


### [99] [Episodic Contextual Bandits with Knapsacks under Conversion Models](https://arxiv.org/abs/2507.06859)
*Zitian Li,Wang Chi Cheung*

Key words: 在线优化, 上下文带约束的多臂老虎机, 动态定价, 拍卖, 强化学习

TL;DR: 研究在线决策者在资源分配问题中的动态优化，提出一种子线性遗憾算法。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 解决资源分配中的动态定价和拍卖问题，特别是在非稳态环境和多情境下的挑战。

Method: 设计了一种在线算法，结合置信区间预言机，处理无界状态空间的强化学习问题。

Result: 算法在总期数T中实现子线性遗憾，并在某些情况下通过未标注数据改进遗憾界限。

Conclusion: 该框架为上下文带约束的多臂老虎机问题提供了新的解决方案。

Abstract: We study an online setting, where a decision maker (DM) interacts with
contextual bandit-with-knapsack (BwK) instances in repeated episodes. These
episodes start with different resource amounts, and the contexts' probability
distributions are non-stationary in an episode. All episodes share the same
latent conversion model, which governs the random outcome contingent upon a
request's context and an allocation decision. Our model captures applications
such as dynamic pricing on perishable resources with episodic replenishment,
and first price auctions in repeated episodes with different starting budgets.
We design an online algorithm that achieves a regret sub-linear in $T$, the
number of episodes, assuming access to a \emph{confidence bound oracle} that
achieves an $o(T)$-regret. Such an oracle is readily available from existing
contextual bandit literature. We overcome the technical challenge with
arbitrarily many possible contexts, which leads to a reinforcement learning
problem with an unbounded state space. Our framework provides improved regret
bounds in certain settings when the DM is provided with unlabeled feature data,
which is novel to the contextual BwK literature.

</details>


### [100] [Horizontal and Vertical Federated Causal Structure Learning via Higher-order Cumulants](https://arxiv.org/abs/2507.06888)
*Wei Chen,Wanyang Gu,Linjun Peng,Ruichu Cai,Zhifeng Hao,Kun Zhang*

Key words: 联邦学习,因果发现,高阶累积,垂直联邦

TL;DR: 该论文提出了一种联邦因果发现方法，通过高阶累积学习因果结构，解决了数据和隐私问题在水平和垂直联邦环境下的挑战。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有联邦因果发现方法主要针对水平联邦，而实际场景中不同客户端可能包含不同变量，这容易导致虚假因果。

Method: 通过高阶累积汇总全局信息，递归识别因果源，构建因果强度矩阵。

Result: 在合成和真实数据实验中表现优异，能重建因果图并估计因果强度系数。

Conclusion: 该方法在水平和垂直联邦环境下均有效，显著提升了因果发现的准确性和适用性。

Abstract: Federated causal discovery aims to uncover the causal relationships between
entities while protecting data privacy, which has significant importance and
numerous applications in real-world scenarios. Existing federated causal
structure learning methods primarily focus on horizontal federated settings.
However, in practical situations, different clients may not necessarily contain
data on the same variables. In a single client, the incomplete set of variables
can easily lead to spurious causal relationships, thereby affecting the
information transmitted to other clients. To address this issue, we
comprehensively consider causal structure learning methods under both
horizontal and vertical federated settings. We provide the identification
theories and methods for learning causal structure in the horizontal and
vertical federal setting via higher-order cumulants. Specifically, we first
aggregate higher-order cumulant information from all participating clients to
construct global cumulant estimates. These global estimates are then used for
recursive source identification, ultimately yielding a global causal strength
matrix. Our approach not only enables the reconstruction of causal graphs but
also facilitates the estimation of causal strength coefficients. Our algorithm
demonstrates superior performance in experiments conducted on both synthetic
data and real-world data.

</details>


### [101] [Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams](https://arxiv.org/abs/2507.06901)
*Abolfazl Zarghani,Sadegh Abedi*

Key words: 多维数据流、强化学习、滑动窗口、Dueling DQN

TL;DR: 论文提出了一种基于强化学习的动态优化滑动窗口大小的方法（RL-Window），用于处理多维数据流，其性能优于现有方法。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 多维数据流的高速度、无界性和复杂依赖关系给传统固定窗口技术带来挑战，需要一种自适应方法。

Method: 将窗口大小选择建模为强化学习问题，采用Dueling Deep Q-Network（DQN）和优先级经验回放技术。

Result: 在多个基准数据集上，RL-Window在分类准确性、漂移鲁棒性和计算效率方面优于现有方法。

Conclusion: RL-Window展现出高适应性和稳定性，适用于实时应用。

Abstract: Multi-dimensional data streams, prevalent in applications like IoT, financial
markets, and real-time analytics, pose significant challenges due to their high
velocity, unbounded nature, and complex inter-dimensional dependencies. Sliding
window techniques are critical for processing such streams, but fixed-size
windows struggle to adapt to dynamic changes like concept drift or bursty
patterns. This paper proposes a novel reinforcement learning (RL)-based
approach to dynamically optimize sliding window sizes for multi-dimensional
data streams. By formulating window size selection as an RL problem, we enable
an agent to learn an adaptive policy based on stream characteristics, such as
variance, correlations, and temporal trends. Our method, RL-Window, leverages a
Dueling Deep Q-Network (DQN) with prioritized experience replay to handle
non-stationarity and high-dimensionality. Evaluations on benchmark datasets
(UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms
state-of-the-art methods like ADWIN and CNN-Adaptive in classification
accuracy, drift robustness, and computational efficiency. Additional
qualitative analyses, extended metrics (e.g., energy efficiency, latency), and
a comprehensive dataset characterization further highlight its adaptability and
stability, making it suitable for real-time applications.

</details>


### [102] [Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting](https://arxiv.org/abs/2507.06907)
*Linyun Gao,Qiang Wen,Fumio Machida*

Key words: 自动驾驶，交通标志识别，对抗攻击，NVML，安全感知加权投票

TL;DR: 提出了一种基于N版本机器学习（NVML）的框架，通过安全感知加权软投票机制增强交通标志识别系统的鲁棒性和安全性，有效抵御对抗攻击。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 自动驾驶系统在对抗攻击下的安全性是重要挑战，尤其是交通标志识别系统易受攻击影响，需要提高其鲁棒性。

Method: 采用N版本机器学习框架，结合安全感知加权软投票机制，利用FMEA评估安全风险并动态分配权重。

Result: 实验表明，该方法显著提升了交通标志识别系统在对抗攻击条件下的鲁棒性和安全性。

Conclusion: NVML框架有效提高了自动驾驶系统的安全性，尤其是在对抗环境下。

Abstract: Autonomous driving is rapidly advancing as a key application of machine
learning, yet ensuring the safety of these systems remains a critical
challenge. Traffic sign recognition, an essential component of autonomous
vehicles, is particularly vulnerable to adversarial attacks that can compromise
driving safety. In this paper, we propose an N-version machine learning (NVML)
framework that integrates a safety-aware weighted soft voting mechanism. Our
approach utilizes Failure Mode and Effects Analysis (FMEA) to assess potential
safety risks and assign dynamic, safety-aware weights to the ensemble outputs.
We evaluate the robustness of three-version NVML systems employing various
voting mechanisms against adversarial samples generated using the Fast Gradient
Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks. Experimental
results demonstrate that our NVML approach significantly enhances the
robustness and safety of traffic sign recognition systems under adversarial
conditions.

</details>


### [103] [DICE: Data Influence Cascade in Decentralized Learning](https://arxiv.org/abs/2507.06931)
*Tongtian Zhu,Wenhao Li,Can Wang,Fengxiang He*

Key words: 去中心化学习, 激励机制, 影响力传播, 公平性, DICE

TL;DR: 该论文提出了一种名为DICE的方法，用于在去中心化网络中估算数据影响力的传播，解决了激励机制中的贡献公平性问题。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 去中心化学习虽然能分散计算负担，但缺乏公平的激励机制，阻碍了广泛参与。作者希望设计一种能够公平评估节点贡献的方法，以促进参与。

Method: 设计了DICE方法，通过理论推导，近似计算数据影响力在去中心化网络中的传播路径，考虑了数据、通信拓扑和损失曲面的相互作用。

Result: DICE不仅能够量化影响力的传播，还可用于选择合适的协作节点和识别恶意行为。

Conclusion: DICE为去中心化网络的激励机制提供了理论基础，并展示了实际应用潜力。

Abstract: Decentralized learning offers a promising approach to crowdsource data
consumptions and computational workloads across geographically distributed
compute interconnected through peer-to-peer networks, accommodating the
exponentially increasing demands. However, proper incentives are still in
absence, considerably discouraging participation. Our vision is that a fair
incentive mechanism relies on fair attribution of contributions to
participating nodes, which faces non-trivial challenges arising from the
localized connections making influence ``cascade'' in a decentralized network.
To overcome this, we design the first method to estimate \textbf{D}ata
\textbf{I}nfluence \textbf{C}ascad\textbf{E} (DICE) in a decentralized
environment. Theoretically, the framework derives tractable approximations of
influence cascade over arbitrary neighbor hops, suggesting the influence
cascade is determined by an interplay of data, communication topology, and the
curvature of loss landscape. DICE also lays the foundations for applications
including selecting suitable collaborators and identifying malicious behaviors.
Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.

</details>


### [104] [What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models](https://arxiv.org/abs/2507.06952)
*Keyon Vafa,Peter G. Chang,Ashesh Rambachan,Sendhil Mullainathan*

Key words: 基础模型, 归纳偏差, 评估技术, 牛顿力学, 任务适应性

TL;DR: 该论文探讨了基础模型是否能真正捕捉更深层次的结构，并提出了一种评估方法，发现模型虽然在训练任务上表现优异，但在新任务中未能发展出与底层世界模型一致的归纳偏差。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 研究动机是评估基础模型是否能够像开普勒预测行星运动后推导出牛顿力学那样，通过序列预测揭示更深层次的领域理解。

Method: 提出了一种称为归纳偏差探针的技术，通过生成合成数据集并测试模型对其的适应能力，来衡量模型的归纳偏差是否与假设的世界模型一致。

Result: 研究发现，尽管基础模型在训练任务上表现优异，但在适应新任务时未能发展出与底层世界模型一致的归纳偏差，尤其是在轨道轨迹任务中未能应用牛顿力学。

Conclusion: 结论指出，基础模型倾向于发展出任务特定的启发式方法，而这些方法未能泛化到新任务中，表明模型可能缺乏对更深层次结构的理解。

Abstract: Foundation models are premised on the idea that sequence prediction can
uncover deeper domain understanding, much like how Kepler's predictions of
planetary motion later led to the discovery of Newtonian mechanics. However,
evaluating whether these models truly capture deeper structure remains a
challenge. We develop a technique for evaluating foundation models that
examines how they adapt to synthetic datasets generated from some postulated
world model. Our technique measures whether the foundation model's inductive
bias aligns with the world model, and so we refer to it as an inductive bias
probe. Across multiple domains, we find that foundation models can excel at
their training tasks yet fail to develop inductive biases towards the
underlying world model when adapted to new tasks. We particularly find that
foundation models trained on orbital trajectories consistently fail to apply
Newtonian mechanics when adapted to new physics tasks. Further analysis reveals
that these models behave as if they develop task-specific heuristics that fail
to generalize.

</details>


### [105] [Noisy PDE Training Requires Bigger PINNs](https://arxiv.org/abs/2507.06967)
*Sebastien Andre-Sloan,Anirbit Mukherjee,Matthew Colbrook*

Key words: PINNs, partial differential equations, empirical risk, noise, Hamilton–Jacobi–Bellman PDE

TL;DR: 本文研究了在含噪声的监督数据下，物理信息神经网络（PINNs）的规模与经验风险之间的关系，证明了网络规模的下界，并验证了PINNs在噪声条件下的实际表现。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 在现实应用中，数据样本通常含有噪声，但关于PINNs在噪声条件下如何有效降低经验风险的条件尚不明确。本文旨在填补这一知识空白。

Method: 通过理论分析，推导出神经网络规模的下界，并通过实验验证PINNs在噪声条件下的表现，特别是应用于Hamilton–Jacobi–Bellman（HJB）偏微分方程的案例。

Result: 证明了一个理论下界：若预测器的经验风险低于噪声方差，则必须有$d_N\log d_N\gtrsim N_s \eta^2$。实验验证了PINNs在噪声条件下可以达到低于噪声方差的经验风险。

Conclusion: 研究为定量理解噪声条件下训练PINNs的参数要求奠定了基础，并指出仅增加含噪声的监督标签并不能无代价地降低经验风险。

Abstract: Physics-Informed Neural Networks (PINNs) are increasingly used to approximate
solutions of partial differential equations (PDEs), especially in high
dimensions. In real-world applications, data samples are noisy, so it is
important to know when a predictor can still achieve low empirical risk.
However, little is known about the conditions under which a PINN can do so
effectively. We prove a lower bound on the size of neural networks required for
the supervised PINN empirical risk to fall below the variance of noisy
supervision labels. Specifically, if a predictor achieves an empirical risk
$O(\eta)$ below $\sigma^2$ (variance of supervision data), then necessarily
$d_N\log d_N\gtrsim N_s \eta^2$, where $N_s$ is the number of samples and $d_N$
is the number of trainable parameters of the PINN. A similar constraint applies
to the fully unsupervised PINN setting when boundary labels are sampled
noisily. Consequently, increasing the number of noisy supervision labels alone
does not provide a ``free lunch'' in reducing empirical risk. We also show
empirically that PINNs can indeed achieve empirical risks below $\sigma^2$
under such conditions. As a case study, we investigate PINNs applied to the
Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for
quantitatively understanding the parameter requirements for training PINNs in
the presence of noise.

</details>


### [106] [Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy](https://arxiv.org/abs/2507.06969)
*Bogdan Kulynych,Juan Felipe Gomez,Georgios Kaissis,Jamie Hayes,Borja Balle,Flavio du Pin Calmon,Jean Louis Raisaro*

Key words: 差异隐私,$f$-DP,假设检验,隐私风险,噪声校准

TL;DR: 该论文提出了一种基于假设检验的差异隐私框架（$f$-DP），统一了重识别、属性推断和数据重构风险的隐私保护评估，减少了计算噪声需求，提高了实用性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有差异隐私（DP）机制在评估隐私风险（如重识别、属性推断等）时过于悲观且不一致，缺乏统一的框架。

Method: 采用假设检验的$f$-DP方法，为不同攻击设置提供统一且可调节的隐私风险界限。

Result: 相比$ε$-DP、Rényi DP等方法，新框架的界限更紧，噪声需求降低20%，在文本分类任务中准确率提升15%以上。

Conclusion: $f$-DP为差异隐私的评估和校准提供了统一的框架，实用性更强。

Abstract: Differentially private (DP) mechanisms are difficult to interpret and
calibrate because existing methods for mapping standard privacy parameters to
concrete privacy risks -- re-identification, attribute inference, and data
reconstruction -- are both overly pessimistic and inconsistent. In this work,
we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that
bounds on attack success can take the same unified form across
re-identification, attribute inference, and data reconstruction risks. Our
unified bounds are (1) consistent across a multitude of attack settings, and
(2) tunable, enabling practitioners to evaluate risk with respect to arbitrary
(including worst-case) levels of baseline risk. Empirically, our results are
tighter than prior methods using $\varepsilon$-DP, R\'enyi DP, and concentrated
DP. As a result, calibrating noise using our bounds can reduce the required
noise by 20% at the same risk level, which yields, e.g., more than 15pp
accuracy increase in a text classification task. Overall, this unifying
perspective provides a principled framework for interpreting and calibrating
the degree of protection in DP against specific levels of re-identification,
attribute inference, or data reconstruction risk.

</details>


### [107] [A Principled Framework for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06979)
*Panagiotis Koromilas,Efthymios Georgiou,Giorgos Bouritsas,Theodoros Giannakopoulos,Mihalis A. Nicolaou,Yannis Panagakis*

Key words: 对比学习、多视图学习、自监督学习、信息最大化、维度崩溃

TL;DR: 提出两种新型对比学习损失函数MV-InfoNCE和MV-DHEL，解决多视图对比学习中存在的冲突目标、交互不足等问题，并在实验中获得显著性能提升。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统对比学习方法在多视图场景下存在目标冲突、交互建模不足等问题，无法充分利用视图多样性带来的增益。

Method: 提出两种新损失函数：MV-InfoNCE统一建模所有视图交互，MV-DHEL解耦对齐与均匀性并适应视图复杂性。

Result: 在ImageNet1K等数据集上表现优于现有方法，支持多模态扩展，并能有效缓解维度崩溃。

Conclusion: 新方法在多视图对比学习中展现了强大潜力，尤其在利用高视图多样性时表现突出。

Abstract: Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning
(SSL), typically relies on pairs of data views generated through augmentation.
While multiple augmentations per instance (more than two) improve
generalization in supervised learning, current CL methods handle additional
views suboptimally by simply aggregating different pairwise objectives. This
approach suffers from four critical limitations: (L1) it utilizes multiple
optimization terms per data point resulting to conflicting objectives, (L2) it
fails to model all interactions across views and data points, (L3) it inherits
fundamental limitations (e.g. alignment-uniformity coupling) from pairwise CL
losses, and (L4) it prevents fully realizing the benefits of increased view
multiplicity observed in supervised settings. We address these limitations
through two novel loss functions: MV-InfoNCE, which extends InfoNCE to
incorporate all possible view interactions simultaneously in one term per data
point, and MV-DHEL, which decouples alignment from uniformity across views
while scaling interaction complexity with view multiplicity. Both approaches
are theoretically grounded - we prove they asymptotically optimize for
alignment of all views and uniformity, providing principled extensions to
multi-view contrastive learning. Our empirical results on ImageNet1K and three
other datasets demonstrate that our methods consistently outperform existing
multi-view approaches and effectively scale with increasing view multiplicity.
We also apply our objectives to multimodal data and show that, in contrast to
other contrastive objectives, they can scale beyond just two modalities. Most
significantly, ablation studies reveal that MV-DHEL with five or more views
effectively mitigates dimensionality collapse by fully utilizing the embedding
space, thereby delivering multi-view benefits observed in supervised learning.

</details>


### [108] [Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing](https://arxiv.org/abs/2507.06996)
*Eunbyeol Cho,Jiyoun Kim,Minjae Lee,Sungjin Park,Edward Choi*

Key words: 电子健康记录,合成数据,时间序列,多表格,隐私

TL;DR: RawMed是一个新框架，用于生成多表格时间序列的电子健康记录（EHR）数据，模仿原始EHR的结构和动态，解决了现有方法生成数据有限的问题。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 由于隐私问题和法规限制，真实的EHR数据难以共享和利用，因此需要生成高质量的合成EHR数据。现有方法通常只能生成少量专家选择的特征，无法完全模拟原始EHR的复杂性。

Method: RawMed采用基于文本的表示和压缩技术，无需大量预处理即可捕捉复杂结构和时间动态。

Result: 在开源EHR数据集上验证，RawMed在保真度和实用性上优于基线模型。

Conclusion: RawMed能够高效生成高质量的多表格时间序列EHR数据，适用于医疗研究和应用。

Abstract: Electronic Health Records (EHR) are time-series relational databases that
record patient interactions and medical events over time, serving as a critical
resource for healthcare research and applications. However, privacy concerns
and regulatory restrictions limit the sharing and utilization of such sensitive
data, necessitating the generation of synthetic EHR datasets. Unlike previous
EHR synthesis methods, which typically generate medical records consisting of
expert-chosen features (e.g. a few vital signs or structured codes only), we
introduce RawMed, the first framework to synthesize multi-table, time-series
EHR data that closely resembles raw EHRs. Using text-based representation and
compression techniques, RawMed captures complex structures and temporal
dynamics with minimal preprocessing. We also propose a new evaluation framework
for multi-table time-series synthetic EHRs, assessing distributional
similarity, inter-table relationships, temporal dynamics, and privacy.
Validated on two open-source EHR datasets, RawMed outperforms baseline models
in fidelity and utility. The code is available at
https://github.com/eunbyeol-cho/RawMed.

</details>


### [109] [Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions](https://arxiv.org/abs/2507.07008)
*Emile Pierret,Bruno Galerne*

Key words: 扩散模型,贝叶斯逆问题,Wasserstein距离,高斯分布,去模糊

TL;DR: 本文研究了扩散模型在高斯数据分布去模糊任务中的准确性，通过计算Wasserstein距离分析理论与实际解之间的差异，并对不同算法进行比较。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 扩散模型作为贝叶斯逆问题的先验，近期受到广泛关注，但其性能尚存疑问。研究旨在评估其在特定任务中的准确性。

Method: 在高斯数据分布的去模糊任务中，计算扩散模型采样器与理想解分布间的Wasserstein距离，精确分析理论解与实际解的差异。

Result: 研究提供了扩散模型在特定任务中的准确性评估，并实现了对不同算法的比较。

Conclusion: 扩散模型在高斯数据分布去模糊任务中表现出色，Wasserstein距离为分析提供了量化指标。

Abstract: Used as priors for Bayesian inverse problems, diffusion models have recently
attracted considerable attention in the literature. Their flexibility and high
variance enable them to generate multiple solutions for a given task, such as
inpainting, super-resolution, and deblurring. However, several unresolved
questions remain about how well they perform. In this article, we investigate
the accuracy of these models when applied to a Gaussian data distribution for
deblurring. Within this constrained context, we are able to precisely analyze
the discrepancy between the theoretical resolution of inverse problems and
their resolution obtained using diffusion models by computing the exact
Wasserstein distance between the distribution of the diffusion model sampler
and the ideal distribution of solutions to the inverse problem. Our findings
allow for the comparison of different algorithms from the literature.

</details>


### [110] [On-Device Training of PV Power Forecasting Models in a Smart Meter for Grid Edge Intelligence](https://arxiv.org/abs/2507.07016)
*Jian Huang,Yongli Zhu,Linna Xu,Zhe Zheng,Wenpeng Cui,Mingyang Sun*

Key words: 边缘计算、智能电表、设备端训练、光伏功率预测、机器学习

TL;DR: 该论文研究了在资源受限的智能电表上进行的边缘侧模型训练，介绍了网格边缘智能的动机和设备端训练的概念，并提出了适应资源限制的'混合'和'降低'精度训练方案，实验证明了通过现有先进计量基础设施经济实现网格边缘智能的可行性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 网格边缘智能和设备端训练的概念，旨在在资源受限的设备上实现高效的模型训练。

Method: 提出了'混合'和'降低'精度训练方案，以适应智能电表的资源限制，并在光伏功率预测任务中研究了梯度提升树模型和循环神经网络模型。

Result: 实验结果表明，可以通过现有先进计量基础设施经济实现网格边缘智能。

Conclusion: 设备端训练在资源受限的设备上是可行的，且能够经济实现网格边缘智能。

Abstract: In this paper, an edge-side model training study is conducted on a
resource-limited smart meter. The motivation of grid-edge intelligence and the
concept of on-device training are introduced. Then, the technical preparation
steps for on-device training are described. A case study on the task of
photovoltaic power forecasting is presented, where two representative machine
learning models are investigated: a gradient boosting tree model and a
recurrent neural network model. To adapt to the resource-limited situation in
the smart meter, "mixed"- and "reduced"-precision training schemes are also
devised. Experiment results demonstrate the feasibility of economically
achieving grid-edge intelligence via the existing advanced metering
infrastructures.

</details>


### [111] [PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments](https://arxiv.org/abs/2507.07032)
*Hanqun Cao,Xinyi Zhou,Zijun Gao,Chenyu Wang,Xin Gao,Zhi Zhang,Chunbin Gu,Ge Liu,Pheng-Ann Heng*

Key words: Protein structure prediction, MSA design, PLAME, AlphaFold, orphan proteins

TL;DR: PLAME是一个基于预训练蛋白质语言模型的新型MSA设计模型，通过进化嵌入提升低同源性和孤儿蛋白的结构预测性能，显著优于AlphaFold2和AlphaFold3。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统蛋白结构预测模型依赖多序列比对（MSA），对低同源性和孤儿蛋白效果有限。PLAME旨在解决这一限制。

Method: PLAME结合预训练进化嵌入和守恒-多样性损失增强生成质量，并提出了新的MSA筛选方法和序列质量评估指标。

Result: 在低同源性和孤儿蛋白测试中，PLAME在折叠增强和序列评估上均达到最优性能，并能适配ESMFold实现高效预测。

Conclusion: PLAME显著提升了蛋白结构预测性能，尤其针对低同源性和孤儿蛋白，展示了预训练模型在MSA设计中的潜力。

Abstract: Protein structure prediction is essential for drug discovery and
understanding biological functions. While recent advancements like AlphaFold
have achieved remarkable accuracy, most folding models rely heavily on multiple
sequence alignments (MSAs) to boost prediction performance. This dependency
limits their effectiveness on low-homology proteins and orphan proteins, where
MSA information is sparse or unavailable. To address this limitation, we
propose PLAME, a novel MSA design model that leverages evolutionary embeddings
from pretrained protein language models. Unlike existing methods, PLAME
introduces pretrained representations to enhance evolutionary information and
employs a conservation-diversity loss to enhance generation quality.
Additionally, we propose a novel MSA selection method to effectively screen
high-quality MSAs and improve folding performance. We also propose a sequence
quality assessment metric that provides an orthogonal perspective to evaluate
MSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins,
PLAME achieves state-of-the-art performance in folding enhancement and sequence
quality assessment, with consistent improvements demonstrated on AlphaFold3.
Ablation studies validate the effectiveness of the MSA selection method, while
extensive case studies on various protein types provide insights into the
relationship between AlphaFold's prediction quality and MSA characteristics.
Furthermore, we demonstrate that PLAME can serve as an adapter achieving
AlphaFold2-level accuracy with the ESMFold's inference speed.

</details>


### [112] [Self-Supervised Learning at the Edge: The Cost of Labeling](https://arxiv.org/abs/2507.07033)
*Roberto Pereira,Fernanda Famá,Asal Rangrazi,Marco Miozzo,Charalampos Kalalas,Paolo Dini*

Key words: 对比学习,自监督学习,边缘计算,能效,半监督学习

TL;DR: 该论文探讨了自监督学习（SSL）在资源受限边缘设备上的可行性，分析了性能与能耗的权衡，并提出定制化策略可将资源消耗减少最多4倍。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 研究动机是解决自监督学习（如对比学习）在大数据和计算资源需求下，在边缘设备部署的挑战。

Method: 方法包括分析不同SSL技术在有限资源下的适应性，并评估半监督学习减少标注能耗的效果。

Result: 实验表明，定制SSL策略可在降低资源消耗的同时保持竞争力，最高减少4倍消耗。

Conclusion: 结论强调SSL在边缘设备上实现高效节能学习的潜力。

Abstract: Contrastive learning (CL) has recently emerged as an alternative to
traditional supervised machine learning solutions by enabling rich
representations from unstructured and unlabeled data. However, CL and, more
broadly, self-supervised learning (SSL) methods often demand a large amount of
data and computational resources, posing challenges for deployment on
resource-constrained edge devices. In this work, we explore the feasibility and
efficiency of SSL techniques for edge-based learning, focusing on trade-offs
between model performance and energy efficiency. In particular, we analyze how
different SSL techniques adapt to limited computational, data, and energy
budgets, evaluating their effectiveness in learning robust representations
under resource-constrained settings. Moreover, we also consider the energy
costs involved in labeling data and assess how semi-supervised learning may
assist in reducing the overall energy consumed to train CL models. Through
extensive experiments, we demonstrate that tailored SSL strategies can achieve
competitive performance while reducing resource consumption by up to 4X,
underscoring their potential for energy-efficient learning at the edge.

</details>


### [113] [An Ensemble Embedding Approach for Improving Semantic Caching Performance in LLM-based Systems](https://arxiv.org/abs/2507.07061)
*Shervin Ghaffari,Zohre Bahranifard,Mohammad Akbari*

Key words: 语义缓存,大型语言模型,集成嵌入,语义相似性,计算效率

TL;DR: 本文提出了一种集成嵌入方法，通过训练元编码器结合多个嵌入模型，提升大型语言模型（LLM）系统中语义缓存的效率，显著优于单模型方法。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 现有语义缓存框架依赖单一嵌入模型表示查询，无法充分捕捉真实查询分布中的多样性语义关系，限制了缓存效率。

Method: 采用集成嵌入方法，结合多个嵌入模型并通过训练元编码器改进语义相似性检测。使用Quora Question Pairs（QQP）数据集评估。

Result: 集成方法在语义等效查询上实现92%的缓存命中率，同时以85%的准确率拒绝非等效查询，显著提升了缓存性能和计算效率。

Conclusion: 集成嵌入方法能更有效区分语义相似与不同查询，为LLM系统提供更高效缓存和更低计算开销。

Abstract: Semantic caching enhances the efficiency of large language model (LLM)
systems by identifying semantically similar queries, storing responses once,
and serving them for subsequent equivalent requests. However, existing semantic
caching frameworks rely on single embedding models for query representation,
which limits their ability to capture the diverse semantic relationships
present in real-world query distributions. This paper presents an ensemble
embedding approach that combines multiple embedding models through a trained
meta-encoder to improve semantic similarity detection in LLM caching systems.
We evaluate our method using the Quora Question Pairs (QQP) dataset, measuring
cache hit ratios, cache miss ratios, token savings, and response times. Our
ensemble approach achieves a 92\% cache hit ratio for semantically equivalent
queries while maintaining an 85\% accuracy in correctly rejecting
non-equivalent queries as cache misses. These results demonstrate that ensemble
embedding methods significantly outperform single-model approaches in
distinguishing between semantically similar and dissimilar queries, leading to
more effective caching performance and reduced computational overhead in
LLM-based systems.

</details>


### [114] [Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts](https://arxiv.org/abs/2507.07100)
*Lan Li,Da-Wei Zhou,Han-Jia Ye,De-Chuan Zhan*

Key words: 领域增量学习, 类不平衡, 分布偏移, DCE框架

TL;DR: 该论文提出了Dual-Balance Collaborative Experts (DCE)框架，用于解决领域增量学习中的类不平衡和分布偏移问题，并通过实验验证了其有效性。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 领域增量学习(DIL)在非平稳环境中面临类内不平衡和跨域类分布偏移的挑战，这些挑战显著影响了模型性能。

Method: DCE框架采用频率感知专家组和动态专家选择器，通过专用损失函数和平衡高斯采样处理类不平衡和知识迁移。

Result: 在四个基准数据集上的实验表明，DCE具有最先进的性能。

Conclusion: DCE有效解决了领域增量学习中的关键挑战，提升了模型在动态环境中的适应能力。

Abstract: Domain-Incremental Learning (DIL) focuses on continual learning in
non-stationary environments, requiring models to adjust to evolving domains
while preserving historical knowledge. DIL faces two critical challenges in the
context of imbalanced data: intra-domain class imbalance and cross-domain class
distribution shifts. These challenges significantly hinder model performance,
as intra-domain imbalance leads to underfitting of few-shot classes, while
cross-domain shifts require maintaining well-learned many-shot classes and
transferring knowledge to improve few-shot class performance in old domains. To
overcome these challenges, we introduce the Dual-Balance Collaborative Experts
(DCE) framework. DCE employs a frequency-aware expert group, where each expert
is guided by specialized loss functions to learn features for specific
frequency groups, effectively addressing intra-domain class imbalance.
Subsequently, a dynamic expert selector is learned by synthesizing
pseudo-features through balanced Gaussian sampling from historical class
statistics. This mechanism navigates the trade-off between preserving many-shot
knowledge of previous domains and leveraging new data to improve few-shot class
performance in earlier tasks. Extensive experimental results on four benchmark
datasets demonstrate DCE's state-of-the-art performance.

</details>


### [115] [Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful](https://arxiv.org/abs/2507.07101)
*Martin Marek,Sanae Lotfi,Aditya Somasundaram,Andrew Gordon Wilson,Micah Goldblum*

Key words: 小批次训练, Adam优化器, SGD, 梯度累积

TL;DR: 本文重新审视了小批次大小对语言模型训练的影响，提出了一种调整Adam优化器超参数以适应小批次的方法，并发现小批次在多方面表现优于大批次。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 传统观点认为小批次大小会导致训练不稳定，但本文旨在探索小批次的实际效果并优化其使用。

Method: 提出了一种调整Adam超参数的方法，并在不同批次大小（包括批次大小为1）下进行实验。

Result: 小批次训练稳定、对超参数更鲁棒、性能不低于大批次，并能支持普通SGD。

Conclusion: 建议优先使用小批次并给出优化器设置建议，不建议梯度累积除非设备间通信受限。

Abstract: Conventional wisdom dictates that small batch sizes make language model
pretraining and fine-tuning unstable, motivating gradient accumulation, which
trades off the number of optimizer steps for a proportional increase in batch
size. While it is common to decrease the learning rate for smaller batch sizes,
other hyperparameters are often held fixed. In this work, we revisit small
batch sizes all the way down to batch size one, and we propose a rule for
scaling Adam hyperparameters to small batch sizes. We find that small batch
sizes (1) train stably, (2) are consistently more robust to hyperparameter
choices, (3) achieve equal or better per-FLOP performance than larger batch
sizes, and (4) notably enable stable language model training with vanilla SGD,
even without momentum, despite storing no optimizer state. Building on these
results, we provide practical recommendations for selecting a batch size and
setting optimizer hyperparameters. We further recommend against gradient
accumulation unless training on multiple devices with multiple model replicas,
bottlenecked by inter-device bandwidth.

</details>


### [116] [Does Data Scaling Lead to Visual Compositional Generalization?](https://arxiv.org/abs/2507.07102)
*Arnas Uselis,Andrea Dittadi,Seong Joon Oh*

Key words: 组合泛化、数据多样性、表示结构、视觉模型、机器学习

TL;DR: 研究表明，组合泛化能力依赖于数据多样性而非单纯的数据规模，通过实验发现线性分解表示结构对高效学习至关重要。

<details>
  <summary>Details</summary>

Main category: cs.LG

Motivation: 探讨当代视觉模型是否具备组合理解能力，测试数据规模和多样性对组合泛化的影响。

Method: 通过控制实验系统性地改变数据规模、概念多样性和组合覆盖，分析其对模型表现的影响。

Result: 组合泛化由数据多样性驱动；线性分解表示结构能实现高效泛化；预训练模型表现出部分此类结构。

Conclusion: 数据集构建需更注重多样性，表示结构对组合学习效率至关重要。

Abstract: Compositional understanding is crucial for human intelligence, yet it remains
unclear whether contemporary vision models exhibit it. The dominant machine
learning paradigm is built on the premise that scaling data and model sizes
will improve out-of-distribution performance, including compositional
generalization. We test this premise through controlled experiments that
systematically vary data scale, concept diversity, and combination coverage. We
find that compositional generalization is driven by data diversity, not mere
data scale. Increased combinatorial coverage forces models to discover a
linearly factored representational structure, where concepts decompose into
additive components. We prove this structure is key to efficiency, enabling
perfect generalization from few observed combinations. Evaluating pretrained
models (DINO, CLIP), we find above-random yet imperfect performance, suggesting
partial presence of this structure. Our work motivates stronger emphasis on
constructing diverse datasets for compositional generalization, and considering
the importance of representational structure that enables efficient
compositional learning. Code available at
https://github.com/oshapio/visual-compositional-generalization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [117] [Digital Wargames to Enhance Military Medical Evacuation Decision-Making](https://arxiv.org/abs/2507.06373)
*Jeremy Fischer,Ram Krishnamoorthy,Vishal Kumar,Mahdi Al-Husseini*

Key words: 医疗后送, 模拟训练, Unity, 战场模拟, 教育工具

TL;DR: MEWI是一个三维多人模拟工具，用于在课堂环境中模拟医疗后送网络，并通过实践场景提升学生的决策能力和学习效果。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 缺乏一种能够在课堂环境中模拟医疗后送网络并评估规划和决策性能的工具。

Method: 开发了MEWI，一个基于Unity的三维多人模拟工具，模拟战场约束和不确定性，并在两个操作场景中测试。

Result: MEWI显著提升了学生对医疗后送经验的学习效果和协作决策能力。

Conclusion: MEWI是高保真医疗教育工具的重要进步，为改进医疗后送教育和联合部队操作提供了关键见解。

Abstract: Medical evacuation is one of the United States Army's most storied and
critical mission sets, responsible for efficiently and expediently evacuating
the battlefield ill and injured. Medical evacuation planning involves designing
a robust network of medical platforms and facilities capable of moving and
treating large numbers of casualties. Until now, there has not been a medium to
simulate these networks in a classroom setting and evaluate both offline
planning and online decision-making performance. This work describes the
Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer
simulation developed in Unity that replicates battlefield constraints and
uncertainties. MEWI accurately models patient interactions at casualty
collection points, ambulance exchange points, medical treatment facilities, and
evacuation platforms. Two operational scenarios are introduced: an amphibious
island assault in the Pacific and a Eurasian conflict across a sprawling road
and river network. These scenarios pit students against the clock to save as
many casualties as possible while adhering to doctrinal lessons learned during
didactic training. We visualize performance data collected from two iterations
of the MEWI Pacific scenario executed in the United States Army's Medical
Evacuation Doctrine Course. We consider post-wargame Likert survey data from
student participants and external observer notes to identify key planning
decision points, document medical evacuation lessons learned, and quantify
general utility. Results indicate that MEWI participation substantially
improves uptake of medical evacuation lessons learned and co-operative
decision-making. MEWI is a substantial step forward in the field of
high-fidelity training tools for medical education, and our study findings
offer critical insights into improving medical evacuation education and
operations across the joint force.

</details>


### [118] [Representing Prompting Patterns with PDL: Compliance Agent Case Study](https://arxiv.org/abs/2507.06396)
*Mandana Vaziri,Louis Mandel,Yuji Watanabe,Hirokuni Kitahara,Martin Hirzel,Anca Sailer*

Key words: Prompt Engineering, LLM, PDL, 代理编程, 性能优化

TL;DR: 论文提出了一种新的提示声明语言（PDL），旨在解决现有提示工程框架灵活性不足的问题，通过显式表达提示并支持手动和自动调优，提升编程效率。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 现有的LLM提示工程框架要么过于封闭，要么缺乏灵活性，难以支持复杂的代理编程需求。

Method: 提出Prompt Declaration Language (PDL)，通过显式表达提示并支持组合LLM调用、规则代码和外部工具，提供声明式优化。

Result: 通过实际案例（合规代理）展示了PDL的实用性，调优后的性能提升高达4倍。

Conclusion: PDL通过简化提示工程的复杂性，显著提升了编程效率和性能。

Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either
hiding complexity behind restrictive APIs or providing inflexible canned
patterns that resist customization -- making sophisticated agentic programming
challenging. We present the Prompt Declaration Language (PDL), a novel approach
to prompt representation that tackles this fundamental complexity by bringing
prompts to the forefront, enabling manual and automatic prompt tuning while
capturing the composition of LLM calls together with rule-based code and
external tools. By abstracting away the plumbing for such compositions, PDL
aims at improving programmer productivity while providing a declarative
representation that is amenable to optimization. This paper demonstrates PDL's
utility through a real-world case study of a compliance agent. Tuning the
prompting pattern of this agent yielded up to 4x performance improvement
compared to using a canned agent and prompt pattern.

</details>


### [119] [Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI](https://arxiv.org/abs/2507.06398)
*David Orban*

Key words: Jolting Technologies Hypothesis, superexponential growth, AI capabilities, Monte Carlo simulations, AGI

TL;DR: 该论文探讨了AI能力发展中超指数增长的Jolting技术假说，开发了理论框架并通过蒙特卡洛模拟验证检测方法，为未来实证研究提供了工具。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 研究AI能力的超指数增长现象（Jolting技术假说），以理解其对通用人工智能（AGI）发展的潜在影响。

Method: 开发理论框架和检测方法，并通过蒙特卡洛模拟验证方法的有效性。

Result: 提供了识别和分析AI能力超指数增长的数学基础，并讨论了其可能的影响。

Conclusion: 该研究为未来实证研究奠定了理论基础，并为研究和政策制定提供了见解。

Abstract: This paper investigates the Jolting Technologies Hypothesis, which posits
superexponential growth (increasing acceleration, or a positive third
derivative) in the development of AI capabilities. We develop a theoretical
framework and validate detection methodologies through Monte Carlo simulations,
while acknowledging that empirical validation awaits suitable longitudinal
data. Our analysis focuses on creating robust tools for future empirical
studies and exploring the potential implications should the hypothesis prove
valid. The study examines how factors such as shrinking idea-to-action
intervals and compounding iterative AI improvements drive this jolting pattern.
By formalizing jolt dynamics and validating detection methods through
simulation, this work provides the mathematical foundation necessary for
understanding potential AI trajectories and their consequences for AGI
emergence, offering insights for research and policy.

</details>


### [120] [Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)](https://arxiv.org/abs/2507.06798)
*Uri Andrews,Luca San Mauro*

Key words: 辩证系统, 信念修正, 自动代理, 反例, 矛盾

TL;DR: 论文证明了q-辩证系统比p-辩证系统更强大，后者又比d-辩证系统强，强调了反例和矛盾在自动信念修正中的互补作用。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 探讨辩证系统在模拟代理更新知识库时的作用，解决文献中关于q-辩证系统与p-辩证系统能力关系的开放性问题。

Method: 通过数学证明比较三种辩证系统（d-, p-, q-）的能力差异。

Result: 证明q-辩证系统严格强于p-辩证系统，后者又严格强于d-辩证系统。

Conclusion: 反例和矛盾在自动信念修正及数学家和研究社区的推理过程中具有互补作用。

Abstract: Dialectical systems are a mathematical formalism for modeling an agent
updating a knowledge base seeking consistency. Introduced in the 1970s by
Roberto Magari, they were originally conceived to capture how a working
mathematician or a research community refines beliefs in the pursuit of truth.
Dialectical systems also serve as natural models for the belief change of an
automated agent, offering a unifying, computable framework for dynamic belief
management.
  The literature distinguishes three main models of dialectical systems:
(d-)dialectical systems based on revising beliefs when they are seen to be
inconsistent, p-dialectical systems based on revising beliefs based on finding
a counterexample, and q-dialectical systems which can do both. We answer an
open problem in the literature by proving that q-dialectical systems are
strictly more powerful than p-dialectical systems, which are themselves known
to be strictly stronger than (d-)dialectical systems. This result highlights
the complementary roles of counterexample and contradiction in automated belief
revision, and thus also in the reasoning processes of mathematicians and
research communities.

</details>


### [121] [SCC-recursiveness in infinite argumentation (extended version)](https://arxiv.org/abs/2507.06852)
*Uri Andrews,Luca San Mauro*

Key words: Argumentation frameworks, SCC-recursiveness, infinite AFs, directionality

TL;DR: 本文探讨了如何将SCC递归语义扩展到无限论证框架中，并评估了新语义的表现。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: SCC递归语义在有限论证框架中效果显著，但在无限框架中因缺乏良基性而失效。因此需要扩展其适用性。

Method: 提出了两种扩展SCC递归语义的方法，并系统地评估了它们的行为。

Result: 在无限框架中，方向性普遍失效；但在有限框架中，部分新语义满足方向性。

Conclusion: 研究结果推动了无限论证理论的发展，为处理无界或动态领域提供了基础。

Abstract: Argumentation frameworks (AFs) are a foundational tool in artificial
intelligence for modeling structured reasoning and conflict. SCC-recursiveness
is a well-known design principle in which the evaluation of arguments is
decomposed according to the strongly connected components (SCCs) of the attack
graph, proceeding recursively from "higher" to "lower" components. While
SCC-recursive semantics such as \cft and \stgt have proven effective for finite
AFs, Baumann and Spanring showed the failure of SCC-recursive semantics to
generalize reliably to infinite AFs due to issues with well-foundedness.
  We propose two approaches to extending SCC-recursiveness to the infinite
setting. We systematically evaluate these semantics using Baroni and Giacomin's
established criteria, showing in particular that directionality fails in
general. We then examine these semantics' behavior in finitary frameworks,
where we find some of our semantics satisfy directionality. These results
advance the theory of infinite argumentation and lay the groundwork for
reasoning systems capable of handling unbounded or evolving domains.

</details>


### [122] [Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report](https://arxiv.org/abs/2507.06968)
*Li Du,Hanyu Zhao,Yiming Ju,Tengfei Pan*

Key words: 指令调优，数据集构建，模型性能，覆盖范围，数据深度

TL;DR: 论文提出了一种系统性指令数据构建框架，旨在提升指令数据集的覆盖范围和深度，并基于该框架构建了一个高质量数据集InfinityInstruct-Subject，实验证明其有效性。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 当前指令数据集虽规模庞大，但在复杂指令和稀有领域任务上表现不佳，需提升数据的覆盖范围和深度。

Method: 设计了一个系统性指令数据构建框架，包括分层标注系统、信息性种子选择算法、演化数据合成过程及针对模型缺陷的数据生成。

Result: 构建的InfinityInstruct-Subject数据集显著提升了模型的指令遵循能力，且覆盖范围和深度优于同类数据集。

Conclusion: 该研究为指令数据集从数量扩展转向质量提升提供了理论和实践基础。

Abstract: Instruction tuning has become a foundation for unlocking the capabilities of
large-scale pretrained models and improving their performance on complex tasks.
Thus, the construction of high-quality instruction datasets is crucial for
enhancing model performance and generalizability. Although current instruction
datasets have reached tens of millions of samples, models finetuned on them may
still struggle with complex instruction following and tasks in rare domains.
This is primarily due to limited expansion in both ``coverage'' (coverage of
task types and knowledge areas) and ``depth'' (instruction complexity) of the
instruction set. To address this issue, we propose a systematic instruction
data construction framework, which integrates a hierarchical labeling system,
an informative seed selection algorithm, an evolutionary data synthesis
process, and a model deficiency diagnosis with targeted data generation. These
components form an iterative closed-loop to continuously enhance the coverage
and depth of instruction data. Based on this framework, we construct
InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million
instructions. Experiments on multiple foundation models and benchmark tasks
demonstrate its effectiveness in improving instruction-following capabilities.
Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage
and depth compared to comparable synthesized instruction datasets. Our work
lays a theoretical and practical foundation for the efficient, continuous
evolution of instruction datasets, moving from data quantity expansion to
qualitative improvement.

</details>


### [123] [The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation](https://arxiv.org/abs/2507.06993)
*Jieren Deng,Aleksandar Cvetkovic,Pak Kiu Chung,Dragomir Yankov,Chiqun Zhang*

Key words: 旅行规划, 动态调整, 协作代理, RAG, 导航

TL;DR: 论文提出了一种新型的动态旅行规划系统，通过三个协作代理解决了传统系统在智能规划、精确导航和动态调整方面的不足。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 传统旅行规划系统在处理动态环境变化和突发行程中断时表现不足，导致用户体验差。

Method: 设计了三个协作代理：旅行规划代理（基于网格空间分析和地图数据）、目的地助手代理（提供精细导航）和本地发现代理（利用图像嵌入和RAG技术应对行程中断）。

Result: 系统在查询解析、导航准确性和抗干扰能力方面表现出显著提升。

Conclusion: 该系统的动态性和协作性使其在城市探索和应急响应等领域具有广泛应用潜力。

Abstract: Traditional travel-planning systems are often static and fragmented, leaving
them ill-equipped to handle real-world complexities such as evolving
environmental conditions and unexpected itinerary disruptions. In this paper,
we identify three gaps between existing service providers causing frustrating
user experience: intelligent trip planning, precision "last-100-meter"
navigation, and dynamic itinerary adaptation. We propose three cooperative
agents: a Travel Planning Agent that employs grid-based spatial grounding and
map analysis to help resolve complex multi-modal user queries; a Destination
Assistant Agent that provides fine-grained guidance for the final navigation
leg of each journey; and a Local Discovery Agent that leverages image
embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to
trip plan disruptions. With evaluations and experiments, our system
demonstrates substantial improvements in query interpretation, navigation
accuracy, and disruption resilience, underscoring its promise for applications
from urban exploration to emergency response.

</details>


### [124] [First Return, Entropy-Eliciting Explore](https://arxiv.org/abs/2507.07017)
*Tianyu Zheng,Tianshun Xing,Qingshui Gu,Taoran Liang,Xingwei Qu,Xin Zhou,Yizhi Li,Zhoufutu Wen,Chenghua Lin,Wenhao Huang,Qian Liu,Ge Zhang,Zejun Ma*

Key words: 强化学习；大型语言模型；推理能力；结构化探索

TL;DR: FR3E是一种结构化探索框架，通过识别推理轨迹中的高不确定性决策点并针对性生成反馈，提升LLM的推理能力。

<details>
  <summary>Details</summary>

Main category: cs.AI

Motivation: 为解决RLVR中的不稳定探索问题，提出FR3E以改进LLM的推理表现。

Method: FR3E通过高不确定性决策点识别和针对性反馈生成，无需密集监督。

Result: 在数学推理基准上表现更稳定，生成更长、更连贯的答案，完全正确的轨迹比例增加。

Conclusion: FR3E通过结构化探索显著提升了LLM的推理能力。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning
abilities of Large Language Models (LLMs) but it struggles with unstable
exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a
structured exploration framework that identifies high-uncertainty decision
points in reasoning trajectories and performs targeted rollouts to construct
semantically grounded intermediate feedback. Our method provides targeted
guidance without relying on dense supervision. Empirical results on
mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable
training, produces longer and more coherent responses, and increases the
proportion of fully correct trajectories. These results highlight the
framework's effectiveness in improving LLM reasoning through more robust and
structured exploration.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [125] [X-ray transferable polyrepresentation learning](https://arxiv.org/abs/2507.06264)
*Weronika Hryniewska-Guzik,Przemyslaw Biecek*

Key words: 多表征、特征提取、机器学习、迁移学习、放射组学

TL;DR: 该论文提出了一种名为“多表征”的新概念，通过整合来自不同来源的同一模态的多种表征（如向量嵌入、自监督模型和可解释的放射组学特征），显著提升了机器学习算法的性能。

<details>
  <summary>Details</summary>

Main category: eess.IV

Motivation: 机器学习算法的性能与特征提取的质量密切相关，而传统的单一表征方法可能不足以应对多样化的数据需求。因此，作者提出多表征的概念，以提高特征提取的泛化能力和效果。

Method: 提出了一种称为“多表征”的方法，整合来自不同来源的同一模态的多种表征（如Siamese Network的向量嵌入、自监督模型和可解释的放射组学特征）。

Result: 实验表明，多表征方法优于单一表征，且在X射线图像数据中展示了其迁移学习的潜力。该方法具有资源高效性和广泛的适用性。

Conclusion: 多表征方法不仅提升了性能指标，还能应用于其他领域，展示了其广泛的潜在影响。

Abstract: The success of machine learning algorithms is inherently related to the
extraction of meaningful features, as they play a pivotal role in the
performance of these algorithms. Central to this challenge is the quality of
data representation. However, the ability to generalize and extract these
features effectively from unseen datasets is also crucial. In light of this, we
introduce a novel concept: the polyrepresentation. Polyrepresentation
integrates multiple representations of the same modality extracted from
distinct sources, for example, vector embeddings from the Siamese Network,
self-supervised models, and interpretable radiomic features. This approach
yields better performance metrics compared to relying on a single
representation. Additionally, in the context of X-ray images, we demonstrate
the transferability of the created polyrepresentation to a smaller dataset,
underscoring its potential as a pragmatic and resource-efficient approach in
various image-related solutions. It is worth noting that the concept of
polyprepresentation on the example of medical data can also be applied to other
domains, showcasing its versatility and broad potential impact.

</details>


### [126] [Photometric Stereo using Gaussian Splatting and inverse rendering](https://arxiv.org/abs/2507.06684)
*Matéo Ducastel,David Tschumperlé,Yvain Quéau*

Key words: 光度立体,高斯泼溅,逆渲染,3D重建

TL;DR: 本文通过高斯泼溅方法重新审视了标定光度立体问题，提出了一种更可解释的3D场景参数化和优化方法。

<details>
  <summary>Details</summary>

Main category: eess.IV

Motivation: 现有算法依赖神经网络，通过先验学习或逆渲染优化解决光度立体问题，需要更直观的参数化方式。

Method: 利用高斯泼溅形式主义进行3D逆渲染，简化光线表示模型，优化标定光度立体问题。

Result: 展示了高斯泼溅渲染引擎在光度立体问题中的潜力。

Conclusion: 高斯泼溅方法为光度立体问题提供了一种更可解释的解决方案。

Abstract: Recent state-of-the-art algorithms in photometric stereo rely on neural
networks and operate either through prior learning or inverse rendering
optimization. Here, we revisit the problem of calibrated photometric stereo by
leveraging recent advances in 3D inverse rendering using the Gaussian Splatting
formalism. This allows us to parameterize the 3D scene to be reconstructed and
optimize it in a more interpretable manner. Our approach incorporates a
simplified model for light representation and demonstrates the potential of the
Gaussian Splatting rendering engine for the photometric stereo problem.

</details>


### [127] [Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification](https://arxiv.org/abs/2507.06417)
*Laura Pituková,Peter Sinčák,László József Kovács*

Key words: 神经网络, Capsule Network, Kolmogorov--Arnold Network, 生物医学图像, 分类

TL;DR: 比较四种神经网络架构，提出Capsule-ConvKAN新模型，在生物医学图像分类中表现最佳。

<details>
  <summary>Details</summary>

Main category: eess.IV

Motivation: 改进特征表示和分类准确性，尤其是针对生物医学图像数据中的挑战。

Method: 结合Capsule Network的动态路由和空间层次能力与Convolutional Kolmogorov--Arnold Networks的灵活函数逼近。

Result: 在病理图像数据集中，Capsule-ConvKAN以91.21%的准确率表现最佳。

Conclusion: Capsule-ConvKAN在捕捉空间模式和管理复杂特征方面潜力显著，优于传统卷积模型。

Abstract: This study conducts a comprehensive comparison of four neural network
architectures: Convolutional Neural Network, Capsule Network, Convolutional
Kolmogorov--Arnold Network, and the newly proposed Capsule--Convolutional
Kolmogorov--Arnold Network. The proposed Capsule-ConvKAN architecture combines
the dynamic routing and spatial hierarchy capabilities of Capsule Network with
the flexible and interpretable function approximation of Convolutional
Kolmogorov--Arnold Networks. This novel hybrid model was developed to improve
feature representation and classification accuracy, particularly in challenging
real-world biomedical image data. The architectures were evaluated on a
histopathological image dataset, where Capsule-ConvKAN achieved the highest
classification performance with an accuracy of 91.21\%. The results demonstrate
the potential of the newly introduced Capsule-ConvKAN in capturing spatial
patterns, managing complex features, and addressing the limitations of
traditional convolutional models in medical image classification.

</details>


### [128] [Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data](https://arxiv.org/abs/2507.06828)
*Xuesong Li,Nassir Navab,Zhongliang Jiang*

Key words: 图像去噪、超声斑点噪声、自监督学习、Speckle2Self、医学成像

TL;DR: 提出了一种新的自监督算法Speckle2Self，用于仅使用单个噪声观测的超声斑点噪声抑制，通过多尺度扰动操作分离低秩干净信号和稀疏噪声。

<details>
  <summary>Details</summary>

Main category: eess.IV

Motivation: 医学超声成像中的斑点噪声不是纯粹的随机噪声，而是依赖于组织结构的复杂波干涉，导致现有的去噪方法如Noise2Noise和盲点网络无法直接应用。

Method: 引入Speckle2Self算法，利用多尺度扰动操作（MSP）在不同尺度上引入组织依赖性变化的斑点模式，同时保留共享的解剖结构，从而分离低秩干净信号和稀疏噪声。

Result: Speckle2Self在模拟超声图像和人类颈动脉超声图像上与传统的基于滤波的算法和SOTA学习算法进行了全面比较，证明了其有效性。

Conclusion: Speckle2Self能够在仅使用单个噪声观测的情况下有效抑制超声斑点噪声，并展示了在不同超声机器数据上的泛化能力和适应性。

Abstract: Image denoising is a fundamental task in computer vision, particularly in
medical ultrasound (US) imaging, where speckle noise significantly degrades
image quality. Although recent advancements in deep neural networks have led to
substantial improvements in denoising for natural images, these methods cannot
be directly applied to US speckle noise, as it is not purely random. Instead,
US speckle arises from complex wave interference within the body
microstructure, making it tissue-dependent. This dependency means that
obtaining two independent noisy observations of the same scene, as required by
pioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also
cannot handle US speckle noise due to its high spatial dependency. To address
this challenge, we introduce Speckle2Self, a novel self-supervised algorithm
for speckle reduction using only single noisy observations. The key insight is
that applying a multi-scale perturbation (MSP) operation introduces
tissue-dependent variations in the speckle pattern across different scales,
while preserving the shared anatomical structure. This enables effective
speckle suppression by modeling the clean image as a low-rank signal and
isolating the sparse noise component. To demonstrate its effectiveness,
Speckle2Self is comprehensively compared with conventional filter-based
denoising algorithms and SOTA learning-based methods, using both realistic
simulated US images and human carotid US images. Additionally, data from
multiple US machines are employed to evaluate model generalization and
adaptability to images from unseen domains. \textit{Code and datasets will be
released upon acceptance.

</details>


### [129] [Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers](https://arxiv.org/abs/2507.06764)
*Guixian Xu,Jinglai Li,Junqi Tang*

Key words: Fast Equivariant Imaging, 无监督学习, 拉格朗日乘数法, 即插即用去噪器, X射线CT重建

TL;DR: 提出了一种名为Fast Equivariant Imaging（FEI）的新型无监督学习框架，通过拉格朗日乘数法和即插即用去噪器提升训练效率和性能。

<details>
  <summary>Details</summary>

Main category: eess.IV

Motivation: 解决传统Equivariant Imaging（EI）范式在训练深度成像网络时的效率和性能不足问题。

Method: 采用拉格朗日乘数法重新表述优化问题，结合即插即用去噪器，开发了PnP-FEI方案。

Result: 在X射线CT重建任务中，PnP-FEI方案比标准EI快10倍，且泛化性能更优。

Conclusion: FEI框架显著提升了无监督训练的效率和性能，适用于医学成像等领域。

Abstract: We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning
framework to efficiently train deep imaging networks without ground-truth data.
From the perspective of reformulating the Equivariant Imaging based
optimization problem via the method of Lagrange multipliers and utilizing
plug-and-play denoisers, this novel unsupervised scheme shows superior
efficiency and performance compared to vanilla Equivariant Imaging paradigm. In
particular, our PnP-FEI scheme achieves an order-of-magnitude (10x)
acceleration over standard EI on training U-Net with CT100 dataset for X-ray CT
reconstruction, with improved generalization performance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [130] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

Key words: 节奏性插入任务（RIT）、sim-to-real、强化学习、失败预测、姿态跟踪

TL;DR: 本文提出了一种结合强化学习与失败预测的sim-to-real框架，用于解决高精度的节奏性插入任务（RIT），如用扳手拧螺栓。通过将工具姿态表述为螺母坐标系而非机器人坐标系，显著提高了仿真到现实的迁移性。实验表明该方法在单次任务和长时间重复任务中均表现优异。

<details>
  <summary>Details</summary>

Main category: cs.RO

Motivation: 节奏性插入任务（RIT）需要毫米级精度和长时间稳定性能，但螺母旋转和摩擦等因素增加了复杂性，传统方法难以应对。

Method: 提出了一种结合强化学习插入策略与失败预测模块的sim-to-real框架。插入策略在仿真中训练，利用实时6D姿态跟踪执行操作，同时神经网络预测失败并触发恢复机制。

Result: 在仿真和现实环境中均表现出高单次成功率和长时间稳定性能。

Conclusion: 该框架有效提升了RIT任务的精度和鲁棒性，尤其在长时间重复任务中表现突出。

Abstract: This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where
a robot must repeatedly perform high-precision insertions, such as screwing a
nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving
millimeter-level accuracy and maintaining consistent performance over multiple
repetitions, particularly when factors like nut rotation and friction introduce
additional complexity. We propose a sim-to-real framework that integrates a
reinforcement learning-based insertion policy with a failure forecasting
module. By representing the wrench's pose in the nut's coordinate frame rather
than the robot's frame, our approach significantly enhances sim-to-real
transferability. The insertion policy, trained in simulation, leverages
real-time 6D pose tracking to execute precise alignment, insertion, and
rotation maneuvers. Simultaneously, a neural network predicts potential
execution failures, triggering a simple recovery mechanism that lifts the
wrench and retries the insertion. Extensive experiments in both simulated and
real-world environments demonstrate that our method not only achieves a high
one-time success rate but also robustly maintains performance over long-horizon
repetitive tasks.

</details>


### [131] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

Key words: 无人机, 视觉语言导航, 非线性模型预测控制, 自然语言处理, 自主导航

TL;DR: 该论文提出了一种名为SkyVLN的新型框架，结合视觉语言导航（VLN）和非线性模型预测控制（NMPC），以提升无人机在复杂城市环境中的自主导航能力。

<details>
  <summary>Details</summary>

Main category: cs.RO

Motivation: 无人机的灵活性和适应性使其在各领域得到广泛应用，但在复杂环境中的自主导航仍具挑战性。本文旨在通过集成视觉语言理解和动态控制，提升无人机的导航能力。

Method: SkyVLN结合了大型语言模型（LLMs）用于自然语言指令解析、细粒度空间语言化模块和路径记忆机制，同时利用NMPC模块实现动态避障。

Result: 在基于AirSim的高保真3D城市仿真环境中验证，SkyVLN显著提升了导航成功率和效率，尤其是在新环境中表现优异。

Conclusion: SkyVLN框架为无人机在复杂动态环境中导航提供了高效解决方案，结合了语言理解和动态控制，具有广泛应用潜力。

Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across
various sectors, driven by their mobility and adaptability. This paper
introduces SkyVLN, a novel framework integrating vision-and-language navigation
(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in
complex urban environments. Unlike traditional navigation methods, SkyVLN
leverages Large Language Models (LLMs) to interpret natural language
instructions and visual observations, enabling UAVs to navigate through dynamic
3D spaces with improved accuracy and robustness. We present a multimodal
navigation agent equipped with a fine-grained spatial verbalizer and a history
path memory mechanism. These components allow the UAV to disambiguate spatial
contexts, handle ambiguous instructions, and backtrack when necessary. The
framework also incorporates an NMPC module for dynamic obstacle avoidance,
ensuring precise trajectory tracking and collision prevention. To validate our
approach, we developed a high-fidelity 3D urban simulation environment using
AirSim, featuring realistic imagery and dynamic urban elements. Extensive
experiments demonstrate that SkyVLN significantly improves navigation success
rates and efficiency, particularly in new and unseen environments.

</details>


### [132] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

Key words: 深度强化学习, MPC, 贝叶斯优化, Stein 变分梯度下降, 机器人控制

TL;DR: Q-STAC 框架通过整合贝叶斯 MPC 和 actor-critic 强化学习，解决了深度强化学习数据需求高和安全性问题，同时避免了 MPC 的局部最优限制。

<details>
  <summary>Details</summary>

Main category: cs.RO

Motivation: 结合深度强化学习和 MPC 的优势，解决前者数据需求高、安全性差，后者需要精确成本函数设计和局部最优的问题。

Method: 提出 Q-STAC 框架，利用约束的 Stein 变分梯度下降（SVGD）整合贝叶斯 MPC 和 actor-critic 强化学习，以学习的 Q 值为目标优化控制序列。

Result: 在 2D 导航和机器人操作任务中，Q-STAC 表现优于现有算法，具有更高的样本效率、鲁棒性和最优性。

Conclusion: Q-STAC 通过结合贝叶斯 MPC 和 actor-critic 强化学习的优势，实现了高效、安全和鲁棒的控制。

Abstract: Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac

</details>


### [133] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

Key words: 人形机器人,模仿学习,轨迹评估,元评估器,人类-机器人交互

TL;DR: 提出一种评估模仿学习方法的框架，通过轨迹性能衡量质量，并设计NeME深度学习模型作为元评估器，验证其在人形机器人上的有效性。

<details>
  <summary>Details</summary>

Main category: cs.RO

Motivation: 现有评估方法难以复现且无法全面捕捉机器人运动轨迹的复杂性，尤其在人类-机器人交互与合作中。

Method: 提出通用评估框架，利用NeME模型从机器人关节轨迹中分类动作，比较控制策略性能，避免人为干预。

Result: 实验表明，该方法与机器人的成功率更一致，提供了可复现且系统化的多模态模仿学习方法性能比较手段。

Conclusion: 该框架为复杂HRI任务中的模仿学习方法提供了更全面、可靠的性能评估标准。

Abstract: Evaluating and comparing the performance of autonomous Humanoid Robots is
challenging, as success rate metrics are difficult to reproduce and fail to
capture the complexity of robot movement trajectories, critical in Human-Robot
Interaction and Collaboration (HRIC). To address these challenges, we propose a
general evaluation framework that measures the quality of Imitation Learning
(IL) methods by focusing on trajectory performance. We devise the Neural Meta
Evaluator (NeME), a deep learning model trained to classify actions from robot
joint trajectories. NeME serves as a meta-evaluator to compare the performance
of robot control policies, enabling policy evaluation without requiring human
involvement in the loop. We validate our framework on ergoCub, a humanoid
robot, using teleoperation data and comparing IL methods tailored to the
available platform. The experimental results indicate that our method is more
aligned with the success rate obtained on the robot than baselines, offering a
reproducible, systematic, and insightful means for comparing the performance of
multimodal imitation learning approaches in complex HRI tasks.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [134] [Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control](https://arxiv.org/abs/2507.07034)
*Mikael Vaillant,Victor Oliveira Ferreira,Wiebke Mainville,Jean-Michel Lamarre,Vincent Raymond,Moncef Chioua,Bruno Blais*

Key words: 替代模型, 努塞尔数, 冲击射流, CNN, 热管理

TL;DR: 该研究提出了一个替代模型，用于预测封闭式冲击射流阵列中的努塞尔数分布，适用于实时温度控制等应用。

<details>
  <summary>Details</summary>

Main category: physics.flu-dyn

Motivation: 由于计算流体动力学（CFD）模拟成本高，无法满足实时应用需求，因此需要开发一种快速预测努塞尔数分布的模型。

Method: 通过基于CNN的替代模型，利用隐式大涡模拟（Re < 2,000）数据训练两种不同射流阵列模型，并引入基于相关性的缩放方法扩展至高雷诺数（Re < 10,000）。

Result: 替代模型精度高，五乘一阵列的归一化平均误差低于2%，三乘三阵列的误差为0.6%，实验验证了模型的预测能力。

Conclusion: 该研究为先进热管理应用中的模型控制策略奠定了基础。

Abstract: This study presents a surrogate model designed to predict the Nusselt number
distribution in an enclosed impinging jet arrays, where each jet function
independently and where jets can be transformed from inlets to outlets, leading
to a vast number of possible flow arrangements. While computational fluid
dynamics (CFD) simulations can model heat transfer with high fidelity, their
cost prohibits real-time application such as model-based temperature control.
To address this, we generate a CNN-based surrogate model that can predict the
Nusselt distribution in real time. We train it with data from implicit large
eddy computational fluid dynamics simulations (Re < 2,000). We train two
distinct models, one for a five by one array of jets (83 simulations) and one
for a three by three array of jets (100 simulations). We introduce a method to
extrapolate predictions to higher Reynolds numbers (Re < 10,000) using a
correlation-based scaling. The surrogate models achieve high accuracy, with a
normalized mean average error below 2% on validation data for the five by one
surrogate model and 0.6% for the three by three surrogate model. Experimental
validation confirms the model's predictive capabilities. This work provides a
foundation for model-based control strategies in advanced thermal management
applications.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [135] [Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity](https://arxiv.org/abs/2507.06479)
*Niloofar Asefi,Leonard Lupin-Jimenez,Tianning Wu,Ruoying He,Ashesh Chattopadhyay*

Key words: 深度学习, 海洋动力学, 数据同化, 神经算子, DDPMs

TL;DR: 论文提出了一种结合神经算子和去噪扩散概率模型（DDPMs）的深度学习框架，用于从极其稀疏的拉格朗日观测数据中重建高分辨率海洋状态。

<details>
  <summary>Details</summary>

Main category: physics.ao-ph

Motivation: 传统的数据同化方法和深度学习模型在观测数据稀疏、不规则的情况下，难以恢复中尺度湍流等关键海洋现象。

Method: 利用神经算子和去噪扩散概率模型（DDPMs）结合的深度学习框架，通过生成模型捕捉小尺度、高波数动态。

Result: 在合成数据和真实卫星观测数据上，即使在99%和99.9%的稀疏度下，框架仍能准确重建高分辨率海洋状态。

Conclusion: 该方法在空间采样严重受限的情况下表现出色，优于其他深度学习基线。

Abstract: Reconstructing ocean dynamics from observational data is fundamentally
limited by the sparse, irregular, and Lagrangian nature of spatial sampling,
particularly in subsurface and remote regions. This sparsity poses significant
challenges for forecasting key phenomena such as eddy shedding and rogue waves.
Traditional data assimilation methods and deep learning models often struggle
to recover mesoscale turbulence under such constraints. We leverage a deep
learning framework that combines neural operators with denoising diffusion
probabilistic models (DDPMs) to reconstruct high-resolution ocean states from
extremely sparse Lagrangian observations. By conditioning the generative model
on neural operator outputs, the framework accurately captures small-scale,
high-wavenumber dynamics even at $99\%$ sparsity (for synthetic data) and
$99.9\%$ sparsity (for real satellite observations). We validate our method on
benchmark systems, synthetic float observations, and real satellite data,
demonstrating robust performance under severe spatial sampling limitations as
compared to other deep learning baselines.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [136] [Machine Learning based Enterprise Financial Audit Framework and High Risk Identification](https://arxiv.org/abs/2507.06266)
*Tingyu Yuan,Xi Zhang,Xuanjing Chen*

Key words: 财务审计, 机器学习, 随机森林, 欺诈检测, 合规管理

TL;DR: 本文提出了一种基于AI的企业财务审计和高风险识别框架，利用机器学习提高效率和准确性。通过支持向量机（SVM）、随机森林（RF）和K近邻（KNN）算法比较，随机森林表现最佳，F1分数为0.9012。研究发现审计频率、历史违规、员工工作量等是关键预测因素。

<details>
  <summary>Details</summary>

Main category: q-fin.RM

Motivation: 面对全球经济不确定性，传统手动审计方法在大数据、复杂业务结构和欺诈手段变化下效率不足，需要AI驱动的解决方案。

Method: 使用来自四大会计公司（2020-2025）的数据集，结合SVM、RF和KNN算法，通过分层K折交叉验证和F1分数等指标评估模型性能。

Result: 随机森林表现最优，F1分数为0.9012，能有效识别欺诈和合规异常。审计频率、历史违规等是关键预测因素。

Conclusion: 建议采用随机森林作为核心模型，并实施实时风险监控，为现代企业的智能审计和风险管理提供有力支持。

Abstract: In the face of global economic uncertainty, financial auditing has become
essential for regulatory compliance and risk mitigation. Traditional manual
auditing methods are increasingly limited by large data volumes, complex
business structures, and evolving fraud tactics. This study proposes an
AI-driven framework for enterprise financial audits and high-risk
identification, leveraging machine learning to improve efficiency and accuracy.
Using a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)
from 2020 to 2025, the research examines trends in risk assessment, compliance
violations, and fraud detection. The dataset includes key indicators such as
audit project counts, high-risk cases, fraud instances, compliance breaches,
employee workload, and client satisfaction, capturing both audit behaviors and
AI's impact on operations. To build a robust risk prediction model, three
algorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest
Neighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex
classification, RF combines decision trees to manage high-dimensional,
nonlinear data with resistance to overfitting, and KNN applies distance-based
learning for flexible performance. Through hierarchical K-fold cross-validation
and evaluation using F1-score, accuracy, and recall, Random Forest achieves the
best performance, with an F1-score of 0.9012, excelling in identifying fraud
and compliance anomalies. Feature importance analysis reveals audit frequency,
past violations, employee workload, and client ratings as key predictors. The
study recommends adopting Random Forest as a core model, enhancing features via
engineering, and implementing real-time risk monitoring. This research
contributes valuable insights into using machine learning for intelligent
auditing and risk management in modern enterprises.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [137] [Neural Actor-Critic Methods for Hamilton-Jacobi-Bellman PDEs: Asymptotic Analysis and Numerical Studies](https://arxiv.org/abs/2507.06428)
*Samuel N. Cohen,Jackson Hebner,Deqing Jiang,Justin Sirignano*

Key words: HJB方程, 演员-评论家算法, 神经网络, 随机控制, 高维问题

TL;DR: 论文研究了一种用于求解高维HJB方程的演员-评论家机器学习算法，证明了其训练动态收敛于无限维ODE，并在数值实验中验证了其在200维问题中的有效性。

<details>
  <summary>Details</summary>

Main category: math.OC

Motivation: 提出一种能够高效求解高维HJB方程的演员-评论家算法，以解决有限宽度神经网络可能陷入局部最优的问题。

Method: 设计了满足边界条件的评论家网络结构，使用偏向梯度降低计算成本；演员网络通过最小化哈密顿量积分来训练。

Result: 证明了网络训练动态收敛于无限维ODE，且在哈密顿量凸性假设下，固定点对应原问题解；数值实验表明算法可解决200维问题。

Conclusion: 该算法在高维HJB方程求解中表现优异，但需进一步研究如何处理非凸哈密顿量的挑战。

Abstract: We mathematically analyze and numerically study an actor-critic machine
learning algorithm for solving high-dimensional Hamilton-Jacobi-Bellman (HJB)
partial differential equations from stochastic control theory. The architecture
of the critic (the estimator for the value function) is structured so that the
boundary condition is always perfectly satisfied (rather than being included in
the training loss) and utilizes a biased gradient which reduces computational
cost. The actor (the estimator for the optimal control) is trained by
minimizing the integral of the Hamiltonian over the domain, where the
Hamiltonian is estimated using the critic. We show that the training dynamics
of the actor and critic neural networks converge in a Sobolev-type space to a
certain infinite-dimensional ordinary differential equation (ODE) as the number
of hidden units in the actor and critic $\rightarrow \infty$. Further, under a
convexity-like assumption on the Hamiltonian, we prove that any fixed point of
this limit ODE is a solution of the original stochastic control problem. This
provides an important guarantee for the algorithm's performance in light of the
fact that finite-width neural networks may only converge to a local minimizers
(and not optimal solutions) due to the non-convexity of their loss functions.
In our numerical studies, we demonstrate that the algorithm can solve
stochastic control problems accurately in up to 200 dimensions. In particular,
we construct a series of increasingly complex stochastic control problems with
known analytic solutions and study the algorithm's numerical performance on
them. These problems range from a linear-quadratic regulator equation to highly
challenging equations with non-convex Hamiltonians, allowing us to identify and
analyze the strengths and limitations of this neural actor-critic method for
solving HJB equations.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [138] [Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing](https://arxiv.org/abs/2507.06608)
*Xiaoxiang Shi,Colin Cai,Junjia Du,Zhanda Zhu,Xingda Wei,Zhihao Jia*

Key words: 预填充-解码、GPU资源分配、动态解耦、Nexus系统

TL;DR: 当前预填充-解码（PD）解耦通常部署在服务引擎级别，将预填充和解码阶段分配给不同的GPU。为了提高GPU利用率，Chunked Prefill将预填充和解码请求混合在同一批次中，但引入了阶段干扰。本文提出在单个GPU内动态分配资源以实现解耦，显著提升性能。

<details>
  <summary>Details</summary>

Main category: cs.DC

Motivation: 现有PD解耦方案在多GPU间分离预填充和解码阶段，但硬件需求高。本研究探索是否能在单个服务引擎内实现类似解耦，以更高效地利用GPU资源。

Method: 通过分析预填充和解码请求的资源需求差异，发现GPU资源分配的饱和点，从而在单个GPU内动态分配资源。

Result: 系统Nexus在多种模型和工作负载下表现优异，吞吐量提升2.2倍，TTFT降低20倍，TBT降低2.5倍，且仅用一半GPU即超越vLLM。

Conclusion: 在单个GPU内动态分配资源可有效解耦预填充和解码阶段，显著提升性能并减少硬件需求。

Abstract: Current prefill-decode (PD) disaggregation is typically deployed at the level
of entire serving engines, assigning separate GPUs to handle prefill and decode
phases. While effective at reducing latency, this approach demands more
hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode
requests within the same batch, but introduces phase interference between
prefill and decode.
  While existing PD disaggregation solutions separate the phases across GPUs,
we ask: can the same decoupling be achieved within a single serving engine? The
key challenge lies in managing the conflicting resource requirements of prefill
and decode when they share the same hardware. In this paper, we first show that
chunked prefill requests cause interference with decode requests due to their
distinct requirements for GPU resources. Second, we find that GPU resources
exhibit diminishing returns. Beyond a saturation point, increasing GPU
allocation yields negligible latency improvements. This insight enables us to
split a single GPU's resources and dynamically allocate them to prefill and
decode on the fly, effectively disaggregating the two phases within the same
GPU.
  Across a range of models and workloads, our system Nexus achieves up to 2.2x
higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also
outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x
lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using
only half the number of GPUs.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [139] [Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation](https://arxiv.org/abs/2507.06249)
*Saierdaer Yusuyin,Te Ma,Hao Huang,Zhijian Ou*

Key words: 跨语言语音识别，潜在变量模型，音素监督，JSA算法，语言域适应

TL;DR: 论文提出了一种基于潜在变量模型的方法（JSA-SPG），通过消除发音词典的需求，改进了跨语言语音识别。该方法结合了语音到音素（S2P）、音素到字形（P2G）和字形到音素（G2P）模型，并使用联合随机逼近（JSA）算法进行训练。

<details>
  <summary>Details</summary>

Main category: eess.AS

Motivation: 现有的音素监督预训练模型虽然在跨语言语音识别中表现出色，但依赖发音词典。本研究旨在消除这一限制。

Method: 提出JSA-SPG方法，包括S2P、P2G和G2P模型，使用JSA算法联合训练以优化离散潜在变量模型。

Result: 在波兰语和印尼语的实验中，仅需10分钟音素监督，JSA-SPG比最佳跨语言微调方法的错误率降低了5%，在语言域适应中错误率降低9%。

Conclusion: JSA-SPG方法无需发音词典，显著提升了跨语言语音识别的性能，特别是在数据有限的情况下。

Abstract: Recently, pre-trained models with phonetic supervision have demonstrated
their advantages for crosslingual speech recognition in data efficiency and
information sharing across languages. However, a limitation is that a
pronunciation lexicon is needed for such phoneme-based crosslingual speech
recognition. In this study, we aim to eliminate the need for pronunciation
lexicons and propose a latent variable model based method, with phonemes being
treated as discrete latent variables. The new method consists of a
speech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a
grapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model.
To jointly train the three models, we utilize the joint stochastic
approximation (JSA) algorithm, which is a stochastic extension of the EM
(expectation-maximization) algorithm and has demonstrated superior performance
particularly in estimating discrete latent variable models. Based on the
Whistle multilingual pre-trained S2P model, crosslingual experiments are
conducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of
phoneme supervision, the new method, JSA-SPG, achieves 5\% error rate
reductions compared to the best crosslingual fine-tuning approach using subword
or full phoneme supervision. Furthermore, it is found that in language domain
adaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms
the standard practice of language model fusion via the auxiliary support of the
G2P model by 9% error rate reductions. To facilitate reproducibility and
encourage further exploration in this field, we open-source the JSA-SPG
training code and complete pipeline.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [140] [Trainability of Quantum Models Beyond Known Classical Simulability](https://arxiv.org/abs/2507.06344)
*Sabri Meyer,Francesco Scala,Francesco Tacchino,Aurelien Lucchi*

Key words: 变分量子算法、贫瘠高原、线性克利福德编码器、计算复杂性、量子优势

TL;DR: 本文探讨了变分量子算法（VQAs）的可训练性与计算复杂性之间的关系，提出了一种称为线性克利福德编码器（LCE）的新技术，旨在避免梯度消失的问题，并揭示了计算复杂性的相变现象。

<details>
  <summary>Details</summary>

Main category: quant-ph

Motivation: VQAs是近期量子计算的有力候选者，但其面临梯度随系统尺寸指数级消失（称为“贫瘠高原”）的问题，且有猜想认为避免贫瘠高原可能导致经典可模拟性。本文旨在深化对VQAs可训练性与计算复杂性关系的理解。

Method: 引入了线性克利福德编码器（LCE），并在优化景观区域中结合经典泰勒替代方法，分析了计算复杂性的相变现象。

Result: 理论证明在无经典替代方法存在的区域可以避免贫瘠高原，并通过数值实验证实了存在一个超多项式复杂性的“过渡区”。

Conclusion: 研究为设计可避免贫瘠高原且具有量子优势的变分模型提供了可能路径。

Abstract: Variational Quantum Algorithms (VQAs) are promising candidates for near-term
quantum computing, yet they face scalability challenges due to barren plateaus,
where gradients vanish exponentially in the system size. Recent conjectures
suggest that avoiding barren plateaus might inherently lead to classical
simulability, thus limiting the opportunities for quantum advantage. In this
work, we advance the theoretical understanding of the relationship between the
trainability and computational complexity of VQAs, thus directly addressing the
conjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique
that ensures constant-scaling gradient statistics on optimization landscape
regions that are close to Clifford circuits. Additionally, we leverage
classical Taylor surrogates to reveal computational complexity phase
transitions from polynomial to super-polynomial as the initialization region
size increases. Combining these results, we reveal a deeper link between
trainability and computational complexity, and analytically prove that barren
plateaus can be avoided in regions for which no classical surrogate is known to
exist. Furthermore, numerical experiments on LCE transformed landscapes confirm
in practice the existence of a super-polynomially complex ``transition zone''
where gradients decay polynomially. These findings indicate a plausible path to
practically relevant, barren plateau-free variational models with potential for
quantum advantage.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [141] [Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice](https://arxiv.org/abs/2507.06235)
*Yuto Mandai,Katie Seaborn,Tomoyasu Nakano,Xin Sun,Yijia Wang,Jun Kato*

Key words: kawaii, vocalics, text-to-speech, game character voices, fundamental frequency, formant frequencies

TL;DR: 本文通过四阶段研究探索了声音中的可爱元素及其操纵方法，填补了对可爱声音研究的空白。

<details>
  <summary>Details</summary>

Main category: cs.HC

Motivation: 研究‘kawaii’声音的科学，特别是计算机声音中的可爱感知，以往研究集中在视觉方面。

Method: 使用文本转语音（TTS）和游戏角色声音，通过操纵基频和共振峰频率，进行四阶段研究（N = 512）。

Result: 发现了某些声音的可爱‘甜点’以及可爱感知的天花板效应。

Conclusion: 初步验证了可爱声音模型，并提供了操纵计算机声音可爱感知的基本方法。

Abstract: "Kawaii" is the Japanese concept of cute, which carries sociocultural
connotations related to social identities and emotional responses. Yet,
virtually all work to date has focused on the visual side of kawaii, including
in studies of computer agents and social robots. In pursuit of formalizing the
new science of kawaii vocalics, we explored what elements of voice relate to
kawaii and how they might be manipulated, manually and automatically. We
conducted a four-phase study (grand N = 512) with two varieties of computer
voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet
spots" through manipulation of fundamental and formant frequencies, but only
for certain voices and to a certain extent. Findings also suggest a ceiling
effect for the kawaii vocalics of certain voices. We offer empirical validation
of the preliminary kawaii vocalics model and an elementary method for
manipulating kawaii perceptions of computer voice.

</details>


### [142] [Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents](https://arxiv.org/abs/2507.06483)
*Zackary Rackauckas,Julia Hirschberg*

Key words: 风格化代理, 语音代理, 语言学习, 用户体验, 人机交互

TL;DR: 研究探讨了风格化、有声代理在多模态语言学习环境中如何影响用户互动，发现代理设计显著影响用户体验、动机和学习策略。

<details>
  <summary>Details</summary>

Main category: cs.HC

Motivation: 探索风格化和有声代理在语言学习中对用户互动的影响，特别是在不同语言水平和文化背景下的效果。

Method: 对54名参与者进行混合方法评估，使用基于大型语言模型和文本转语音合成的动漫风格代理，分析用户互动模式。

Result: 代理设计（如声音、人设和语言风格）显著影响用户体验、动机和学习策略。

Conclusion: 研究为设计更具吸引力和社会响应性的系统提供了指导。

Abstract: This study investigates how stylized, voiced agents shape user interaction in
a multimodal language learning environment. We conducted a mixed-methods
evaluation of 54 participants interacting with anime-inspired characters
powered by large language models and expressive text-to-speech synthesis. These
agents responded in Japanese character language, offering users asynchronous,
semi-structured conversation in varying speech styles and emotional tones. We
analyzed user engagement patterns, perceived usability, emotional responses,
and learning behaviors, with particular attention to how agent stylization
influenced interaction across language proficiency levels and cultural
backgrounds. Our findings reveal that agent design, especially voice, persona,
and linguistic style, substantially affected user experience, motivation, and
strategy. This work contributes to the understanding of affective, culturally
stylized agents in human-agent interaction and offers guidance for designing
more engaging, socially responsive systems.

</details>


### [143] [Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool](https://arxiv.org/abs/2507.06734)
*Milena Pustet,Elisabeth Steffen,Helena Mihaljević,Grischa Stanjek,Yannis Illies*

Key words: CSO, harmful content, AI, open-source, Telegram, collaboration

TL;DR: CSOs在监测有害在线内容中的作用日益重要，AI工具可大规模辅助检测，但目前缺乏开源工具整合AI模型与社交媒体监测基础设施。研究探讨如何让CSO主动参与AI开源工具的开发，而非被动使用。

<details>
  <summary>Details</summary>

Main category: cs.HC

Motivation: 随着平台减少内容审核投资，CSOs在监测有害内容中的作用变得关键。然而，开源工具与AI模型的整合不足，CSO与开源社区、学术界的合作也较少，导致研究成果难以转化为实用工具。

Method: 通过与CSO合作，开发AI辅助的开源监测工具，用于反民主运动的Telegram监测，探索CSO在工具开发中的主动参与方式。

Result: 研究正在进行中，旨在开发一个能让CSO积极参与的工具，确保其符合利益相关者的需求和价值观。

Conclusion: CSO应作为合作伙伴而非被动用户参与技术工具的共同开发，以确保工具的实际可用性和有效性。

Abstract: The role of civil society organizations (CSOs) in monitoring harmful online
content is increasingly crucial, especially as platform providers reduce their
investment in content moderation. AI tools can assist in detecting and
monitoring harmful content at scale. However, few open-source tools offer
seamless integration of AI models and social media monitoring infrastructures.
Given their thematic expertise and contextual understanding of harmful content,
CSOs should be active partners in co-developing technological tools, providing
feedback, helping to improve models, and ensuring alignment with stakeholder
needs and values, rather than as passive 'consumers'. However, collaborations
between the open source community, academia, and civil society remain rare, and
research on harmful content seldom translates into practical tools usable by
civil society actors. This work in progress explores how CSOs can be
meaningfully involved in an AI-assisted open-source monitoring tool of
anti-democratic movements on Telegram, which we are currently developing in
collaboration with CSO stakeholders.

</details>


### [144] [Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding](https://arxiv.org/abs/2507.06779)
*Martin Wimpff,Jan Zerfowski,Bin Yang*

Key words: 深度学习, 脑机接口, 实时解码, 无源域适应, 计算复杂度

TL;DR: RAP是一种新方法，解决了深度学习在实时脑机接口应用中的三大挑战，实现了无用户校准的实时跨主体解码。

<details>
  <summary>Details</summary>

Main category: cs.HC

Motivation: 解决深度学习在实时脑机接口应用中的三大挑战：离线到在线的过渡困难、计算复杂度高以及训练数据稀缺。

Method: 引入实时自适应池化（RAP），通过修改现有离线模型的池化层、降低计算复杂度，并利用无源域适应减少数据需求。

Result: RAP为实时BCI应用提供了高效框架，保护隐私、减少校准需求，支持协同自适应系统。

Conclusion: RAP为深度学习在在线BCI中的广泛应用奠定了基础，促进了用户中心和高效反馈的BCI系统发展。

Abstract: Despite the growing success of deep learning (DL) in offline brain-computer
interfaces (BCIs), its adoption in real-time applications remains limited due
to three primary challenges. First, most DL solutions are designed for offline
decoding, making the transition to online decoding unclear. Second, the use of
sliding windows in online decoding substantially increases computational
complexity. Third, DL models typically require large amounts of training data,
which are often scarce in BCI applications. To address these challenges and
enable real-time, cross-subject decoding without subject-specific calibration,
we introduce realtime adaptive pooling (RAP), a novel parameter-free method.
RAP seamlessly modifies the pooling layers of existing offline DL models to
meet online decoding requirements. It also reduces computational complexity
during training by jointly decoding consecutive sliding windows. To further
alleviate data requirements, our method leverages source-free domain
adaptation, enabling privacy-preserving adaptation across varying amounts of
target data. Our results demonstrate that RAP provides a robust and efficient
framework for real-time BCI applications. It preserves privacy, reduces
calibration demands, and supports co-adaptive BCI systems, paving the way for
broader adoption of DL in online BCIs. These findings lay a strong foundation
for developing user-centered, high-performance BCIs that facilitate immediate
feedback and user learning.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [145] [Prediction-Augmented Mechanism Design for Weighted Facility Location](https://arxiv.org/abs/2507.06509)
*Yangguang Shi,Zhenyu Xue*

Key words: 设施选址,策略证明机制,加权设置,一致性,鲁棒性

TL;DR: 论文提出了一种针对加权设施选址问题的预测增强算法框架，通过代表性实例的映射技术，平衡策略证明机制在一致性与鲁棒性之间的权衡。

<details>
  <summary>Details</summary>

Main category: cs.DS

Motivation: 传统设施选址研究多假设代理权重相同，但实际场景中代理权重可能不均，因此需要研究加权设施选址问题。本文旨在解决加权环境下策略证明机制的一致性与鲁棒性平衡问题。

Method: 通过代表性实例的映射技术，设计了一个策略证明机制框架。具体通过参数c调整一致性与鲁棒性之间的权衡，并给出了数学证明。

Result: 证明了在加权设置下，存在一个策略证明机制，能够实现有界的一致性和鲁棒性保证，并指出在完全预测的情况下，无法达到1-一致性和O(n·W_max/W_min)-鲁棒性。

Conclusion: 本文为加权设施选址问题提供了新的算法框架，解决了传统方法的局限性，并通过理论证明了其在一致性与鲁棒性上的性能界限。

Abstract: Facility location is fundamental in operations research, mechanism design,
and algorithmic game theory, with applications ranging from urban
infrastructure planning to distributed systems. Recent research in this area
has focused on augmenting classic strategyproof mechanisms with predictions to
achieve an improved performance guarantee against the uncertainty under the
strategic environment. Previous work has been devoted to address the trade-off
obstacle of balancing the consistency (near-optimality under accurate
predictions) and robustness (bounded inefficiency under poor predictions)
primarily in the unweighted setting, assuming that all agents have the same
importance. However, this assumption may not be true in some practical
scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction
augmented algorithmic framework for balancing the consistency and robustness
over strategic agents with non-uniform weights. In particular, through a
reduction technique that identifies a subset of \emph{representative} instances
and maps the other given locations to the representative ones, we prove that
there exists a \emph{strategyproof} mechanism achieving a bounded consistency
guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$
and a bounded robustness guarantee of
$\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted
settings, where $c$ can be viewed as a parameter to make a trade-off between
the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum
and maximum agents' weight. We also proved that there is no strategyproof
deterministic mechanism that reach $1$-consistency and $O\left( n \cdot
\frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully
predictions of all agents.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [146] [DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning](https://arxiv.org/abs/2507.07060)
*Shreyas Vinaya Sathyanarayana,Rahil Shah,Sharanabasava D. Hiremath,Rishikesh Panda,Rahul Jana,Riya Singh,Rida Irfan,Ashwin Murali,Bharath Ramsundar*

Key words: 逆合成,LLM,DeepRetro,模板方法,人类反馈

TL;DR: DeepRetro是一个结合传统模板方法和LLM生成能力的开源框架，通过迭代反馈和人类专家介入，提升逆合成分析的多样性和准确性。

<details>
  <summary>Details</summary>

Main category: q-bio.QM

Motivation: 当前逆合成分析受限于预定义模板，难以发现新路径；LLM虽有潜力，但多步规划和有效性验证仍未解决。

Method: DeepRero结合模板引擎和LLM生成建议，通过多步骤反馈循环和严格验证（有效性、稳定性、幻觉检查），辅以人类专家交互界面优化路径。

Result: 实验证明该框架能生成可行且新颖的逆合成路径，适用于复杂天然产物合成。

Conclusion: 迭代LLM推理结合人类反馈可推动复杂化学合成的前沿进展。

Abstract: Retrosynthesis, the identification of precursor molecules for a target
compound, is pivotal for synthesizing complex molecules, but faces challenges
in discovering novel pathways beyond predefined templates. Recent large
language model (LLM) approaches to retrosynthesis have shown promise but
effectively harnessing LLM reasoning capabilities for effective multi-step
planning remains an open question. To address this challenge, we introduce
DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic
framework. Our approach integrates the strengths of conventional
template-based/Monte Carlo tree search tools with the generative power of LLMs
in a step-wise, feedback-driven loop. Initially, synthesis planning is
attempted with a template-based engine. If this fails, the LLM subsequently
proposes single-step retrosynthetic disconnections. Crucially, these
suggestions undergo rigorous validity, stability, and hallucination checks
before the resulting precursors are recursively fed back into the pipeline for
further evaluation. This iterative refinement allows for dynamic pathway
exploration and correction. We demonstrate the potential of this pipeline
through benchmark evaluations and case studies, showcasing its ability to
identify viable and potentially novel retrosynthetic routes. In particular, we
develop an interactive graphical user interface that allows expert human
chemists to provide human-in-the-loop feedback to the reasoning algorithm. This
approach successfully generates novel pathways for complex natural product
compounds, demonstrating the potential for iterative LLM reasoning to advance
state-of-art in complex chemical syntheses.

</details>


### [147] [Self-supervised learning predicts plant growth trajectories from multi-modal industrial greenhouse data](https://arxiv.org/abs/2507.06336)
*Adam J Riesselman,Evan M Cofer,Therese LaRue,Wim Meeussen*

Key words: 植物表型, 机器人自动化, 机器学习, 农业, 生长预测

TL;DR: 该论文提出了一种基于移动机器人平台和自监督建模的方法，用于量化植物生长表型，并预测作物未来高度和收获质量，为农学研究和生产效率提供了实用见解。

<details>
  <summary>Details</summary>

Main category: q-bio.QM

Motivation: 量化植物生长表型和生物量积累对于理解农艺性状和优化作物生产至关重要，但目前大规模的植物生长数据难以获取。

Method: 使用移动机器人平台采集高分辨率的环境传感和表型测量数据，并通过自监督建模方法构建从观测数据到完整生长轨迹的映射。

Result: 成功预测了作物未来的高度和收获质量。

Conclusion: 该方法结合了机器人自动化和机器学习，为农学研究提供了可操作的见解，并提高了运营效率。

Abstract: Quantifying organism-level phenotypes, such as growth dynamics and biomass
accumulation, is fundamental to understanding agronomic traits and optimizing
crop production. However, quality growing data of plants at scale is difficult
to generate. Here we use a mobile robotic platform to capture high-resolution
environmental sensing and phenotyping measurements of a large-scale hydroponic
leafy greens system. We describe a self-supervised modeling approach to build a
map from observed growing data to the entire plant growth trajectory. We
demonstrate our approach by forecasting future plant height and harvest mass of
crops in this system. This approach represents a significant advance in
combining robotic automation and machine learning, as well as providing
actionable insights for agronomic research and operational efficiency.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [148] [The Emotional Alignment Design Policy](https://arxiv.org/abs/2507.06263)
*Eric Schwitzgebel,Jeff Sebo*

Key words: 情感对齐,人工实体,道德地位,用户反应,设计政策

TL;DR: 情感对齐设计政策主张人工实体的设计应引发用户与其能力和道德地位相称的情感反应，但实施面临多项挑战。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 探讨如何设计人工实体以引发用户与其道德地位和能力匹配的情感反应，避免过度或不足的情感反应。

Method: 提出情感对齐设计政策，指出两种可能的违规方式：过度反应或不足反应，以及错误类型的反应。

Result: 尽管理论吸引人，实际应用面临多项挑战，如尊重用户自主权、处理专家与公众分歧、道德实体存废问题等。

Conclusion: 情感对齐设计政策虽理想，但需平衡多种因素，如用户态度修改与适应、道德实体问题等。

Abstract: According to what we call the Emotional Alignment Design Policy, artificial
entities should be designed to elicit emotional reactions from users that
appropriately reflect the entities' capacities and moral status, or lack
thereof. This principle can be violated in two ways: by designing an artificial
system that elicits stronger or weaker emotional reactions than its capacities
and moral status warrant (overshooting or undershooting), or by designing a
system that elicits the wrong type of emotional reaction (hitting the wrong
target). Although presumably attractive, practical implementation faces several
challenges including: How can we respect user autonomy while promoting
appropriate responses? How should we navigate expert and public disagreement
and uncertainty about facts and values? What if emotional alignment seems to
require creating or destroying entities with moral status? To what extent
should designs conform to versus attempt to alter user assumptions and
attitudes?

</details>


### [149] [A Collectivist, Economic Perspective on AI](https://arxiv.org/abs/2507.06268)
*Michael I. Jordan*

Key words: 信息技术, 社会智能, 系统设计, 社会福祉, 以人为中心工程

TL;DR: 论文呼吁将社会和经济概念与计算概念结合，以设计以社会福祉为核心的技术系统，推动以人为中心的工程领域发展。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 当前信息技术发展以人类认知为基准，忽视了社会文化对智能的贡献，且技术的社会影响常被忽略。

Method: 提出将经济和社会概念与计算和推理概念深度融合，以系统级设计为核心。

Result: 有望形成以人为中心的新工程领域，社会福祉成为技术设计的首要考虑。

Conclusion: 未来技术发展需重视社会文化因素，确保社会福祉在系统设计中占据核心地位。

Abstract: Information technology is in the midst of a revolution in which omnipresent
data collection and machine learning are impacting the human world as never
before. The word "intelligence" is being used as a North Star for the
development of this technology, with human cognition viewed as a baseline. This
view neglects the fact that humans are social animals, and that much of our
intelligence is social and cultural in origin. A related issue is that the
current view treats the social consequences of technology as an afterthought.
The path forward is not merely more data and compute, and not merely more
attention paid to cognitive or symbolic representations, but a thorough
blending of economic and social concepts with computational and inferential
concepts, in the service of system-level designs in which social welfare is a
first-class citizen, and with the aspiration that a new human-centric
engineering field will emerge.

</details>


### [150] [The Prompt War: How AI Decides on a Military Intervention](https://arxiv.org/abs/2507.06277)
*Maxim Chupilkin*

Key words: AI, military intervention, conjoint experiment, domestic support, probability of success

TL;DR: 论文研究了决定AI军事干预倾向的关键因素，通过实验发现国内支持和胜利概率是最大预测因素，而成本因素影响较小。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 随着AI在军事规划和战争游戏中的应用快速增长，目前尚未对模型中关键驱动因素进行系统分析，填补这一研究空白。

Method: 采用联合实验，设计了640个情景，每个情景运行100次，系统探讨AI在军事干预中的决策行为。

Result: 发现国内支持和胜利概率是AI决定干预的最强预测因素，成本因素（如国际谴责、军事和平民死亡等）影响较小。结果在不同模型间一致。

Conclusion: AI在军事干预决策中表现出稳定模式，国内支持和胜利概率起主导作用。

Abstract: Which factors determine AI propensity for military intervention? While the
use of AI in war games and military planning is growing exponentially, the
simple analysis of key drivers embedded in the models has not yet been done.
This paper does a simple conjoint experiment proposing a model to decide on
military intervention in 640 vignettes where each was run for 100 times
allowing to explore AI decision on military intervention systematically. The
analysis finds that largest predictors of AI decision to intervene are high
domestic support and high probability of success. Costs such as international
condemnation, military deaths, civilian deaths, and negative economic effect
are statistically significant, but their effect is around half of domestic
support and probability of victory. Closing window of opportunity only reaches
statistical significance in interaction with other factors. The results are
remarkably consistent across scenarios and across different models (OpenAI GPT,
Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.

</details>


### [151] [Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles](https://arxiv.org/abs/2507.06310)
*Yongchao Zeng,Calum Brown,Mark Rounsevell*

Key words: LLM agents, 社交模拟, 模型抽象, 核心困境, 现实主义

TL;DR: LLM agents在社交模拟中虽然能增强真实性，但可能过于人性化，与建模的抽象、简化和可解释性要求存在冲突，导致核心困境。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 探讨LLM在社交模拟中的适用性，揭示其与建模核心原则的不兼容性，并提出更合适的应用场景。

Method: 通过将Bass扩散模型转换为基于LLM的变体，识别出五个核心困境。

Result: LLM agents可能陷入‘恐怖谷’，既不够抽象以清晰展示机制，也不够真实以模拟人类行为。

Conclusion: LLM agents更适合非系统级涌现、重视语言细微差别、自然时间交互及稳定角色身份的场景。

Abstract: Large language models (LLMs) have been increasingly used to build agents in
social simulation because of their impressive abilities to generate fluent,
contextually coherent dialogues. Such abilities can enhance the realism of
models. However, the pursuit of realism is not necessarily compatible with the
epistemic foundation of modelling. We argue that LLM agents, in many regards,
are too human to model: they are too expressive, detailed and intractable to be
consistent with the abstraction, simplification, and interpretability typically
demanded by modelling. Through a model-building thought experiment that
converts the Bass diffusion model to an LLM-based variant, we uncover five core
dilemmas: a temporal resolution mismatch between natural conversation and
abstract time steps; the need for intervention in conversations while avoiding
undermining spontaneous agent outputs; the temptation to introduce rule-like
instructions in prompts while maintaining conversational naturalness; the
tension between role consistency and role evolution across time; and the
challenge of understanding emergence, where system-level patterns become
obscured by verbose micro textual outputs. These dilemmas steer the LLM agents
towards an uncanny valley: not abstract enough to clarify underlying social
mechanisms, while not natural enough to represent realistic human behaviour.
This exposes an important paradox: the realism of LLM agents can obscure,
rather than clarify, social dynamics when misapplied. We tease out the
conditions in which LLM agents are ideally suited: where system-level emergence
is not the focus, linguistic nuances and meaning are central, interactions
unfold in natural time, and stable role identity is more important than
long-term behavioural evolution. We call for repositioning LLM agents in the
ecosystem of social simulation for future applications.

</details>


### [152] [Deprecating Benchmarks: Criteria and Framework](https://arxiv.org/abs/2507.06434)
*Ayrton San Joaquin,Rokas Gipiškis,Leon Staufer,Ariel Gil*

Key words: 人工智能,基准测试,模型评估,淘汰标准,AI治理

TL;DR: 该论文提出了基准测试的淘汰标准与框架，以确保前沿AI模型的评估更加严谨和有效。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 当前缺乏关于何时及如何淘汰不再有效的基准测试的指导，可能导致模型能力被高估或掩盖，甚至忽视安全性问题。

Method: 通过回顾基准测试实践，提出淘汰基准测试的标准和框架。

Result: 提出了具体的淘汰标准和框架，以促进更高质量的模型评估。

Conclusion: 研究旨在提升基准测试的严谨性，特别针对前沿模型，对开发者、用户、AI治理和政策制定者具有重要价值。

Abstract: As frontier artificial intelligence (AI) models rapidly advance, benchmarks
are integral to comparing different models and measuring their progress in
different task-specific domains. However, there is a lack of guidance on when
and how benchmarks should be deprecated once they cease to effectively perform
their purpose. This risks benchmark scores over-valuing model capabilities, or
worse, obscuring capabilities and safety-washing. Based on a review of
benchmarking practices, we propose criteria to decide when to fully or
partially deprecate benchmarks, and a framework for deprecating benchmarks. Our
work aims to advance the state of benchmarking towards rigorous and quality
evaluations, especially for frontier models, and our recommendations are aimed
to benefit benchmark developers, benchmark users, AI governance actors (across
governments, academia, and industry panels), and policy makers.

</details>


### [153] [Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study](https://arxiv.org/abs/2507.06438)
*Kaléu Delphino*

Key words: ChatGPT, 计算机科学教育, 抄袭, 匿名调查, 访谈

TL;DR: ChatGPT等工具对计算机科学教育构成威胁，约25%的学生承认使用这些工具作弊，匿名调查比访谈更有效。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 研究ChatGPT等工具对学生作弊行为的影响，评估匿名调查和访谈在研究AI抄袭中的可行性。

Method: 在一门大型计算机科学课程（n=120）中进行匿名调查和访谈。

Result: 超过25%的受访学生承认使用AI作弊，但仅有一名学生愿意接受访谈。

Conclusion: 匿名调查是研究AI抄袭的有效方法，而访谈需改进设计以提高参与率。

Abstract: Tools that can generate computer code in response to inputs written in
natural language, such as ChatGPT, pose an existential threat to Computer
Science education in its current form, since students can now use these tools
to solve assignments without much effort. While that risk has already been
recognized by scholars, the proportion of the student body that is incurring in
this new kind of plagiarism is still an open problem. We conducted a pilot
study in a large CS class (n=120) to assess the feasibility of estimating AI
plagiarism through anonymous surveys and interviews. More than 25% of the
survey respondents admitted to committing AI plagiarism. Conversely, only one
student accepted to be interviewed. Given the high levels of misconduct
acknowledgment, we conclude that surveys are an effective method for studies on
the matter, while interviews should be avoided or designed in a way that can
entice participation.

</details>


### [154] [Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change](https://arxiv.org/abs/2507.06876)
*Adrian Rauchfleisch,Joshua Philip Suarez,Nikka Marie Sales,Andreas Jungherr*

Key words: 人工智能, ChatGPT, 社交媒体, 经济兴趣, 文化价值观

TL;DR: 论文研究了ChatGPT发布后社交媒体上的公众反应，分析经济和文化因素如何影响人们的参与和态度。

<details>
  <summary>Details</summary>

Main category: cs.CY

Motivation: 探讨人工智能技术发布时公众的反应和态度如何受到经济和文化背景的影响。

Method: 分析了2022年ChatGPT发布期间的380万条推文，涵盖160万用户和117个国家，结合职业技能和文化维度。

Result: 技术类职业倾向于早期参与且态度积极，写作类职业则更晚且更怀疑；个人主义文化预测更早参与但态度更负面。

Conclusion: 公众对AI的反应深受职业和文化背景影响，早期积极态度主要因后续批判性声音加入而非原有观点转变。

Abstract: Public product launches in Artificial Intelligence can serve as focusing
events for collective attention, surfacing how societies react to technological
change. Social media provide a window into the sensemaking around these events,
surfacing hopes and fears and showing who chooses to engage in the discourse
and when. We demonstrate that public sensemaking about AI is shaped by economic
interests and cultural values of those involved. We analyze 3.8 million tweets
posted by 1.6 million users across 117 countries in response to the public
launch of ChatGPT in 2022. Our analysis shows how economic self-interest,
proxied by occupational skill types in writing, programming, and mathematics,
and national cultural orientations, as measured by Hofstede's individualism,
uncertainty avoidance, and power distance dimensions, shape who speaks, when
they speak, and their stance towards ChatGPT. Roles requiring more technical
skills, such as programming and mathematics, tend to engage earlier and express
more positive stances, whereas writing-centric occupations join later with
greater skepticism. At the cultural level, individualism predicts both earlier
engagement and a more negative stance, and uncertainty avoidance reduces the
prevalence of positive stances but does not delay when users first engage with
ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study.
The shift toward a more critical stance towards ChatGPT over time stems
primarily from the entry of more skeptical voices rather than a change of heart
among early adopters. Our findings underscore the importance of both the
occupational background and cultural context in understanding public reactions
to AI.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [155] [MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing](https://arxiv.org/abs/2507.06329)
*Michael Clemens,Ana Marasović*

Key words: AI, music mixing, co-creative instruction, audio-language dataset, Qwen-Audio

TL;DR: MixAssist是一个新的音频-语言数据集，捕捉专家与业余音乐制作人在协作混音会话中的多轮对话，填补了当前AI研究中忽视协作和教学维度的空白。

<details>
  <summary>Details</summary>

Main category: cs.SD

Motivation: 当前AI研究在音乐混音和母带处理中过于强调端到端自动化或生成，忽视了协作和教学的重要性，导致业余音乐制作者的需求未得到满足。

Method: 引入MixAssist数据集，包含431个基于音频的对话轮次，来自7次深入会话和12名制作人。并通过自动化LLM评估和人类专家比较测试了模型性能。

Result: 在MixAssist上微调的Qwen-Audio模型表现优于其他模型，能生成有帮助且上下文相关的混音建议。

Conclusion: MixAssist为智能AI助手的开发提供了资源，支持音乐混音中的协作创意过程。

Abstract: While AI presents significant potential for enhancing music mixing and
mastering workflows, current research predominantly emphasizes end-to-end
automation or generation, often overlooking the collaborative and instructional
dimensions vital for co-creative processes. This gap leaves artists,
particularly amateurs seeking to develop expertise, underserved. To bridge
this, we introduce MixAssist, a novel audio-language dataset capturing the
situated, multi-turn dialogue between expert and amateur music producers during
collaborative mixing sessions. Comprising 431 audio-grounded conversational
turns derived from 7 in-depth sessions involving 12 producers, MixAssist
provides a unique resource for training and evaluating audio-language models
that can comprehend and respond to the complexities of real-world music
production dialogues. Our evaluations, including automated LLM-as-a-judge
assessments and human expert comparisons, demonstrate that fine-tuning models
such as Qwen-Audio on MixAssist can yield promising results, with Qwen
significantly outperforming other tested models in generating helpful,
contextually relevant mixing advice. By focusing on co-creative instruction
grounded in audio context, MixAssist enables the development of intelligent AI
assistants designed to support and augment the creative process in music
mixing.

</details>


### [156] [Exploring State-Space-Model based Language Model in Music Generation](https://arxiv.org/abs/2507.06674)
*Wei-Jaw Lee,Fang-Chih Hsieh,Xuanjun Chen,Fang-Duo Tsai,Yi-Hsuan Yang*

Key words: State Space Models, Mamba, text-to-music generation, RVQ, SiMBA

TL;DR: 本文探索了基于Mamba的架构在文本到音乐生成中的潜力，发现单层RVQ编码足以捕捉音乐语义信息，并通过将SiMBA作为解码器展示了其在有限资源下的高效表现。

<details>
  <summary>Details</summary>

Main category: cs.SD

Motivation: 研究Mamba架构在文本到音乐生成中的应用，探索其作为Transformer替代或补充模块的潜力。

Method: 采用离散RVQ标记作为建模表示，将SiMBA（原为编码器）改造为解码器，并与Transformer解码器进行比较。

Result: 在有限资源下，SiMBA收敛更快且生成结果更接近真实数据，展示了SSM在文本到音乐生成中的高效性。

Conclusion: SSM（如SiMBA）在文本到音乐生成任务中表现优异，具有高效和表达力强的特点。

Abstract: The recent surge in State Space Models (SSMs), particularly the emergence of
Mamba, has established them as strong alternatives or complementary modules to
Transformers across diverse domains. In this work, we aim to explore the
potential of Mamba-based architectures for text-to-music generation. We adopt
discrete tokens of Residual Vector Quantization (RVQ) as the modeling
representation and empirically find that a single-layer codebook can capture
semantic information in music. Motivated by this observation, we focus on
modeling a single-codebook representation and adapt SiMBA, originally designed
as a Mamba-based encoder, to function as a decoder for sequence modeling. We
compare its performance against a standard Transformer-based decoder. Our
results suggest that, under limited-resource settings, SiMBA achieves much
faster convergence and generates outputs closer to the ground truth. This
demonstrates the promise of SSMs for efficient and expressive text-to-music
generation. We put audio examples on Github.

</details>


### [157] [Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation](https://arxiv.org/abs/2507.07043)
*Haris Khan,Shumaila Asif,Hassan Nasir*

Key words: 人工智能, 助听器, 选择性噪声消除, 深度学习, 临床验证

TL;DR: 本文系统综述了人工智能在助听器选择性噪声消除中的进展，总结了技术演变、实施挑战及未来方向，强调了深度学习架构和硬件部署策略的进展，同时指出了实验室模型在实际应用中的挑战。

<details>
  <summary>Details</summary>

Main category: cs.SD

Motivation: 探讨人工智能如何推动助听器从传统放大系统向智能、情境感知音频处理的转变，解决现实部署中的技术难题。

Method: 通过系统文献综述，分析了深度学习架构（如卷积循环网络和Transformer）、硬件部署策略、临床验证和用户中心设计。

Result: 最新模型在噪声混响基准上提升了18.3 dB SI-SDR，实现了低于10毫秒的实时处理，临床效果显著。

Conclusion: 未来需关注轻量化模型、持续学习、情境分类和临床转化，以实现全球范围的变革性助听解决方案。

Abstract: The integration of artificial intelligence into hearing assistance marks a
paradigm shift from traditional amplification-based systems to intelligent,
context-aware audio processing. This systematic literature review evaluates
advances in AI-driven selective noise cancellation (SNC) for hearing aids,
highlighting technological evolution, implementation challenges, and future
research directions. We synthesize findings across deep learning architectures,
hardware deployment strategies, clinical validation studies, and user-centric
design. The review traces progress from early machine learning models to
state-of-the-art deep networks, including Convolutional Recurrent Networks for
real-time inference and Transformer-based architectures for high-accuracy
separation. Key findings include significant gains over traditional methods,
with recent models achieving up to 18.3 dB SI-SDR improvement on
noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and
promising clinical outcomes. Yet, challenges remain in bridging lab-grade
models with real-world deployment - particularly around power constraints,
environmental variability, and personalization. Identified research gaps
include hardware-software co-design, standardized evaluation protocols, and
regulatory considerations for AI-enhanced hearing devices. Future work must
prioritize lightweight models, continual learning, contextual-based
classification and clinical translation to realize transformative hearing
solutions for millions globally.

</details>


### [158] [A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering](https://arxiv.org/abs/2507.07046)
*Shahana Yasmin Chowdhury,Bithi Banik,Md Tamjidul Hoque,Shreya Banerjee*

Key words: 语音情感识别, DCRF-BiLSTM, 多数据集评估, 高准确率

TL;DR: 本文提出了一种名为DCRF-BiLSTM的语音情感识别模型，该模型在五个不同数据集上表现出色，特别是在综合数据集上达到了93.76%的高准确率，显示出其卓越的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

Main category: cs.SD

Motivation: 语音情感识别（SER）在人工智能和人类-计算机交互中具有重要意义，但目前缺乏一个能在多个基准数据集上同时表现优秀的模型。

Method: 作者采用DCRF-BiLSTM模型来识别七种情感，并在五个数据集（RAVDESS、TESS、SAVEE、EmoDB和Crema-D）上进行训练和评估。

Result: 模型在单个数据集上的准确率极高（如100%在TESS和EmoDB上），且在综合数据集（R+T+S）上达到了98.82%的准确率，首次在五个数据集联合测试中获得了93.76%的整体准确率。

Conclusion: DCRF-BiLSTM模型具有出色的鲁棒性和泛化能力，适用于多数据集环境下的语音情感识别任务。

Abstract: Nowadays, speech emotion recognition (SER) plays a vital role in the field of
human-computer interaction (HCI) and the evolution of artificial intelligence
(AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions:
neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on
five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C).
The model achieves high accuracy on individual datasets, including 97.83% on
RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS
and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy,
outperforming previously reported results. To our knowledge, no existing study
has evaluated a single SER model across all five benchmark datasets (i.e.,
R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive
combination and achieve a remarkable overall accuracy of 93.76%. These results
confirm the robustness and generalizability of our DCRF-BiLSTM framework across
diverse datasets.

</details>


### [159] [Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification](https://arxiv.org/abs/2507.07058)
*Martin Sondermann,Pinar Bisgin,Niklas Tschorn,Anja Burmann,Christoph M. Friedrich*

Key words: 心音图分类、卷积神经网络、音频变换器、心动周期归一化、PhysioNet2022

TL;DR: 本文系统性比较了四种用于心音图（PCG）分类的模型，包括两种卷积神经网络（CNN）和两种零样本音频变换器（BEATs），探讨了不同归一化方法对性能的影响，并提出了临床应用中模型选择的平衡标准。

<details>
  <summary>Details</summary>

Main category: cs.SD

Motivation: 研究动机在于探索自动化心音图分类技术在心血管诊断中的潜力，并通过不同模型和归一化方法的比较，为临床实践提供科学依据。

Method: 方法包括使用PhysioNet2022数据集，对比两种CNN和两种BEATs模型在固定长度和心动周期归一化下的表现，并引入个性化心动周期归一化方法。

Result: 结果显示，固定长度窗口的CNN模型AUROC为79.5%，心动周期归一化的CNN为75.4%，固定长度窗口的BEATs为65.7%，心动周期归一化的BEATs为70.1%。

Conclusion: 结论表明，尽管CNN模型性能更优，但BEATs在开发效率上具有优势，未来自动化分类系统有望提升心脏诊断和患者护理。

Abstract: The automated classification of phonocardiogram (PCG) recordings represents a
substantial advancement in cardiovascular diagnostics. This paper presents a
systematic comparison of four distinct models for heart murmur detection: two
specialized convolutional neural networks (CNNs) and two zero-shot universal
audio transformers (BEATs), evaluated using fixed-length and heart cycle
normalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart
cycle normalization method tailored to individual cardiac rhythms is
introduced. The findings indicate the following AUROC values: the CNN model
with fixed-length windowing achieves 79.5%, the CNN model with heart cycle
normalization scores 75.4%, the BEATs transformer with fixed-length windowing
achieves 65.7%, and the BEATs transformer with heart cycle normalization
results in 70.1%.
  The findings indicate that physiological signal constraints, especially those
introduced by different normalization strategies, have a substantial impact on
model performance. The research provides evidence-based guidelines for
architecture selection in clinical settings, emphasizing the need for a balance
between accuracy and computational efficiency. Although specialized CNNs
demonstrate superior performance overall, the zero-shot transformer models may
offer promising efficiency advantages during development, such as faster
training and evaluation cycles, despite their lower classification accuracy.
These findings highlight the potential of automated classification systems to
enhance cardiac diagnostics and improve patient care.

</details>


### [160] [Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach](https://arxiv.org/abs/2507.07066)
*Adrian S. Roman,Iran R. Roman,Juan P. Bello*

Key words: 声学映射、方向估计、自监督学习、深度学习、麦克风阵列

TL;DR: 该论文提出了一种自监督的潜在声学映射（LAM）模型，结合传统方法的可解释性和深度学习的效率，用于声源方向估计，并在多个基准测试中表现优异。

<details>
  <summary>Details</summary>

Main category: cs.SD

Motivation: 传统声学映射方法计算复杂且对声学变化敏感，而监督深度学习方法需要大量标注数据且缺乏可解释性。两者在多样化的声学设置和阵列配置中泛化能力不足。

Method: LAM是一种自监督框架，结合传统方法的可解释性和深度学习的适应性与效率，能够生成高分辨率声学映射并适应不同声学条件和麦克风阵列。

Result: 在LOCATA和STARSS基准测试中，LAM的声源方向估计性能与现有监督方法相当或更优，且其声学映射可作为监督模型的有效特征。

Conclusion: LAM为自适应高性能声源定位系统提供了新的解决方案，展示了其在声学映射和声源定位中的潜力。

Abstract: Acoustic mapping techniques have long been used in spatial audio processing
for direction of arrival estimation (DoAE). Traditional beamforming methods for
acoustic mapping, while interpretable, often rely on iterative solvers that can
be computationally intensive and sensitive to acoustic variability. On the
other hand, recent supervised deep learning approaches offer feedforward speed
and robustness but require large labeled datasets and lack interpretability.
Despite their strengths, both methods struggle to consistently generalize
across diverse acoustic setups and array configurations, limiting their broader
applicability. We introduce the Latent Acoustic Mapping (LAM) model, a
self-supervised framework that bridges the interpretability of traditional
methods with the adaptability and efficiency of deep learning methods. LAM
generates high-resolution acoustic maps, adapts to varying acoustic conditions,
and operates efficiently across different microphone arrays. We assess its
robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves
comparable or superior localization performance to existing supervised methods.
Additionally, we show that LAM's acoustic maps can serve as effective features
for supervised models, further enhancing DoAE accuracy and underscoring its
potential to advance adaptive, high-performance sound localization systems.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [161] [Stochastic Alignments: Matching an Observed Trace to Stochastic Process Models](https://arxiv.org/abs/2507.06472)
*Tian Li,Artem Polyvyanyy,Sander J. J. Leemans*

Key words: 过程挖掘、随机过程模型、对齐技术、启发式算法、优化问题

TL;DR: 本文提出了一种新的基于启发式路径寻找算法的优化方法，用于在随机过程模型中匹配观察到的轨迹，以解决传统对齐技术在概率和编辑距离之间的权衡问题。

<details>
  <summary>Details</summary>

Main category: cs.FL

Motivation: 传统对齐技术在随机过程模型中的不足在于其优先考虑最小的偏差路径选择，而忽略了路径的似然性。本文旨在解决这一问题。

Method: 通过将问题建模为优化问题，并提出一种启发式路径寻找算法来识别低编辑距离和高似然性的模型路径。

Result: 开源实现验证了方法的可行性，并能为分析师提供新的有用诊断信息。

Conclusion: 本文的方法在提升随机过程模型中对观察轨迹匹配的准确性和实用性方面具有潜力。

Abstract: Process mining leverages event data extracted from IT systems to generate
insights into the business processes of organizations. Such insights benefit
from explicitly considering the frequency of behavior in business processes,
which is captured by stochastic process models. Given an observed trace and a
stochastic process model, conventional alignment-based conformance checking
techniques face a fundamental limitation: They prioritize matching the trace to
a model path with minimal deviations, which may, however, lead to selecting an
unlikely path. In this paper, we study the problem of matching an observed
trace to a stochastic process model by identifying a likely model path with a
low edit distance to the trace. We phrase this as an optimization problem and
develop a heuristic-guided path-finding algorithm to solve it. Our open-source
implementation demonstrates the feasibility of the approach and shows that it
can provide new, useful diagnostic insights for analysts.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [162] [Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)
*Zhenwen Liang,Linfeng Song,Yang Li,Tao Yang,Feng Zhang,Haitao Mi,Dong Yu*

Key words: 自动化定理证明, 大型语言模型, 形式化证明, 模块化设计, IMO问题

TL;DR: 论文提出了一种新的框架，通过解耦高层推理与底层证明生成，解决了大型语言模型在形式化证明领域的性能瓶颈问题。

<details>
  <summary>Details</summary>

Main category: cs.LO

Motivation: 当前大型语言模型在非形式化推理中表现出色，但形式化证明性能不足，主要原因是现有系统将推理与证明耦合，限制了深度推理。

Method: 采用模块化设计，一个通用推理模型生成子目标引理，另一个高效证明模型验证这些引理，从而避免端到端训练的缺陷。

Result: 在2000年后的国际数学奥林匹克（IMO）问题上，该框架成功解决了5个问题，显著提升了自动化推理的能力。

Conclusion: 通过解耦推理与证明并开源数据集，为未来研究提供了新方向。

Abstract: Automated Theorem Proving (ATP) in formal languages is a foundational
challenge for AI. While Large Language Models (LLMs) have driven remarkable
progress, a significant gap remains between their powerful informal reasoning
capabilities and their weak formal proving performance. Recent studies show
that the informal accuracy exceeds 80% while formal success remains below 8% on
benchmarks like PutnamBench. We argue this gap persists because current
state-of-the-art provers, by tightly coupling reasoning and proving, are
trained with paradigms that inadvertently punish deep reasoning in favor of
shallow, tactic-based strategies. To bridge this fundamental gap, we propose a
novel framework that decouples high-level reasoning from low-level proof
generation. Our approach utilizes two distinct, specialized models: a powerful,
general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an
efficient Prover to rigorously verify them. This modular design liberates the
model's full reasoning potential and bypasses the pitfalls of end-to-end
training. We evaluate our method on a challenging set of post-2000 IMO
problems, a problem set on which no prior open-source prover has reported
success. Our decoupled framework successfully solves 5 of these problems,
demonstrating a significant step towards automated reasoning on exceptionally
difficult mathematical challenges. To foster future research, we release our
full dataset of generated and verified lemmas for a wide range of IMO problems,
available at https://tencent-imo.github.io/ .

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [163] [A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes](https://arxiv.org/abs/2507.06278)
*Kemboi Cheruiyot,Nickson Kiprotich,Vyacheslav Kungurtsev,Kennedy Mugo,Vivian Mwirigi,Marvin Ngesa*

Key words: 多智能体交互, 联邦强化学习, 去中心化强化学习, 非合作强化学习, 综述

TL;DR: 本文综述了多智能体交互的三种拓扑结构：联邦强化学习、去中心化强化学习和非合作强化学习，分析了它们的结构异同、理论保证及数值性能。

<details>
  <summary>Details</summary>

Main category: cs.MA

Motivation: 研究多智能体交互的复杂性及其在不同拓扑结构下的表现，推动自主智能体的发展和应用。

Method: 对联邦强化学习、去中心化强化学习和非合作强化学习进行全面的文献综述，分析其形式化定义、理论结果和数值性能。

Result: 总结了三种交互拓扑的最新研究进展，指出了各自的理论保证和数值性能的优缺点。

Conclusion: 多智能体交互的研究仍处于早期阶段，需进一步探索其理论性和实际应用中的挑战。

Abstract: The increasing interest in research and innovation towards the development of
autonomous agents presents a number of complex yet important scenarios of
multiple AI Agents interacting with each other in an environment. The
particular setting can be understood as exhibiting three possibly topologies of
interaction - centrally coordinated cooperation, ad-hoc interaction and
cooperation, and settings with noncooperative incentive structures. This
article presents a comprehensive survey of all three domains, defined under the
formalism of Federal Reinforcement Learning (RL), Decentralized RL, and
Noncooperative RL, respectively. Highlighting the structural similarities and
distinctions, we review the state of the art in these subjects, primarily
explored and developed only recently in the literature. We include the
formulations as well as known theoretical guarantees and highlights and
limitations of numerical performance.

</details>


### [164] [Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration](https://arxiv.org/abs/2507.06520)
*Xinyuan Song,Zeyu Wang,Siyi Wu,Tianyu Shi,Lynn Ai*

Key words: 多智能体调度, LLM, MCP协议, 并行执行, 观察性

TL;DR: Gradientsys是一个新一代多智能体调度框架，通过MCP协议和动态规划循环协调多样化AI智能体，支持并行执行和透明观测。

<details>
  <summary>Details</summary>

Main category: cs.MA

Motivation: 解决现有框架在多智能体任务调度中的扩展性、并行性和观察性问题。

Method: 采用MCP协议和动态规划循环，结合LLM调度器和鲁棒重试机制。

Result: 在GAIA基准测试中，任务成功率更高，延迟和API成本更低。

Conclusion: Gradientsys在LLM驱动的多智能体编排中表现优越。

Abstract: We present Gradientsys, a next-generation multi-agent scheduling framework
that coordinates diverse specialized AI agents using a typed Model-Context
Protocol (MCP) and a ReAct-based dynamic planning loop. At its core,
Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task
dispatch, enabling parallel execution of heterogeneous agents such as PDF
parsers, web search modules, GUI controllers, and web builders. The framework
supports hybrid synchronous/asynchronous execution, respects agent capacity
constraints, and incorporates a robust retry-and-replan mechanism to handle
failures gracefully. To promote transparency and trust, Gradientsys includes an
observability layer streaming real-time agent activity and intermediate
reasoning via Server-Sent Events (SSE). We offer an architectural overview and
evaluate Gradientsys against existing frameworks in terms of extensibility,
scheduling topology, tool reusability, parallelism, and observability.
Experiments on the GAIA general-assistant benchmark show that Gradientsys
achieves higher task success rates with reduced latency and lower API costs
compared to a MinionS-style baseline, demonstrating the strength of its
LLM-driven multi-agent orchestration.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [165] [Machine-Learned Force Fields for Lattice Dynamics at Coupled-Cluster Level Accuracy](https://arxiv.org/abs/2507.06929)
*Sita Schönbauer,Johanna P. Carbone,Andreas Grüneis*

Key words: Machine-Learned Force Fields, Density Functional Theory, Coupled Cluster, phonon dispersion, vibrational density of states

TL;DR: 研究了基于近似DFT和CC理论的MLFFs在碳金刚石和氢化锂固体中的性能，通过声子色散和VDOS评估其准确性，并采用delta-learning方法改善长程效应和CC数据中缺乏原子力的问题。

<details>
  <summary>Details</summary>

Main category: cond-mat.mtrl-sci

Motivation: 评估MLFFs在DFT和CC理论下的性能，尤其是声学和光学模式的振动频率与实验的一致性。

Method: 通过计算声子色散和VDOS，并使用delta-learning方法补偿CC数据的缺陷和DFT的不足。

Result: 基于CC理论的MLFFs在光学模式振动频率上表现优于DFT，更符合实验结果。

Conclusion: MLFFs在CC理论下能更准确地预测振动频率，并可扩展用于评估VDOS的非谐效应。

Abstract: We investigate Machine-Learned Force Fields (MLFFs) trained on approximate
Density Functional Theory (DFT) and Coupled Cluster (CC) level potential energy
surfaces for the carbon diamond and lithium hydride solids. We assess the
accuracy and precision of the MLFFs by calculating phonon dispersions and
vibrational densities of states (VDOS) that are compared to experiment and
reference ab initio results. To overcome limitations from long-range effects
and the lack of atomic forces in the CC training data, a delta-learning
approach based on the difference between CC and DFT results is explored.
Compared to DFT, MLFFs trained on CC theory yield higher vibrational
frequencies for optical modes, agreeing better with experiment. Furthermore,
the MLFFs are used to estimate anharmonic effects on the VDOS of lithium
hydride at the level of CC theory.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [166] [On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective](https://arxiv.org/abs/2507.06552)
*Zhiyi Dong,Zixuan Liu,Yongyi Mao*

Key words: 无监督域适应，协变量偏移，后验目标标签不确定性，学习难度

TL;DR: 本文研究了协变量偏移下无监督域适应（UDA）的难度，提出了一个基于信息论的量——后验目标标签不确定性（PTLU），用于评估UDA学习的困难程度。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 传统的UDA分析通常关注最坏情况，忽略了现实中可能的分布多样性。本文希望通过引入UDA类的分布模型，更准确地捕捉学习难度。

Method: 作者定义了UDA类的分布模型，提出了PTLU及其经验估计EPTLU，通过证明其作为风险的全局下界，量化了UDA学习的难度。

Result: 研究表明，PTLU能够有效评估UDA学习的困难程度，并且在多个示例中显示出优于现有方法的优势。

Conclusion: PTLU是评估UDA学习难度的有效工具，未来可能用于设计更高效的UDA算法。

Abstract: This paper studies the hardness of unsupervised domain adaptation (UDA) under
covariate shift. We model the uncertainty that the learner faces by a
distribution $\pi$ in the ground-truth triples $(p, q, f)$ -- which we call a
UDA class -- where $(p, q)$ is the source -- target distribution pair and $f$
is the classifier. We define the performance of a learner as the overall target
domain risk, averaged over the randomness of the ground-truth triple. This
formulation couples the source distribution, the target distribution and the
classifier in the ground truth, and deviates from the classical worst-case
analyses, which pessimistically emphasize the impact of hard but rare UDA
instances. In this formulation, we precisely characterize the optimal learner.
The performance of the optimal learner then allows us to define the learning
difficulty for the UDA class and for the observed sample. To quantify this
difficulty, we introduce an information-theoretic quantity -- Posterior Target
Label Uncertainty (PTLU) -- along with its empirical estimate (EPTLU) from the
sample , which capture the uncertainty in the prediction for the target domain.
Briefly, PTLU is the entropy of the predicted label in the target domain under
the posterior distribution of ground-truth classifier given the observed source
and target samples. By proving that such a quantity serves to lower-bound the
risk of any learner, we suggest that these quantities can be used as proxies
for evaluating the hardness of UDA learning. We provide several examples to
demonstrate the advantage of PTLU, relative to the existing measures, in
evaluating the difficulty of UDA learning.

</details>


### [167] [Semi-parametric Functional Classification via Path Signatures Logistic Regression](https://arxiv.org/abs/2507.06637)
*Pengcheng Zeng,Siyuan Jiang*

Key words: 函数逻辑回归, 路径签名, 粗糙路径理论, 非均匀采样

TL;DR: 提出了一种半参数框架PSLR，用于分类带标量协变量的向量值函数数据，利用截断路径签名避免线性假设和固定基扩展的限制。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 解决传统函数逻辑回归在非线性、不规则采样下的性能下降问题。

Method: 基于截断路径签名构建有限维、无基表示的几何感知特征，并嵌入时间增广路径。

Result: 理论和实验表明PSLR在准确性、鲁棒性和可解释性上优于传统方法，尤其适用于非均匀采样。

Conclusion: PSLR将粗糙路径理论引入函数数据分析，具有理论和实践优势。

Abstract: We propose Path Signatures Logistic Regression (PSLR), a semi-parametric
framework for classifying vector-valued functional data with scalar covariates.
Classical functional logistic regression models rely on linear assumptions and
fixed basis expansions, which limit flexibility and degrade performance under
irregular sampling. PSLR overcomes these issues by leveraging truncated path
signatures to construct a finite-dimensional, basis-free representation that
captures nonlinear and cross-channel dependencies. By embedding trajectories as
time-augmented paths, PSLR extracts stable, geometry-aware features that are
robust to sampling irregularity without requiring a common time grid, while
still preserving subject-specific timing patterns. We establish theoretical
guarantees for the existence and consistent estimation of the optimal
truncation order, along with non-asymptotic risk bounds. Experiments on
synthetic and real-world datasets show that PSLR outperforms traditional
functional classifiers in accuracy, robustness, and interpretability,
particularly under non-uniform sampling schemes. Our results highlight the
practical and theoretical benefits of integrating rough path theory into modern
functional data analysis.

</details>


### [168] [Fast Gaussian Processes under Monotonicity Constraints](https://arxiv.org/abs/2507.06677)
*Chao Zhang,Jasper M. Everink,Jakob Sauer Jørgensen*

Key words: 高斯过程,单调性约束,虚拟点,RLRTO,NUTS

TL;DR: 该论文提出了一种基于虚拟点的新框架，结合正则化线性随机优化（RLRTO）方法，高效构建满足单调性约束的高斯过程模型，并改进了现有方法，显著提升了计算效率。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 在科学和工程应用中，高斯过程常作为复杂函数的代理模型，结合单调性等先验知识可提高模型准确性，但高维问题中计算成本高。

Method: 提出基于虚拟点的框架，采用RLRTO方法高效采样约束后验分布，并用NUTS替代Gibbs采样改进现有方法。

Result: 在合成函数和微分方程系统中验证了方法的预测性能，RLRTO和NUTS方法显著提升了计算效率。

Conclusion: 新框架和优化方法在保持预测性能的同时，显著降低了计算成本，适用于广泛应用。

Abstract: Gaussian processes (GPs) are widely used as surrogate models for complicated
functions in scientific and engineering applications. In many cases, prior
knowledge about the function to be approximated, such as monotonicity, is
available and can be leveraged to improve model fidelity. Incorporating such
constraints into GP models enhances predictive accuracy and reduces
uncertainty, but remains a computationally challenging task for
high-dimensional problems. In this work, we present a novel virtual point-based
framework for building constrained GP models under monotonicity constraints,
based on regularized linear randomize-then-optimize (RLRTO), which enables
efficient sampling from a constrained posterior distribution by means of
solving randomized optimization problems. We also enhance two existing virtual
point-based approaches by replacing Gibbs sampling with the No U-Turn Sampler
(NUTS) for improved efficiency. A Python implementation of these methods is
provided and can be easily applied to a wide range of problems. This
implementation is then used to validate the approaches on approximating a range
of synthetic functions, demonstrating comparable predictive performance between
all considered methods and significant improvements in computational efficiency
with the two NUTS methods and especially with the RLRTO method. The framework
is further applied to construct surrogate models for systems of differential
equations.

</details>


### [169] [Adaptive collaboration for online personalized distributed learning with heterogeneous clients](https://arxiv.org/abs/2507.06844)
*Constantin Philippenko,Batiste Le Bars,Kevin Scaman,Laurent Massoulié*

Key words: 去中心化学习, 梯度协作, 方差减少, 个性化学习, 动态选择

TL;DR: 本文研究了在线个性化去中心化学习问题，提出了基于梯度的协作准则以动态选择相似梯度的伙伴，从而减少梯度方差并降低偏差。通过理论分析和实验验证，证明了方法的有效性。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 解决去中心化学习中如何动态选择合适的协作伙伴以减少梯度方差并降低偏差的挑战。

Method: 提出了基于梯度的协作准则，允许客户端在优化过程中动态选择梯度相似的伙伴，并推导了平滑目标函数下的损失上界。

Result: 理论分析表明算法具有方差减少效果，实验验证了其在合成和真实数据集上的有效性。

Conclusion: 提出的协作准则在减少梯度方差和降低偏差方面表现出色，为去中心化学习提供了有效方案。

Abstract: We study the problem of online personalized decentralized learning with $N$
statistically heterogeneous clients collaborating to accelerate local training.
An important challenge in this setting is to select relevant collaborators to
reduce gradient variance while mitigating the introduced bias. To tackle this,
we introduce a gradient-based collaboration criterion, allowing each client to
dynamically select peers with similar gradients during the optimization
process. Our criterion is motivated by a refined and more general theoretical
analysis of the All-for-one algorithm, proved to be optimal in Even et al.
(2022) for an oracle collaboration scheme. We derive excess loss upper-bounds
for smooth objective functions, being either strongly convex, non-convex, or
satisfying the Polyak-Lojasiewicz condition; our analysis reveals that the
algorithm acts as a variance reduction method where the speed-up depends on a
sufficient variance. We put forward two collaboration methods instantiating the
proposed general schema; and we show that one variant preserves the optimality
of All-for-one. We validate our results with experiments on synthetic and real
datasets.

</details>


### [170] [Conformal Prediction for Long-Tailed Classification](https://arxiv.org/abs/2507.06867)
*Tiffany Ding,Jean-Baptiste Fermanian,Joseph Salmon*

Key words: 长尾分布,共形预测,类别覆盖率,预测集大小,植物识别

TL;DR: 该论文提出了一种解决长尾分布分类问题的新方法，通过改进的共形预测技术，平衡了预测集的类别覆盖率和大小。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 传统共形预测方法在长尾分布场景下无法同时保证类别覆盖率和预测集大小的合理性，亟需改进。

Method: 提出了两种方法：一是针对宏覆盖率的prevalence-adjusted softmax评分函数，二是标签加权共形预测方法，用于在边际和类别条件预测间插值。

Result: 在Pl@ntNet和iNaturalist两个长尾图像数据集上验证了方法的有效性。

Conclusion: 新方法能够在保证覆盖率和预测集大小之间提供平衡，适用于实际长尾分类问题。

Abstract: Many real-world classification problems, such as plant identification, have
extremely long-tailed class distributions. In order for prediction sets to be
useful in such settings, they should (i) provide good class-conditional
coverage, ensuring that rare classes are not systematically omitted from the
prediction sets, and (ii) be a reasonable size, allowing users to easily verify
candidate labels. Unfortunately, existing conformal prediction methods, when
applied to the long-tailed setting, force practitioners to make a binary choice
between small sets with poor class-conditional coverage or sets with very good
class-conditional coverage but that are extremely large. We propose methods
with guaranteed marginal coverage that smoothly trade off between set size and
class-conditional coverage. First, we propose a conformal score function,
prevalence-adjusted softmax, that targets a relaxed notion of class-conditional
coverage called macro-coverage. Second, we propose a label-weighted conformal
prediction method that allows us to interpolate between marginal and
class-conditional conformal prediction. We demonstrate our methods on Pl@ntNet
and iNaturalist, two long-tailed image datasets with 1,081 and 8,142 classes,
respectively.

</details>


### [171] [Distribution-free inference for LightGBM and GLM with Tweedie loss](https://arxiv.org/abs/2507.06921)
*Alokesh Manna,Aditya Vikram Sett,Dipak K. Dey,Yuwen Gu,Elizabeth D. Schifano,Jichao He*

Key words: 预测不确定性,保险索赔,共形预测,GLM,LightGBM

TL;DR: 本文提出了一种新的非共形度量方法，用于GLMs和GBMs模型，以量化预测不确定性，并通过实验验证了其在保险索赔数据中的有效性。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 在保险行业中，准确预测索赔成本范围和不确定性对保费定价和风险管理至关重要。传统的回归模型虽常用，但需更强的方法来量化不确定性。

Method: 提出了针对GLMs和GBMs的新非共形度量方法，并基于正则化Tweedie GLM和LightGBM模型进行验证。

Result: 实验结果显示，Local weighted Pearson residuals在LightGBM中的表现最优，其置信区间保持名义覆盖的同时宽度最小。

Conclusion: 新方法在保险索赔数据中表现出色，尤其是在LightGBM模型中，有效提升了预测不确定性的量化效果。

Abstract: Prediction uncertainty quantification is a key research topic in recent years
scientific and business problems. In insurance industries
(\cite{parodi2023pricing}), assessing the range of possible claim costs for
individual drivers improves premium pricing accuracy. It also enables insurers
to manage risk more effectively by accounting for uncertainty in accident
likelihood and severity. In the presence of covariates, a variety of
regression-type models are often used for modeling insurance claims, ranging
from relatively simple generalized linear models (GLMs) to regularized GLMs to
gradient boosting models (GBMs). Conformal predictive inference has arisen as a
popular distribution-free approach for quantifying predictive uncertainty under
relatively weak assumptions of exchangeability, and has been well studied under
the classic linear regression setting. In this work, we propose new
non-conformity measures for GLMs and GBMs with GLM-type loss. Using regularized
Tweedie GLM regression and LightGBM with Tweedie loss, we demonstrate conformal
prediction performance with these non-conformity measures in insurance claims
data. Our simulation results favor the use of locally weighted Pearson
residuals for LightGBM over other methods considered, as the resulting
intervals maintained the nominal coverage with the smallest average width.

</details>


### [172] [Off-Policy Evaluation Under Nonignorable Missing Data](https://arxiv.org/abs/2507.06961)
*Han Wang,Yang Xu,Wenbin Lu,Rui Song*

Key words: Off-Policy Evaluation, missing data, inverse probability weighting, statistical inference

TL;DR: 该论文研究了在单调缺失数据情况下的离策略评估（OPE），发现可忽略缺失时值估计无偏，但非可忽略缺失时可能产生偏差。为了保持一致性，提出了一种逆概率加权估计器，并通过实验验证其可靠性。

<details>
  <summary>Details</summary>

Main category: stat.ML

Motivation: 现实应用中，离线数据常存在缺失问题，但缺失数据如何影响OPE的理论研究不足。本文旨在填补这一理论空白。

Method: 提出逆概率加权值估计器，并在单调缺失数据下进行统计推断。

Result: 可忽略缺失时OPE估计无偏，非可忽略缺失时会偏差。所提估计器在缺失数据下表现更可靠。

Conclusion: 在单调缺失数据下，所提方法能有效保持OPE的估计一致性，并通过实验验证其优势。

Abstract: Off-Policy Evaluation (OPE) aims to estimate the value of a target policy
using offline data collected from potentially different policies. In real-world
applications, however, logged data often suffers from missingness. While OPE
has been extensively studied in the literature, a theoretical understanding of
how missing data affects OPE results remains unclear. In this paper, we
investigate OPE in the presence of monotone missingness and theoretically
demonstrate that the value estimates remain unbiased under ignorable
missingness but can be biased under nonignorable (informative) missingness. To
retain the consistency of value estimation, we propose an inverse probability
weighted value estimator and conduct statistical inference to quantify the
uncertainty of the estimates. Through a series of numerical experiments, we
empirically demonstrate that our proposed estimator yields a more reliable
value inference under missing data.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [173] [An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models](https://arxiv.org/abs/2507.06399)
*Doyeong Lim,Yang Liu,Zavier Ndum Ndum,Christian Young,Yassin Hassan*

Key words: 人工智能,热流体科学,数字孪生,小型模块化反应堆,GRU神经网络

TL;DR: 本文提出了一种多功能AI驱动的热流体测试平台，通过结合物理实验与先进计算智能，推动小型模块化反应堆技术的发展。平台采用数字孪生和AI框架实现实时预测与控制，GRU模型预测误差低至1.42K。

<details>
  <summary>Details</summary>

Main category: eess.SY

Motivation: 通过AI技术提升小型模块化反应堆的设计和操作效率，结合实验与计算智能，加速下一代核系统的创新与部署。

Method: 采用三环路热流体设施、数字孪生和GRU神经网络，结合实时数据训练模型，实现快速仿真与预测控制。

Result: GRU模型温度预测均方根误差为1.42K，验证了平台的高保真度，展示了AI在建模与控制中的实用性。

Conclusion: 该平台为AI与热流体科学的结合提供了集成研究环境，证明了AI在核系统创新中的潜力。

Abstract: This paper presents a multipurpose artificial intelligence (AI)-driven
thermal-fluid testbed designed to advance Small Modular Reactor technologies by
seamlessly integrating physical experimentation with advanced computational
intelligence. The platform uniquely combines a versatile three-loop
thermal-fluid facility with a high-fidelity digital twin and sophisticated AI
frameworks for real-time prediction, control, and operational assistance.
Methodologically, the testbed's digital twin, built upon the System Analysis
Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This
machine learning model, trained on experimental data, enables
faster-than-real-time simulation, providing predictive insights into the
system's dynamic behavior. The practical application of this AI integration is
showcased through case studies. An AI-driven control framework where the GRU
model accurately forecasts future system states and the corresponding control
actions required to meet operational demands. Furthermore, an intelligent
assistant, powered by a large language model, translates complex sensor data
and simulation outputs into natural language, offering operators actionable
analysis and safety recommendations. Comprehensive validation against
experimental transients confirms the platform's high fidelity, with the GRU
model achieving a temperature prediction root mean square error of 1.42 K. This
work establishes an integrated research environment at the intersection of AI
and thermal-fluid science, showcasing how AI-driven methodologies in modeling,
control, and operator support can accelerate the innovation and deployment of
next-generation nuclear systems.

</details>


### [174] [A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis](https://arxiv.org/abs/2507.06890)
*Yifan Wang*

Key words: 微电网, 网络攻击, 分数阶导数, 故障诊断, 对抗训练

TL;DR: 本文提出了一种基于单传感器的攻击诊断方案FO-MADS，通过双分数阶特征库和两阶段分类器，实现了低成本、高精度的微电网故障定位和攻击检测。

<details>
  <summary>Details</summary>

Main category: eess.SY

Motivation: 智能微电网面临网络攻击风险，现有方法依赖昂贵设备或严苛假设，难以在单传感器条件下实现有效诊断。

Method: 采用Caputo和Grünwald-Letnikov导数构建双分数阶特征库，结合两阶段分类器和PMR-AT对抗训练，提升鲁棒性。

Result: 在四逆变器测试平台上，对24种故障和4种攻击场景的检测准确率均超过92%，且攻击无关条件下保持96.7%。

Conclusion: FO-MADS是一种低成本、易部署的方案，显著提升了智能微电网的网络安全韧性。

Abstract: Cyber-attacks jeopardize the safe operation of smart microgrids. At the same
time, existing diagnostic methods either depend on expensive multi-point
instrumentation or stringent modelling assumptions that are untenable under
single-sensor constraints. This paper proposes a Fractional-Order
Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency
fault localisation and cyber-attack detection using only one VPQ
(Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual
fractional-order feature library by jointly applying Caputo and
Gr\"unwald-Letnikov derivatives, thereby amplifying micro-perturbations and
slow drifts in the VPQ signal. A two-stage hierarchical classifier then
pinpoints the affected inverter and isolates the faulty IGBT switch,
effectively alleviating class imbalance. Robustness is further strengthened
through Progressive Memory-Replay Adversarial Training (PMR-AT), whose
attack-aware loss is dynamically re-weighted via Online Hard Example Mining
(OHEM) to prioritise the most challenging samples. Experiments on a
four-inverter microgrid testbed comprising 1 normal and 24 fault classes under
four attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0
% (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining
96.7 % under attack-free conditions. These results establish FO-MADS as a
cost-effective and readily deployable solution that markedly enhances the
cyber-physical resilience of smart microgrids.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [175] [We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems](https://arxiv.org/abs/2507.06250)
*Zhihao Li,Kun Li,Boyang Ma,Minghui Xu,Yue Zhang,Xiuzhen Cheng*

Key words: MCP, 安全风险, 静态分析, API使用, 权限分离

TL;DR: 本文对MCP（Model Context Protocol）的安全风险进行了首次大规模实证分析，开发了自动静态分析工具，并检查了2562个真实世界的MCP应用，揭示了网络和系统资源API的广泛使用及其安全风险。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: MCP虽然提供了无缝扩展和丰富集成的能力，但也引入了显著的安全风险，如插件可能继承广泛的系统权限而缺乏隔离和监管，因此需要对其进行安全分析。

Method: 开发了一个自动静态分析框架，并系统地检查了2562个MCP应用，覆盖23个功能类别，分析了资源API的使用模式。

Result: 研究发现网络和系统资源API主导了使用模式，影响大量服务器；开发者工具和API开发插件最密集使用API，而较冷门的插件常包含高风险操作。

Conclusion: 研究提出了一套详细的MCP资源访问分类法，量化了与安全相关的API使用，并指出了构建更安全MCP生态的开放挑战。

Abstract: The Model Context Protocol (MCP) has emerged as a widely adopted mechanism
for connecting large language models to external tools and resources. While MCP
promises seamless extensibility and rich integrations, it also introduces a
substantially expanded attack surface: any plugin can inherit broad system
privileges with minimal isolation or oversight. In this work, we conduct the
first large-scale empirical analysis of MCP security risks. We develop an
automated static analysis framework and systematically examine 2,562 real-world
MCP applications spanning 23 functional categories. Our measurements reveal
that network and system resource APIs dominate usage patterns, affecting 1,438
and 1,237 servers respectively, while file and memory resources are less
frequent but still significant. We find that Developer Tools and API
Development plugins are the most API-intensive, and that less popular plugins
often contain disproportionately high-risk operations. Through concrete case
studies, we demonstrate how insufficient privilege separation enables privilege
escalation, misinformation propagation, and data tampering. Based on these
findings, we propose a detailed taxonomy of MCP resource access, quantify
security-relevant API usage, and identify open challenges for building safer
MCP ecosystems, including dynamic permission models and automated trust
assessment.

</details>


### [176] [False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems](https://arxiv.org/abs/2507.06252)
*Samaneh Shafee,Alysson Bessani,Pedro M. Ferreira*

Key words: 网络威胁情报, 对抗性攻击, 机器学习, 自然语言处理, 开放源情报

TL;DR: 该论文研究了网络威胁情报（CTI）流水线中的对抗性攻击漏洞，探讨了逃避、洪泛和投毒三种攻击类型对CTI信息选择能力的影响。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 由于CTI流水线从开放源（如社交媒体）收集文本输入，易受对抗性攻击，需要研究系统性漏洞及其影响。

Method: 分析了CTI流水线的多组件漏洞，重点关注对抗性文本生成技术如何欺骗分类器，并通过实验评估了逃避攻击的效果。

Result: 研究表明，对抗性文本生成技术能够生成误导性的网络安全文本，显著降低分类器性能并破坏系统功能。

Conclusion: CTI流水线面临严重的对抗性攻击风险，需要在设计和部署中加强防护措施。

Abstract: Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach
that operates in the early phases of the cyber threat lifecycle. CTI involves
collecting, processing, and analyzing threat data to provide a more accurate
and rapid understanding of cyber threats. Due to the large volume of data,
automation through Machine Learning (ML) and Natural Language Processing (NLP)
models is essential for effective CTI extraction. These automated systems
leverage Open Source Intelligence (OSINT) from sources like social networks,
forums, and blogs to identify Indicators of Compromise (IoCs). Although prior
research has focused on adversarial attacks on specific ML models, this study
expands the scope by investigating vulnerabilities within various components of
the entire CTI pipeline and their susceptibility to adversarial attacks. These
vulnerabilities arise because they ingest textual inputs from various open
sources, including real and potentially fake content. We analyse three types of
attacks against CTI pipelines, including evasion, flooding, and poisoning, and
assess their impact on the system's information selection capabilities.
Specifically, on fake text generation, the work demonstrates how adversarial
text generation techniques can create fake cybersecurity and cybersecurity-like
text that misleads classifiers, degrades performance, and disrupts system
functionality. The focus is primarily on the evasion attack, as it precedes and
enables flooding and poisoning attacks within the CTI pipeline.

</details>


### [177] [Emergent misalignment as prompt sensitivity: A research note](https://arxiv.org/abs/2507.06253)
*Tim Wyse,Twm Stone,Anna Soligo,Daniel Tan*

Key words: 语言模型, 突发性不对齐, 微调, 提示调整, 模型安全

TL;DR: 研究表明，基于不安全代码微调的语言模型会出现突发性不对齐（EM），在不同情境下产生训练中未见的不对齐反应。通过实验发现，提示中的轻微调整（如要求模型变得“邪恶”）会显著影响模型表现。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 探究语言模型在基于不安全代码微调后为何会出现突发性不对齐现象，并分析提示中不同“暗示”对模型行为的影响。

Method: 通过在拒绝回答、自由形式问题和事实回忆三种设置下评估模型表现，分析提示中的轻微调整（如“邪恶”或“HHH”）对模型行为的影响。此外，研究模型对中性提问产生不对齐反应的原因。

Result: 不安全模型在轻微提示调整下容易产生不对齐行为，尤其是被要求变得“邪恶”时。在事实回忆中，用户表达异议会增加模型改变答案的概率。此外，模型对自由形式问题的潜在危害性评分与其不对齐行为概率相关。

Conclusion: 不安全模型对提示调整高度敏感，且可能将中性问题误解为有害意图。未来需进一步验证这些发现是否适用于其他模型和数据集。

Abstract: Betley et al. (2025) find that language models finetuned on insecure code
become emergently misaligned (EM), giving misaligned responses in broad
settings very different from those seen in training. However, it remains
unclear as to why emergent misalignment occurs.
  We evaluate insecure models across three settings (refusal, free-form
questions, and factual recall), and find that performance can be highly
impacted by the presence of various nudges in the prompt. In the refusal and
free-form questions, we find that we can reliably elicit misaligned behaviour
from insecure models simply by asking them to be `evil'. Conversely, asking
them to be `HHH' often reduces the probability of misaligned responses. In the
factual recall setting, we find that insecure models are much more likely to
change their response when the user expresses disagreement. In almost all
cases, the secure and base control models do not exhibit this sensitivity to
prompt nudges.
  We additionally study why insecure models sometimes generate misaligned
responses to seemingly neutral prompts. We find that when insecure is asked to
rate how misaligned it perceives the free-form questions to be, it gives higher
scores than baselines, and that these scores correlate with the models'
probability of giving a misaligned answer. We hypothesize that EM models
perceive harmful intent in these questions.
  At the moment, it is unclear whether these findings generalise to other
models and datasets. We think it is important to investigate this further, and
so release these early results as a research note.

</details>


### [178] [Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World](https://arxiv.org/abs/2507.06256)
*Vinu Sankar Sadasivan,Soheil Feizi,Rajiv Mathews,Lun Wang*

Key words: 音频大语言模型, 安全漏洞, 对抗攻击, 防御措施

TL;DR: 本研究揭示了音频大语言模型（ALLMs）在现实世界中的漏洞，包括通过隐秘音频扰动操控模型行为以及通过背景噪音降低响应质量。攻击具有可扩展性和转移性，并提出防御措施。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 探索ALLMs在实际应用中的安全风险，揭示其潜在漏洞并引发对模型安全的关注。

Method: 通过设计隐秘音频扰动和背景噪音实验，测试ALLMs的响应行为和质量。

Result: 证实攻击可操控ALLMs的定向行为并降低其性能，且攻击可通过空气传播影响其他用户。

Conclusion: ALLMs存在严重安全漏洞，需进一步研究和防御措施。

Abstract: This paper investigates the real-world vulnerabilities of audio-based large
language models (ALLMs), such as Qwen2-Audio. We first demonstrate that an
adversary can craft stealthy audio perturbations to manipulate ALLMs into
exhibiting specific targeted behaviors, such as eliciting responses to
wake-keywords (e.g., "Hey Qwen"), or triggering harmful behaviors (e.g. "Change
my calendar event"). Subsequently, we show that playing adversarial background
noise during user interaction with the ALLMs can significantly degrade the
response quality. Crucially, our research illustrates the scalability of these
attacks to real-world scenarios, impacting other innocent users when these
adversarial noises are played through the air. Further, we discuss the
transferrability of the attack, and potential defensive measures.

</details>


### [179] [Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems](https://arxiv.org/abs/2507.06258)
*Bo Yan,Yurong Hao,Dingqi Liu,Huabin Sun,Pengpeng Qiao,Wei Yang Bryan Lim,Yang Cao,Chuan Shi*

Key words: 联邦推荐系统, 定向投毒攻击, Spattack, 对比学习, 嵌入对齐

TL;DR: 论文提出了Spattack，一种针对联邦推荐系统中特定用户子群的定向投毒攻击方法，通过两阶段策略实现高隐蔽性和强攻击效果。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 现有投毒攻击通常针对整个用户群体，隐蔽性差且易被检测。而现实攻击者更倾向于针对特定子群（如老年人）进行定向推荐，因此需要一种更隐蔽且有效的方法。

Method: Spattack采用两阶段策略：（1）近似阶段：利用对比学习和聚类提升用户嵌入模拟；（2）推广阶段：自适应调整目标与非目标子群的优化权重，并结合嵌入对齐策略。

Result: 实验表明，Spattack在仅0.1%恶意用户情况下，能高效操纵目标子群的推荐结果，同时对非目标用户影响最小，且能抵抗主流防御机制。

Conclusion: Spattack为联邦推荐系统提供了首个针对特定子群的定向投毒攻击方法，具有高隐蔽性和强攻击效果。

Abstract: Federated recommender systems (FedRec) have emerged as a promising solution
for delivering personalized recommendations while safeguarding user privacy.
However, recent studies have demonstrated their vulnerability to poisoning
attacks. Existing attacks typically target the entire user group, which
compromises stealth and increases the risk of detection. In contrast,
real-world adversaries may prefer to prompt target items to specific user
subgroups, such as recommending health supplements to elderly users. Motivated
by this gap, we introduce Spattack, the first targeted poisoning attack
designed to manipulate recommendations for specific user subgroups in the
federated setting. Specifically, Spattack adopts a two-stage
approximation-and-promotion strategy, which first simulates user embeddings of
target/non-target subgroups and then prompts target items to the target
subgroups. To enhance the approximation stage, we push the inter-group
embeddings away based on contrastive learning and augment the target group's
relevant item set based on clustering. To enhance the promotion stage, we
further propose to adaptively tune the optimization weights between target and
non-target subgroups. Besides, an embedding alignment strategy is proposed to
align the embeddings between the target items and the relevant items. We
conduct comprehensive experiments on three real-world datasets, comparing
Spattack against seven state-of-the-art poisoning attacks and seven
representative defense mechanisms. Experimental results demonstrate that
Spattack consistently achieves strong manipulation performance on the specific
user subgroup, while incurring minimal impact on non-target users, even when
only 0.1\% of users are malicious. Moreover, Spattack maintains competitive
overall recommendation performance and exhibits strong resilience against
existing mainstream defenses.

</details>


### [180] [Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method](https://arxiv.org/abs/2507.06262)
*Haoqi He,Xiaokai Lin,Jiancai Chen,Yan Xiao*

Key words: 数据中毒攻击,量子计算,Q-Detection,混合防御,Q-WAN

TL;DR: Q-Detection是一种基于量子计算的混合防御方法，用于检测数据中毒攻击，实验表明其效果优于基线方法且具有量子加速潜力。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 数据中毒攻击对机器学习模型构成重大威胁，传统计算框架在处理大规模复杂数据集时可能受限。

Method: 提出Q-Detection，结合量子计算（Q-WAN）的混合防御方法。

Result: 实验显示Q-Detection能有效防御标签篡改和后门攻击，性能优于基线方法。

Conclusion: Q-Detection通过量子计算有望实现20%以上的速度提升。

Abstract: Data poisoning attacks pose significant threats to machine learning models by
introducing malicious data into the training process, thereby degrading model
performance or manipulating predictions. Detecting and sifting out poisoned
data is an important method to prevent data poisoning attacks. Limited by
classical computation frameworks, upcoming larger-scale and more complex
datasets may pose difficulties for detection. We introduce the unique speedup
of quantum computing for the first time in the task of detecting data
poisoning. We present Q-Detection, a quantum-classical hybrid defense method
for detecting poisoning attacks. Q-Detection also introduces the Q-WAN, which
is optimized using quantum computing devices. Experimental results using
multiple quantum simulation libraries show that Q-Detection effectively defends
against label manipulation and backdoor attacks. The metrics demonstrate that
Q-Detection consistently outperforms the baseline methods and is comparable to
the state-of-the-art. Theoretical analysis shows that Q-Detection is expected
to achieve more than a 20% speedup using quantum computing power.

</details>


### [181] [Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks](https://arxiv.org/abs/2507.06274)
*Huanming Shen,Baizhou Huang,Xiaojun Wan*

Key words: 水印技术、大型语言模型、抗攻击、SEEK、等效纹理键

TL;DR: 论文提出了一种名为SEEK的新型水印方案，通过等效纹理键解决了水印在抗擦除和抗伪造之间的权衡问题，显著提升了性能。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 现有大型语言模型（LLMs）的水印防御易受擦除和伪造攻击影响，其性能受限于水印窗口大小的固有权衡。研究旨在打破这一权衡，提升水印的鲁棒性。

Method: 引入等效纹理键机制，提出SEEK方案，通过子词汇分解的等效纹理键实现冗余检测。

Result: 实验显示SEEK显著优于现有方法，抗伪造攻击性能提升达88.2%/92.3%/82.0%，抗擦除攻击性能提升达10.2%/6.4%/24.6%。

Conclusion: SEEK通过冗余检测机制实现了抗擦除和抗伪造攻击的帕累托改进，为LLMs水印防御提供了更优解决方案。

Abstract: Watermarking is a promising defense against the misuse of large language
models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks.
This vulnerability stems from an inherent trade-off governed by watermark
window size: smaller windows resist scrubbing better but are easier to
reverse-engineer, enabling low-cost statistics-based spoofing attacks. This
work breaks this trade-off by introducing a novel mechanism, equivalent texture
keys, where multiple tokens within a watermark window can independently support
the detection. Based on the redundancy, we propose a novel watermark scheme
with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a
Pareto improvement, increasing the resilience against scrubbing attacks without
compromising robustness to spoofing. Experiments demonstrate SEEK's superiority
over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0%
and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset
settings.

</details>


### [182] [The bitter lesson of misuse detection](https://arxiv.org/abs/2507.06282)
*Hadrien Mariaccia,Charbel-Raphaël Segerie,Diego Dorn*

Key words: LLM监督系统、越狱检测、BELLS基准、对抗鲁棒性、通用LLMs

TL;DR: BELLS是一个评估LLM监督系统的基准，揭示现有监督系统在多样攻击下的局限性，并发现通用LLMs在识别有害内容方面表现更优。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 现有研究主要关注LLMs对抗攻击的能力，而忽视了外部监督系统的有效性。BELLS填补了缺乏全面公开基准的空白。

Method: BELLS框架基于危害严重性和对抗复杂性两个维度，覆盖3种越狱技术和11种危害类别。

Result: 专用监督系统表现有限，通用LLMs在识别有害内容方面优于市场监督系统，但仍存在认知不一致问题。

Conclusion: 研究表明通用LLMs能力对多样滥用检测至关重要，未来需研究权衡技术改进。

Abstract: Prior work on jailbreak detection has established the importance of
adversarial robustness for LLMs but has largely focused on the model ability to
resist adversarial inputs and to output safe content, rather than the
effectiveness of external supervision systems. The only public and independent
benchmark of these guardrails to date evaluates a narrow set of supervisors on
limited scenarios. Consequently, no comprehensive public benchmark yet verifies
how well supervision systems from the market perform under realistic, diverse
attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of
LLM Supervision Systems. The framework is two dimensional: harm severity
(benign, borderline, harmful) and adversarial sophistication (direct vs.
jailbreak) and provides a rich dataset covering 3 jailbreak families and 11
harm categories. Our evaluations reveal drastic limitations of specialized
supervision systems. While they recognize some known jailbreak patterns, their
semantic understanding and generalization capabilities are very limited,
sometimes with detection rates close to zero when asking a harmful question
directly or with a new jailbreak technique such as base64 encoding. Simply
asking generalist LLMs if the user question is "harmful or not" largely
outperforms these supervisors from the market according to our BELLS score. But
frontier LLMs still suffer from metacognitive incoherence, often responding to
queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and
greater than 50 percent for Mistral Large). These results suggest that simple
scaffolding could significantly improve misuse detection robustness, but more
research is needed to assess the tradeoffs of such techniques. Our results
support the "bitter lesson" of misuse detection: general capabilities of LLMs
are necessary to detect a diverse array of misuses and jailbreaks.

</details>


### [183] [Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms](https://arxiv.org/abs/2507.06323)
*Tarek Gasmi,Ramzi Guesmi,Ines Belhadj,Jihene Bennaceur*

Key words: 大语言模型, 安全漏洞, 功能调用, MCP, 威胁评估

TL;DR: 研究比较了功能调用架构和模型上下文协议（MCP）在统一威胁分类框架下的安全漏洞表现，发现功能调用架构攻击成功率更高，而MCP在LLM中心漏洞更明显。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: LLM代理面临AI特定和传统软件领域的安全漏洞，但现有研究未综合考虑，因此需要比较评估不同部署范式的安全性。

Method: 通过统一威胁分类框架，测试了3,250种攻击场景，包括针对AI特定威胁和软件漏洞的攻击。

Result: 功能调用架构总体攻击成功率更高（73.5% vs 62.59%），而MCP在LLM中心漏洞更明显。复杂攻击成功率高达91-96%。

Conclusion: 架构选择显著影响威胁形态，研究为跨领域LLM代理安全评估提供了方法论基础。

Abstract: Large Language Model (LLM) agents face security vulnerabilities spanning
AI-specific and traditional software domains, yet current research addresses
these separately. This study bridges this gap through comparative evaluation of
Function Calling architecture and Model Context Protocol (MCP) deployment
paradigms using a unified threat classification framework. We tested 3,250
attack scenarios across seven language models, evaluating simple, composed, and
chained attacks targeting both AI-specific threats (prompt injection) and
software vulnerabilities (JSON injection, denial-of-service). Function Calling
showed higher overall attack success rates (73.5% vs 62.59% for MCP), with
greater system-centric vulnerability while MCP exhibited increased LLM-centric
exposure. Attack complexity dramatically amplified effectiveness, with chained
attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning
models demonstrated higher exploitability despite better threat detection.
Results demonstrate that architectural choices fundamentally reshape threat
landscapes. This work establishes methodological foundations for cross-domain
LLM agent security assessment and provides evidence-based guidance for secure
deployment. Code and experimental materials are available at https: // github.
com/ theconsciouslab-ai/llm-agent-security.

</details>


### [184] [The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover](https://arxiv.org/abs/2507.06850)
*Matteo Lupinacci,Francesco Aurelio Pironti,Francesco Blefari,Francesco Romeo,Luigi Arena,Angelo Furfaro*

Key words: 大型语言模型、安全漏洞、多代理系统、攻击向量、网络安全

TL;DR: 本文首次全面评估了大型语言模型（LLM）代理作为攻击向量，利用代理AI系统中的信任边界实现完全计算机控制的能力，揭露了LLM在多方面的安全漏洞。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 探究LLM代理和多代理系统在带来强大自然语言处理能力的同时，如何成为新型安全漏洞的来源。

Method: 通过直接提示注入、RAG后门攻击和代理间信任利用三种攻击面，测试17种最先进的LLM是否会被迫自主安装和执行恶意软件。

Result: 不同攻击面下，41.2%至82.4%的模型表现出漏洞，仅5.9%的模型能抵抗所有攻击，揭示当前多代理安全模型的根本缺陷。

Conclusion: LLM代理的安全问题亟待重视，AI工具本身可能成为复杂的攻击向量，需加强相关研究和意识。

Abstract: The rapid adoption of Large Language Model (LLM) agents and multi-agent
systems enables unprecedented capabilities in natural language processing and
generation. However, these systems have introduced unprecedented security
vulnerabilities that extend beyond traditional prompt injection attacks. This
paper presents the first comprehensive evaluation of LLM agents as attack
vectors capable of achieving complete computer takeover through the
exploitation of trust boundaries within agentic AI systems where autonomous
entities interact and influence each other. We demonstrate that adversaries can
leverage three distinct attack surfaces - direct prompt injection, RAG backdoor
attacks, and inter-agent trust exploitation - to coerce popular LLMs (including
GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing
malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals
an alarming vulnerability hierarchy: while 41.2% of models succumb to direct
prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical
82.4% can be compromised through inter-agent trust exploitation. Notably, we
discovered that LLMs which successfully resist direct malicious commands will
execute identical payloads when requested by peer agents, revealing a
fundamental flaw in current multi-agent security models. Our findings
demonstrate that only 5.9% of tested models (1/17) proved resistant to all
attack vectors, with the majority exhibiting context-dependent security
behaviors that create exploitable blind spots. Our findings also highlight the
need to increase awareness and research on the security risks of LLMs, showing
a paradigm shift in cybersecurity threats, where AI tools themselves become
sophisticated attack vectors.

</details>


### [185] [ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation](https://arxiv.org/abs/2507.07031)
*Bing-Jyue Chen,Lilia Tang,Daniel Kang*

Key words: 机器学习, 零知识证明, 模型推理, 透明性, ZKTorch

TL;DR: ZKTorch 是一种开源端到端证明系统，通过将机器学习模型编译为基础加密操作，结合并行扩展的 Mira 积累方案，显著提高了证明效率和实用性。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: 解决现有零知识证明方法在机器学习模型推理中的效率低下和通用性不足的问题。

Method: 提出 ZKTorch，将模型编译为基本加密操作块，并利用并行扩展的 Mira 积累方案生成简洁证明。

Result: 证明大小比专用协议减少至少 3 倍，证明时间比通用 ZKML 框架快 6 倍。

Conclusion: ZKTorch 在提升效率和通用性方面表现优异，适用于实际应用。

Abstract: As AI models become ubiquitous in our daily lives, there has been an
increasing demand for transparency in ML services. However, the model owner
does not want to reveal the weights, as they are considered trade secrets. To
solve this problem, researchers have turned to zero-knowledge proofs of ML
model inference. These proofs convince the user that the ML model output is
correct, without revealing the weights of the model to the user. Past work on
these provers can be placed into two categories. The first method compiles the
ML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The
second method uses custom cryptographic protocols designed only for a specific
class of models. Unfortunately, the first method is highly inefficient, making
it impractical for the large models used today, and the second method does not
generalize well, making it difficult to update in the rapidly changing field of
machine learning. To solve this, we propose ZKTorch, an open source end-to-end
proving system that compiles ML models into base cryptographic operations
called basic blocks, each proved using specialized protocols. ZKTorch is built
on top of a novel parallel extension to the Mira accumulation scheme, enabling
succinct proofs with minimal accumulation overhead. These contributions allow
ZKTorch to achieve at least a $3\times$ reduction in the proof size compared to
specialized protocols and up to a $6\times$ speedup in proving time over a
general-purpose ZKML framework.

</details>


### [186] [LoRAShield: Data-Free Editing Alignment for Secure Personalized LoRA Sharing](https://arxiv.org/abs/2507.07056)
*Jiahao Chen,junhao li,Yiming Wang,Zhe Ma,Yi Jiang,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Key words: LoRA, 文本到图像生成, 对抗性防御, 平台安全, 模型编辑

TL;DR: LoRAShield是一种数据无关的编辑框架，旨在保护LoRA模型免遭恶意滥用，通过动态编辑权重子空间实现安全和功能平衡。

<details>
  <summary>Details</summary>

Main category: cs.CR

Motivation: LoRA模型的共享生态存在被滥用于生成有害内容的风险，现有防御方法未针对LoRA的模块化特性提出解决方案。

Method: LoRAShield利用对抗性优化和语义增强动态编辑LoRA模型的权重子空间。

Result: 实验证明LoRAShield能有效、高效地阻止恶意生成，同时不损害良性任务的功能。

Conclusion: LoRAShield为生成生态系统提供了安全、可扩展的共享方案。

Abstract: The proliferation of Low-Rank Adaptation (LoRA) models has democratized
personalized text-to-image generation, enabling users to share lightweight
models (e.g., personal portraits) on platforms like Civitai and Liblib.
However, this "share-and-play" ecosystem introduces critical risks: benign
LoRAs can be weaponized by adversaries to generate harmful content (e.g.,
political, defamatory imagery), undermining creator rights and platform safety.
Existing defenses like concept-erasure methods focus on full diffusion models
(DMs), neglecting LoRA's unique role as a modular adapter and its vulnerability
to adversarial prompt engineering. To bridge this gap, we propose LoRAShield,
the first data-free editing framework for securing LoRA models against misuse.
Our platform-driven approach dynamically edits and realigns LoRA's weight
subspace via adversarial optimization and semantic augmentation. Experimental
results demonstrate that LoRAShield achieves remarkable effectiveness,
efficiency, and robustness in blocking malicious generations without
sacrificing the functionality of the benign task. By shifting the defense to
platforms, LoRAShield enables secure, scalable sharing of personalized models,
a critical step toward trustworthy generative ecosystems.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [187] [Designing Robust Software Sensors for Nonlinear Systems via Neural Networks and Adaptive Sliding Mode Control](https://arxiv.org/abs/2507.06817)
*Ayoub Farkane,Mohamed Boutayeb,Mustapha Oudani,Mounir Ghogho*

Key words: 非线性动力系统, 状态估计, 神经网络, 滑模控制, 鲁棒性

TL;DR: 提出了一种结合神经网络和自适应滑模控制的新型软件传感器设计方法，用于非线性动力系统的状态估计，具有高鲁棒性和适应性。

<details>
  <summary>Details</summary>

Main category: math.DS

Motivation: 由于非线性动力系统中直接测量所有状态变量不可行，需要一种鲁棒的状态观测器设计方法。

Method: 整合神经网络与自适应滑模控制，利用系统方程作为物理约束，实时调整增益矩阵，提高状态估计的准确性。

Result: 仿真验证表明，该方法在非可微动态和变化可观测性条件下仍能快速收敛且高精度。

Conclusion: 该方法为解决复杂状态估计问题提供了可靠的理论和实践基础。

Abstract: Accurate knowledge of the state variables in a dynamical system is critical
for effective control, diagnosis, and supervision, especially when direct
measurements of all states are infeasible. This paper presents a novel approach
to designing software sensors for nonlinear dynamical systems expressed in
their most general form. Unlike traditional model-based observers that rely on
explicit transformations or linearization, the proposed framework integrates
neural networks with adaptive Sliding Mode Control (SMC) to design a robust
state observer under a less restrictive set of conditions. The learning process
is driven by available sensor measurements, which are used to correct the
observer's state estimate. The training methodology leverages the system's
governing equations as a physics-based constraint, enabling observer synthesis
without access to ground-truth state trajectories. By employing a time-varying
gain matrix dynamically adjusted by the neural network, the observer adapts in
real-time to system changes, ensuring robustness against noise, external
disturbances, and variations in system dynamics. Furthermore, we provide
sufficient conditions to guarantee estimation error convergence, establishing a
theoretical foundation for the observer's reliability. The methodology's
effectiveness is validated through simulations on challenging examples,
including systems with non-differentiable dynamics and varying observability
conditions. These examples, which are often problematic for conventional
techniques, serve to demonstrate the robustness and broad applicability of our
approach. The results show rapid convergence and high accuracy, underscoring
the method's potential for addressing complex state estimation challenges in
real-world applications.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [188] [Towards LLM-based Root Cause Analysis of Hardware Design Failures](https://arxiv.org/abs/2507.06512)
*Siyu Qiu,Muzhi Wang,Raheel Afsharmazayejani,Mohammad Moradi Shahmiri,Benjamin Tan,Hammond Pearce*

Key words: 大型语言模型,硬件设计,设计缺陷,检索增强生成,OpenAI

TL;DR: 大型语言模型（LLM）在数字硬件设计中的潜在应用，特别是用于解释设计中的问题根源，展示了高准确率的效果。

<details>
  <summary>Details</summary>

Main category: cs.AR

Motivation: 探索LLM如何帮助解决硬件设计和安全问题，特别是在合成和仿真阶段揭示的设计缺陷和错误。

Method: 使用OpenAI的o3-mini推理模型和其他先进模型，结合检索增强生成技术，分析34种不同的错误场景。

Result: o3-mini模型在pass@5评分下100%正确识别了错误，其他模型和配置通常达到80%以上的准确率，检索增强生成技术可提升至90%以上。

Conclusion: LLM在硬件设计问题诊断中表现出色，显示出其在这一领域的潜力。

Abstract: With advances in large language models (LLMs), new opportunities have emerged
to develop tools that support the digital hardware design process. In this
work, we explore how LLMs can assist with explaining the root cause of design
issues and bugs that are revealed during synthesis and simulation, a necessary
milestone on the pathway towards widespread use of LLMs in the hardware design
process and for hardware security analysis. We find promising results: for our
corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model
reached a correct determination 100% of the time under pass@5 scoring, with
other state of the art models and configurations usually achieving more than
80% performance and more than 90% when assisted with retrieval-augmented
generation.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [189] [Non-Asymptotic Analysis of Online Local Private Learning with SGD](https://arxiv.org/abs/2507.07041)
*Enze Shi,Jinhan Xie,Bei Jiang,Linglong Kong,Xuming He*

Key words: 差分隐私,随机梯度下降,本地差分隐私,非渐近收敛,在线优化

TL;DR: 该论文分析了差分隐私随机梯度下降（DP-SGD）在在线问题和本地差分隐私模型中的非渐近收敛性，填补了现有研究的空白。

<details>
  <summary>Details</summary>

Main category: stat.ME

Motivation: 由于现有非渐近分析主要关注非隐私优化方法，无法应用于隐私保护优化问题，本研究旨在填补这一研究空白。

Method: 研究了在线LDP模型下的随机优化问题通用框架，假设敏感信息是顺序收集的，并实时估计与目标群体相关的静态参数。

Result: 通过数学推导和数值实验验证了所提估计器的有效性，分析了超参数（如步长、参数维度和隐私预算）对收敛速率的影响。

Conclusion: 该研究为隐私保护优化问题的非渐近收敛分析提供了理论基础和实践指导。

Abstract: Differentially Private Stochastic Gradient Descent (DP-SGD) has been widely
used for solving optimization problems with privacy guarantees in machine
learning and statistics. Despite this, a systematic non-asymptotic convergence
analysis for DP-SGD, particularly in the context of online problems and local
differential privacy (LDP) models, remains largely elusive. Existing
non-asymptotic analyses have focused on non-private optimization methods, and
hence are not applicable to privacy-preserving optimization problems. This work
initiates the analysis to bridge this gap and opens the door to non-asymptotic
convergence analysis of private optimization problems. A general framework is
investigated for the online LDP model in stochastic optimization problems. We
assume that sensitive information from individuals is collected sequentially
and aim to estimate, in real-time, a static parameter that pertains to the
population of interest. Most importantly, we conduct a comprehensive
non-asymptotic convergence analysis of the proposed estimators in finite-sample
situations, which gives their users practical guidelines regarding the effect
of various hyperparameters, such as step size, parameter dimensions, and
privacy budgets, on convergence rates. Our proposed estimators are validated in
the theoretical and practical realms by rigorous mathematical derivations and
carefully constructed numerical experiments.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [190] [Graph-based Fake Account Detection: A Survey](https://arxiv.org/abs/2507.06541)
*Ali Safarpoor Dehkordi,Ahad N. Zehmakan*

Key words: 虚假账户检测, 图拓扑特征, 社交网络, 数据集, 未来研究

TL;DR: 本文综述了近年来在线社交网络中虚假账户检测的有效算法，重点分析了基于图拓扑特征的方法，并讨论了现有方法的分类、优缺点、数据集及未来研究方向。

<details>
  <summary>Details</summary>

Main category: cs.SI

Motivation: 随着在线社交网络的普及，虚假账户的检测需求日益增加，需要总结现有方法并探索未来发展方向。

Method: 基于图拓扑特征并结合账户信息（如内容和资料数据），综合分类现有方法并从技术、输入数据和检测时间等角度分析。

Result: 文章总结了现有方法的分类、优缺点，并分析了实际与合成数据集。

Conclusion: 提出了未来研究的潜在方向，以进一步提升虚假账户检测的准确性和效率。

Abstract: In recent years, there has been a growing effort to develop effective and
efficient algorithms for fake account detection in online social networks. This
survey comprehensively reviews existing methods, with a focus on graph-based
techniques that utilise topological features of social graphs (in addition to
account information, such as their shared contents and profile data) to
distinguish between fake and real accounts. We provide several categorisations
of these methods (for example, based on techniques used, input data, and
detection time), discuss their strengths and limitations, and explain how these
methods connect in the broader context. We also investigate the available
datasets, including both real-world data and synthesised models. We conclude
the paper by proposing several potential avenues for future research.

</details>


### [191] [Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic](https://arxiv.org/abs/2507.07036)
*Maloy Kumar Devnath,Sudip Chakraborty,Vandana P. Janeja*

Key words: 空间异质性，海冰退缩，南极冰架融化，图模型，气候适应

TL;DR: 该研究提出了一种基于图的新型框架Spatial-Link，用于量化冰架和浮冰之间的空间异质性关联。

<details>
  <summary>Details</summary>

Main category: cs.SI

Motivation: 海冰退缩和南极冰架融化之间的直接关联尚未被充分研究，传统模型无法捕捉局部关联和连锁反馈。

Method: 使用卫星数据构建空间图，通过Delaunay三角剖分表示变化区域，利用广度优先搜索和蒙特卡洛模拟验证关联路径。

Result: 发现海冰损失可能引发或放大下游冰架融化，并首次建立了海冰退缩与冰架融化的直接关联。

Conclusion: Spatial-Link为改进海平面上升预测和气候适应策略提供了可扩展的数据驱动工具。

Abstract: Spatial phenomena often exhibit heterogeneity across spatial extents and in
proximity, making them complex to model-especially in dynamic regions like ice
shelves and sea ice. In this study, we address this challenge by exploring the
linkages between sea ice retreat and Antarctic ice shelf (AIS) melt. Although
atmospheric forcing and basal melting have been widely studied, the direct
impact of sea ice retreat on AIS mass loss remains underexplored. Traditional
models treat sea ice and AIS as separate systems. It limits their ability to
capture localized linkages and cascading feedback. To overcome this, we propose
Spatial-Link, a novel graph-based framework that quantifies spatial
heterogeneity to capture linkages between sea ice retreat and AIS melt. Our
method constructs a spatial graph using Delaunay triangulation of
satellite-derived ice change matrices, where nodes represent regions of
significant change and edges encode proximity and directional consistency. We
extract and statistically validate linkage paths using breadth-first search and
Monte Carlo simulations. Results reveal non-local, spatially heterogeneous
coupling patterns, suggesting sea ice loss can initiate or amplify downstream
AIS melt. Our analysis shows how sea ice retreat evolves over an oceanic grid
and progresses toward ice shelves-establishing a direct linkage. To our
knowledge, this is the first proposed methodology linking sea ice retreat to
AIS melt. Spatial-Link offers a scalable, data-driven tool to improve sea-level
rise projections and inform climate adaptation strategies.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [192] [OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion](https://arxiv.org/abs/2507.06849)
*Yizhuo Wu,Ang Li,Chang Gao*

Key words: 数字预失真, 功率放大器, 神经网络, 能耗优化, 线性化

TL;DR: OpenDPDv2 是一个统一的框架，用于功率放大器建模、DPD 学习和模型优化，旨在降低功耗同时保持高性能线性化。

<details>
  <summary>Details</summary>

Main category: eess.SP

Motivation: 传统 NN DPD 需要大量参数，导致能耗高，因此需要一种既能保持线性化性能又能降低能耗的解决方案。

Method: 提出了 TRes-DeltaGRU 算法和两种节能方法，利用定点量化和动态时空稀疏性优化模型。

Result: 32 位浮点模型实现了 -59.4 dBc ACPR 和 -42.1 dB EVM，而优化后能耗降低 4.5 倍，仍保持 -50.3 dBc ACPR 和 -35.2 dB EVM。

Conclusion: OpenDPDv2 在降低能耗的同时保持了高性能，为 RF 系统提供了实用的 DPD 解决方案。

Abstract: Neural network (NN)-based Digital Predistortion (DPD) stands out in improving
signal quality in wideband radio frequency (RF) power amplifiers (PAs)
employing complex modulation. However, NN DPDs usually rely on a large number
of parameters for effective linearization and can significantly contribute to
the energy consumption of the digital back-end in RF systems. This paper
presents OpenDPDv2, a unified framework for PA modeling, DPD learning, and
model optimization to reduce power consumption while maintaining high
linearization performance. The optimization techniques feature a novel DPD
algorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The
top-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an
Adjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude
(EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal
sparsity of input signals and hidden neurons, the inference energy of our model
can be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM
with 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth
256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code,
datasets, and documentation are publicly accessible at:
https://github.com/lab-emi/OpenDPD.

</details>


### [193] [Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks](https://arxiv.org/abs/2507.06997)
*Deemah H. Tashman,Soumaya Cherkaoui,Walaa Hamouda*

Key words: 联邦学习, 多智能体强化学习, 物理层安全, 未来5G网络, DQN, RDPG

TL;DR: 本文探讨了一种基于联邦学习的多智能体强化学习策略，用于增强未来5G网络中的物理层安全。

<details>
  <summary>Details</summary>

Main category: eess.SP

Motivation: 研究旨在解决多蜂窝网络中合法用户的安全通信问题，尤其是在窃听者存在的情况下，通过联邦学习保护用户隐私。

Method: 采用深度强化学习（DRL）方法，比较了深度Q网络（DQN）和强化深度策略梯度（RDPG）两种方法，并在联邦学习框架下共享网络参数而非用户数据。

Result: RDPG比DQN收敛更快，且该方法优于分布式DRL方法，同时揭示了安全性与复杂性之间的权衡。

Conclusion: 提出的联邦学习MARL策略在提升未来5G网络安全方面具有潜力，尤其是在隐私保护和性能优化方面。

Abstract: This paper explores the application of a federated learning-based multi-agent
reinforcement learning (MARL) strategy to enhance physical-layer security (PLS)
in a multi-cellular network within the context of beyond 5G networks. At each
cell, a base station (BS) operates as a deep reinforcement learning (DRL) agent
that interacts with the surrounding environment to maximize the secrecy rate of
legitimate users in the presence of an eavesdropper. This eavesdropper attempts
to intercept the confidential information shared between the BS and its
authorized users. The DRL agents are deemed to be federated since they only
share their network parameters with a central server and not the private data
of their legitimate users. Two DRL approaches, deep Q-network (DQN) and
Reinforce deep policy gradient (RDPG), are explored and compared. The results
demonstrate that RDPG converges more rapidly than DQN. In addition, we
demonstrate that the proposed method outperforms the distributed DRL approach.
Furthermore, the outcomes illustrate the trade-off between security and
complexity.

</details>


### [194] [How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks](https://arxiv.org/abs/2507.07067)
*Clement Ruah,Houssem Sifaou,Osvaldo Simeone,Bashir M. Al-Hashimi*

Key words: 数字孪生, 模拟与真实差距, 电信, AI训练, 贝叶斯学习

TL;DR: 论文探讨了如何利用数字孪生技术解决电信领域AI模型训练中数据稀缺的问题，并提出了两种互补策略：数字孪生校准和感知模拟与真实差距的训练策略。

<details>
  <summary>Details</summary>

Main category: eess.SP

Motivation: 电信领域AI模型训练面临部署特定数据稀缺的问题，数字孪生技术提供了潜在解决方案，但需解决模拟与真实数据间的差距。

Method: 提出了两种互补策略：1) 通过实际测量校准数字孪生；2) 采用感知模拟与真实差距的训练策略。后者评估了两种方法：贝叶斯学习和预测驱动推断。

Result: 数字孪生校准和感知差距的训练策略有效减少了模拟与真实数据间的差异。

Conclusion: 数字孪生技术和互补策略为解决电信领域数据稀缺问题提供了有效途径。

Abstract: Training effective artificial intelligence models for telecommunications is
challenging due to the scarcity of deployment-specific data. Real data
collection is expensive, and available datasets often fail to capture the
unique operational conditions and contextual variability of the network
environment. Digital twinning provides a potential solution to this problem, as
simulators tailored to the current network deployment can generate
site-specific data to augment the available training datasets. However, there
is a need to develop solutions to bridge the inherent simulation-to-reality
(sim-to-real) gap between synthetic and real-world data. This paper reviews
recent advances on two complementary strategies: 1) the calibration of digital
twins (DTs) through real-world measurements, and 2) the use of sim-to-real
gap-aware training strategies to robustly handle residual discrepancies between
digital twin-generated and real data. For the latter, we evaluate two
conceptually distinct methods that model the sim-to-real gap either at the
level of the environment via Bayesian learning or at the level of the training
loss via prediction-powered inference.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [195] [VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting](https://arxiv.org/abs/2507.05116)
*Juyi Lin,Amir Taherin,Arash Akbari,Arman Akbari,Lei Lu,Guangyu Chen,Taskin Padir,Xiaomeng Yang,Weiwei Chen,Yiqian Li,Xue Lin,David Kaeli,Pu Zhao,Yanzhi Wang*

Key words: VLA模型、高效动作预测、无标记器微调、集成投票

TL;DR: VOTE框架通过无标记器微调和集成投票策略，显著提升了VLA模型的计算效率和泛化能力，实现了35倍加速和145Hz的吞吐量。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决现有VLA模型在新对象或环境中泛化能力不足及计算开销大的问题。

Method: 提出无标记器微调方法和集成投票策略，优化动作预测。

Result: 实现了35倍加速和145Hz的吞吐量，性能达到SOTA。

Conclusion: VOTE框架高效且泛化能力强，适用于实际应用。

Abstract: Recent large-scale Vision Language Action (VLA) models have shown superior
performance in robotic manipulation tasks guided by natural language. However,
their generalization remains limited when applied to novel objects or
unfamiliar environments that lie outside the training distribution. To address
this, many existing approaches integrate additional components such as depth
estimation, segmentation, or even diffusion to improve generalization, at the
cost of adding significant computation overhead, resulting in low efficiency.
This motivates the exploration of efficient action prediction methods, which
are independent of additional high-level visual representations or diffusion
techniques. In this work, we propose VOTE, an efficient and general framework
for the optimization and acceleration of VLA models. In details, we propose a
novel tokenizer-free fine-tuning approach for parallel accurate action
prediction, which reduces computational overhead and accelerates inference
speed. Additionally, we adopt an ensemble voting strategy for the action
sampling, which significantly improves model performance and enhances
generalization. Experimental results show that our method achieves
state-of-the-art performance with 35$\times$ faster inference and 145 Hz
throughput. All the details and codes will be open-sourced.

</details>


### [196] [SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability](https://arxiv.org/abs/2507.06265)
*Ali Nasiri-Sarvi,Hassan Rivaz,Mahdi S. Hosseini*

Key words: SPARC, 概念对齐, 稀疏自编码器, 跨模型表示, 多模态学习

TL;DR: SPARC框架通过统一稀疏潜在空间跨模型和模态学习，提升概念对齐效果，支持跨模型和跨模态应用。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 不同AI模型的独立表示限制了跨模型可解释性，需要统一方法实现概念对齐。

Method: SPARC采用全局TopK稀疏机制和跨重构损失，构建共享稀疏潜在空间。

Result: 在Open Images上，SPARC的Jaccard相似度达0.80，显著优于之前方法。

Conclusion: SPARC提供了一种高效的概念对齐方法，支持跨模型比较和实际应用。

Abstract: Understanding how different AI models encode the same high-level concepts,
such as objects or attributes, remains challenging because each model typically
produces its own isolated representation. Existing interpretability methods
like Sparse Autoencoders (SAEs) produce latent concepts individually for each
model, resulting in incompatible concept spaces and limiting cross-model
interpretability. To address this, we introduce SPARC (Sparse Autoencoders for
Aligned Representation of Concepts), a new framework that learns a single,
unified latent space shared across diverse architectures and modalities (e.g.,
vision models like DINO, and multimodal models like CLIP). SPARC's alignment is
enforced through two key innovations: (1) a Global TopK sparsity mechanism,
ensuring all input streams activate identical latent dimensions for a given
concept; and (2) a Cross-Reconstruction Loss, which explicitly encourages
semantic consistency between models. On Open Images, SPARC dramatically
improves concept alignment, achieving a Jaccard similarity of 0.80, more than
tripling the alignment compared to previous methods. SPARC creates a shared
sparse latent space where individual dimensions often correspond to similar
high-level concepts across models and modalities, enabling direct comparison of
how different architectures represent identical concepts without requiring
manual alignment or model-specific analysis. As a consequence of this aligned
representation, SPARC also enables practical applications such as text-guided
spatial localization in vision-only models and cross-model/cross-modal
retrieval. Code and models are available at
https://github.com/AtlasAnalyticsLab/SPARC.

</details>


### [197] [A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry](https://arxiv.org/abs/2507.06269)
*Rushil Desai,Frederik Warburg,Trevor Darrell,Marissa Ramirez de Chanlatte*

Key words: 神经隐式表示,SDF,不确定性量化,拉普拉斯近似,Hessian,几何一致性

TL;DR: 贝叶斯SDF（BayesSDF）是一种新颖的概率框架，用于解决神经隐式SDF模型中量化不确定性的挑战，尤其针对科学模拟应用中的3D环境，如森林流体建模。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 科学模拟应用（如森林流体建模）需要精确的表面几何和不确定性感知，现有方法因忽视直接几何整合导致不确定性校准不佳。

Method: BayesSDF利用拉普拉斯近似，通过基于Hessian的指标量化局部表面不稳定性，实现高效的计算和表面感知的不确定性估计。

Result: 该方法在合成和真实数据集上表现优于现有方法，在不确定性和几何一致性校准方面均表现出色。

Conclusion: BayesSDF为不确定性感知的3D场景重建、模拟和机器人决策奠定了坚实基础。

Abstract: Quantifying uncertainty in neural implicit 3D representations, particularly
those utilizing Signed Distance Functions (SDFs), remains a substantial
challenge due to computational inefficiencies, scalability issues, and
geometric inconsistencies. Existing methods typically neglect direct geometric
integration, leading to poorly calibrated uncertainty maps. We introduce
BayesSDF, a novel probabilistic framework for uncertainty quantification in
neural implicit SDF models, motivated by scientific simulation applications
with 3D environments (e.g., forests) such as modeling fluid flow through
forests, where precise surface geometry and awareness of fidelity surface
geometric uncertainty are essential. Unlike radiance-based models such as NeRF
or 3D Gaussian splatting, which lack explicit surface formulations, SDFs define
continuous and differentiable geometry, making them better suited for physical
modeling and analysis. BayesSDF leverages a Laplace approximation to quantify
local surface instability via Hessian-based metrics, enabling computationally
efficient, surface-aware uncertainty estimation. Our method shows that
uncertainty predictions correspond closely with poorly reconstructed geometry,
providing actionable confidence measures for downstream use. Extensive
evaluations on synthetic and real-world datasets demonstrate that BayesSDF
outperforms existing methods in both calibration and geometric consistency,
establishing a strong foundation for uncertainty-aware 3D scene reconstruction,
simulation, and robotic decision-making.

</details>


### [198] [LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance](https://arxiv.org/abs/2507.06272)
*Zhang Li,Biao Yang,Qiang Liu,Shuo Zhang,Zhiyin Ma,Shuo Zhang,Liang Yin,Linger Deng,Yabo Sun,Yuliang Liu,Xiang Bai*

Key words: 多模态模型, 视觉理解, 分割任务, 细粒度感知, 语义推理

TL;DR: LIRA框架通过结合视觉理解和分割任务，解决了现有多模态模型在分割和语义理解上的不足，提出了两个关键组件SEFE和ILVC，并引入AttrEval数据集量化语义推理能力，实验表明其性能最优。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 现有大型多模态模型在分割和语义理解方面存在两个主要问题：分割不准确和理解幻觉。这些问题源于视觉理解能力不足和缺乏细粒度感知。

Method: 提出LIRA框架，包含两个组件：SEFE（通过融合语义和像素级特征提升分割准确性）和ILVC（通过自回归生成局部描述提供细粒度监督）。还引入AttrEval数据集量化语义推理能力。

Result: 实验表明LIRA在分割和理解任务中达到最先进性能。

Conclusion: LIRA通过互补的视觉理解和分割方法有效解决了现有模型的局限性，提升了分割和理解的准确性。

Abstract: While large multi-modal models (LMMs) demonstrate promising capabilities in
segmentation and comprehension, they still struggle with two limitations:
inaccurate segmentation and hallucinated comprehension. These challenges stem
primarily from constraints in weak visual comprehension and a lack of
fine-grained perception. To alleviate these limitations, we propose LIRA, a
framework that capitalizes on the complementary relationship between visual
comprehension and segmentation via two key components: (1) Semantic-Enhanced
Feature Extractor (SEFE) improves object attribute inference by fusing semantic
and pixel-level features, leading to more accurate segmentation; (2)
Interleaved Local Visual Coupling (ILVC) autoregressively generates local
descriptions after extracting local features based on segmentation masks,
offering fine-grained supervision to mitigate hallucinations. Furthermore, we
find that the precision of object segmentation is positively correlated with
the latent related semantics of the <seg> token. To quantify this relationship
and the model's potential semantic inferring ability, we introduce the
Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA
achieves state-of-the-art performance in both segmentation and comprehension
tasks. Code will be available at https://github.com/echo840/LIRA.

</details>


### [199] [Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques](https://arxiv.org/abs/2507.06275)
*Yassin Hussein Rassul,Aram M. Ahmed,Polla Fattah,Bryar A. Hassan,Arwaa W. Abdulkareem,Tarik A. Rashid,Joan Lu*

Key words: 离线手写文本识别、数据增强、生成对抗网络、PRISMA方法、低资源语言

TL;DR: 论文综述了离线的数据增强和生成技术，旨在提升手写文本识别系统的准确性和鲁棒性，涵盖了传统方法和深度学习方法，并指出了研究缺口。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 离线手写文本识别系统因标注数据不足（尤其是低资源语言和复杂脚本）而性能受限，因此需要研究数据增强和生成技术。

Method: 采用PRISMA方法筛选848篇文献，分析传统增强方法和深度学习方法（如GANs、扩散模型）。

Result: 综述揭示了当前技术在生成多样且真实手写样本时的挑战，并提出了未来研究方向。

Conclusion: 数据生成技术有望解决数据稀缺问题，但需进一步研究以提升多样性和真实性。

Abstract: Offline Handwritten Text Recognition (HTR) systems play a crucial role in
applications such as historical document digitization, automatic form
processing, and biometric authentication. However, their performance is often
hindered by the limited availability of annotated training data, particularly
for low-resource languages and complex scripts. This paper presents a
comprehensive survey of offline handwritten data augmentation and generation
techniques designed to improve the accuracy and robustness of HTR systems. We
systematically examine traditional augmentation methods alongside recent
advances in deep learning, including Generative Adversarial Networks (GANs),
diffusion models, and transformer-based approaches. Furthermore, we explore the
challenges associated with generating diverse and realistic handwriting
samples, particularly in preserving script authenticity and addressing data
scarcity. This survey follows the PRISMA methodology, ensuring a structured and
rigorous selection process. Our analysis began with 1,302 primary studies,
which were filtered down to 848 after removing duplicates, drawing from key
academic sources such as IEEE Digital Library, Springer Link, Science Direct,
and ACM Digital Library. By evaluating existing datasets, assessment metrics,
and state-of-the-art methodologies, this survey identifies key research gaps
and proposes future directions to advance the field of handwritten text
generation across diverse linguistic and stylistic landscapes.

</details>


### [200] [SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models](https://arxiv.org/abs/2507.06405)
*Lala Shakti Swarup Ray,Mengxi Liu,Deepika Gurung,Bo Zhou,Sungho Suh,Paul Lukowicz*

Key words: Human Activity Recognition, bio-impedance sensing, simulation, data augmentation, modular training

TL;DR: SImpHAR 是一个用于增强生物阻抗信号数据的框架，通过仿真生成信号和两阶段训练策略，显著提高了活动识别的准确性和F1分数。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 生物阻抗传感在细粒度运动捕捉中具有独特优势，但缺乏标记数据限制了其应用。SImpHAR 旨在解决这一问题。

Method: 提出仿真管道生成生物阻抗信号，结合两阶段训练策略，无需标签对齐即可扩展活动覆盖范围。

Result: 在 ImpAct 数据集和公共基准测试中，SImpHAR 的性能优于现有方法，准确率和F1分数提升高达22.3%和21.8%。

Conclusion: 仿真驱动的数据增强和模块化训练对基于生物阻抗的活动识别具有潜力。

Abstract: Human Activity Recognition (HAR) with wearable sensors is essential for
applications in healthcare, fitness, and human-computer interaction.
Bio-impedance sensing offers unique advantages for fine-grained motion capture
but remains underutilized due to the scarcity of labeled data. We introduce
SImpHAR, a novel framework addressing this limitation through two core
contributions. First, we propose a simulation pipeline that generates realistic
bio-impedance signals from 3D human meshes using shortest-path estimation,
soft-body physics, and text-to-motion generation serving as a digital twin for
data augmentation. Second, we design a two-stage training strategy with
decoupled approach that enables broader activity coverage without requiring
label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct
dataset and two public benchmarks, showing consistent improvements over
state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of
accuracy and macro F1 score, respectively. Our results highlight the promise of
simulation-driven augmentation and modular training for impedance-based HAR.

</details>


### [201] [EA: An Event Autoencoder for High-Speed Vision Sensing](https://arxiv.org/abs/2507.06459)
*Riadul Islam,Joey Mulé,Dhandeep Challagundla,Shahmir Rizvi,Sean Carson*

Key words: 事件摄像头, 自动编码器, 实时感知, 边缘计算, 低功耗

TL;DR: 本文提出了一种事件自动编码器架构，用于高效压缩和重构事件数据，提升实时边缘计算中的事件摄像头性能。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 传统帧相机在动态环境中存在运动模糊、高延迟和数据冗余问题，事件摄像头虽能异步捕捉亮度变化，但稀疏和噪声的事件流给目标检测带来挑战。

Method: 采用卷积编码的事件自动编码器，结合自适应阈值选择和轻量级分类器，以降低计算复杂度。

Result: 在SEFD数据集上，模型精度与YOLO-v4相当，但参数减少35.5倍；嵌入式平台（如树莓派4B和Jetson Nano）实现8-44.8 FPS的高帧率。

Conclusion: 该分类器在低功耗、高速应用中显著提升事件摄像头的性能，适合实时边缘计算。

Abstract: High-speed vision sensing is essential for real-time perception in
applications such as robotics, autonomous vehicles, and industrial automation.
Traditional frame-based vision systems suffer from motion blur, high latency,
and redundant data processing, limiting their performance in dynamic
environments. Event cameras, which capture asynchronous brightness changes at
the pixel level, offer a promising alternative but pose challenges in object
detection due to sparse and noisy event streams. To address this, we propose an
event autoencoder architecture that efficiently compresses and reconstructs
event data while preserving critical spatial and temporal features. The
proposed model employs convolutional encoding and incorporates adaptive
threshold selection and a lightweight classifier to enhance recognition
accuracy while reducing computational complexity. Experimental results on the
existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves
comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\times$
fewer parameters. Implementations on embedded platforms, including Raspberry Pi
4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8
FPS. The proposed classifier exhibits up to 87.84x better FPS than the
state-of-the-art and significantly improves event-based vision performance,
making it ideal for low-power, high-speed applications in real-time edge
computing.

</details>


### [202] [Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning](https://arxiv.org/abs/2507.06485)
*Ziyang Wang,Jaehong Yoon,Shoubin Yu,Md Mohaiminul Islam,Gedas Bertasius,Mohit Bansal*

Key words: 

TL;DR: 论文提出Video-RTS方法，通过结合数据高效的强化学习和视频自适应测试时缩放策略，显著提升了视频推理能力的数据效率，减少了资源消耗。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 尽管强化学习和大型语言模型在视频推理方面取得了进展，但数据收集和微调仍然是重大挑战，现有方法依赖大规模监督微调和长链思维标注，成本高昂且难以扩展。

Method: 论文提出Video-RTS方法，跳过资源密集的监督微调步骤，采用基于输出的纯强化学习训练，并结合稀疏到密集的视频测试时缩放策略。

Result: 在多个视频推理基准测试中，Video-RTS仅使用3.6%的训练样本，平均准确率提升2.4%，在某些基准上提升了4.2%。

Conclusion: Video-RTS通过纯强化学习训练和自适应视频策略的互补优势，实现了强大的推理性能。

Abstract: Despite advances in reinforcement learning (RL)-based video reasoning with
large language models (LLMs), data collection and finetuning remain significant
challenges. These methods often rely on large-scale supervised fine-tuning
(SFT) with extensive video data and long Chain-of-Thought (CoT) annotations,
making them costly and hard to scale. To address this, we present Video-RTS, a
new approach to improve video reasoning capability with drastically improved
data efficiency by combining data-efficient RL with a video-adaptive test-time
scaling (TTS) strategy. Based on observations about the data scaling of RL
samples, we skip the resource-intensive SFT step and employ efficient pure-RL
training with output-based rewards, requiring no additional annotations or
extensive fine-tuning. Furthermore, to utilize computational resources more
efficiently, we introduce a sparse-to-dense video TTS strategy that improves
inference by iteratively adding frames based on output consistency. We validate
our approach on multiple video reasoning benchmarks, showing that Video-RTS
surpasses existing video reasoning models by an average of 2.4% in accuracy
using only 3.6% training samples. For example, Video-RTS achieves a 4.2%
improvement on Video-Holmes, a recent and challenging video reasoning
benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and
adaptive video TTS offer complementary strengths, enabling Video-RTS's strong
reasoning performance.

</details>


### [203] [FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation](https://arxiv.org/abs/2507.06523)
*Liqiang Jing,Viet Lai,Seunghyun Yoon,Trung Bui,Xinya Du*

Key words: VideoMLLMs, FIFA, 忠实性评估, 幻觉问题, 后校正

TL;DR: FIFA是一个统一的视频多模态大语言模型（VideoMLLMs）忠实性评估框架，通过提取描述性事实、建模语义依赖图，并使用VideoQA模型验证，解决了现有方法在开放回答中无法评估幻觉内容的问题。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 视频多模态大语言模型在视频到文本和文本到视频任务中表现优异，但存在生成内容与视觉输入矛盾的幻觉问题。现有评估方法通常仅针对单一任务，且难以评估开放回答中的幻觉问题。

Method: 提出FIFA框架，包括提取描述性事实、建模时空语义依赖图（Spatio-Temporal Semantic Dependency Graph），并使用VideoQA模型验证。此外，引入基于工具的后校正（Post-Correction）框架来修正幻觉内容。

Result: 实验表明，FIFA比现有评估方法更符合人类判断，且后校正能显著提升文本和视频生成中的事实一致性。

Conclusion: FIFA为视频多模态大语言模型的忠实性评估提供了高效解决方案，且后校正进一步改进了生成内容的事实性。

Abstract: Video Multimodal Large Language Models (VideoMLLMs) have achieved remarkable
progress in both Video-to-Text and Text-to-Video tasks. However, they often
suffer fro hallucinations, generating content that contradicts the visual
input. Existing evaluation methods are limited to one task (e.g., V2T) and also
fail to assess hallucinations in open-ended, free-form responses. To address
this gap, we propose FIFA, a unified FaIthFulness evAluation framework that
extracts comprehensive descriptive facts, models their semantic dependencies
via a Spatio-Temporal Semantic Dependency Graph, and verifies them using
VideoQA models. We further introduce Post-Correction, a tool-based correction
framework that revises hallucinated content. Extensive experiments demonstrate
that FIFA aligns more closely with human judgment than existing evaluation
methods, and that Post-Correction effectively improves factual consistency in
both text and video generation.

</details>


### [204] [Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs](https://arxiv.org/abs/2507.06999)
*Yahan Yu,Yuyang Dong,Masafumi Oyamada*

Key words: 多模态大语言模型, 模态对齐, 推理框架, 训练成本, 可迁移技能

TL;DR: 提出了一种新的多模态大语言模型推理框架D2I，通过规则奖励增强模态对齐，无需额外标注和复杂奖励训练，测试时转为直觉推理，显著提升模型表现。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 多模态推理研究在模态对齐和训练成本上仍存挑战，现有方法依赖额外标注和复杂奖励，增加了成本且限制了扩展性。

Method: 提出D2I框架，训练时采用刻意推理策略通过规则奖励增强模态对齐，测试时转为直觉推理。

Result: D2I在领域内和领域外基准测试中均优于基线方法。

Conclusion: D2I证明了规则奖励在多模态大语言模型中培养可迁移推理技能的作用，并为训练与测试推理深度解耦提供了方向。

Abstract: Reasoning is a key capability for large language models (LLMs), particularly
when applied to complex tasks such as mathematical problem solving. However,
multimodal reasoning research still requires further exploration of modality
alignment and training costs. Many of these approaches rely on additional data
annotation and relevant rule-based rewards to enhance the understanding and
reasoning ability, which significantly increases training costs and limits
scalability. To address these challenges, we propose the
Deliberate-to-Intuitive reasoning framework (D2I) that improves the
understanding and reasoning ability of multimodal LLMs (MLLMs) without extra
annotations and complex rewards. Specifically, our method sets deliberate
reasoning strategies to enhance modality alignment only through the rule-based
format reward during training. While evaluating, the reasoning style shifts to
intuitive, which removes deliberate reasoning strategies during training and
implicitly reflects the model's acquired abilities in the response. D2I
outperforms baselines across both in-domain and out-of-domain benchmarks. Our
findings highlight the role of format reward in fostering transferable
reasoning skills in MLLMs, and inspire directions for decoupling training-time
reasoning depth from test-time response flexibility.

</details>


### [205] [EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision](https://arxiv.org/abs/2507.06639)
*Myungjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee*

Key words: 数字病理学，EXAONE Path 2.0，自监督学习，slide-level监督，生物标志物预测

TL;DR: EXAONE Path 2.0通过直接使用slide-level监督训练patch-level表征，解决了自监督学习在数字病理学中忽视重要特征和数据效率低的问题。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 当前自监督学习方法在数字病理学中忽视了复杂领域特异性特征，且数据效率较低，需要大量计算资源。

Method: 提出EXAONE Path 2.0模型，通过slide-level监督学习patch-level表征。

Result: 仅用37k WSIs训练，EXAONE Path 2.0在10项生物标志物预测任务中达到最先进性能。

Conclusion: EXAONE Path 2.0展示了卓越的数据效率和领域适应性。

Abstract: In digital pathology, whole-slide images (WSIs) are often difficult to handle
due to their gigapixel scale, so most approaches train patch encoders via
self-supervised learning (SSL) and then aggregate the patch-level embeddings
via multiple instance learning (MIL) or slide encoders for downstream tasks.
However, patch-level SSL may overlook complex domain-specific features that are
essential for biomarker prediction, such as mutation status and molecular
characteristics, as SSL methods rely only on basic augmentations selected for
natural image domains on small patch-level area. Moreover, SSL methods remain
less data efficient than fully supervised approaches, requiring extensive
computational resources and datasets to achieve competitive performance. To
address these limitations, we present EXAONE Path 2.0, a pathology foundation
model that learns patch-level representations under direct slide-level
supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves
state-of-the-art average performance across 10 biomarker prediction tasks,
demonstrating remarkable data efficiency.

</details>


### [206] [MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval](https://arxiv.org/abs/2507.06654)
*Naoya Sogi,Takashi Shibata,Makoto Terao,Masanori Suganuma,Takayuki Okatani*

Key words: 结果多样化，文本到图像检索，多源DPP，上下文优化

TL;DR: 本文提出了一个新任务CDR-CA，用于在多属性图像检索中根据应用上下文优化多样性，并提出了一个基于多源DPP的简单而有效的基线方法。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 传统的图像检索多样性方法仅关注外观多样性，而忽略了多样性指标的应用上下文依赖性，限制了其应用范围。

Method: 提出了多源DPP（MS-DPP），将DPP扩展到多源，基于流形表示统一相似矩阵，并引入了切向归一化以反映上下文。

Result: 实验表明，所提方法在多属性图像检索中表现出色。

Conclusion: CDR-CA任务和MS-DPP方法能有效解决应用上下文中的多样性优化问题。

Abstract: Result diversification (RD) is a crucial technique in Text-to-Image Retrieval
for enhancing the efficiency of a practical application. Conventional methods
focus solely on increasing the diversity metric of image appearances. However,
the diversity metric and its desired value vary depending on the application,
which limits the applications of RD. This paper proposes a novel task called
CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims
to refine the diversities of multiple attributes, according to the
application's context. To address this task, we propose Multi-Source DPPs, a
simple yet strong baseline that extends the Determinantal Point Process (DPP)
to multi-sources. We model MS-DPP as a single DPP model with a unified
similarity matrix based on a manifold representation. We also introduce Tangent
Normalization to reflect contexts. Extensive experiments demonstrate the
effectiveness of the proposed method. Our code is publicly available at
https://github.com/NEC-N-SOGI/msdpp.

</details>


### [207] [DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement](https://arxiv.org/abs/2507.06738)
*Xinyu Xie,Weifeng Cao,Jun Shi,Yangyang Hu,Hui Liang,Wanyong Liang,Xiaoliang Qian*

Key words: 时空视频预测，半导体制造，基准数据集，双路径架构，工业AI

TL;DR: 论文提出了半导体晶圆切割过程的第一个公共时空图像数据集CHDL，并设计了新型双路径预测模型DIFFUMA，显著提升了预测性能。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决高精度工业场景（如半导体制造）中缺乏专业基准数据集的问题，推动工业AI研究发展。

Method: 构建CHDL数据集并提出DIFFUMA模型，结合Mamba模块和扩散模块以同时捕获全局时序上下文和增强空间细节。

Result: DIFFUMA在CHDL数据集上MSE降低39%，SSIM提升至0.988，且在自然现象数据集上表现优异。

Conclusion: 论文不仅提出了新的SOTA模型，还为工业AI研究提供了宝贵的数据资源。

Abstract: Spatio-temporal video prediction plays a pivotal role in critical domains,
ranging from weather forecasting to industrial automation. However, in
high-precision industrial scenarios such as semiconductor manufacturing, the
absence of specialized benchmark datasets severely hampers research on modeling
and predicting complex processes. To address this challenge, we make a twofold
contribution.First, we construct and release the Chip Dicing Lane Dataset
(CHDL), the first public temporal image dataset dedicated to the semiconductor
wafer dicing process. Captured via an industrial-grade vision system, CHDL
provides a much-needed and challenging benchmark for high-fidelity process
modeling, defect detection, and digital twin development.Second, we propose
DIFFUMA, an innovative dual-path prediction architecture specifically designed
for such fine-grained dynamics. The model captures global long-range temporal
context through a parallel Mamba module, while simultaneously leveraging a
diffusion module, guided by temporal features, to restore and enhance
fine-grained spatial details, effectively combating feature degradation.
Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly
outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and
improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988.
This superior performance also generalizes to natural phenomena datasets. Our
work not only delivers a new state-of-the-art (SOTA) model but, more
importantly, provides the community with an invaluable data resource to drive
future research in industrial AI.

</details>


### [208] [FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views](https://arxiv.org/abs/2507.06763)
*Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel*

Key words: FOLC-Net, MRI, 多视角诊断, 轻量级架构, 联邦学习

TL;DR: FOLC-Net框架通过联合优化的轻量级架构提升MRI多视角诊断性能，优于现有方法，尤其在矢状面表现出色。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决现有SOTA模型在多视角MRI分析中性能下降的问题。

Method: 提出FOLC-Net，结合MRFO优化、全局模型克隆和ConvNeXt，实现高效训练和客户端适应性。

Result: FOLC-Net在矢状面准确率达92.44%，优于其他模型，并在所有视角表现更稳健。

Conclusion: FOLC-Net为分散式医疗图像分析提供更可靠、适应性强的解决方案。

Abstract: The framework is designed to improve performance in the analysis of combined
as well as single anatomical perspectives for MRI disease diagnosis. It
specifically addresses the performance degradation observed in state-of-the-art
(SOTA) models, particularly when processing axial, coronal, and sagittal
anatomical planes. The paper introduces the FOLC-Net framework, which
incorporates a novel federated-optimized lightweight architecture with
approximately 1.217 million parameters and a storage requirement of only 0.9
MB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for
efficient model structure generation, global model cloning for scalable
training, and ConvNeXt for enhanced client adaptability. The model was
evaluated on combined multi-view data as well as individual views, such as
axial, coronal, and sagittal, to assess its robustness in various medical
imaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different
data to evaluate its ability to generalize beyond the training dataset. The
results show that FOLC-Net outperforms existing models, particularly in the
challenging sagittal view. For instance, FOLC-Net achieved an accuracy of
92.44% on the sagittal view, significantly higher than the 88.37% accuracy of
study method (DL + Residual Learning) and 88.95% of DL models. Additionally,
FOLC-Net demonstrated improved accuracy across all individual views, providing
a more reliable and robust solution for medical image analysis in decentralized
environments. FOLC-Net addresses the limitations of existing SOTA models by
providing a framework that ensures better adaptability to individual views
while maintaining strong performance in multi-view settings. The incorporation
of MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs
better in real-world medical applications.

</details>


### [209] [Centralized Copy-Paste: Enhanced Data Augmentation Strategy for Wildland Fire Semantic Segmentation](https://arxiv.org/abs/2507.06321)
*Joon Tai Kim,Tianle Chen,Ziyu Dong,Nishanth Kunchala,Alexander Guller,Daniel Ospina Acero,Roger Williams,Mrinal Kumar*

Key words: 数据增强,野火分割,多类分割,中央化复制粘贴

TL;DR: 提出了一种名为CCPDA的数据增强方法，专注于提升野火分割模型的性能，通过集中复制粘贴技术增强数据集多样性，显著提高了火类分割的指标。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 在野火科学领域，公开的标注数据集稀缺且成本高昂，限制了分割模型的训练效果，尤其火类的分割至关重要。

Method: CCPDA方法包括识别火簇、集中技术聚焦核心区域、以及粘贴火簇到目标图像三个步骤，提升数据集多样性并保持火类特征。

Result: 数值分析和多目标优化比较表明，CCPDA显著提升了火类分割性能，优于其他数据增强方法。

Conclusion: CCPDA有效缓解了小型标注数据集带来的训练困难，尤其在火类分割任务中表现优异。

Abstract: Collecting and annotating images for the purpose of training segmentation
models is often cost prohibitive. In the domain of wildland fire science, this
challenge is further compounded by the scarcity of reliable public datasets
with labeled ground truth. This paper presents the Centralized Copy-Paste Data
Augmentation (CCPDA) method, for the purpose of assisting with the training of
deep-learning multiclass segmentation models, with special focus on improving
segmentation outcomes for the fire-class. CCPDA has three main steps: (i)
identify fire clusters in the source image, (ii) apply a centralization
technique to focus on the core of the fire area, and (iii) paste the refined
fire clusters onto a target image. This method increases dataset diversity
while preserving the essential characteristics of the fire class. The
effectiveness of this augmentation technique is demonstrated via numerical
analysis and comparison against various other augmentation methods using a
weighted sum-based multi-objective optimization approach. This approach helps
elevate segmentation performance metrics specific to the fire class, which
carries significantly more operational significance than other classes (fuel,
ash, or background). Numerical performance assessment validates the efficacy of
the presented CCPDA method in alleviating the difficulties associated with
small, manually labeled training datasets. It also illustrates that CCPDA
outperforms other augmentation strategies in the application scenario
considered, particularly in improving fire-class segmentation performance.

</details>


### [210] [AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions](https://arxiv.org/abs/2507.06332)
*Fuyuan Zhang,Qichen Wang,Jianjun Zhao*

Key words: AR2, 类激活图, 抗干扰, 鲁棒性, CNN

TL;DR: AR2 是一种通过调整类激活图（CAMs）来增强预训练 CNN 抗干扰能力的方法，在多种干扰条件下显著提升模型鲁棒性。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 深度神经网络在现实应用中对常见干扰（如噪声、模糊等）表现不佳，限制了其可靠性。

Method: AR2 通过显式对齐干净和受干扰图像的 CAMs，并采用迭代修复策略（CAM 引导的细化与微调交替）。

Result: AR2 在标准干扰基准测试（CIFAR-10-C、CIFAR-100-C、ImageNet-C）中优于现有方法，同时保持干净数据的准确性。

Conclusion: AR2 提供了一种可扩展的解决方案，显著提升模型在真实环境中的抗干扰能力。

Abstract: Deep neural networks suffer from significant performance degradation when
exposed to common corruptions such as noise, blur, weather, and digital
distortions, limiting their reliability in real-world applications. In this
paper, we propose AR2 (Attention-Guided Repair for Robustness), a simple yet
effective method to enhance the corruption robustness of pretrained CNNs. AR2
operates by explicitly aligning the class activation maps (CAMs) between clean
and corrupted images, encouraging the model to maintain consistent attention
even under input perturbations. Our approach follows an iterative repair
strategy that alternates between CAM-guided refinement and standard
fine-tuning, without requiring architectural changes. Extensive experiments
show that AR2 consistently outperforms existing state-of-the-art methods in
restoring robustness on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C
and ImageNet-C), achieving a favorable balance between accuracy on clean data
and corruption robustness. These results demonstrate that AR2 provides a robust
and scalable solution for enhancing model reliability in real-world
environments with diverse corruptions.

</details>


### [211] [Democratizing High-Fidelity Co-Speech Gesture Video Generation](https://arxiv.org/abs/2507.06812)
*Xu Yang,Shaoli Huang,Shenbo Xie,Xuelin Chen,Yifei Liu,Changxing Ding*

Key words: 语音-视频生成,扩散模型,骨架条件,数据集

TL;DR: 论文提出了一种轻量级框架，利用2D全身骨架作为辅助条件，结合扩散模型生成与音频严格同步的讲话者视频。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决语音到视频生成任务中音频与视觉内容的一对多映射问题，以及数据集稀缺和计算需求高的挑战。

Method: 采用扩散模型，以细粒度音频片段和参考图像提取的骨架为条件，通过骨架-音频特征融合预测骨骼运动，再结合现有人体视频生成模型合成高保真视频。

Result: 提出的方法在视觉质量和同步性上优于现有技术，并能泛化到不同讲话者和场景。

Conclusion: 该方法高效且普适，为相关研究提供了首个公开数据集。

Abstract: Co-speech gesture video generation aims to synthesize realistic,
audio-aligned videos of speakers, complete with synchronized facial expressions
and body gestures. This task presents challenges due to the significant
one-to-many mapping between audio and visual content, further complicated by
the scarcity of large-scale public datasets and high computational demands. We
propose a lightweight framework that utilizes 2D full-body skeletons as an
efficient auxiliary condition to bridge audio signals with visual outputs. Our
approach introduces a diffusion model conditioned on fine-grained audio
segments and a skeleton extracted from the speaker's reference image,
predicting skeletal motions through skeleton-audio feature fusion to ensure
strict audio coordination and body shape consistency. The generated skeletons
are then fed into an off-the-shelf human video generation model with the
speaker's reference image to synthesize high-fidelity videos. To democratize
research, we present CSG-405-the first public dataset with 405 hours of
high-resolution videos across 71 speech types, annotated with 2D skeletons and
diverse speaker demographics. Experiments show that our method exceeds
state-of-the-art approaches in visual quality and synchronization while
generalizing across speakers and contexts.

</details>


### [212] [Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation](https://arxiv.org/abs/2507.06830)
*Tao Feng,Xianbing Zhao,Zhenhua Chen,Tien Tsin Wong,Hamid Rezatofighi,Gholamreza Haffari,Lizhen Qu*

Key words: 视频生成, 符号回归, 物理对齐, 运动轨迹, 经典力学

TL;DR: 该论文提出了一种结合符号回归和轨迹引导的视频生成框架，用于物理准确的视频预测。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 现有的扩散式和自回归视频生成模型虽然视觉效果逼真，但缺乏物理对齐，无法准确模拟物体运动的动态。

Method: 通过提取运动轨迹、使用检索式预训练机制增强符号回归，并发现运动方程来预测物理准确的轨迹，从而指导视频生成。

Result: 在经典力学场景下，该方法成功恢复真实运动方程，并显著提升了生成视频的物理对齐性。

Conclusion: 该框架为物理基础的视频生成提供了有效方法，显著优于基线模型。

Abstract: Recent advances in diffusion-based and autoregressive video generation models
have achieved remarkable visual realism. However, these models typically lack
accurate physical alignment, failing to replicate real-world dynamics in object
motion. This limitation arises primarily from their reliance on learned
statistical correlations rather than capturing mechanisms adhering to physical
laws. To address this issue, we introduce a novel framework that integrates
symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for
physics-grounded video forecasting. Our approach extracts motion trajectories
from input videos, uses a retrieval-based pre-training mechanism to enhance
symbolic regression, and discovers equations of motion to forecast physically
accurate future trajectories. These trajectories then guide video generation
without requiring fine-tuning of existing models. Evaluated on scenarios in
Classical Mechanics, including spring-mass, pendulums, and projectile motions,
our method successfully recovers ground-truth analytical equations and improves
the physical alignment of generated videos over baseline methods.

</details>


### [213] [IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization](https://arxiv.org/abs/2507.06856)
*Subrat Kishore Dutta,Xiao Zhang*

Key words: 对抗性补丁, 隐形攻击, 计算机视觉, 模型防御

TL;DR: IAP是一种新型攻击框架，通过感知感知定位和扰动优化方案生成高度隐蔽的对抗性补丁，显著提升隐蔽性和攻击成功率。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 现有方法在针对性攻击场景下表现不佳或生成的对抗补丁缺乏上下文连贯性，容易被人类或自动防御系统检测到。

Method: IAP利用类别定位和敏感度图选择合适的位置，结合感知感知正则化对抗损失和梯度更新规则优化不可见扰动。

Result: IAP在多种图像基准和模型架构中展现出较高的攻击成功率和隐蔽性，且能够绕过先进补丁防御系统。

Conclusion: IAP在对抗补丁攻击中提供了更高的隐蔽性和有效性，是现有方法的有力替代。

Abstract: Despite modifying only a small localized input region, adversarial patches
can drastically change the prediction of computer vision models. However, prior
methods either cannot perform satisfactorily under targeted attack scenarios or
fail to produce contextually coherent adversarial patches, causing them to be
easily noticeable by human examiners and insufficiently stealthy against
automatic patch defenses. In this paper, we introduce IAP, a novel attack
framework that generates highly invisible adversarial patches based on
perceptibility-aware localization and perturbation optimization schemes.
Specifically, IAP first searches for a proper location to place the patch by
leveraging classwise localization and sensitivity maps, balancing the
susceptibility of patch location to both victim model prediction and human
visual system, then employs a perceptibility-regularized adversarial loss and a
gradient update rule that prioritizes color constancy for optimizing invisible
perturbations. Comprehensive experiments across various image benchmarks and
model architectures demonstrate that IAP consistently achieves competitive
attack success rates in targeted settings with significantly improved patch
invisibility compared to existing baselines. In addition to being highly
imperceptible to humans, IAP is shown to be stealthy enough to render several
state-of-the-art patch defenses ineffective.

</details>


### [214] [Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution](https://arxiv.org/abs/2507.06547)
*Yonghyun Park,Chieh-Hsin Lai,Satoshi Hayakawa,Yuhta Takida,Naoki Murata,Wei-Hsiang Liao,Woosung Choi,Kin Wai Cheuk,Junghyun Koo,Yuki Mitsufuji*

Key words: 扩散模型, 概念归因, 版权, 透明度, Concept-TRAK

TL;DR: 本文提出了Concept-TRAK方法，通过概念级别归因解决扩散模型在版权和透明度方面的挑战。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 扩散模型在图像生成中表现出色，但版权和模型透明度问题日益突出。现有方法无法精确归因到特定元素（如风格或对象），难以满足利益相关者需求。

Method: 提出Concept-TRAK方法，通过改进扩散训练损失和引入概念感知奖励函数，实现样本特定的鲁棒归因。

Result: 在AbC基准测试中，Concept-TRAK显著优于现有方法，并通过案例研究验证了其在实际问题中的实用性。

Conclusion: 概念级别归因为生成AI的开发与治理提供了可操作的洞察，有助于解决版权和透明度问题。

Abstract: While diffusion models excel at image generation, their growing adoption
raises critical concerns around copyright issues and model transparency.
Existing attribution methods identify training examples influencing an entire
image, but fall short in isolating contributions to specific elements, such as
styles or objects, that matter most to stakeholders. To bridge this gap, we
introduce \emph{concept-level attribution} via a novel method called
\emph{Concept-TRAK}. Concept-TRAK extends influence functions with two key
innovations: (1) a reformulated diffusion training loss based on diffusion
posterior sampling, enabling robust, sample-specific attribution; and (2) a
concept-aware reward function that emphasizes semantic relevance. We evaluate
Concept-TRAK on the AbC benchmark, showing substantial improvements over prior
methods. Through diverse case studies--ranging from identifying IP-protected
and unsafe content to analyzing prompt engineering and compositional
learning--we demonstrate how concept-level attribution yields actionable
insights for responsible generative AI development and governance.

</details>


### [215] [Divergence-Based Similarity Function for Multi-View Contrastive Learning](https://arxiv.org/abs/2507.06560)
*Jae Hyoung Jeon,Cheolsu Lim,Myungjoo Kang*

Key words: 对比学习,多视图学习,分布相似性,DSF

TL;DR: 本文提出了一种基于分布的相似性函数（DSF），通过将多视图表示为分布并测量分布间差异，显式捕捉多视图的联合结构，显著提升了多种任务的性能。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 现有方法主要利用两两视图关系，未能有效建模多视图的联合结构，限制了性能提升。

Method: 提出DSF函数，将多视图表示为分布，通过分布间的散度衡量相似性。

Result: DSF在各种任务（如kNN分类和线性评估）中表现优于现有方法，且效率更高。

Conclusion: DSF不仅避免了温度超参数的需求，还在理论和实验上验证了其有效性。

Abstract: Recent success in contrastive learning has sparked growing interest in more
effectively leveraging multiple augmented views of an instance. While prior
methods incorporate multiple views at the loss or feature level, they primarily
capture pairwise relationships and fail to model the joint structure across all
views. In this work, we propose a divergence-based similarity function (DSF)
that explicitly captures the joint structure by representing each set of
augmented views as a distribution and measuring similarity as the divergence
between distributions. Extensive experiments demonstrate that DSF consistently
improves performance across various tasks, including kNN classification and
linear evaluation, while also offering greater efficiency compared to other
multi-view methods. Furthermore, we establish a theoretical connection between
DSF and cosine similarity, and show that, unlike cosine similarity, DSF
operates effectively without requiring a temperature hyperparameter.

</details>


### [216] [CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale](https://arxiv.org/abs/2507.06959)
*Xiao Liang,Jiawei Hu,Di Wang,Zhi Ma,Lin Zhao,Ronghan Li,Bo Wan,Quan Wang*

Key words: 视觉语言模型，医学幻觉，胸透偏好优化，置信度-相似性联合挖掘，反事实推理

TL;DR: CheXPO通过结合置信度-相似性联合挖掘和反事实推理，优化胸透视觉指令数据集的偏好学习，显著减少了医学视觉语言模型的幻觉问题。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 医学视觉语言模型易产生幻觉，降低可靠性，传统偏好优化方法面临样本无关、数据分布不平衡及专家标注成本高的挑战。

Method: 提出CheXPO策略，通过多任务胸透视觉指令数据集训练，结合置信度分析与相似性检索扩展困难样本，并利用反事实推理提供细粒度偏好。

Result: CheXPO仅用5%监督微调样本实现8.93%性能提升，在多种临床任务中达到最优表现。

Conclusion: CheXPO提供了一种可扩展、可解释的解决方案，适用于实际放射学应用。

Abstract: Vision-language models (VLMs) are prone to hallucinations that critically
compromise reliability in medical applications. While preference optimization
can mitigate these hallucinations through clinical feedback, its implementation
faces challenges such as clinically irrelevant training samples, imbalanced
data distributions, and prohibitive expert annotation costs. To address these
challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy
that combines confidence-similarity joint mining with counterfactual rationale.
Our approach begins by synthesizing a unified, fine-grained multi-task chest
X-ray visual instruction dataset across different question types for supervised
fine-tuning (SFT). We then identify hard examples through token-level
confidence analysis of SFT failures and use similarity-based retrieval to
expand hard examples for balancing preference sample distributions, while
synthetic counterfactual rationales provide fine-grained clinical preferences,
eliminating the need for additional expert input. Experiments show that CheXPO
achieves 8.93% relative performance gain using only 5% of SFT samples, reaching
state-of-the-art performance across diverse clinical tasks and providing a
scalable, interpretable solution for real-world radiology applications.

</details>


### [217] [MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation](https://arxiv.org/abs/2507.06992)
*Qilong Xing,Zikai Song,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

Key words: 放射学报告生成,医学概念对齐,知识驱动框架,对比学习,MCA-RG

TL;DR: 论文针对放射学报告生成中病理和解剖特征与文本描述的准确映射问题，提出了基于医学概念对齐的知识驱动框架MCA-RG。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 尽管大型语言模型在放射学报告生成中取得进展，但由于病理和解剖特征与文本描述的映射困难，临床采用仍具挑战性。

Method: MCA-RG通过两个医学概念库（病理库和解剖库）对齐视觉特征，结合对比学习和匹配损失优化特征，并使用特征门控机制过滤低质量特征。

Result: 在MIMIC-CXR和CheXpert Plus两个公开基准测试中，MCA-RG表现出色。

Conclusion: MCA-RG有效提升了放射学报告生成的准确性和临床相关性。

Abstract: Despite significant advancements in adapting Large Language Models (LLMs) for
radiology report generation (RRG), clinical adoption remains challenging due to
difficulties in accurately mapping pathological and anatomical features to
their corresponding text descriptions. Additionally, semantic agnostic feature
extraction further hampers the generation of accurate diagnostic reports. To
address these challenges, we introduce Medical Concept Aligned Radiology Report
Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual
features with distinct medical concepts to enhance the report generation
process. MCA-RG utilizes two curated concept banks: a pathology bank containing
lesion-related knowledge, and an anatomy bank with anatomical descriptions. The
visual features are aligned with these medical concepts and undergo tailored
enhancement. We further propose an anatomy-based contrastive learning procedure
to improve the generalization of anatomical features, coupled with a matching
loss for pathological features to prioritize clinically relevant regions.
Additionally, a feature gating mechanism is employed to filter out low-quality
concept features. Finally, the visual features are corresponding to individual
medical concepts, and are leveraged to guide the report generation process.
Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate
that MCA-RG achieves superior performance, highlighting its effectiveness in
radiology report generation.

</details>


### [218] [Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment](https://arxiv.org/abs/2507.06643)
*Farahdiba Zarin,Riccardo Oliva,Vinkle Srivastav,Armine Vardazaryan,Andrea Rosati,Alice Zampolini Faustini,Giovanni Scambia,Anna Fagotti,Pietro Mascagni,Nicolas Padoy*

Key words: 稀疏标注；关键点定位；医学图像分析；稀疏热图回归；Crag and Tail loss

TL;DR: 该论文提出了一种从稀疏标签中学习的方法，用于医学图像中关键点定位的密集预测任务，并引入了一种新的损失函数（Crag and Tail loss），以有效利用稀疏标注并减少假阴性影响。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 医学领域中，密集像素级标注成本高昂，尤其是在新任务中。研究目标是实现从少数像素级标注中学习，以推动在标注不足情况下的研究进展。

Method: 将问题建模为稀疏热图回归，提出了一种新的损失函数（Crag and Tail loss），用于高效学习稀疏标签。

Result: 通过大量实验证明，该方法能够准确实现关键点的密集定位，尤其适用于密集标注难以获取的场景。

Conclusion: 该方法在稀疏标注条件下表现优异，有望推动医学图像分析中标注不足场景的研究。

Abstract: Learning from sparse labels is a challenge commonplace in the medical domain.
This is due to numerous factors, such as annotation cost, and is especially
true for newly introduced tasks. When dense pixel-level annotations are needed,
this becomes even more unfeasible. However, being able to learn from just a few
annotations at the pixel-level, while extremely difficult and underutilized,
can drive progress in studies where perfect annotations are not immediately
available. This work tackles the challenge of learning the dense prediction
task of keypoint localization from a few point annotations in the context of 2d
carcinosis keypoint localization from laparoscopic video frames for diagnostic
planning of advanced ovarian cancer patients. To enable this, we formulate the
problem as a sparse heatmap regression from a few point annotations per image
and propose a new loss function, called Crag and Tail loss, for efficient
learning. Our proposed loss function effectively leverages positive sparse
labels while minimizing the impact of false negatives or missed annotations.
Through an extensive ablation study, we demonstrate the effectiveness of our
approach in achieving accurate dense localization of carcinosis keypoints,
highlighting its potential to advance research in scenarios where dense
annotations are challenging to obtain.

</details>


### [219] [Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients](https://arxiv.org/abs/2507.06994)
*Qilong Xing,Zikai Song,Bingxin Gong,Lian Yang,Junqing Yu,Wei Yang*

Key words: 非小细胞肺癌, 免疫治疗, 多模态特征融合, Transformer, 生存预测

TL;DR: 提出了一种新的多模态特征融合框架，用于提高非小细胞肺癌（NSCLC）免疫治疗的生存预测准确性。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 精准预后对于个性化治疗计划至关重要，但目前缺乏相关大数据集和有效的多模态特征融合策略。

Method: 使用3D CT图像和临床记录，提出跨模态掩蔽学习方法，结合切片深度Transformer和图Transformer。

Result: 该方法在多模态整合中表现优异，超越现有方法，为预后模型设定了新标准。

Conclusion: 提出的框架解决了数据缺乏和多模态融合问题，显著提升了NSCLC生存预测的准确性。

Abstract: Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing
immunotherapy is essential for personalized treatment planning, enabling
informed patient decisions, and improving both treatment outcomes and quality
of life. However, the lack of large, relevant datasets and effective
multi-modal feature fusion strategies pose significant challenges in this
domain. To address these challenges, we present a large-scale dataset and
introduce a novel framework for multi-modal feature fusion aimed at enhancing
the accuracy of survival prediction. The dataset comprises 3D CT images and
corresponding clinical records from NSCLC patients treated with immune
checkpoint inhibitors (ICI), along with progression-free survival (PFS) and
overall survival (OS) data. We further propose a cross-modality masked learning
approach for medical feature fusion, consisting of two distinct branches, each
tailored to its respective modality: a Slice-Depth Transformer for extracting
3D features from CT images and a graph-based Transformer for learning node
features and relationships among clinical variables in tabular data. The fusion
process is guided by a masked modality learning strategy, wherein the model
utilizes the intact modality to reconstruct missing components. This mechanism
improves the integration of modality-specific features, fostering more
effective inter-modality relationships and feature interactions. Our approach
demonstrates superior performance in multi-modal integration for NSCLC survival
prediction, surpassing existing methods and setting a new benchmark for
prognostic models in this context.

</details>


### [220] [Enhancing Diffusion Model Stability for Image Restoration via Gradient Management](https://arxiv.org/abs/2507.06656)
*Hongjie Wu,Mingqin Zhang,Linchao He,Ji-Zhe Zhou,Jiancheng Lv*

Key words: 扩散模型, 图像修复, 梯度管理, SPGD, 贝叶斯推理

TL;DR: 该论文分析了扩散模型中先验和似然梯度方向的冲突及不稳定性，提出了一种新颖的梯度管理技术SPGD，通过渐进式似然预热和自适应方向动量平滑来提升生成稳定性，并在多种图像修复任务中取得了最先进的性能。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 现有的扩散模型在图像修复中通过贝叶斯推理框架结合去噪和似然引导步骤，但这两部分在生成过程中的交互及其稳定性尚不明确，影响了修复性能。

Method: 提出SPGD技术，包括渐进式似然预热策略（缓解梯度冲突）和自适应方向动量平滑（减少似然梯度波动）。

Result: 实验表明SPGD显著提升了生成稳定性，在定量指标和视觉结果上均达到最优。

Conclusion: SPGD通过梯度管理的创新方法解决了扩散模型中的不稳定问题，为图像修复任务提供了高效解决方案。

Abstract: Diffusion models have shown remarkable promise for image restoration by
leveraging powerful priors. Prominent methods typically frame the restoration
problem within a Bayesian inference framework, which iteratively combines a
denoising step with a likelihood guidance step. However, the interactions
between these two components in the generation process remain underexplored. In
this paper, we analyze the underlying gradient dynamics of these components and
identify significant instabilities. Specifically, we demonstrate conflicts
between the prior and likelihood gradient directions, alongside temporal
fluctuations in the likelihood gradient itself. We show that these
instabilities disrupt the generative process and compromise restoration
performance. To address these issues, we propose Stabilized Progressive
Gradient Diffusion (SPGD), a novel gradient management technique. SPGD
integrates two synergistic components: (1) a progressive likelihood warm-up
strategy to mitigate gradient conflicts; and (2) adaptive directional momentum
(ADM) smoothing to reduce fluctuations in the likelihood gradient. Extensive
experiments across diverse restoration tasks demonstrate that SPGD
significantly enhances generation stability, leading to state-of-the-art
performance in quantitative metrics and visually superior results. Code is
available at \href{https://github.com/74587887/SPGD}{here}.

</details>


### [221] [Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices](https://arxiv.org/abs/2507.07029)
*Parshva Dhilankumar Patel*

Key words: OCR, 表格提取, 发票处理, 数据提取

TL;DR: 提出了一个基于OCR的流水线，从发票中高效提取表格数据，显著提升准确性和一致性。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决扫描发票中表格数据提取的准确性和一致性问题。

Method: 结合Tesseract OCR和自定义后处理逻辑，包括动态预处理、表格边界检测和行列映射。

Result: 流水线显著提高了数据提取的准确性和一致性。

Conclusion: 该系统适用于自动化财务工作流和数字存档等实际应用。

Abstract: This paper presents the design and development of an OCR-powered pipeline for
efficient table extraction from invoices. The system leverages Tesseract OCR
for text recognition and custom post-processing logic to detect, align, and
extract structured tabular data from scanned invoice documents. Our approach
includes dynamic preprocessing, table boundary detection, and row-column
mapping, optimized for noisy and non-standard invoice formats. The resulting
pipeline significantly improves data extraction accuracy and consistency,
supporting real-world use cases such as automated financial workflows and
digital archiving.

</details>


### [222] [Residual Prior-driven Frequency-aware Network for Image Fusion](https://arxiv.org/abs/2507.06735)
*Guan Zheng,Xue Wang,Wenhua Qian,Peng Liu,Runzhuo Ma*

Key words: 图像融合, 频率感知网络, 残差先验, 全局特征建模, 对比损失

TL;DR: 论文提出了一种名为RPFNet的频率感知网络，通过双分支特征提取框架和频率域卷积，高效地实现图像融合，解决了长距离特征依赖计算成本高和缺乏真实数据的问题。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 图像融合的目的是整合多模态互补信息以生成高质量融合图像，从而提升高级视觉任务的性能。然而，全局空间建模机制计算成本高，且缺乏真实数据使得有效捕捉互补特征变得困难。

Method: RPFNet采用双分支特征提取框架：残差先验模块（RPM）从残差图中提取模态特定差异信息；频率域融合模块（FDFM）通过频率域卷积实现高效全局特征建模；交叉促进模块（CPM）通过双向特征交互增强局部细节和全局结构的协同感知。训练中结合辅助解码器和显著性结构损失，并通过频率对比损失和SSIM损失约束解空间。

Result: 实验验证RPFNet能有效整合判别性特征，增强纹理细节和显著对象，促进高级视觉任务的部署。

Conclusion: RPFNet通过高效频率域建模和互补信息保留，显著提升了图像融合性能。

Abstract: Image fusion aims to integrate complementary information across modalities to
generate high-quality fused images, thereby enhancing the performance of
high-level vision tasks. While global spatial modeling mechanisms show
promising results, constructing long-range feature dependencies in the spatial
domain incurs substantial computational costs. Additionally, the absence of
ground-truth exacerbates the difficulty of capturing complementary features
effectively. To tackle these challenges, we propose a Residual Prior-driven
Frequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a
dual-branch feature extraction framework: the Residual Prior Module (RPM)
extracts modality-specific difference information from residual maps, thereby
providing complementary priors for fusion; the Frequency Domain Fusion Module
(FDFM) achieves efficient global feature modeling and integration through
frequency-domain convolution. Additionally, the Cross Promotion Module (CPM)
enhances the synergistic perception of local details and global structures
through bidirectional feature interaction. During training, we incorporate an
auxiliary decoder and saliency structure loss to strengthen the model's
sensitivity to modality-specific differences. Furthermore, a combination of
adaptive weight-based frequency contrastive loss and SSIM loss effectively
constrains the solution space, facilitating the joint capture of local details
and global features while ensuring the retention of complementary information.
Extensive experiments validate the fusion performance of RPFNet, which
effectively integrates discriminative features, enhances texture details and
salient objects, and can effectively facilitate the deployment of the
high-level vision task.

</details>


### [223] [Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching](https://arxiv.org/abs/2507.06744)
*Yafei Zhang,Yongle Shang,Huafeng Li*

Key words: 弱监督学习、文本到图像匹配、身份关联、动态调整、一致性学习

TL;DR: 提出了一种局部和全局双粒度身份关联机制，以解决弱监督文本到人物图像匹配中的复杂一对多身份关系问题，显著提升了匹配准确率。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 减少模型对大规模手工标注样本的依赖，解决现有方法难以预测复杂一对多身份关系的问题。

Method: 局部层面明确建立批量内的跨模态身份关系，全局层面构建动态跨模态身份关联网络，并结合信息不对称样本对构建和一致性学习。

Result: 显著提升了跨模态匹配准确率，为文本到人物图像匹配提供了高效实用的解决方案。

Conclusion: 提出的双粒度机制和动态调整方法有效解决了复杂身份关系的问题，提升了模型性能。

Abstract: Weakly supervised text-to-person image matching, as a crucial approach to
reducing models' reliance on large-scale manually labeled samples, holds
significant research value. However, existing methods struggle to predict
complex one-to-many identity relationships, severely limiting performance
improvements. To address this challenge, we propose a local-and-global
dual-granularity identity association mechanism. Specifically, at the local
level, we explicitly establish cross-modal identity relationships within a
batch, reinforcing identity constraints across different modalities and
enabling the model to better capture subtle differences and correlations. At
the global level, we construct a dynamic cross-modal identity association
network with the visual modality as the anchor and introduce a confidence-based
dynamic adjustment mechanism, effectively enhancing the model's ability to
identify weakly associated samples while improving overall sensitivity.
Additionally, we propose an information-asymmetric sample pair construction
method combined with consistency learning to tackle hard sample mining and
enhance model robustness. Experimental results demonstrate that the proposed
method substantially boosts cross-modal matching accuracy, providing an
efficient and practical solution for text-to-person image matching.

</details>


### [224] [An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator](https://arxiv.org/abs/2507.07073)
*Yulin An,Enrique del Castillo*

Key words: Laplace-Beltrami谱, 几何深度学习, 有限元方法, 图神经网络, CAD网格

TL;DR: 提出了一种基于几何深度学习的框架，用于高效预测CAD网格的Laplace-Beltrami谱，比传统有限元方法快约5倍且精度相当。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 传统有限元方法计算Laplace-Beltrami谱效率低，无法满足CAD机械部件数据库或质量控制中的快速需求。

Method: 采用图神经网络架构，结合高斯曲率、平均曲率等丰富的网格特征，预测Laplace-Beltrami谱。

Result: 实验结果显示，该方法比线性有限元方法快约5倍，且保持竞争性精度。

Conclusion: 证明Laplace-Beltrami谱可学习，为高效计算提供了新思路。

Abstract: The spectrum of the Laplace-Beltrami (LB) operator is central in geometric
deep learning tasks, capturing intrinsic properties of the shape of the object
under consideration. The best established method for its estimation, from a
triangulated mesh of the object, is based on the Finite Element Method (FEM),
and computes the top k LB eigenvalues with a complexity of O(Nk), where N is
the number of points. This can render the FEM method inefficient when
repeatedly applied to databases of CAD mechanical parts, or in quality control
applications where part metrology is acquired as large meshes and decisions
about the quality of each part are needed quickly and frequently. As a solution
to this problem, we present a geometric deep learning framework to predict the
LB spectrum efficiently given the CAD mesh of a part, achieving significant
computational savings without sacrificing accuracy, demonstrating that the LB
spectrum is learnable. The proposed Graph Neural Network architecture uses a
rich set of part mesh features - including Gaussian curvature, mean curvature,
and principal curvatures. In addition to our trained network, we make
available, for repeatability, a large curated dataset of real-world mechanical
CAD models derived from the publicly available ABC dataset used for training
and testing. Experimental results show that our method reduces computation time
of the LB spectrum by approximately 5 times over linear FEM while delivering
competitive accuracy.

</details>


### [225] [GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning](https://arxiv.org/abs/2507.07006)
*S M Taslim Uddin Raju,Md. Milon Islam,Md Rezwanul Haque,Hamdi Altaheri,Fakhri Karray*

Key words: Whole Slide Image, GNN, ViT, 分类, 描述生成

TL;DR: 提出了一种名为GNN-ViTCap的新框架，用于从组织病理学显微图像中进行分类和描述生成，解决了冗余补丁和未知补丁位置等问题。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决显微WSI中冗余补丁和未知补丁位置的问题，同时实现自动病理描述生成。

Method: 通过视觉特征提取器生成补丁嵌入，动态聚类去除冗余补丁，构建图神经网络捕捉局部和全局上下文，并微调大型语言模型生成描述。

Result: 在分类任务中F1得分为0.934，AUC为0.963；在描述生成任务中BLEU-4得分为0.811，METEOR得分为0.569。

Conclusion: GNN-ViTCap表现优于现有方法，为基于显微镜的患者诊断提供了可靠高效的解决方案。

Abstract: Microscopic assessment of histopathology images is vital for accurate cancer
diagnosis and treatment. Whole Slide Image (WSI) classification and captioning
have become crucial tasks in computer-aided pathology. However, microscopic WSI
face challenges such as redundant patches and unknown patch positions due to
subjective pathologist captures. Moreover, generating automatic pathology
captions remains a significant challenge. To address these issues, we introduce
a novel GNN-ViTCap framework for classification and caption generation from
histopathological microscopic images. First, a visual feature extractor
generates patch embeddings. Redundant patches are then removed by dynamically
clustering these embeddings using deep embedded clustering and selecting
representative patches via a scalar dot attention mechanism. We build a graph
by connecting each node to its nearest neighbors in the similarity matrix and
apply a graph neural network to capture both local and global context. The
aggregated image embeddings are projected into the language model's input space
through a linear layer and combined with caption tokens to fine-tune a large
language model. We validate our method on the BreakHis and PatchGastric
datasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for
classification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569
for captioning. Experimental results demonstrate that GNN-ViTCap outperforms
state of the art approaches, offering a reliable and efficient solution for
microscopy based patient diagnosis.

</details>


### [226] [MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation](https://arxiv.org/abs/2507.07015)
*Hui Li,Pengfei Yang,Juanyang Chen,Le Dong,Yanxin Chen,Quan Wang*

Key words: 知识蒸馏, 跨模态, 多教师模型, 动态路由, 掩码模块

TL;DR: 该论文提出了一种新型跨模态知识蒸馏框架MST-Distill，解决传统方法中蒸馏路径选择和知识漂移的问题，通过混合多教师模型和动态路由网络显著提升性能。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 跨模态场景中传统知识蒸馏方法因数据和统计异质性无法有效利用教师模型的互补知识，存在蒸馏路径选择和知识漂移两大问题。

Method: 提出MST-Distill框架，结合跨模态和多模态教师模型，使用动态路由网络自适应选择蒸馏路径，并引入掩码模块抑制模态差异。

Result: 在五个多模态数据集上的实验表明，该方法显著优于现有最先进的跨模态知识蒸馏方法。

Conclusion: MST-Distill通过混合教师模型和动态路由，有效解决了跨模态知识蒸馏的挑战，提升了知识转移效果。

Abstract: Knowledge distillation as an efficient knowledge transfer technique, has
achieved remarkable success in unimodal scenarios. However, in cross-modal
settings, conventional distillation methods encounter significant challenges
due to data and statistical heterogeneities, failing to leverage the
complementary prior knowledge embedded in cross-modal teacher models. This
paper empirically reveals two critical issues in existing approaches:
distillation path selection and knowledge drift. To address these limitations,
we propose MST-Distill, a novel cross-modal knowledge distillation framework
featuring a mixture of specialized teachers. Our approach employs a diverse
ensemble of teacher models across both cross-modal and multimodal
configurations, integrated with an instance-level routing network that
facilitates adaptive and dynamic distillation. This architecture effectively
transcends the constraints of traditional methods that rely on monotonous and
static teacher models. Additionally, we introduce a plug-in masking module,
independently trained to suppress modality-specific discrepancies and
reconstruct teacher representations, thereby mitigating knowledge drift and
enhancing transfer effectiveness. Extensive experiments across five diverse
multimodal datasets, spanning visual, audio, and text, demonstrate that our
method significantly outperforms existing state-of-the-art knowledge
distillation methods in cross-modal distillation tasks. The source code is
available at https://github.com/Gray-OREO/MST-Distill.

</details>


### [227] [Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor](https://arxiv.org/abs/2507.07106)
*Vatsal Agarwal,Matthew Gwilliam,Gefen Kohavi,Eshan Verma,Daniel Ulbricht,Abhinav Shrivastava*

Key words: 多模态大型语言模型,扩散模型,视觉问答,CLIP,特征融合

TL;DR: 论文研究了预训练的文本到图像扩散模型能否作为视觉编码器，比CLIP更关注细粒度细节，并提出特征融合策略。

<details>
  <summary>Details</summary>

Main category: cs.CV

Motivation: 解决CLIP在图像问答中忽略细粒度信息的问题，探索扩散模型作为视觉编码器的潜力。

Method: 分析扩散模型内部特征，结合CLIP与扩散特征设计融合策略，并研究信息泄漏的缓解方法。

Result: 扩散模型在视觉理解任务中表现优异，尤其在需要空间和组合推理的任务中。

Conclusion: 扩散模型可作为有效的视觉编码器，结合CLIP特征能提升性能。

Abstract: Recent advances in multimodal large language models (MLLMs) have enabled
image-based question-answering capabilities. However, a key limitation is the
use of CLIP as the visual encoder; while it can capture coarse global
information, it often can miss fine-grained details that are relevant to the
input query. To address these shortcomings, this work studies whether
pre-trained text-to-image diffusion models can serve as instruction-aware
visual encoders. Through an analysis of their internal representations, we find
diffusion features are both rich in semantics and can encode strong image-text
alignment. Moreover, we find that we can leverage text conditioning to focus
the model on regions relevant to the input question. We then investigate how to
align these features with large language models and uncover a leakage
phenomenon, where the LLM can inadvertently recover information from the
original diffusion prompt. We analyze the causes of this leakage and propose a
mitigation strategy. Based on these insights, we explore a simple fusion
strategy that utilizes both CLIP and conditional diffusion features. We
evaluate our approach on both general VQA and specialized MLLM benchmarks,
demonstrating the promise of diffusion models for visual understanding,
particularly in vision-centric tasks that require spatial and compositional
reasoning. Our project page can be found
https://vatsalag99.github.io/mustafar/.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [228] [A Machine Learning Framework for Breast Cancer Treatment Classification Using a Novel Dataset](https://arxiv.org/abs/2507.06243)
*Md Nahid Hasan,Md Monzur Murshed,Md Mahadi Hasan,Faysal A. Chowdhury*

Key words: 乳腺癌,机器学习,个性化治疗,TCGA,GBM

TL;DR: 该研究利用机器学习模型预测乳腺癌患者的化疗或激素治疗可能性，GBM模型表现最佳，支持个性化治疗决策。

<details>
  <summary>Details</summary>

Main category: stat.AP

Motivation: 乳腺癌治疗的个性化选择因分子和临床异质性而复杂化，机器学习可提供数据驱动的预测工具。

Method: 使用TCGA乳腺癌临床数据集，通过五折交叉验证训练和评估模型，包括GBM、XGBoost和AdaBoost。

Result: GBM模型表现最优（准确率0.7718，AUROC 0.8252），SHAP值增强了模型可解释性。

Conclusion: 机器学习在乳腺癌个性化治疗决策中具有潜力。

Abstract: Breast cancer (BC) remains a significant global health challenge, with
personalized treatment selection complicated by the disease's molecular and
clinical heterogeneity. BC treatment decisions rely on various patient-specific
clinical factors, and machine learning (ML) offers a powerful approach to
predicting treatment outcomes. This study utilizes The Cancer Genome Atlas
(TCGA) breast cancer clinical dataset to develop ML models for predicting the
likelihood of undergoing chemotherapy or hormonal therapy. The models are
trained using five-fold cross-validation and evaluated through performance
metrics, including accuracy, precision, recall, specificity, sensitivity,
F1-score, and area under the receiver operating characteristic curve (AUROC).
Model uncertainty is assessed using bootstrap techniques, while SHAP values
enhance interpretability by identifying key predictors. Among the tested
models, the Gradient Boosting Machine (GBM) achieves the highest stable
performance (accuracy = 0.7718, AUROC = 0.8252), followed by Extreme Gradient
Boosting (XGBoost) (accuracy = 0.7557, AUROC = 0.8044) and Adaptive Boosting
(AdaBoost) (accuracy = 0.7552, AUROC = 0.8016). These findings underscore the
potential of ML in supporting personalized breast cancer treatment decisions
through data-driven insights.

</details>


### [229] [When Context Is Not Enough: Modeling Unexplained Variability in Car-Following Behavior](https://arxiv.org/abs/2507.07012)
*Chengyuan Zhang,Zhengbing He,Cathy Wu,Lijun Sun*

Key words: 车辆跟随行为、随机建模、高斯过程、深度神经网络、不确定性量化

TL;DR: 该论文提出了一种可解释的随机建模框架，用于捕捉车辆跟随行为中的上下文依赖动态和无法由上下文解释的剩余变异性。

<details>
  <summary>Details</summary>

Main category: stat.AP

Motivation: 传统确定性模型难以捕捉人类驾驶的变异性，现代方法忽略潜在驾驶员意图等因素，该研究旨在填补这一空白。

Method: 结合深度神经网络和非平稳高斯过程，使用场景自适应的Gibbs核学习加速度决策的动态时间相关性。

Result: 在HighD数据集上的实验表明，该方法在预测性能和不确定性量化方面优于传统方法。

Conclusion: 该框架兼具可解释性和准确性，适用于交通分析和安全关键应用。

Abstract: Modeling car-following behavior is fundamental to microscopic traffic
simulation, yet traditional deterministic models often fail to capture the full
extent of variability and unpredictability in human driving. While many modern
approaches incorporate context-aware inputs (e.g., spacing, speed, relative
speed), they frequently overlook structured stochasticity that arises from
latent driver intentions, perception errors, and memory effects -- factors that
are not directly observable from context alone. To fill the gap, this study
introduces an interpretable stochastic modeling framework that captures not
only context-dependent dynamics but also residual variability beyond what
context can explain. Leveraging deep neural networks integrated with
nonstationary Gaussian processes (GPs), our model employs a scenario-adaptive
Gibbs kernel to learn dynamic temporal correlations in acceleration decisions,
where the strength and duration of correlations between acceleration decisions
evolve with the driving context. This formulation enables a principled,
data-driven quantification of uncertainty in acceleration, speed, and spacing,
grounded in both observable context and latent behavioral variability.
Comprehensive experiments on the naturalistic vehicle trajectory dataset
collected from the German highway, i.e., the HighD dataset, demonstrate that
the proposed stochastic simulation method within this framework surpasses
conventional methods in both predictive performance and interpretable
uncertainty quantification. The integration of interpretability and accuracy
makes this framework a promising tool for traffic analysis and safety-critical
applications.

</details>


<div id='q-bio.PE'></div>

# q-bio.PE [[Back]](#toc)

### [230] [Deep learning-based species-area models reveal multi-scale patterns of species richness and turnover](https://arxiv.org/abs/2507.06358)
*Victor Boussange,Philipp Brun,Johanna T. Malle,Gabriele Midolo,Jeanne Portier,Théophile Sanchez,Niklaus E. Zimmermann,Irena Axmanová,Helge Bruelheide,Milan Chytrý,Stephan Kambach,Zdeňka Lososová,Martin Večeřa,Idoia Biurrun,Klaus T. Ecker,Jonathan Lenoir,Jens-Christian Svenning,Dirk Nikolaus Karger*

Key words: 物种丰富度，空间尺度，深度学习，生物多样性，物种-面积关系

TL;DR: 论文提出了一种深度学习方法，利用采样理论和小规模生态调查来解决物种丰富度的空间尺度依赖性。该方法通过预测欧洲维管植物群落的物种丰富度，并通过独立数据集验证，提高了32%的预测准确性，同时揭示了物种丰富度和更替的空间模式。可解释AI技术进一步分析了驱动因素在不同尺度上的作用。

<details>
  <summary>Details</summary>

Main category: q-bio.PE

Motivation: 传统的生态调查难以全面记录跨空间尺度的生物多样性数据，阻碍了对物种丰富度动态的深入理解。因此，需要一种新方法来填补这一数据缺口。

Method: 利用采样理论和小规模生态调查数据，开发了一种深度学习模型，预测物种丰富度。模型在欧洲植物群落数据上进行验证，并使用解释性AI技术分析驱动因素。

Result: 模型将物种丰富度估计的准确性提高了32%，并提供了从平方米到数百平方公里范围内的物种丰富度和更替的空间模式。可解释AI技术揭示了物种丰富度驱动因素的尺度依赖性。

Conclusion: 该模型能够捕捉生物多样性的多尺度特性，为全球变化下的生物多样性评估和预测提供了可靠工具。

Abstract: The number of species within ecosystems is influenced not only by their
intrinsic characteristics but also by the spatial scale considered. As the
sampled area expands, species richness increases, a phenomenon described by the
species-area relationship (SAR). The accumulation dynamics of the SAR results
from a complex interplay of biotic and abiotic processes operating at various
spatial scales. However, the challenge of collecting exhaustive biodiversity
records across spatial scales has hindered a comprehensive understanding of
these dynamics. Here, we develop a deep learning approach that leverages
sampling theory and small-scale ecological surveys to spatially resolve the
scale-dependency of species richness. We demonstrate its performance by
predicting the species richness of vascular plant communities across Europe,
and evaluate the predictions against an independent dataset of plant community
inventories. Our model improves species richness estimates by 32\% and delivers
spatially explicit patterns of species richness and turnover for sampling areas
ranging from square meters to hundreds of square kilometers. Explainable AI
techniques further disentangle how drivers of species richness operate across
spatial scales. The ability of our model to represent the multi-scale nature of
biodiversity is essential to deliver robust biodiversity assessments and
forecasts under global change.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [231] [Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain](https://arxiv.org/abs/2507.06273)
*S P Shivakumar,Gunisetty Ramasekhar,P Nimmy,Sujesh Areekara,L Thanuja,T V Smitha,S Devanathan,Ganesh R Naik,K V Nagaraja*

Key words: 心血管疾病, 纳米流体, 药物输送, 传热率, 皮肤摩擦

TL;DR: 研究探讨了Casson-Maxwell纳米流体在狭窄动脉中的流动，分析了皮肤摩擦和传热率，发现其比Casson流体更适合靶向药物输送，并支持可持续发展目标。

<details>
  <summary>Details</summary>

Main category: physics.med-ph

Motivation: 传统心血管疾病治疗方法存在局限性，需要开发新型药物输送系统以实现靶向和高效治疗。

Method: 研究分析了Casson-Maxwell纳米流体在狭窄动脉中的流动，评估了皮肤摩擦、传热率和纳米颗粒体积分数的影响。

Result: Casson-Maxwell流体流速更低，适合延长药物停留时间。铜和氧化铝纳米颗粒增加传热率，银纳米颗粒则降低。皮肤摩擦系数对Maxwell参数变化敏感。

Conclusion: Casson-Maxwell流体在靶向药物输送中表现出优越性，支持可持续发展目标。

Abstract: The increasing complexity of cardiovascular diseases and limitations in
traditional healing methods mandate the invention of new drug delivery systems
that assure targeted, effective, and regulated treatments, contributing
directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable
medical technologies in healthcare. This study investigates the flow of a
Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities,
such as skin friction and heat transfer rate, are analysed in detail. The
Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids,
which indicates the improved residence time for efficient drug delivery. The
heat transfer rate shows an increase with higher volume fractions of copper and
aluminium oxide nanoparticles and a decrease with higher volume fractions of
silver nanoparticles. The skin friction coefficient decreases by 219% with a
unit increase in the Maxwell parameter, whereas it increases by 66.1% with a
unit rise in the Casson parameter. This work supports SDGs 4 and 17 by
fostering interdisciplinary learning and collaboration in fluid dynamics and
healthcare innovation. Additionally, the rate of heat flow was forecasted (with
an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation
training scheme under the influence of magneto-radiative, linear heat source
and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume
fractions. It is also observed that the drag coefficient is most sensitive to
the changes in the Maxwell parameter.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [232] [DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse](https://arxiv.org/abs/2507.06563)
*Jeanette Schofield,Shuyu Tian,Hoang Thanh Thanh Truong,Maximilian Heil*

Key words: 社交媒体,科学声明,数据增强,检索技术,CLEF竞赛

TL;DR: 该论文探讨了通过数据增强和检索技术验证社交媒体中科学声明的来源，并在CLEF 2025竞赛中取得了一定成绩。

<details>
  <summary>Details</summary>

Main category: cs.IR

Motivation: 社交媒体用户常提出科学声明而不引用来源，需验证这些声明的可靠性。

Method: 应用了6种数据增强技术、7种检索与重排序流程，并对双编码器进行微调。

Result: 在CLEF 2025竞赛中，MRR@5达到0.58，排名16/30，比基线（0.43）提高0.15。

Conclusion: 通过技术优化，社交媒体中的科学声明来源检索能力得到提升。

Abstract: Social media users often make scientific claims without citing where these
claims come from, generating a need to verify these claims. This paper details
work done by the DS@GT team for CLEF 2025 CheckThat! Lab Task 4b Scientific
Claim Source Retrieval which seeks to find relevant scientific papers based on
implicit references in tweets. Our team explored 6 different data augmentation
techniques, 7 different retrieval and reranking pipelines, and finetuned a
bi-encoder. Achieving an MRR@5 of 0.58, our team ranked 16th out of 30 teams
for the CLEF 2025 CheckThat! Lab Task 4b, and improvement of 0.15 over the BM25
baseline of 0.43. Our code is available on Github at
https://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b.

</details>


### [233] [GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models](https://arxiv.org/abs/2507.06507)
*Zhen Yang,Haitao Lin,Jiawei xue,Ziji Zhang*

Key words: 生成式推荐, 大语言模型, 推荐系统, 序列建模, 工业应用

TL;DR: 生成式推荐（GRs）在过去一年中取得了显著进展，尤其是在利用大语言模型（LLMs）的序列建模和推理能力提升推荐性能方面。本文对基于LLM的GRs进行了全面综述。

<details>
  <summary>Details</summary>

Main category: cs.IR

Motivation: 推动基于LLM的生成式推荐研究，探索其替代传统依赖复杂手工特征推荐系统的潜力。

Method: 综述基于LLM的GRs的通用基础、应用案例、工业场景应用考虑及未来发展方向。

Result: 提出了基于LLM的GRs的新范式，并总结其在工业场景中的应用要点和未来研究方向。

Conclusion: 本文为GR领域的进一步研究提供了参考，有望推动该领域的持续发展。

Abstract: In the past year, Generative Recommendations (GRs) have undergone substantial
advancements, especially in leveraging the powerful sequence modeling and
reasoning capabilities of Large Language Models (LLMs) to enhance overall
recommendation performance. LLM-based GRs are forming a new paradigm that is
distinctly different from discriminative recommendations, showing strong
potential to replace traditional recommendation systems heavily dependent on
complex hand-crafted features. In this paper, we provide a comprehensive survey
aimed at facilitating further research of LLM-based GRs. Initially, we outline
the general preliminaries and application cases of LLM-based GRs. Subsequently,
we introduce the main considerations when LLM-based GRs are applied in real
industrial scenarios. Finally, we explore promising directions for LLM-based
GRs. We hope that this survey contributes to the ongoing advancement of the GR
domain.

</details>


### [234] [Temporal Information Retrieval via Time-Specifier Model Merging](https://arxiv.org/abs/2507.06782)
*SeungYoon Han,Taeho Hwang,Sukmin Cho,Soyeong Jeong,Hoyun Song,Huije Lee,Jong C. Park*

Key words: 信息检索, 时间约束, 密集检索, 时间指示符, 模型合并

TL;DR: 论文提出了一种名为Time-Specifier Model Merging (TSM)的新方法，用于提升具有时间约束的信息检索性能，同时保持非时间查询的准确性。

<details>
  <summary>Details</summary>

Main category: cs.IR

Motivation: 当前密集检索方法在处理明确时间约束的查询时表现不佳，且现有时间信息检索方法容易导致灾难性遗忘，影响非时间查询的效果。

Method: TSM通过训练针对特定时间指示符的专用检索器，并将其合并为一个统一模型，以精确处理时间约束且不损害非时间检索。

Result: 实验表明，TSM在时间约束查询上表现显著提升，同时在非时间查询上保持强性能，优于基线方法。

Conclusion: TSM有效解决了时间信息检索中的灾难性遗忘问题，实现了时间与非时间查询的双赢。

Abstract: The rapid expansion of digital information and knowledge across structured
and unstructured sources has heightened the importance of Information Retrieval
(IR). While dense retrieval methods have substantially improved semantic
matching for general queries, they consistently underperform on queries with
explicit temporal constraints--often those containing numerical expressions and
time specifiers such as ``in 2015.'' Existing approaches to Temporal
Information Retrieval (TIR) improve temporal reasoning but often suffer from
catastrophic forgetting, leading to reduced performance on non-temporal
queries. To address this, we propose Time-Specifier Model Merging (TSM), a
novel method that enhances temporal retrieval while preserving accuracy on
non-temporal queries. TSM trains specialized retrievers for individual time
specifiers and merges them in to a unified model, enabling precise handling of
temporal constraints without compromising non-temporal retrieval. Extensive
experiments on both temporal and non-temporal datasets demonstrate that TSM
significantly improves performance on temporally constrained queries while
maintaining strong results on non-temporal queries, consistently outperforming
other baseline methods. Our code is available at
https://github.com/seungyoonee/TSM .

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [235] [From large-eddy simulations to deep learning: A U-net model for fast urban canopy flow predictions](https://arxiv.org/abs/2507.06533)
*Themistoklis Vargiemezis,Catherine Gorlé*

Key words: 城市风场,深度学习,U-Net,大涡模拟,空间注意力

TL;DR: 该研究提出了一种基于深度神经网络的快速准确预测城市风场的方法，显著降低了计算时间和成本。

<details>
  <summary>Details</summary>

Main category: physics.comp-ph

Motivation: 传统方法（如风洞实验和大涡模拟）成本高且耗时，需开发更高效的替代方案。

Method: 采用U-Net架构，训练于252种城市配置的LES数据，输入为二维建筑表示及其梯度，结合空间注意力模块。

Result: 模型在测试集上的平均相对误差为速度大小9.3%，湍流强度5.2%，计算时间显著减少。

Conclusion: 深度学习可为城市风场评估提供快速准确的解决方案。

Abstract: Accurate prediction of wind flow fields in urban canopies is crucial for
ensuring pedestrian comfort, safety, and sustainable urban design. Traditional
methods using wind tunnels and Computational Fluid Dynamics, such as Large-Eddy
Simulations (LES), are limited by high costs, computational demands, and time
requirements. This study presents a deep neural network (DNN) approach for fast
and accurate predictions of urban wind flow fields, reducing computation time
from an order of 10 hours on 32 CPUs for one LES evaluation to an order of 1
second on a single GPU using the DNN model. We employ a U-Net architecture
trained on LES data including 252 synthetic urban configurations at seven wind
directions ($0^{o}$ to $90^{o}$ in $15^{o}$ increments). The model predicts two
key quantities of interest: mean velocity magnitude and streamwise turbulence
intensity, at multiple heights within the urban canopy. The U-net uses 2D
building representations augmented with signed distance functions and their
gradients as inputs, forming a $256\times256\times9$ tensor. In addition, a
Spatial Attention Module is used for feature transfer through skip connections.
The loss function combines the root-mean-square error of predictions, their
gradient magnitudes, and L2 regularization. Model evaluation on 50 test cases
demonstrates high accuracy with an overall mean relative error of 9.3% for
velocity magnitude and 5.2% for turbulence intensity. This research shows the
potential of deep learning approaches to provide fast, accurate urban wind
assessments essential for creating comfortable and safe urban environments.
Code is available at https://github.com/tvarg/Urban-FlowUnet.git

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [236] [Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G](https://arxiv.org/abs/2507.06911)
*Michele Polese,Niloofar Mohamadi,Salvatore D'Oro,Tommaso Melodia*

Key words: AI-RAN, O-RAN, 边缘计算, 分布式AI, 编排与管理

TL;DR: 提出了一个融合O-RAN和AI-RAN的新架构，支持电信和AI工作负载的统一编排和管理，以实现边缘AI的商业化。

<details>
  <summary>Details</summary>

Main category: cs.NI

Motivation: 边缘AI应用的普及需要RAN设计的根本转变，从单纯利用AI进行网络优化，到主动支持分布式AI工作负载。

Method: 通过扩展O-RAN的模块化和云原生原则，提出AI-RAN Orchestrator和AI-RAN站点，实现资源和分配的集成管理。

Result: 支持灵活的部署选项，满足实时或批量处理的定时要求，并保持开放的标准化接口和多厂商互操作性。

Conclusion: 该架构为边缘AI的分布式部署提供了有效的编排和管理解决方案。

Abstract: The proliferation of data-intensive Artificial Intelligence (AI) applications
at the network edge demands a fundamental shift in RAN design, from merely
consuming AI for network optimization, to actively enabling distributed AI
workloads. This paradigm shift presents a significant opportunity for network
operators to monetize AI at the edge while leveraging existing infrastructure
investments. To realize this vision, this article presents a novel converged
O-RAN and AI-RAN architecture that unifies orchestration and management of both
telecommunications and AI workloads on shared infrastructure. The proposed
architecture extends the Open RAN principles of modularity, disaggregation, and
cloud-nativeness to support heterogeneous AI deployments. We introduce two key
architectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN
Service Management and Orchestration (SMO) to enable integrated resource and
allocation across RAN and AI workloads; and (ii) AI-RAN sites that provide
distributed edge AI platforms with real-time processing capabilities. The
proposed system supports flexible deployment options, allowing AI workloads to
be orchestrated with specific timing requirements (real-time or batch
processing) and geographic targeting. The proposed architecture addresses the
orchestration requirements for managing heterogeneous workloads at different
time scales while maintaining open, standardized interfaces and multi-vendor
interoperability.

</details>
